{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["9R_g1Ghv7cGE","PDP2cpaiZpPX","dsdvChbcvgp5","jtaV1q3SBHow","OBo0IKv80oM7","85Iqlq_c_lQv","0Fllcm_N50Zu","16CQTjZ77wci","JsT_qlx49FQT"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"29deef7cf95b41598aa1223bd98eb8c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd8e4defdd3c4797bcf8fb8130f514d7","IPY_MODEL_4bcfba648527436080b2e4dcda2acda3","IPY_MODEL_b0a9771772064dfda5841a28c1ff3b14"],"layout":"IPY_MODEL_a63b2e423f80405ebf7f9698a9a5f1ea"}},"bd8e4defdd3c4797bcf8fb8130f514d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3718cbbf56784ba6bb4f3a8833c2b849","placeholder":"​","style":"IPY_MODEL_1b101c4cfa0c4c759920e2f46274e721","value":"tokenizer_config.json: 100%"}},"4bcfba648527436080b2e4dcda2acda3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24c206659ca844019a4cd6635e5fd854","max":1618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a302f1613d5844e4a27d3d7c4a3af738","value":1618}},"b0a9771772064dfda5841a28c1ff3b14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fec1749bf3864c17a35fd16699a22ef1","placeholder":"​","style":"IPY_MODEL_3d6f009895914d78b0adca61bed33a1b","value":" 1.62k/1.62k [00:00&lt;00:00, 140kB/s]"}},"a63b2e423f80405ebf7f9698a9a5f1ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3718cbbf56784ba6bb4f3a8833c2b849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b101c4cfa0c4c759920e2f46274e721":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24c206659ca844019a4cd6635e5fd854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a302f1613d5844e4a27d3d7c4a3af738":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fec1749bf3864c17a35fd16699a22ef1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d6f009895914d78b0adca61bed33a1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d4005bc52214cfdbaae352f79412ec8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d8b72469ac941b48073bdc3b7b36c7e","IPY_MODEL_4e41f4b6b861495eb4a2b9867aa5d0a1","IPY_MODEL_e5b00feab3354260886cdbe109b71731"],"layout":"IPY_MODEL_74668726ab744d0a84415242e57e418f"}},"3d8b72469ac941b48073bdc3b7b36c7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_250e595a3626487d94b39e36b41dca12","placeholder":"​","style":"IPY_MODEL_5b5d8f9e8a9f4e579d74bcde1523d24c","value":"tokenizer.model: 100%"}},"4e41f4b6b861495eb4a2b9867aa5d0a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6b27de291844e7cb6cbff5930752d77","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3331e44d11a6429a870c2aa491481fe3","value":499723}},"e5b00feab3354260886cdbe109b71731":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf3cacd054ab406c9f9a0a1282b963eb","placeholder":"​","style":"IPY_MODEL_34ddf7f6bdc041ba832b1c797f2c18e7","value":" 500k/500k [00:00&lt;00:00, 19.6MB/s]"}},"74668726ab744d0a84415242e57e418f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"250e595a3626487d94b39e36b41dca12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b5d8f9e8a9f4e579d74bcde1523d24c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6b27de291844e7cb6cbff5930752d77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3331e44d11a6429a870c2aa491481fe3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf3cacd054ab406c9f9a0a1282b963eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34ddf7f6bdc041ba832b1c797f2c18e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8194b773a5b142cfb41b2ce454761b63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eee3e0d1be66458c8638080e738a7f87","IPY_MODEL_3a34a7f906c94e75af432fd6bce615f4","IPY_MODEL_dc583029106142b3a717ae008799286f"],"layout":"IPY_MODEL_6047dd12d0f9426e80bc25a5f0be7e81"}},"eee3e0d1be66458c8638080e738a7f87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46030e7c133b49f7ac81a293b7d4cd2a","placeholder":"​","style":"IPY_MODEL_b8f6ca98df744323bee9277a16178d25","value":"special_tokens_map.json: 100%"}},"3a34a7f906c94e75af432fd6bce615f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d978097a1c4d8fab7c15333d8e89ba","max":414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff2cedb6f3ee4a289ff88db6118a831e","value":414}},"dc583029106142b3a717ae008799286f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_993435010b7349c496175be876b17185","placeholder":"​","style":"IPY_MODEL_982dbe2805ed4bcc9a8de50529cd119f","value":" 414/414 [00:00&lt;00:00, 34.3kB/s]"}},"6047dd12d0f9426e80bc25a5f0be7e81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46030e7c133b49f7ac81a293b7d4cd2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f6ca98df744323bee9277a16178d25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65d978097a1c4d8fab7c15333d8e89ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff2cedb6f3ee4a289ff88db6118a831e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"993435010b7349c496175be876b17185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"982dbe2805ed4bcc9a8de50529cd119f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d95bcb9c706a42d9992fd0f67d233c50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29d128c812374e23a1c6196b5b52ce74","IPY_MODEL_a612012029b641eabb1cfa6e84b007e3","IPY_MODEL_0d82aa1263394c7f94de8f489dd708e7"],"layout":"IPY_MODEL_281ca4e8de454e129cdd17eff9fe2e7b"}},"29d128c812374e23a1c6196b5b52ce74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73221b3b5ed941469b21adad1bb3557e","placeholder":"​","style":"IPY_MODEL_cf7f72b6a1dd4363b1e0cb2de8d42870","value":"tokenizer.json: 100%"}},"a612012029b641eabb1cfa6e84b007e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cb4c06c377941b1b4a31fe733997cc8","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c17103b03fa84346901089477980551b","value":1842767}},"0d82aa1263394c7f94de8f489dd708e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13f95e55c5744b03b4d7b780e350134d","placeholder":"​","style":"IPY_MODEL_a59225fc7d354f119e8d25fe7e44f221","value":" 1.84M/1.84M [00:00&lt;00:00, 4.15MB/s]"}},"281ca4e8de454e129cdd17eff9fe2e7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73221b3b5ed941469b21adad1bb3557e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf7f72b6a1dd4363b1e0cb2de8d42870":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cb4c06c377941b1b4a31fe733997cc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c17103b03fa84346901089477980551b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"13f95e55c5744b03b4d7b780e350134d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59225fc7d354f119e8d25fe7e44f221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0378c4b404bd49dcb71a53db7aab2152":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe502fad4c504cdcb976f7a00d173d79","IPY_MODEL_cfd2b448f48648d887eab356f282e64b","IPY_MODEL_39f0c3a0c4f546a0913af979343b1be0"],"layout":"IPY_MODEL_70c35a7c9ca54ad59ac0caedbabdd05a"}},"fe502fad4c504cdcb976f7a00d173d79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78133963ca46481cb540b8f39f2f1f2b","placeholder":"​","style":"IPY_MODEL_8b1cb998460a44bdbe190d7fe0e72ce5","value":"config.json: 100%"}},"cfd2b448f48648d887eab356f282e64b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0945eac6592c437cbaa6f1cdb493bf45","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_063d48348eb44ee4ade7ad7805f4fd89","value":614}},"39f0c3a0c4f546a0913af979343b1be0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ac6fbab45f8411b907ace4897cfa43e","placeholder":"​","style":"IPY_MODEL_b6978d275dc4454c8b82b36732ceb679","value":" 614/614 [00:00&lt;00:00, 55.5kB/s]"}},"70c35a7c9ca54ad59ac0caedbabdd05a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78133963ca46481cb540b8f39f2f1f2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1cb998460a44bdbe190d7fe0e72ce5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0945eac6592c437cbaa6f1cdb493bf45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063d48348eb44ee4ade7ad7805f4fd89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ac6fbab45f8411b907ace4897cfa43e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6978d275dc4454c8b82b36732ceb679":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7abbcd2d58404cef8841ee2dff6fd8b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68905067168a403e90247614b8ba7f6d","IPY_MODEL_27e4b4344e384ea28a5faeec9ce326de","IPY_MODEL_dd8beb4fa06f41f4bbaced93658edac0"],"layout":"IPY_MODEL_77f6785bdc5b4d66ad8b9b7628e14006"}},"68905067168a403e90247614b8ba7f6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd256ebda0554809a5ced6382268127b","placeholder":"​","style":"IPY_MODEL_1e4552d1d61f462dbe9d78effaf6f866","value":"model.safetensors.index.json: 100%"}},"27e4b4344e384ea28a5faeec9ce326de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2700c3b398ce491cb8943ac2ffb92123","max":26788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b08f4fa0513405f9bef85a74ccd3e96","value":26788}},"dd8beb4fa06f41f4bbaced93658edac0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_368b855f66484c11a162b3a938d2fa16","placeholder":"​","style":"IPY_MODEL_8794552d1f95440998496e4b9ccce31b","value":" 26.8k/26.8k [00:00&lt;00:00, 2.33MB/s]"}},"77f6785bdc5b4d66ad8b9b7628e14006":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd256ebda0554809a5ced6382268127b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4552d1d61f462dbe9d78effaf6f866":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2700c3b398ce491cb8943ac2ffb92123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b08f4fa0513405f9bef85a74ccd3e96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"368b855f66484c11a162b3a938d2fa16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8794552d1f95440998496e4b9ccce31b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6daffd25e26485a8efdc924629c4553":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ded32eba995c4f9a9538b4c218842b69","IPY_MODEL_85304ae68eca47c0b8e74cf109ce2907","IPY_MODEL_3edc03b904284315b0f51c3a9463dc6f"],"layout":"IPY_MODEL_2640799d072740b8a28349ab38694188"}},"ded32eba995c4f9a9538b4c218842b69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_651eb6cd7c6144df8ad9fa197f1dc337","placeholder":"​","style":"IPY_MODEL_c8a1d4f67a2e40059c75556b272e62b8","value":"Downloading shards: 100%"}},"85304ae68eca47c0b8e74cf109ce2907":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_458556b1152846459ca13d5924063ac1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58538933a19a464ca63f1fdaaea55e29","value":2}},"3edc03b904284315b0f51c3a9463dc6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b481a30e8844db19486ee077dacd6ba","placeholder":"​","style":"IPY_MODEL_118c1bfc6cb949209f63e473ccb9502d","value":" 2/2 [00:35&lt;00:00, 16.32s/it]"}},"2640799d072740b8a28349ab38694188":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651eb6cd7c6144df8ad9fa197f1dc337":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8a1d4f67a2e40059c75556b272e62b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"458556b1152846459ca13d5924063ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58538933a19a464ca63f1fdaaea55e29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b481a30e8844db19486ee077dacd6ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"118c1bfc6cb949209f63e473ccb9502d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"245b79f1f86443249fef990e39a44bb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38d095eafa90452d8dd9a01f479b9989","IPY_MODEL_693957842d0844d382db955b556a7a4d","IPY_MODEL_21b823ffd76147f1b6b4e4b7c81941e8"],"layout":"IPY_MODEL_2416b6a757d04fb28c689e4194a96cea"}},"38d095eafa90452d8dd9a01f479b9989":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6bed829489a43cf8f9dabdafb5c328d","placeholder":"​","style":"IPY_MODEL_e596b6e9ec9742049968a863e5949464","value":"model-00001-of-00002.safetensors: 100%"}},"693957842d0844d382db955b556a7a4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea4789bdd48e4f9988b5a1fc3efd2858","max":9976576152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b442869080f441f81ba33fbf1855ac0","value":9976576152}},"21b823ffd76147f1b6b4e4b7c81941e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3edcefd85f8643e5a26eeba73f11549f","placeholder":"​","style":"IPY_MODEL_945a4135ba5e4c75ac96d5ae614dbcaa","value":" 9.98G/9.98G [00:27&lt;00:00, 393MB/s]"}},"2416b6a757d04fb28c689e4194a96cea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6bed829489a43cf8f9dabdafb5c328d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e596b6e9ec9742049968a863e5949464":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea4789bdd48e4f9988b5a1fc3efd2858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b442869080f441f81ba33fbf1855ac0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3edcefd85f8643e5a26eeba73f11549f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"945a4135ba5e4c75ac96d5ae614dbcaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a3cbcb930754a839ce69e65e7586caf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ab2659036f1430b9d0e4220cbf1e958","IPY_MODEL_9db4adbef0e8425d8eed184f344c78d4","IPY_MODEL_869694e8edf046f2bf296f55076588c7"],"layout":"IPY_MODEL_d6c159cf88b3473095843b4d82699c04"}},"7ab2659036f1430b9d0e4220cbf1e958":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e25a20fad442c58ec81c5159ec3a53","placeholder":"​","style":"IPY_MODEL_e3783cb3859043969710baad8b197744","value":"model-00002-of-00002.safetensors: 100%"}},"9db4adbef0e8425d8eed184f344c78d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_805b1bd3000e461484494f0dcbab40ea","max":3500296424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8129629cc3964565bf0d37112d280671","value":3500296424}},"869694e8edf046f2bf296f55076588c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d99535dd47045f4afea00a69a9851e4","placeholder":"​","style":"IPY_MODEL_e20c0ca900b24b5a81d58bd81a0f39a2","value":" 3.50G/3.50G [00:08&lt;00:00, 315MB/s]"}},"d6c159cf88b3473095843b4d82699c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e25a20fad442c58ec81c5159ec3a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3783cb3859043969710baad8b197744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"805b1bd3000e461484494f0dcbab40ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8129629cc3964565bf0d37112d280671":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d99535dd47045f4afea00a69a9851e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e20c0ca900b24b5a81d58bd81a0f39a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91f85faf8e6a4305952d752a186decb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92f3a3d71b1e4633ad63bf0f3ea2e665","IPY_MODEL_d8c2a368a6cc42029fe2067d5bfa5292","IPY_MODEL_1d82b9e985014241aa9d50fc7b9da16a"],"layout":"IPY_MODEL_b7726cc5fa5d4f9388439828b38fb1d7"}},"92f3a3d71b1e4633ad63bf0f3ea2e665":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b726d341f4d14907a70ddf419e9c2de5","placeholder":"​","style":"IPY_MODEL_d1bf97a73d7d4b62bcbb85bf756b7300","value":"Loading checkpoint shards: 100%"}},"d8c2a368a6cc42029fe2067d5bfa5292":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a259b9487474814a509b2eda528f69f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_642b8a6ed99f40599db828e031b49695","value":2}},"1d82b9e985014241aa9d50fc7b9da16a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b855bdc2b8754a38b941f2874cc3f8d3","placeholder":"​","style":"IPY_MODEL_9c7e5d7272b84e98aa51bdf4d420618a","value":" 2/2 [00:04&lt;00:00,  1.89s/it]"}},"b7726cc5fa5d4f9388439828b38fb1d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b726d341f4d14907a70ddf419e9c2de5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1bf97a73d7d4b62bcbb85bf756b7300":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a259b9487474814a509b2eda528f69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642b8a6ed99f40599db828e031b49695":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b855bdc2b8754a38b941f2874cc3f8d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c7e5d7272b84e98aa51bdf4d420618a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d53db7bf33c14011bf6a5ec65661a94a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_558f10760ebf4652bd55db62557f5fca","IPY_MODEL_b0b464767a414810866c0acbff406fd0","IPY_MODEL_aa5ba36efe0b4ae3af9c6ccc976d5260"],"layout":"IPY_MODEL_5c0c45abde6d4dd0aa9790b2e3896739"}},"558f10760ebf4652bd55db62557f5fca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5916ed46c3e74b39b29abd4e355501b5","placeholder":"​","style":"IPY_MODEL_e8e77a1f22e447ef9a6eacc95cd5bf4f","value":"generation_config.json: 100%"}},"b0b464767a414810866c0acbff406fd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd945ca421ec45d193ae7846f057f13d","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_878b50a30a4244e3b128bce559a043d0","value":188}},"aa5ba36efe0b4ae3af9c6ccc976d5260":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a74b57f0844fd9bb965379639e434c","placeholder":"​","style":"IPY_MODEL_21b4c6d50b004d7da8cc5eeddddd0256","value":" 188/188 [00:00&lt;00:00, 16.3kB/s]"}},"5c0c45abde6d4dd0aa9790b2e3896739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5916ed46c3e74b39b29abd4e355501b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8e77a1f22e447ef9a6eacc95cd5bf4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd945ca421ec45d193ae7846f057f13d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"878b50a30a4244e3b128bce559a043d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79a74b57f0844fd9bb965379639e434c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21b4c6d50b004d7da8cc5eeddddd0256":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"code","source":["save_files = True"],"metadata":{"id":"KSKP_OsTDki6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6b1n2tvIAiD"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuhzYxbsIAiE"},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer #, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFMTUcQiIAiF"},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717943664638,"user_tz":-60,"elapsed":2831,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"084b5afd-886f-4259-ca29-2596e3d8217e","id":"F8TXMRL3CoPd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 967, done.\u001b[K\n","remote: Counting objects: 100% (433/433), done.\u001b[K\n","remote: Compressing objects: 100% (262/262), done.\u001b[K\n","remote: Total 967 (delta 254), reused 335 (delta 160), pack-reused 534\u001b[K\n","Receiving objects: 100% (967/967), 17.66 MiB | 12.13 MiB/s, done.\n","Resolving deltas: 100% (617/617), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","# don't improt this\n","# # from dataset import Dataset\n","\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["import random\n"],"metadata":{"id":"jsJmCq-C2Zu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a dict whose values are tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_longer(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text\n","        # 'text': model.to_string(tokens)[0]\n","        }\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    # for i, tok in enumerate(tokens):\n","    #     prompt_dict['S'+str(i)] = model.to_string(tok)\n","\n","    # prompt_dict = {\n","    #     'corr': '4',\n","    #     'incorr': '3',\n","    #     'text': model.to_string(tokens)[0]\n","    # }\n","    # # list_tokens = tokenizer.tokenize('1 2 3 ')\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i, tok_as_str in enumerate(tokens_as_strs):\n","    #     if tok_as_str == '▁':\n","    #         prompt_dict['S'+str(i)] = ' '\n","    #     else:\n","    #         prompt_dict['S'+str(i)] = tok_as_str\n","    prompts_list.append(prompt_dict)\n","    return prompts_list"],"metadata":{"id":"VZKVG778QYyn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDP2cpaiZpPX"},"source":["# Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGCiZUPpJUsD"},"outputs":[],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CocJpgjsf_M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717943680984,"user_tz":-60,"elapsed":11877,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"64965b06-c65c-454d-8583-14628c87d424"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLgpia0tI6O8","colab":{"base_uri":"https://localhost:8080/","height":493,"referenced_widgets":["29deef7cf95b41598aa1223bd98eb8c7","bd8e4defdd3c4797bcf8fb8130f514d7","4bcfba648527436080b2e4dcda2acda3","b0a9771772064dfda5841a28c1ff3b14","a63b2e423f80405ebf7f9698a9a5f1ea","3718cbbf56784ba6bb4f3a8833c2b849","1b101c4cfa0c4c759920e2f46274e721","24c206659ca844019a4cd6635e5fd854","a302f1613d5844e4a27d3d7c4a3af738","fec1749bf3864c17a35fd16699a22ef1","3d6f009895914d78b0adca61bed33a1b","7d4005bc52214cfdbaae352f79412ec8","3d8b72469ac941b48073bdc3b7b36c7e","4e41f4b6b861495eb4a2b9867aa5d0a1","e5b00feab3354260886cdbe109b71731","74668726ab744d0a84415242e57e418f","250e595a3626487d94b39e36b41dca12","5b5d8f9e8a9f4e579d74bcde1523d24c","f6b27de291844e7cb6cbff5930752d77","3331e44d11a6429a870c2aa491481fe3","cf3cacd054ab406c9f9a0a1282b963eb","34ddf7f6bdc041ba832b1c797f2c18e7","8194b773a5b142cfb41b2ce454761b63","eee3e0d1be66458c8638080e738a7f87","3a34a7f906c94e75af432fd6bce615f4","dc583029106142b3a717ae008799286f","6047dd12d0f9426e80bc25a5f0be7e81","46030e7c133b49f7ac81a293b7d4cd2a","b8f6ca98df744323bee9277a16178d25","65d978097a1c4d8fab7c15333d8e89ba","ff2cedb6f3ee4a289ff88db6118a831e","993435010b7349c496175be876b17185","982dbe2805ed4bcc9a8de50529cd119f","d95bcb9c706a42d9992fd0f67d233c50","29d128c812374e23a1c6196b5b52ce74","a612012029b641eabb1cfa6e84b007e3","0d82aa1263394c7f94de8f489dd708e7","281ca4e8de454e129cdd17eff9fe2e7b","73221b3b5ed941469b21adad1bb3557e","cf7f72b6a1dd4363b1e0cb2de8d42870","4cb4c06c377941b1b4a31fe733997cc8","c17103b03fa84346901089477980551b","13f95e55c5744b03b4d7b780e350134d","a59225fc7d354f119e8d25fe7e44f221","0378c4b404bd49dcb71a53db7aab2152","fe502fad4c504cdcb976f7a00d173d79","cfd2b448f48648d887eab356f282e64b","39f0c3a0c4f546a0913af979343b1be0","70c35a7c9ca54ad59ac0caedbabdd05a","78133963ca46481cb540b8f39f2f1f2b","8b1cb998460a44bdbe190d7fe0e72ce5","0945eac6592c437cbaa6f1cdb493bf45","063d48348eb44ee4ade7ad7805f4fd89","1ac6fbab45f8411b907ace4897cfa43e","b6978d275dc4454c8b82b36732ceb679","7abbcd2d58404cef8841ee2dff6fd8b8","68905067168a403e90247614b8ba7f6d","27e4b4344e384ea28a5faeec9ce326de","dd8beb4fa06f41f4bbaced93658edac0","77f6785bdc5b4d66ad8b9b7628e14006","cd256ebda0554809a5ced6382268127b","1e4552d1d61f462dbe9d78effaf6f866","2700c3b398ce491cb8943ac2ffb92123","7b08f4fa0513405f9bef85a74ccd3e96","368b855f66484c11a162b3a938d2fa16","8794552d1f95440998496e4b9ccce31b","d6daffd25e26485a8efdc924629c4553","ded32eba995c4f9a9538b4c218842b69","85304ae68eca47c0b8e74cf109ce2907","3edc03b904284315b0f51c3a9463dc6f","2640799d072740b8a28349ab38694188","651eb6cd7c6144df8ad9fa197f1dc337","c8a1d4f67a2e40059c75556b272e62b8","458556b1152846459ca13d5924063ac1","58538933a19a464ca63f1fdaaea55e29","2b481a30e8844db19486ee077dacd6ba","118c1bfc6cb949209f63e473ccb9502d","245b79f1f86443249fef990e39a44bb8","38d095eafa90452d8dd9a01f479b9989","693957842d0844d382db955b556a7a4d","21b823ffd76147f1b6b4e4b7c81941e8","2416b6a757d04fb28c689e4194a96cea","e6bed829489a43cf8f9dabdafb5c328d","e596b6e9ec9742049968a863e5949464","ea4789bdd48e4f9988b5a1fc3efd2858","3b442869080f441f81ba33fbf1855ac0","3edcefd85f8643e5a26eeba73f11549f","945a4135ba5e4c75ac96d5ae614dbcaa","9a3cbcb930754a839ce69e65e7586caf","7ab2659036f1430b9d0e4220cbf1e958","9db4adbef0e8425d8eed184f344c78d4","869694e8edf046f2bf296f55076588c7","d6c159cf88b3473095843b4d82699c04","30e25a20fad442c58ec81c5159ec3a53","e3783cb3859043969710baad8b197744","805b1bd3000e461484494f0dcbab40ea","8129629cc3964565bf0d37112d280671","8d99535dd47045f4afea00a69a9851e4","e20c0ca900b24b5a81d58bd81a0f39a2","91f85faf8e6a4305952d752a186decb9","92f3a3d71b1e4633ad63bf0f3ea2e665","d8c2a368a6cc42029fe2067d5bfa5292","1d82b9e985014241aa9d50fc7b9da16a","b7726cc5fa5d4f9388439828b38fb1d7","b726d341f4d14907a70ddf419e9c2de5","d1bf97a73d7d4b62bcbb85bf756b7300","2a259b9487474814a509b2eda528f69f","642b8a6ed99f40599db828e031b49695","b855bdc2b8754a38b941f2874cc3f8d3","9c7e5d7272b84e98aa51bdf4d420618a","d53db7bf33c14011bf6a5ec65661a94a","558f10760ebf4652bd55db62557f5fca","b0b464767a414810866c0acbff406fd0","aa5ba36efe0b4ae3af9c6ccc976d5260","5c0c45abde6d4dd0aa9790b2e3896739","5916ed46c3e74b39b29abd4e355501b5","e8e77a1f22e447ef9a6eacc95cd5bf4f","cd945ca421ec45d193ae7846f057f13d","878b50a30a4244e3b128bce559a043d0","79a74b57f0844fd9bb965379639e434c","21b4c6d50b004d7da8cc5eeddddd0256"]},"executionInfo":{"status":"ok","timestamp":1717943727614,"user_tz":-60,"elapsed":46774,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"57c36975-b29f-4f58-cd57-459e142de77c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29deef7cf95b41598aa1223bd98eb8c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d4005bc52214cfdbaae352f79412ec8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8194b773a5b142cfb41b2ce454761b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95bcb9c706a42d9992fd0f67d233c50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0378c4b404bd49dcb71a53db7aab2152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7abbcd2d58404cef8841ee2dff6fd8b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6daffd25e26485a8efdc924629c4553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245b79f1f86443249fef990e39a44bb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3cbcb930754a839ce69e65e7586caf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91f85faf8e6a4305952d752a186decb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53db7bf33c14011bf6a5ec65661a94a"}},"metadata":{}}],"source":["LLAMA_2_7B_CHAT_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n","\n","tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH)\n","# tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH, use_fast= False, add_prefix_space= False)\n","hf_model = LlamaForCausalLM.from_pretrained(LLAMA_2_7B_CHAT_PATH, low_cpu_mem_usage=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rtZ2e3sMY5S"},"outputs":[],"source":["import transformer_lens.utils as utils\n","from transformer_lens.hook_points import HookPoint\n","from transformer_lens import HookedTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUnSHvA-Myx8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717943758099,"user_tz":-60,"elapsed":30602,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"225a406a-6231-43b2-8702-3a801e42018a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n","Moving model to device:  cuda\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    LLAMA_2_7B_CHAT_PATH,\n","    hf_model = hf_model,\n","    tokenizer = tokenizer,\n","    device = \"cpu\",\n","    fold_ln = False,\n","    center_writing_weights = False,\n","    center_unembed = False,\n",")\n","\n","del hf_model\n","\n","model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["# new ablation functions"],"metadata":{"id":"dsdvChbcvgp5"}},{"cell_type":"code","source":["def get_heads_actv_mean(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Output: The mean activations of a head's output\n","    '''\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    # for layer in range(model.cfg.n_layers):\n","    #     z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","    #     for template_group in means_dataset.groups:\n","    #         z_for_this_template = z_for_this_layer[template_group]\n","    #         z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","    #         if z_means_for_this_template.shape[0] == 5:\n","    #             pdb.set_trace()\n","    #         means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means"],"metadata":{"id":"6KlWYoEy72Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def mask_circ_heads(\n","#     means_dataset: Dataset,\n","#     model: HookedTransformer,\n","#     circuit: Dict[str, List[Tuple[int, int]]],\n","#     seq_pos_to_keep: Dict[str, str],\n","# ) -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","#     '''\n","#     Output: for each layer, a mask of circuit components that should not be ablated\n","#     '''\n","#     heads_and_posns_to_keep = {}\n","#     batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","#     for layer in range(model.cfg.n_layers):\n","\n","#         mask = t.zeros(size=(batch, seq, n_heads))\n","\n","#         for (head_type, head_list) in circuit.items():\n","#             seq_pos = seq_pos_to_keep[head_type]\n","#             # if seq_pos == 'S7':\n","#             #     pdb.set_trace()\n","#             indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","#             for (layer_idx, head_idx) in head_list:\n","#                 if layer_idx == layer:\n","#                     # if indices.item() == 7:\n","#                     #     pdb.set_trace()\n","#                     mask[:, indices, head_idx] = 1\n","#                     # mask[:, :, head_idx] = 1  # keep L.H at all pos\n","\n","#         heads_and_posns_to_keep[layer] = mask.bool()\n","#     # pdb.set_trace()\n","#     return heads_and_posns_to_keep"],"metadata":{"id":"bFDQMOt9CyVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mask_circ_heads(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Output: for each layer, a mask of circuit components that should not be ablated\n","    '''\n","    heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","    batch, seq, n_heads = len(means_dataset), len(circuit.keys()), model.cfg.n_heads\n","    # print(seq)\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    # mask[:, indices, head_idx] = 1\n","                    mask[:, :, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep"],"metadata":{"id":"E1boH1469_HI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def hook_func_mask_head(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    # components_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    # means: Float[Tensor, \"layer batch seq head d_head\"],\n","    circuit: Dict[str, List[Tuple[int, int]]],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Use this to not mask components\n","    '''\n","    # mask_for_this_layer = components_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","    # z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    ###\n","    # heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = z.shape[0], z.shape[1], model.cfg.n_heads  # components_to_keep[0].shape[0] is batch\n","\n","    # for layer in range(model.cfg.n_layers):\n","\n","    #     mask = t.zeros(size=(batch, seq, n_heads))\n","\n","    #     for (head_type, head_list) in circuit.items():\n","    #         # seq_pos = seq_pos_to_keep[head_type]\n","    #         # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","    #         for (layer_idx, head_idx) in head_list:\n","    #             if layer_idx == layer:\n","    #                 # mask[:, indices, head_idx] = 1\n","    #                 mask[:, :, head_idx] = 1\n","\n","    #     heads_and_posns_to_keep[layer] = mask.bool()\n","    ###\n","    mask_for_this_layer = t.zeros(size=(z.shape[0], z.shape[1], z.shape[2]))\n","    for (head_type, head_list) in circuit.items():\n","        # seq_pos = seq_pos_to_keep[head_type]\n","        # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","        for (layer_idx, head_idx) in head_list:\n","            if layer_idx == hook.layer():\n","                # mask[:, indices, head_idx] = 1\n","                mask_for_this_layer[:, :, head_idx] = 1\n","\n","    mask_for_this_layer = mask_for_this_layer.bool()\n","    mask_for_this_layer = mask_for_this_layer.unsqueeze(-1).to(z.device)  # d_model is 1; then is broadcast in where\n","\n","    z = t.where(mask_for_this_layer, z, 0)\n","\n","    return z"],"metadata":{"id":"KdxeNJ5C9tHx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_ablation_hook_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Ablate the model, except as components and positions to keep\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","    means = get_heads_actv_mean(means_dataset, model)\n","    components_to_keep = mask_circ_heads(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=circuit,\n","    )\n","\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","    return model"],"metadata":{"id":"dg3XuWScAVvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from dataset import Dataset\n","from transformer_lens import HookedTransformer, utils\n","from transformer_lens.hook_points import HookPoint\n","import einops\n","from functools import partial\n","import torch as t\n","from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool\n","\n","# from head_ablation_fns import *\n","# from mlp_ablation_fns import *\n","\n","def add_ablation_hook_MLP_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    heads_lst, mlp_lst,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        CIRCUIT['S'+str(i)] = heads_lst\n","        # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","        # if i == num_pos - 1:\n","        #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        # else:\n","        SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = get_heads_actv_mean(means_dataset, model)\n","    # Convert this into a boolean map\n","    components_to_keep = mask_circ_heads(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=CIRCUIT,\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    # if all_entries_true(components_to_keep) == False:\n","    #     pdb.set_trace()\n","    ########################\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","    # # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    # num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    # for i in range(num_pos ):\n","    #     CIRCUIT['S'+str(i)] = mlp_lst\n","    #     # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","    #     # if i == num_pos - 1:\n","    #     #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","    #     # else:\n","    #     SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    # # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    # means = get_MLPs_actv_mean(means_dataset, model)\n","\n","    # # Convert this into a boolean map\n","    # components_to_keep = mask_circ_MLPs(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # # Get a hook function which will patch in the mean z values for each head, at\n","    # # all positions which aren't important for the circuit\n","    # hook_fn = partial(\n","    #     hook_func_mask_mlp_out,\n","    #     components_to_keep=components_to_keep,\n","    #     means=means\n","    # )\n","\n","    # model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"6ILjxwH9YUYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def all_entries_true(tensor_dict):\n","    for key, tensor in tensor_dict.items():\n","        if not torch.all(tensor).item():\n","            return False\n","    return True"],"metadata":{"id":"u-YuOEDieLgE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ablation fns mult tok answers"],"metadata":{"id":"jtaV1q3SBHow"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    # tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","        # if next_char == '':\n","        #     next_char = ' '\n","        # clean_text = clean_text + next_char\n","        # tokens = model.to_tokens(clean_text).to(device)\n","    return corr_ans_tokLen"],"metadata":{"id":"WgbtY5fFPb71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    for i in range(corr_ans_tokLen):\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        if i == corr_ans_tokLen - 1:\n","            print(model.to_string(tokens))\n","            # print(f\"Sequence so far: {clean_text}\")\n","            # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","        # pos_dict = {}\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())"],"metadata":{"id":"lp4MyZ52cUTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to randomly choose 50 pairs ensuring less than 10 overlap with heads_of_circ\n","def choose_heads_to_remove(filtered_pairs, heads_of_circ, num_pairs=50, max_overlap=10):\n","    while True:\n","        head_to_remove = random.sample(filtered_pairs, num_pairs)\n","        overlap_count = len([head for head in head_to_remove if head in heads_of_circ])\n","        if overlap_count < max_overlap:\n","            return head_to_remove"],"metadata":{"id":"S8KYb2BBSm-G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define circs"],"metadata":{"id":"JPKiYdKTAMni"}},{"cell_type":"code","source":["# from Llama2_numerals_1to10.ipynb\n","nums_1to9 = [(0, 2), (0, 5), (0, 6), (0, 15), (1, 15), (1, 28), (2, 13), (2, 24), (3, 24), (4, 3), (4, 16), (5, 11), (5, 13), (5, 15), (5, 16), (5, 23), (5, 25), (5, 27), (6, 11), (6, 14), (6, 20), (6, 23), (6, 24), (6, 26), (6, 28), (6, 30), (6, 31), (7, 0), (7, 13), (7, 21), (7, 30), (8, 0), (8, 2), (8, 12), (8, 15), (8, 26), (8, 27), (8, 30), (8, 31), (9, 15), (9, 16), (9, 23), (9, 26), (9, 27), (9, 29), (9, 31), (10, 1), (10, 13), (10, 18), (10, 23), (10, 29), (11, 7), (11, 8), (11, 9), (11, 17), (11, 18), (11, 25), (11, 28), (12, 18), (12, 19), (12, 23), (12, 27), (13, 6), (13, 11), (13, 20), (14, 18), (14, 19), (14, 20), (14, 21), (16, 0), (18, 19), (18, 21), (18, 25), (18, 26), (18, 31), (19, 28), (20, 17), (21, 0), (21, 2), (22, 18), (22, 20), (22, 25), (23, 27), (26, 2)]\n","len(nums_1to9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YId1M9rIroEe","executionInfo":{"status":"ok","timestamp":1717943758101,"user_tz":-60,"elapsed":263,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d0100b7b-653c-435c-f28e-9d490df27af3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["84"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# nw_circ = [(0, 1), (0, 4), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (1, 16), (1, 24), (1, 27), (1, 28), (2, 2), (2, 5), (2, 8), (2, 24), (2, 30), (3, 7), (3, 14), (3, 19), (3, 23), (4, 3), (5, 16), (5, 25), (6, 11), (6, 14), (7, 0), (7, 30), (8, 0), (8, 2), (8, 3), (8, 4), (8, 6), (8, 21), (8, 31), (9, 1), (9, 3), (9, 7), (9, 11), (9, 29), (9, 31), (10, 13), (10, 18), (10, 23), (10, 24), (10, 25), (10, 27), (11, 18), (11, 28), (12, 18), (12, 26), (13, 11), (13, 17), (13, 18), (13, 19), (13, 20), (13, 21), (13, 23), (14, 7), (14, 14), (15, 25), (15, 28), (16, 0), (16, 12), (16, 14), (16, 15), (16, 16), (16, 19), (16, 24), (16, 29), (17, 17), (17, 23), (17, 31), (18, 31), (19, 12), (20, 17), (27, 20), (27, 25), (27, 27), (27, 31), (28, 5), (29, 5)]\n","# in order from most impt to least based on how much changes perf when ablated\n","nw_circ = [(20, 17), (5, 25), (16, 0), (29, 5), (3, 19), (6, 11), (15, 25), (8, 0), (16, 24), (8, 4), (7, 0), (6, 14), (16, 29), (5, 16), (12, 26), (4, 3), (3, 7), (7, 30), (11, 28), (28, 5), (17, 31), (13, 11), (13, 20), (12, 18), (1, 27), (10, 13), (18, 31), (8, 6), (9, 1), (0, 4), (2, 2), (9, 11), (19, 12), (1, 16), (13, 17), (9, 7), (11, 18), (2, 24), (10, 18), (9, 31), (9, 29), (2, 30), (2, 5), (1, 24), (2, 8), (15, 28), (27, 31), (16, 14), (3, 23), (3, 14), (10, 23), (27, 20), (8, 3), (14, 7), (14, 14), (16, 15), (8, 2), (17, 17), (0, 1), (10, 27), (16, 19), (0, 8), (0, 12), (1, 28), (0, 11), (17, 23), (0, 10), (0, 6), (13, 19), (8, 31), (10, 24), (16, 12), (13, 23), (13, 21), (27, 27), (9, 3), (27, 25), (16, 16), (8, 21), (0, 7), (13, 18), (10, 25)]\n","len(nw_circ)"],"metadata":{"id":"wzTeD-OvAOwC","executionInfo":{"status":"ok","timestamp":1717943758101,"user_tz":-60,"elapsed":262,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f74a140-cc35-4f24-ba36-4e0f87d60a6f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["82"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# impt_months_heads = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","months_circ = [(20, 17), (6, 11), (16, 0), (5, 15), (17, 11), (23, 16), (5, 25), (7, 0), (26, 14), (6, 14), (12, 22), (8, 4), (12, 15), (16, 29), (15, 25), (5, 16), (18, 31), (14, 7), (11, 18), (4, 12), (3, 19), (12, 2), (11, 28), (4, 3), (18, 9), (8, 14), (12, 3), (11, 2), (10, 13), (4, 16), (1, 22), (11, 16), (3, 15), (13, 31), (2, 4), (2, 16), (8, 13), (0, 13), (8, 15), (12, 28), (1, 5), (0, 4), (0, 25), (3, 24), (13, 11), (1, 24), (8, 16), (13, 8), (3, 26), (0, 6), (3, 23), (1, 3), (14, 3), (8, 19), (8, 12), (14, 2), (8, 5), (1, 28), (8, 20), (2, 30), (8, 6), (10, 1), (13, 20), (19, 27)]\n","len(months_circ)"],"metadata":{"id":"a8zrblGeHiND","executionInfo":{"status":"ok","timestamp":1717943758101,"user_tz":-60,"elapsed":261,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"64b499ec-0087-4bd3-9432-7942cf1ea70c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["intersect_all = list(set(nums_1to9) & set(nw_circ) & set(months_circ))\n","len(intersect_all)"],"metadata":{"id":"e2XFugMsd3BY","executionInfo":{"status":"ok","timestamp":1717943758101,"user_tz":-60,"elapsed":260,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1fdf4ab-ade1-41b3-92dc-fdeec36767c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["union_all = list(set(nums_1to9) | set(nw_circ) | set(months_circ))\n","len(union_all)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2CL3XqQ4E7R","executionInfo":{"status":"ok","timestamp":1717943758101,"user_tz":-60,"elapsed":260,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6185822c-d2c4-4fbc-a01d-71a34610b959"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["172"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["# test prompts"],"metadata":{"id":"oOoMYJ14bZcb"}},{"cell_type":"code","source":["instruction = \"Answer yes or no. \"\n","clean_text =  \"Is 16 greater than 11? Answer: \"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKHD7iN1CnWd","executionInfo":{"status":"ok","timestamp":1717943838166,"user_tz":-60,"elapsed":1065,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6f351170-3f75-447b-a192-70ae5fbf47d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Answer yes or no.Is 16 greater than 11? Answer:  Yes.']\n"]}]},{"cell_type":"code","source":["instruction = \"Be concise. \"\n","clean_text =  \"What number is greater than 11? Answer: \"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJwhAlOvbvd2","executionInfo":{"status":"ok","timestamp":1717943886636,"user_tz":-60,"elapsed":1643,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6bf454b9-8c0b-40bc-e822-1db54eadc28e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What number is greater than 11? Answer: 12']\n"]}]},{"cell_type":"markdown","source":["# 1 2 3 genr ablation expms"],"metadata":{"id":"H5H-d2URUSVJ"}},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"id":"rseVgwqtjnCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"id":"sBN3wGX2ys8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866004752,"user_tz":-60,"elapsed":1735,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"26dc65b2-86d6-4986-9558-9f58bcd7f40f","id":"54lN0z-DekER"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 1 2 3 1']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717865960241,"user_tz":-60,"elapsed":1504,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"427e08a9-58fb-43f8-fbc4-961f6b098b96","id":"HYIdJj637K7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 1 2 3 1']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvGTDEVRyl9k","executionInfo":{"status":"ok","timestamp":1717865983052,"user_tz":-60,"elapsed":1784,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9fdf2ea0-dc02-41a0-a2f9-563c0a7c0cff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 1 2 3 2']\n"]}]},{"cell_type":"markdown","source":["# 2 4 6"],"metadata":{"id":"bbNUFkV0z8sP"}},{"cell_type":"code","source":["clean_text = \"2 4 6\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"9MYk0cE7z8sP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDO2i8Omz8sQ","executionInfo":{"status":"ok","timestamp":1717866386791,"user_tz":-60,"elapsed":1341,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3a1fc8f2-6fee-477c-f6dd-70a3fd3c8c17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 4 6 8']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866388310,"user_tz":-60,"elapsed":1531,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8b7788f9-1ce6-43d0-f655-14cc8fe7484c","id":"fpkxwipRz8sQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 4 6 6']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866389960,"user_tz":-60,"elapsed":1691,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0684ed08-439e-47ba-bcec-9a4525e36a7f","id":"u6TWCITWz8sQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 4 6 2']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866391539,"user_tz":-60,"elapsed":1609,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"468d5c33-2773-487b-903d-b956331ce493","id":"zuwO75Qwz8sQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 4 6 6']\n"]}]},{"cell_type":"markdown","source":["# \"Be concise. If today is the 11th of a month, what date will it be in 6 days?”"],"metadata":{"id":"OBo0IKv80oM7"}},{"cell_type":"code","source":["clean_text = \"Be concise. If today is the 11th of a month, what date will it be in 6 days?\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 20"],"metadata":{"id":"Lil7lW9P0oM8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866548793,"user_tz":-60,"elapsed":7198,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3270e1b4-0284-4974-e8d9-a74640715022","id":"P8qvABGq0oM8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: 17th\\n\\nExplanation: If today is the ']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866556189,"user_tz":-60,"elapsed":7406,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1da6a085-29bf-4cc8-e78f-71362a250e0e","id":"RFdroLJ00oM9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: In 6 days, the date will be the 11th of']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866563599,"user_tz":-60,"elapsed":7442,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5fbedab1-5b34-4a1f-c669-2e91becb5be3","id":"SO0z5XOd0oM9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: If today is the 1st of a month, in 6 days']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866571605,"user_tz":-60,"elapsed":8022,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b5128c53-244b-4861-f91b-08b91425c43f","id":"i9KDcTsI0oM-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\n\\n\\nAnswer: 6 days from today will be 6 days ago.\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y2g4pew42WWR","executionInfo":{"status":"ok","timestamp":1717867794437,"user_tz":-60,"elapsed":7380,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"121933f2-0e71-4f04-c607-58e832ce90ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: 17th\\n\\nExplanation: If today is the ']\n"]}]},{"cell_type":"markdown","source":["# What are the months in a year?"],"metadata":{"id":"85Iqlq_c_lQv"}},{"cell_type":"code","source":["clean_text = \"What are the months in a year? Give all of them as a list. Be concise.\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 50"],"metadata":{"id":"UEg9BhbH_lQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3mwqDRI_skN","executionInfo":{"status":"ok","timestamp":1717869700159,"user_tz":-60,"elapsed":18629,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f909a721-33a1-49f4-fec5-5c17287bec8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nThe months in a year are:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n6. June\\n7. July\\n8. August\\n9. September\\n10']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869718555,"user_tz":-60,"elapsed":18408,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"10c794e2-f9d4-4eaf-8fd1-c6b041a5b65c","id":"uk4dPlDW_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nAnswer:\\nThe months in a year are:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n6. June\\n7. July\\n8. August\\n9. September']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869735716,"user_tz":-60,"elapsed":17240,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cab28cc4-18b7-422e-e915-77b29b69db5b","id":"D5ZSEzzN_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nThe months of the year are:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n7. June\\n\\nSo there you have it, the months of the year in a']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869753486,"user_tz":-60,"elapsed":17800,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5fb6ce42-ae25-42b0-a3d8-ebc4935d1a74","id":"1YOcHosP_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nAnswer:\\nThe months in a year are:\\n\\n1. January\\n2. February\\n\\nNote: The list only includes the 124 months of the standard Gregorian calendar used in most of the world.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869770772,"user_tz":-60,"elapsed":17316,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a158e65c-7fcb-4b9d-abf0-43b9847cd059","id":"Zi_AzXVV_lQ7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\n\\nAnswer:\\nThe months of the year are:\\n\\n\\n1. January\\n2. February\\n2. February\\n3. March\\n3. April\\n3. May\\n3. August\\n3. August\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869788511,"user_tz":-60,"elapsed":17779,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"adbcca1d-02bd-4ce2-b7bb-d4084ee2c026","id":"68BLgm07_lQ7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nThere are 12 months in a year:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n6. June\\n7. July\\n8. August\\n9. September']\n"]}]},{"cell_type":"markdown","source":["# The months in a year are:"],"metadata":{"id":"lehO97wBBagh"}},{"cell_type":"code","source":["clean_text = \"The months in a year are: January, \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 20"],"metadata":{"id":"YYh71gKYBagr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869989020,"user_tz":-60,"elapsed":7207,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ac7e0c88-c52f-4f4d-8705-98ffa64b3fce","id":"OYxnN39bBagr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> The months in a year are: January,  February, March, April, May, June, July, August, September, October, November']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869997190,"user_tz":-60,"elapsed":8193,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"880036d8-1e5e-4ef5-9db2-d708d91532f2","id":"ApD1X_LLBagr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> The months in a year are: January,  February,  March,  April,  May,  July,  August,  October']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717870005109,"user_tz":-60,"elapsed":8000,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"41e0230f-fd87-4e91-dc09-17e7439bbc7e","id":"BAtyxpQUBagr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> The months in a year are: January,  February, March, April, May, June, July, August, October, November.\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717870011416,"user_tz":-60,"elapsed":6410,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ecdf6af1-d50d-4a76-823d-b8da23775606","id":"cGvQXyQRBags"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> The months in a year are: January,  February,  March,  April,  May,  June,  September,  November']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717870018957,"user_tz":-60,"elapsed":7622,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d1270d5e-8087-4720-c181-5d09b1c899f9","id":"Eyt-pYSLBags"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> The months in a year are: January,  January, February, February, March, March, April, May, June, July, August']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717870026136,"user_tz":-60,"elapsed":7203,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c3d35b4c-3647-4845-b434-5f00f6a695d0","id":"gCFUix5tBags"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> The months in a year are: January,  February,  March,  April,  May,  June,  July,  August']\n"]}]},{"cell_type":"markdown","source":["# If this month is March, and 3 months pass"],"metadata":{"id":"sMhVxHdxkLVy"}},{"cell_type":"code","source":["clean_text = \"Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"P-GyzEk0kLVy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879151053,"user_tz":-60,"elapsed":3897,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2b339960-b1b8-43aa-ef90-163350fdc953","id":"-xddE8H6kLVy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  June.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879151771,"user_tz":-60,"elapsed":747,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3dd3bfee-24b0-4ecf-a41a-6858a91c6392","id":"6giMxZ2VkLVy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  June.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879153336,"user_tz":-60,"elapsed":1585,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"31ecbb79-943c-403a-854e-6b5fbbee146a","id":"wpAqC206kLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  September.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879154939,"user_tz":-60,"elapsed":1615,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"944a11cf-7c82-4d6e-bbb6-d2aba6f82057","id":"kZ_csJ_7kLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  April.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879156698,"user_tz":-60,"elapsed":1775,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"98590f87-0cd5-450f-d214-2ae0ce0d0a0e","id":"HCFEYto_kLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  December.']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879157583,"user_tz":-60,"elapsed":1094,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"359ebec2-ce30-4b70-d1e1-aa60734a1086","id":"u1KKDsnGkLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  June.']\n"]}]},{"cell_type":"markdown","source":["# If this month is April, and 5 months pass"],"metadata":{"id":"GHxOlZIalUXI"}},{"cell_type":"code","source":["clean_text = \"Be concise. If this month is July, and 5 months pass, what is month name is it? Answer: December. If this month is April, and 5 months pass, what month name is it? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"Z4YzZDFFlUXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879425915,"user_tz":-60,"elapsed":1686,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"41b48fee-f78e-41ef-cf45-f67ae18b13d8","id":"MJgIx1ANlUXJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 5 months pass, what is month name is it? Answer: December. If this month is April, and 5 months pass, what month name is it? Answer:  September.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879427941,"user_tz":-60,"elapsed":2049,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"94a5689a-ea74-446c-f0a7-dfec500a001b","id":"9jSgUNLulUXK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 5 months pass, what is month name is it? Answer: December. If this month is April, and 5 months pass, what month name is it? Answer:  December.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879429093,"user_tz":-60,"elapsed":1176,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"af05f170-ec01-4d74-e22d-a72e384ada51","id":"-MbHa6pXlUXK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 5 months pass, what is month name is it? Answer: December. If this month is April, and 5 months pass, what month name is it? Answer:  July.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879431749,"user_tz":-60,"elapsed":2675,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a8147aa-7094-4491-e17d-d4a55bfa8c02","id":"SnHKhUNTlUXK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 5 months pass, what is month name is it? Answer: December. If this month is April, and 5 months pass, what month name is it? Answer:  July.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879432458,"user_tz":-60,"elapsed":753,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"82d947a7-893e-4301-a308-a5d34d72e8bf","id":"keyUB_hhlUXL"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 5 months pass, what is month name is it? Answer: December. If this month is April, and 5 months pass, what month name is it? Answer:  December.']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879434571,"user_tz":-60,"elapsed":2137,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"abd40123-695f-4249-8a2c-94ad4c316709","id":"eDyyTEhVlUXL"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 5 months pass, what is month name is it? Answer: December. If this month is April, and 5 months pass, what month name is it? Answer:  September.']\n"]}]},{"cell_type":"markdown","source":["# If this month is September, and 2 months pass"],"metadata":{"id":"gU-2_9hfmbDx"}},{"cell_type":"code","source":["clean_text = \"Be concise. If this month is July, and 2 months pass, what is month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"QSXqo0q4mbDy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879593148,"user_tz":-60,"elapsed":1402,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5e1d3fe6-f4a2-453d-e065-c10ec25c6ad9","id":"wOltPI4QmbDy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what is month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  November.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879594117,"user_tz":-60,"elapsed":985,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d19a5f0d-fff7-4303-9ede-4b514f69936f","id":"gXaZITS6mbDz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what is month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  November.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879595957,"user_tz":-60,"elapsed":1867,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"369e001c-0d98-4ede-c368-27e1ecdfaecd","id":"u7Pn7EGEmbDz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what is month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  August.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879598055,"user_tz":-60,"elapsed":2123,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"833f1330-e488-4673-996c-87353c401980","id":"HM_7NxyPmbDz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what is month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  October.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879599985,"user_tz":-60,"elapsed":1953,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"20663486-17fa-4a43-e3e5-c4d291bdd30d","id":"fDUysmdcmbDz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what is month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  November.']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 10\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879683672,"user_tz":-60,"elapsed":4257,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9cda0beb-4d6c-48ae-8680-4bad9e160a48","id":"V75mo9GrmbD0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what is month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  November.\\n\\nSo, the pattern is']\n"]}]},{"cell_type":"markdown","source":["# If this month is September, and 2 months pass"],"metadata":{"id":"H9SQKSEInAoF"}},{"cell_type":"code","source":["clean_text = \"Be concise. If this month is July, and 2 months pass, what month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"Qn96n1qKnAoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880119721,"user_tz":-60,"elapsed":636,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"598c86e5-766d-45f8-d9ff-bde3738147f5","id":"hBKYSzQHnAoQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  November.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880121493,"user_tz":-60,"elapsed":1794,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"227b8b7c-050d-4c92-9032-5dc90cffcabc","id":"ZfHOIuXSnAoQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  November.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880124017,"user_tz":-60,"elapsed":2557,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"eac4a480-0386-4ae7-a089-659ad40cae13","id":"3DUX9-zWnAoQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  October.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880124636,"user_tz":-60,"elapsed":636,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"105ea606-1aa5-4d16-f226-89fa02de9ca8","id":"_yeUg-NPnAoR"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  December.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880127473,"user_tz":-60,"elapsed":2859,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a449f17d-3c90-4557-973a-ed63040426e8","id":"JpCnCGYPnAoR"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  September.']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 10\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880444121,"user_tz":-60,"elapsed":5405,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e067074c-ac6b-42c8-cc08-75a55da1e712","id":"WTpTXEQAnAoS"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 2 months pass, what month name is it? Answer: September. If this month is September, and 2 months pass, what month name is it? Answer:  October.\\n\\nSo, the pattern is']\n"]}]},{"cell_type":"markdown","source":["# If this month is April, and 3 months pass"],"metadata":{"id":"q1ffpJCJqKFi"}},{"cell_type":"code","source":["clean_text = \"Be concise. If this month is July, and 4 months pass, what month name is it? Answer: October. If this month is April, and 4 months pass, what month name is it? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"cBNyrVgGqKF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880610004,"user_tz":-60,"elapsed":1480,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"18b5782f-33de-4ea8-ae73-800573947d00","id":"Mx3UZhoWqKF_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 4 months pass, what month name is it? Answer: October. If this month is April, and 4 months pass, what month name is it? Answer:  August.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880611926,"user_tz":-60,"elapsed":1930,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bc338bc5-2a40-4601-8765-686275020d4e","id":"QuNkJsmpqKGA"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 4 months pass, what month name is it? Answer: October. If this month is April, and 4 months pass, what month name is it? Answer:  August.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880613876,"user_tz":-60,"elapsed":1966,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fd3deff7-382b-4c77-8086-1bed715cf4e1","id":"k9uzwaxQqKGG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 4 months pass, what month name is it? Answer: October. If this month is April, and 4 months pass, what month name is it? Answer:  July.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880615345,"user_tz":-60,"elapsed":1483,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0be5cf7f-aa6b-42e2-9b1d-7139e2e95285","id":"tDOjRnHfqKGH"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 4 months pass, what month name is it? Answer: October. If this month is April, and 4 months pass, what month name is it? Answer:  December.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880618107,"user_tz":-60,"elapsed":2782,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"78aae2bc-e6b6-41b3-9ea9-1067964746f0","id":"Q9ZZfAGnqKGI"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 4 months pass, what month name is it? Answer: October. If this month is April, and 4 months pass, what month name is it? Answer:  April.']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 10\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717880621204,"user_tz":-60,"elapsed":3341,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"aaaa9b4e-a71a-42f2-96c5-3ff606ddd72f","id":"KjvttCr2qKGP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is July, and 4 months pass, what month name is it? Answer: October. If this month is April, and 4 months pass, what month name is it? Answer:  August.\\n\\nSo, the answer to']\n"]}]},{"cell_type":"markdown","source":["# What are all the months in Fall? List them in order."],"metadata":{"id":"DtJ4P8i9DkBC"}},{"cell_type":"code","source":["clean_text = \"Be concise. What are all the months in Fall? List them in order.\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 30"],"metadata":{"id":"RIqoEyzODkBD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921465013,"user_tz":-60,"elapsed":11147,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"bfa6855a-2b37-412b-8995-a509913b3c50","id":"-Pd8OMF6DkBE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Fall? List them in order.\\n\\nAnswer:\\n\\nThe months in the Fall season are September, October, and November.</s>s\\n\\n\\n\\n\\n</s>\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921476045,"user_tz":-60,"elapsed":11037,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"c5795a14-482d-49bc-c176-54da51a4408d","id":"rfQZO5PnDkBF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Fall? List them in order.\\n\\nAnswer:\\n\\nThe months in the Fall season are September, October, and November.</s><s> # What are the months in the']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921486609,"user_tz":-60,"elapsed":10569,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"8376984a-a2ef-4fc8-d3a6-7c2ef915ba7f","id":"5pCuglf1DkBF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Fall? List them in order.\\n\\nAnswer:\\n\\nThe months in the fall season are:\\n\\n1. September\\n2. October\\n3. November\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921497386,"user_tz":-60,"elapsed":10783,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"41b3b16a-ef0a-4ad2-9f9c-dd0e21614bf3","id":"6BXhLd-sDkBH"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Fall? List them in order.\\n\\nAnswer:\\nThe months in the Fall season are:\\n\\n1. September\\n2. October\\n\\nNote: The months in']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 50\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921515006,"user_tz":-60,"elapsed":17624,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"5b1f99f5-9462-4df0-f5b5-e486e07f53c3","id":"ZQ-34zYcDkBH"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Fall? List them in order.\\n\\n\\nAnswer:\\n\\nThe months of Fall are:\\n\\n\\n1. September\\n2. October\\n3. November\\n\\n\\nNote: The months of Fall are listed in order.</s><s> #Fall #Fall']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 50\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921531801,"user_tz":-60,"elapsed":16834,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"3d9a30c7-9411-414a-b8d7-85f60f900c7b","id":"V041oKqHDkBH"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Fall? List them in order.\\n\\nAnswer:\\n\\nThere are 3 months in the Fall season:\\n\\n1. September\\n2. October\\n3. November</s>s\\n\\nNote: The exact dates of the Fall season vary depending on the location and cultural']\n"]}]},{"cell_type":"markdown","source":["# What are all the months in Winter? List them in order."],"metadata":{"id":"GMMoMlMMFDHV"}},{"cell_type":"code","source":["clean_text = \"Be concise. What are all the months in Winter? List them in order. Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 30"],"metadata":{"id":"wOJporNpFDHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921583663,"user_tz":-60,"elapsed":11627,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"7e6e6efd-e917-4243-9570-14c85d8cb498","id":"QxW51U-6FDHZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Winter? List them in order. Answer: 3. The months in Winter are December, January, and February.\\n\\nBe concise. What are all the months in Spring? List']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921594427,"user_tz":-60,"elapsed":10777,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"f84da058-8a51-42cf-a667-d44eeda9506e","id":"qdgfHoO9FDHa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Winter? List them in order. Answer: 3.\\n\\nHere is a list of the months in Winter, in order:\\n\\n1. December\\n2. January\\n3.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921605144,"user_tz":-60,"elapsed":10739,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"1cb0d395-d793-4538-b750-3476ac4949d4","id":"Maycp1WfFDHc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Winter? List them in order. Answer: \\n\\nWinter months are December, January, February, and March.\\n\\n\\nSolution:\\n\\nWinter months are December,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921615455,"user_tz":-60,"elapsed":10321,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"a43228e4-36dc-4048-b6df-7d94d8676001","id":"U4zESBykFDHd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Winter? List them in order. Answer: 1. January 2. February 2. March 2. April 2. May 2. June 2. September 2']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 50\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921633058,"user_tz":-60,"elapsed":17608,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"bf7b991b-ff99-4098-d418-0fc1bcfdb240","id":"AaGz0zjsFDHe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Winter? List them in order. Answer: 1. January 2. February 3. March 3. May 3. September 3. November 3. December 3.\\n\\n\\n\\nNote: The months in Winter are January, February, March, May,']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 50\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921650101,"user_tz":-60,"elapsed":17088,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"4e8a3ba7-baef-4f07-de4a-f39bfc07e29e","id":"NeeFS008FDHf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What are all the months in Winter? List them in order. Answer:  Winter months are January, February, and March.\\n\\nBe concise. What are all the months in Winter? List them in order.\\n\\nAnswer: Winter months are January, February, and March.</s><s> nobody likes a']\n"]}]},{"cell_type":"markdown","source":["# What are all the months in Spring? List them in order."],"metadata":{"id":"DByUDFyjFmYj"}},{"cell_type":"code","source":["clean_text = \"Be concise. What are all the months in Spring? List them in order. Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 30"],"metadata":{"id":"EkQKyjdLFmYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921542810,"user_tz":-60,"elapsed":11041,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"d52fa864-01ea-4390-96b1-f220c6aa7e40","id":"6ICTHv-XFmYm"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are all the months in Spring? List them in order.\\nSpring is a season that occurs between winter and summer, and it typically lasts from March to May in the Northern Hemisphere and from']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921553832,"user_tz":-60,"elapsed":11027,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"15ee2e12-f908-426c-8c10-e151bbde3f91","id":"dFT1huVhFmYn"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are all the months in Spring? List them in order.\\nSpring is a season that occurs between winter and summer, and it typically lasts for three months in the Northern Hemisphere. The months']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"executionInfo":{"status":"error","timestamp":1717921558641,"user_tz":-60,"elapsed":4813,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"785b92dd-0f0d-4e15-f221-da883ee7ff46","id":"qiYejZqkFmYo"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-1fed01dda0d6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmlps_not_ablate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mablate_then_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads_not_ablate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlps_not_ablate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_toks_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-18d5f5c91030>\u001b[0m in \u001b[0;36mablate_then_gen\u001b[0;34m(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mnext_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get the predicted token at the end of our sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    547\u001b[0m                     )\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    550\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/transformer_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m    150\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/abstract_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \"\"\"\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_qkv_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_kv_cache_entry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/abstract_attention.py\u001b[0m in \u001b[0;36mcalculate_qkv_matrices\u001b[0;34m(self, query_input, key_input, value_input)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             q = self.hook_q(\n\u001b[0;32m--> 331\u001b[0;31m                 einsum(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mqkv_einops_string\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_model\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m->\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mpos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mnew_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_equation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fancy_einsum/__init__.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"id":"UvOoNHowFmYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 50\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"id":"GarzBJ33FmYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 50\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"id":"ez-kVTHCFmYp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# What is the month that is 3 months after March?"],"metadata":{"id":"g0NSuK6dHSJU"}},{"cell_type":"code","source":["clean_text = \"Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 10"],"metadata":{"id":"D9_U_CEEHSJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921827635,"user_tz":-60,"elapsed":3976,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"281267d8-7ecd-411c-cddb-0a434401b0b4","id":"HGoCez5bHSJb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  June.\\n\\nAnswer:\\nThe month']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921832086,"user_tz":-60,"elapsed":4453,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"caaa6df7-22e3-4461-96f6-ac158d96f05d","id":"0JEZjkNWHSJc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  June.\\n\\nAnswer:\\n\\nThe']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921835828,"user_tz":-60,"elapsed":3755,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"5374f7e8-a62f-40a5-e63c-8695b657ad10","id":"1ZHhdpu1HSJc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  April.\\n\\nSo, the pattern is']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717921840375,"user_tz":-60,"elapsed":4555,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"NxrtIT2eHSJd","outputId":"074301ec-0d42-4bb5-ec71-8726a93410f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  April.\\n\\nAnswer:\\nMarch']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717921843817,"user_tz":-60,"elapsed":3449,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"uTeL46hoHSJe","outputId":"acbf71f4-7fca-420b-d5bb-c8d51728c962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  April. What is the month that is ']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717921848528,"user_tz":-60,"elapsed":4722,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"5-OG6tCWHSJe","outputId":"47227ac9-43bb-4bd6-9143-f9c46899fb37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  June.\\n\\nWhat is the month that']\n"]}]},{"cell_type":"markdown","source":["#  Answer yes or no. Is 16 greater than 11? Answer:  "],"metadata":{"id":"gQQeTN-6b-Dp"}},{"cell_type":"code","source":["clean_text = \"Answer yes or no. Is 16 greater than 11? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 4"],"metadata":{"id":"5JN43ylUb-Dp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717943968515,"user_tz":-60,"elapsed":2430,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9d8cf5a0-2c43-42c0-e3f8-36ebffe35643","id":"qAIIvfaGb-Dq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>  Answer yes or no. Is 16 greater than 11? Answer:  Yes.</s>']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717943970621,"user_tz":-60,"elapsed":2125,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"56d0c40a-5cc2-4068-ac03-a48cb213bd33","id":"fya3HcqZb-Dq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>  Answer yes or no. Is 16 greater than 11? Answer:  Yes.</s>']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717943972744,"user_tz":-60,"elapsed":2316,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"eb16de38-7722-4e5e-f0fc-d115b29b935d","id":"_ALo9tWob-Dq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>  Answer yes or no. Is 16 greater than 11? Answer:  No, ']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717943974741,"user_tz":-60,"elapsed":2021,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"47207caf-cf84-46bb-bde5-a047bf7eb3e7","id":"dXgiyrZob-Dq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>  Answer yes or no. Is 16 greater than 11? Answer:  Yes.\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717943976711,"user_tz":-60,"elapsed":1995,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ebd35b8b-d81a-4763-81cb-04c76068de75","id":"-stuS1n2b-Dr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>  Answer yes or no. Is 16 greater than 11? Answer:  No. ']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717943978418,"user_tz":-60,"elapsed":1724,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"31a2415f-0db3-4d7d-8d48-03eec464e524","id":"I-cS_uI2b-Dr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s>  Answer yes or no. Is 16 greater than 11? Answer:  Yes.</s>']\n"]}]},{"cell_type":"markdown","source":["#  Be concise. What number is greater than 11? Answer:"],"metadata":{"id":"yLIxG7Kcd9rM"}},{"cell_type":"code","source":["clean_text = \"Be concise. What number is greater than 11? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 4"],"metadata":{"id":"qglZAAJEd9rV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717944471470,"user_tz":-60,"elapsed":2038,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8c176f65-78de-4ac2-ade1-80ed36227448","id":"La7RJsU5d9rW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What number is greater than 11? Answer: 12.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717944474009,"user_tz":-60,"elapsed":2557,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5b349659-d1f5-40e7-c9b4-5bb9ed6b0550","id":"s1AcYSHtd9rW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What number is greater than 11? Answer: 12.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717944475874,"user_tz":-60,"elapsed":1885,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"163b7762-3409-4d83-a986-72d29dc09451","id":"jCLD7Ym9d9rW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What number is greater than 11? Answer: 111']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717944477406,"user_tz":-60,"elapsed":1544,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0be82593-8c70-48e2-b059-38759ec80bc8","id":"Pas7Xi3xd9rX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What number is greater than 11? Answer: 1, ']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717944479665,"user_tz":-60,"elapsed":2277,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8fd57634-6064-480b-f061-5e2e7686753e","id":"LU_t07TLd9rX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What number is greater than 11? Answer: 1 is greater']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717944481655,"user_tz":-60,"elapsed":2015,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee2c9ea9-d1ff-4736-c34d-1f328f249f71","id":"NGhF_Oo8d9rX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What number is greater than 11? Answer: 12.']\n"]}]},{"cell_type":"markdown","source":["# \"5 + 16 = “"],"metadata":{"id":"0Fllcm_N50Zu"}},{"cell_type":"code","source":["clean_text = \"5 + 16 = \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"JAcCXrL-50Z0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717867890652,"user_tz":-60,"elapsed":1254,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7a633206-1ffe-444e-960f-3831c8dfa74a","id":"6ZKdOLPx50Z1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 + 16 = 21']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717867892262,"user_tz":-60,"elapsed":1620,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f3672227-b422-4de7-80d7-43119e5f23e7","id":"YfB_bzQ350Z1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 + 16 = 21']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717867893950,"user_tz":-60,"elapsed":1705,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e3b358f-d3ba-4ec9-f2e9-fbb9a80ec4f5","id":"0tyRkAMZ50Z1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 + 16 = 11']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717867895561,"user_tz":-60,"elapsed":1632,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f0169395-6383-4737-c2e2-9fe18937dcc0","id":"GdF5h8vC50Z1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 + 16 = 16']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717867897450,"user_tz":-60,"elapsed":1908,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c1127874-c0a6-4ce4-d8f5-01fdd25858e8","id":"SbgyrZEk50Z1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 + 16 = 21']\n"]}]},{"cell_type":"markdown","source":["# Be concise. 100 + 58 ="],"metadata":{"id":"16CQTjZ77wci"}},{"cell_type":"code","source":["clean_text = \"Be concise. 100 + 58 = \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 5"],"metadata":{"id":"WVtwReTf7wcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868391916,"user_tz":-60,"elapsed":1834,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a1b09cd7-8a29-4bbb-a287-e65bf92875e3","id":"Cfc4bzPI7wcw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. 100 + 58 = 158.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868394309,"user_tz":-60,"elapsed":2402,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e541c6e-3e0d-4640-a785-34d7376b6848","id":"opHH1YGQ7wcx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. 100 + 58 = 1050']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868396717,"user_tz":-60,"elapsed":2426,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ed097bd2-0359-4e95-d6ee-49abd21a8387","id":"DnkweJF47wcx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. 100 + 58 = 100 +']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868398843,"user_tz":-60,"elapsed":2146,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3f9e1a05-a653-4c4f-ee39-e2f585d5cc81","id":"I5fNvz237wcx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. 100 + 58 = 10 + ']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868401133,"user_tz":-60,"elapsed":2309,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"40190d64-b4bf-4249-eeac-0d6ef9759998","id":"hQrqwS2C7wcx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. 100 + 58 = 158 words']\n"]}]},{"cell_type":"markdown","source":["# 5 x 6 ="],"metadata":{"id":"JsT_qlx49FQT"}},{"cell_type":"code","source":["clean_text = \"5 x 6 = \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"NyFckpqe9FQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868738517,"user_tz":-60,"elapsed":1496,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e79fd953-3975-48c6-f460-1c24a1843c45","id":"OrMsUHoF9FQV"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 x 6 = 30']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868739973,"user_tz":-60,"elapsed":1466,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e004308a-c398-458a-a6c1-7d1d04722cec","id":"YkR5JbTz9FQW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 x 6 = 30']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868741918,"user_tz":-60,"elapsed":1956,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9aca8c55-e97e-4994-a75d-933f56df1fa7","id":"b2OMJ3u59FQW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 x 6 = 30']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868743436,"user_tz":-60,"elapsed":1531,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1df649f5-0009-4e82-f8ae-63cce3982a06","id":"RqopI9ek9FQX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 x 6 = 30']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868745222,"user_tz":-60,"elapsed":1798,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"16680475-981b-40ad-8f83-02848f447a8e","id":"XpUexORN9FQX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 5 x 6 = 30']\n"]}]},{"cell_type":"markdown","source":["# 2 x 2 ="],"metadata":{"id":"sAxMpsVS9S_U"}},{"cell_type":"code","source":["clean_text = \"2 x 2 = \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"tQmG6O6q9S_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868785263,"user_tz":-60,"elapsed":1120,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9f382a14-ae4b-42a6-a5b6-89452abc3835","id":"E5BhnlyE9S_f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 x 2 = 4\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868787493,"user_tz":-60,"elapsed":2240,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a2b8984-ab0c-4e9b-813d-8821f0bf46c9","id":"a9IsgYcq9S_g"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 x 2 = 4\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868788612,"user_tz":-60,"elapsed":1131,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"37a9b383-5a80-47ba-e0f9-1124cda82cb7","id":"A5koK7Et9S_g"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 x 2 = 4\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868790257,"user_tz":-60,"elapsed":1656,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9dd0e6eb-ed5a-4eb3-e084-7defdfe272be","id":"WL7tv9I49S_g"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 x 2 = 10']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717868791845,"user_tz":-60,"elapsed":1607,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b49168a9-3ba9-4700-fd82-f2cb9f6baea3","id":"r54rTR_39S_g"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> 2 x 2 = 4\\n']\n"]}]}]}