{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["DcZG9rm2IAiA","6Fuq8XW770vX","cvDoLG2YR73k","NXLKleFoSQMO","StWTdvI1hz4H","pJ804aWuhqu8","JSQkrPMHiJYI","TVyYiX9DZh3V","-D7DD-WPZzQr"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ba1282f769ac4ce0a479d8dd1c0663c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_463fa65fccb24ae3a235c39bc7cd6a19","IPY_MODEL_9059414317194ea993716d46679ed089","IPY_MODEL_a401e6cb58004b199313e26ad9eb2f1c"],"layout":"IPY_MODEL_85fd8209af8444e6acaf93b1bb1e0272"}},"463fa65fccb24ae3a235c39bc7cd6a19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ef3aad1eaf43178d36d75db63c98a5","placeholder":"​","style":"IPY_MODEL_f859fee1916b4645ad57de603b6bd749","value":"config.json: 100%"}},"9059414317194ea993716d46679ed089":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69191b1be6f647a08be7378f1dad8c5d","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a348d320a8264d598c03ffebcbbb56ab","value":665}},"a401e6cb58004b199313e26ad9eb2f1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c05044f6e8e74a2c854f6f9f74dbad60","placeholder":"​","style":"IPY_MODEL_8d5d5b7d859b437aa89a2d8050df80eb","value":" 665/665 [00:00&lt;00:00, 62.8kB/s]"}},"85fd8209af8444e6acaf93b1bb1e0272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50ef3aad1eaf43178d36d75db63c98a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f859fee1916b4645ad57de603b6bd749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69191b1be6f647a08be7378f1dad8c5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a348d320a8264d598c03ffebcbbb56ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c05044f6e8e74a2c854f6f9f74dbad60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d5d5b7d859b437aa89a2d8050df80eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7143ff0d7d5b4ed6a9802535918e492a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35b41beb807f441d9336eacd7161a3f4","IPY_MODEL_f108e34a991d4fee99a284bc152e49ed","IPY_MODEL_560720aa52e840949fa82ac82e5deb0b"],"layout":"IPY_MODEL_3c6000afe78d4f80aff8f8f0cf7ffa90"}},"35b41beb807f441d9336eacd7161a3f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b84891cf998e4af5bdb084892bb3ede4","placeholder":"​","style":"IPY_MODEL_10e4c217d9ef40b082a687f7c2ede51c","value":"model.safetensors: 100%"}},"f108e34a991d4fee99a284bc152e49ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cf485307a2d439ea65db41733088a89","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_633ea2eb5b4c446d949c45fb7bebcb54","value":548105171}},"560720aa52e840949fa82ac82e5deb0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_814eac03ffb94af0822b6adf55493245","placeholder":"​","style":"IPY_MODEL_9c0ac17223c04f7186b9202cd6c56932","value":" 548M/548M [00:01&lt;00:00, 421MB/s]"}},"3c6000afe78d4f80aff8f8f0cf7ffa90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b84891cf998e4af5bdb084892bb3ede4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10e4c217d9ef40b082a687f7c2ede51c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cf485307a2d439ea65db41733088a89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"633ea2eb5b4c446d949c45fb7bebcb54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"814eac03ffb94af0822b6adf55493245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c0ac17223c04f7186b9202cd6c56932":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e31fefb7537b40a5a11646c6be7acf0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c43750a5bdc64831a1250a77a9ed3dd9","IPY_MODEL_5c70fab18b52491fb917405c12f61611","IPY_MODEL_af579ab76de54cae80610c13d784bfc2"],"layout":"IPY_MODEL_f1017d48c0fe4dfca1667a5232dabd09"}},"c43750a5bdc64831a1250a77a9ed3dd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bef17bfceed4431ad9444f28520f6cc","placeholder":"​","style":"IPY_MODEL_b267d16a974744a4aa3c3b6cf9c64097","value":"generation_config.json: 100%"}},"5c70fab18b52491fb917405c12f61611":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c288765266e74a6c91d31ad55ffd62f8","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b454bc1b7bc4891aa070be2f5129d31","value":124}},"af579ab76de54cae80610c13d784bfc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f229db4e0e94b42af10beadb358e63a","placeholder":"​","style":"IPY_MODEL_5302130aab014a73b0616f23c9ff03cf","value":" 124/124 [00:00&lt;00:00, 11.3kB/s]"}},"f1017d48c0fe4dfca1667a5232dabd09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bef17bfceed4431ad9444f28520f6cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b267d16a974744a4aa3c3b6cf9c64097":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c288765266e74a6c91d31ad55ffd62f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b454bc1b7bc4891aa070be2f5129d31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f229db4e0e94b42af10beadb358e63a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5302130aab014a73b0616f23c9ff03cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"767691c76a59498f8095f2d61caec35f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa32d4e87be5417cbb401fea14dee524","IPY_MODEL_2df8917042694184bfaf7450580360ae","IPY_MODEL_46df78cd48a1469c8587d1bad3cf616f"],"layout":"IPY_MODEL_46ad149c89de4ed7911fc19c842b6b78"}},"aa32d4e87be5417cbb401fea14dee524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_642ed90d598048e2bd5e06809902b21c","placeholder":"​","style":"IPY_MODEL_5aacd9b0b4414979bbce270273f6dde5","value":"tokenizer_config.json: 100%"}},"2df8917042694184bfaf7450580360ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_411c245ca2e74b97b44ce89d57da2fb9","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27d5c5cbfb844f14b176b9cd91f01121","value":26}},"46df78cd48a1469c8587d1bad3cf616f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6baf5adce3a746c8966b9f34d54b4886","placeholder":"​","style":"IPY_MODEL_0bf9942ce02a469c9b38c85e4ef6383c","value":" 26.0/26.0 [00:00&lt;00:00, 2.26kB/s]"}},"46ad149c89de4ed7911fc19c842b6b78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642ed90d598048e2bd5e06809902b21c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aacd9b0b4414979bbce270273f6dde5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"411c245ca2e74b97b44ce89d57da2fb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27d5c5cbfb844f14b176b9cd91f01121":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6baf5adce3a746c8966b9f34d54b4886":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bf9942ce02a469c9b38c85e4ef6383c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"503cbeab86c9419f9888755a1cee761b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3eb066aaeaa5474b8b48b7dfba400e5c","IPY_MODEL_62f6afa82b4542d3abacd19b794b65e5","IPY_MODEL_6d1d889b7b004d309004b3b97f0df98e"],"layout":"IPY_MODEL_2618e7bac2ce4096962c7a92cf577c30"}},"3eb066aaeaa5474b8b48b7dfba400e5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1084552653bb4552ae8836d67be73679","placeholder":"​","style":"IPY_MODEL_f0da640fe1614e74b6e6c11c6ab7627f","value":"vocab.json: 100%"}},"62f6afa82b4542d3abacd19b794b65e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f221b17aa924fcc861523ca5ff32d73","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fdbf7e505fc4f0094bd5650194ed9f3","value":1042301}},"6d1d889b7b004d309004b3b97f0df98e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61eed594e96944dbb3a89dee2be98e3b","placeholder":"​","style":"IPY_MODEL_4653826c1400449fb7f719793e89731a","value":" 1.04M/1.04M [00:00&lt;00:00, 3.17MB/s]"}},"2618e7bac2ce4096962c7a92cf577c30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1084552653bb4552ae8836d67be73679":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0da640fe1614e74b6e6c11c6ab7627f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f221b17aa924fcc861523ca5ff32d73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fdbf7e505fc4f0094bd5650194ed9f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61eed594e96944dbb3a89dee2be98e3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4653826c1400449fb7f719793e89731a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a72f62dbd37f49a28db8c6d2bb336c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e75584eb5f584daead2f57451b8c734c","IPY_MODEL_adc4d24bb72f496ba7d06189df194e93","IPY_MODEL_d1410a19014242e8a108b5c03951f225"],"layout":"IPY_MODEL_a7b7a0a0f50c45eba122ee7b241a5964"}},"e75584eb5f584daead2f57451b8c734c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_528ff831cf564210b0b39e50a7a2ac2f","placeholder":"​","style":"IPY_MODEL_075c1c709aef4dfa9479c4add90a613f","value":"merges.txt: 100%"}},"adc4d24bb72f496ba7d06189df194e93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09652f0b4ed74b6cba1cb5589eceeb09","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f96943dc0734039b7ebd863136a6749","value":456318}},"d1410a19014242e8a108b5c03951f225":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea64912793f74540817831b664a501dd","placeholder":"​","style":"IPY_MODEL_ff16b98781cc4d2bb18d571cbcca2366","value":" 456k/456k [00:00&lt;00:00, 1.88MB/s]"}},"a7b7a0a0f50c45eba122ee7b241a5964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"528ff831cf564210b0b39e50a7a2ac2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"075c1c709aef4dfa9479c4add90a613f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09652f0b4ed74b6cba1cb5589eceeb09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f96943dc0734039b7ebd863136a6749":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea64912793f74540817831b664a501dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff16b98781cc4d2bb18d571cbcca2366":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"701b3c142a7145fab418f1bcb5baf4ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e4a724c98a447d18b27bf4e31eb1e8d","IPY_MODEL_ad560e0aa05c4390bc91bea12a33e739","IPY_MODEL_b70bcb266feb467c897b4a10dc30786f"],"layout":"IPY_MODEL_c37dcadb1a7842639d9b131d987222ff"}},"4e4a724c98a447d18b27bf4e31eb1e8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8fa081aac7b421d9c4d1a3901b69ff1","placeholder":"​","style":"IPY_MODEL_0ab6d9e29d964feca6ac14deefbcaef6","value":"tokenizer.json: 100%"}},"ad560e0aa05c4390bc91bea12a33e739":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_804745dfff034fdf80a35b0a11f81618","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eda99eb2e00b475b940d0d9236ddc5fc","value":1355256}},"b70bcb266feb467c897b4a10dc30786f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26fa15bc2fc6479ebbc4faea18506507","placeholder":"​","style":"IPY_MODEL_13f5a0d30d0e4cf59dd84f7a47c5d1f0","value":" 1.36M/1.36M [00:00&lt;00:00, 3.26MB/s]"}},"c37dcadb1a7842639d9b131d987222ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8fa081aac7b421d9c4d1a3901b69ff1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ab6d9e29d964feca6ac14deefbcaef6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"804745dfff034fdf80a35b0a11f81618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eda99eb2e00b475b940d0d9236ddc5fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26fa15bc2fc6479ebbc4faea18506507":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13f5a0d30d0e4cf59dd84f7a47c5d1f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"markdown","source":["## Change Inputs Here"],"metadata":{"id":"vKYgaZ9JjihZ"}},{"cell_type":"code","source":["model_name = \"gpt2-small\"\n","save_files = True"],"metadata":{"id":"KSKP_OsTDki6","executionInfo":{"status":"ok","timestamp":1716842085739,"user_tz":240,"elapsed":52,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0","executionInfo":{"status":"ok","timestamp":1716842156970,"user_tz":240,"elapsed":71281,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1716842160687,"user_tz":240,"elapsed":3945,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1716842163196,"user_tz":240,"elapsed":2681,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy","executionInfo":{"status":"ok","timestamp":1716842163196,"user_tz":240,"elapsed":195,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"cFMTUcQiIAiF","executionInfo":{"status":"ok","timestamp":1716842163197,"user_tz":240,"elapsed":195,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"xLwDyosvIAiJ","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["ba1282f769ac4ce0a479d8dd1c0663c0","463fa65fccb24ae3a235c39bc7cd6a19","9059414317194ea993716d46679ed089","a401e6cb58004b199313e26ad9eb2f1c","85fd8209af8444e6acaf93b1bb1e0272","50ef3aad1eaf43178d36d75db63c98a5","f859fee1916b4645ad57de603b6bd749","69191b1be6f647a08be7378f1dad8c5d","a348d320a8264d598c03ffebcbbb56ab","c05044f6e8e74a2c854f6f9f74dbad60","8d5d5b7d859b437aa89a2d8050df80eb","7143ff0d7d5b4ed6a9802535918e492a","35b41beb807f441d9336eacd7161a3f4","f108e34a991d4fee99a284bc152e49ed","560720aa52e840949fa82ac82e5deb0b","3c6000afe78d4f80aff8f8f0cf7ffa90","b84891cf998e4af5bdb084892bb3ede4","10e4c217d9ef40b082a687f7c2ede51c","4cf485307a2d439ea65db41733088a89","633ea2eb5b4c446d949c45fb7bebcb54","814eac03ffb94af0822b6adf55493245","9c0ac17223c04f7186b9202cd6c56932","e31fefb7537b40a5a11646c6be7acf0b","c43750a5bdc64831a1250a77a9ed3dd9","5c70fab18b52491fb917405c12f61611","af579ab76de54cae80610c13d784bfc2","f1017d48c0fe4dfca1667a5232dabd09","3bef17bfceed4431ad9444f28520f6cc","b267d16a974744a4aa3c3b6cf9c64097","c288765266e74a6c91d31ad55ffd62f8","1b454bc1b7bc4891aa070be2f5129d31","3f229db4e0e94b42af10beadb358e63a","5302130aab014a73b0616f23c9ff03cf","767691c76a59498f8095f2d61caec35f","aa32d4e87be5417cbb401fea14dee524","2df8917042694184bfaf7450580360ae","46df78cd48a1469c8587d1bad3cf616f","46ad149c89de4ed7911fc19c842b6b78","642ed90d598048e2bd5e06809902b21c","5aacd9b0b4414979bbce270273f6dde5","411c245ca2e74b97b44ce89d57da2fb9","27d5c5cbfb844f14b176b9cd91f01121","6baf5adce3a746c8966b9f34d54b4886","0bf9942ce02a469c9b38c85e4ef6383c","503cbeab86c9419f9888755a1cee761b","3eb066aaeaa5474b8b48b7dfba400e5c","62f6afa82b4542d3abacd19b794b65e5","6d1d889b7b004d309004b3b97f0df98e","2618e7bac2ce4096962c7a92cf577c30","1084552653bb4552ae8836d67be73679","f0da640fe1614e74b6e6c11c6ab7627f","3f221b17aa924fcc861523ca5ff32d73","2fdbf7e505fc4f0094bd5650194ed9f3","61eed594e96944dbb3a89dee2be98e3b","4653826c1400449fb7f719793e89731a","a72f62dbd37f49a28db8c6d2bb336c1e","e75584eb5f584daead2f57451b8c734c","adc4d24bb72f496ba7d06189df194e93","d1410a19014242e8a108b5c03951f225","a7b7a0a0f50c45eba122ee7b241a5964","528ff831cf564210b0b39e50a7a2ac2f","075c1c709aef4dfa9479c4add90a613f","09652f0b4ed74b6cba1cb5589eceeb09","0f96943dc0734039b7ebd863136a6749","ea64912793f74540817831b664a501dd","ff16b98781cc4d2bb18d571cbcca2366","701b3c142a7145fab418f1bcb5baf4ae","4e4a724c98a447d18b27bf4e31eb1e8d","ad560e0aa05c4390bc91bea12a33e739","b70bcb266feb467c897b4a10dc30786f","c37dcadb1a7842639d9b131d987222ff","c8fa081aac7b421d9c4d1a3901b69ff1","0ab6d9e29d964feca6ac14deefbcaef6","804745dfff034fdf80a35b0a11f81618","eda99eb2e00b475b940d0d9236ddc5fc","26fa15bc2fc6479ebbc4faea18506507","13f5a0d30d0e4cf59dd84f7a47c5d1f0"],"height":0},"executionInfo":{"status":"ok","timestamp":1716842173160,"user_tz":240,"elapsed":10158,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ee1452a1-940f-4126-c04e-1aecd482b547"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1282f769ac4ce0a479d8dd1c0663c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7143ff0d7d5b4ed6a9802535918e492a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31fefb7537b40a5a11646c6be7acf0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"767691c76a59498f8095f2d61caec35f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"503cbeab86c9419f9888755a1cee761b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a72f62dbd37f49a28db8c6d2bb336c1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"701b3c142a7145fab418f1bcb5baf4ae"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    model_name,\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842174757,"user_tz":240,"elapsed":1770,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"67d0ae89-2449-4845-c2a6-54ee332085b4","id":"F8TXMRL3CoPd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 875, done.\u001b[K\n","remote: Counting objects: 100% (341/341), done.\u001b[K\n","remote: Compressing objects: 100% (223/223), done.\u001b[K\n","remote: Total 875 (delta 187), reused 257 (delta 107), pack-reused 534\u001b[K\n","Receiving objects: 100% (875/875), 16.78 MiB | 21.61 MiB/s, done.\n","Resolving deltas: 100% (550/550), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","# don't improt this\n","# # from dataset import Dataset\n","\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ","executionInfo":{"status":"ok","timestamp":1716842174757,"user_tz":240,"elapsed":80,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R","executionInfo":{"status":"ok","timestamp":1716842174757,"user_tz":240,"elapsed":79,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_longer(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text}\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    prompts_list.append(prompt_dict)\n","    return prompts_list"],"metadata":{"id":"VZKVG778QYyn","executionInfo":{"status":"ok","timestamp":1716842174757,"user_tz":240,"elapsed":78,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Load datasets"],"metadata":{"id":"6Fuq8XW770vX"}},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': str(i),\n","            'S2': str(i+1),\n","            'S3': str(i+2),\n","            'S4': str(i+3),\n","            'corr': str(i+4),\n","            'incorr': str(i+3),\n","            'text': f\"{i} {i+1} {i+2} {i+3}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 2)\n","prompts_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvAkKJI06Vt5","executionInfo":{"status":"ok","timestamp":1716842174758,"user_tz":240,"elapsed":78,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"981e5872-8a33-497e-fde2-6fe762cb8ddb"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': '1',\n","  'S2': '2',\n","  'S3': '3',\n","  'S4': '4',\n","  'corr': '5',\n","  'incorr': '4',\n","  'text': '1 2 3 4'}]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["pos_dict = {}\n","for i in range(len(model.tokenizer.tokenize(prompts_list[0]['text']))):\n","    pos_dict['S'+str(i)] = i"],"metadata":{"id":"kS_Tlrb_70vg","executionInfo":{"status":"ok","timestamp":1716842174758,"user_tz":240,"elapsed":76,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["dataset = Dataset(prompts_list, pos_dict, model.tokenizer)"],"metadata":{"id":"u0NPSKcZ1iDe","executionInfo":{"status":"ok","timestamp":1716842174758,"user_tz":240,"elapsed":75,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(prompt_list):\n","    outlist = []\n","    # for i in range(100):\n","    for prompt_dict in prompts_list:\n","        r1 = random.randint(1, 12)\n","        r2 = random.randint(1, 12)\n","        while True:\n","            r3 = random.randint(1, 12)\n","            r4 = random.randint(1, 12)\n","            if r4 - 1 != r3:\n","                break\n","        new_text = prompt_dict['text'].replace(prompt_dict['S1'], str(r1)).replace(prompt_dict['S2'], str(r2)).replace(prompt_dict['S3'], str(r3)).replace(prompt_dict['S4'], str(r4))\n","        new_prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': prompt_dict['corr'],\n","            'incorr': prompt_dict['incorr'],\n","            'text': new_text\n","        }\n","        outlist.append(new_prompt_dict)\n","    return outlist\n","prompts_list_2 = generate_prompts_list_corr(prompts_list)\n","len(prompts_list_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Jtstw1o7Gkj","executionInfo":{"status":"ok","timestamp":1716842174758,"user_tz":240,"elapsed":75,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f3e2de4a-3d95-4a33-f70c-7a0cfc58b01e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)"],"metadata":{"id":"msu6D4p_feW5","executionInfo":{"status":"ok","timestamp":1716842174758,"user_tz":240,"elapsed":74,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Get orig score"],"metadata":{"id":"BHHvz84w70vh"}},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","logits_original = model(dataset.toks)\n","orig_score = get_logit_diff(logits_original, dataset)\n","orig_score"],"metadata":{"id":"OI3FcmpMaNxB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842174992,"user_tz":240,"elapsed":307,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"98e1001e-ac39-4a7d-b6c4-b2586887d12b"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.0631, device='cuda:0')"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["import gc\n","\n","del(logits_original)\n","torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842175297,"user_tz":240,"elapsed":44,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"A-TjmW5PUwGC","outputId":"52e2467a-2bb8-4b9f-9f9f-b3cd3d3fcd22"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# logit diff for mult tok answers"],"metadata":{"id":"jtaV1q3SBHow"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        dataset = Dataset(prompts_list, pos_dict, model.tokenizer)\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","\n","        # measure how far away predicted logit is from corr token?\n","\n","        # corr_logits = logits[:, dataset.word_idx[\"end\"], dataset.corr_tokenIDs]\n","        # incorr_logits = logits[:, dataset.word_idx[\"end\"], dataset.incorr_tokenIDs]\n","        # new_score = corr_logits - incorr_logits\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","    return corr_ans_tokLen"],"metadata":{"id":"WgbtY5fFPb71","executionInfo":{"status":"ok","timestamp":1716842175297,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["clean_text = \"1 2 3 4\"\n","corr_ans = ' 5'\n","corr_ans_tokLen = clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7ScEnVdeJwD","executionInfo":{"status":"ok","timestamp":1716842175297,"user_tz":240,"elapsed":42,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fd341b8d-2bab-4e4c-92b6-84354e2cdc87"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4'\n","logit diff of new char: tensor([16.8118], device='cuda:0')\n","5th char = ' 5'\n","\n","Total logit diff:  16.811784744262695\n"]}]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","    for i in range(corr_ans_tokLen):\n","    # for i in range(5):\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        clean_text = clean_text + next_char\n","        tokens = model.to_tokens(clean_text).to(device)\n","        tokens = tokens[:, 1:]\n","        print(clean_text)\n","\n","        # get new ablation dataset\n","        model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        corr_text = corr_text + next_char\n","        corr_tokens = model.to_tokens(corr_text).to(device)\n","        prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","        print(corr_text)\n","\n","        pos_dict = {}\n","        for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","            pos_dict['S'+str(i)] = i\n","\n","        dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","\n","        model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        print('\\n')\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","\n","        new_score = get_logit_diff(logits, dataset)\n","        total_score += new_score\n","        print(f\"corr logit of new char: {new_score}\")\n","    print('\\n Total corr logit: ', total_score.item())"],"metadata":{"id":"lp4MyZ52cUTK","executionInfo":{"status":"ok","timestamp":1716842175297,"user_tz":240,"elapsed":41,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\"\n","heads_not_ablate = []  # ablate all heads but not MLPs\n","mlps_not_ablate = []  # ablate all MLPs\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmBaWRhCctue","executionInfo":{"status":"ok","timestamp":1716842176794,"user_tz":240,"elapsed":1538,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3adc006d-b51e-4314-f47d-50015068ad07"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = '.'\n","1 2 3.\n","5 3 9.\n","\n","\n","Sequence so far: '1 2 3.'\n","corr logit of new char: 0.861663818359375\n","\n"," Total corr logit:  0.861663818359375\n"]}]},{"cell_type":"markdown","source":["# 1 2 3 genr ablation expms"],"metadata":{"id":"H5H-d2URUSVJ"}},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\""],"metadata":{"id":"rseVgwqtjnCc","executionInfo":{"status":"ok","timestamp":1716842176795,"user_tz":240,"elapsed":173,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## ablate just head 9.1 and MLP 9"],"metadata":{"id":"cvDoLG2YR73k"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFezBzOtje6o","executionInfo":{"status":"ok","timestamp":1716842180888,"user_tz":240,"elapsed":4265,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"42f28160-3428-4a32-db78-5ada39d48d6a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 0.42961740493774414\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 0.42962169647216797\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 0.4296226501464844\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 0.42961835861206055\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 0.42961645126342773\n","\n"," Total corr logit:  2.1480965614318848\n"]}]},{"cell_type":"markdown","source":["## ablate 4.4, 7.11, 9.1"],"metadata":{"id":"NXLKleFoSQMO"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzSEb7OGj0vt","executionInfo":{"status":"ok","timestamp":1716842184417,"user_tz":240,"elapsed":3677,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bd99eca8-0f1b-48bf-a531-419cc4164ea2"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 3.36678409576416\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 3.3667917251586914\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 3.3667922019958496\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 3.3667869567871094\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 3.3667917251586914\n","\n"," Total corr logit:  16.833946228027344\n"]}]},{"cell_type":"markdown","source":["## ablate mlp 9"],"metadata":{"id":"StWTdvI1hz4H"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgoE5T8DkCd_","executionInfo":{"status":"ok","timestamp":1716842188667,"user_tz":240,"elapsed":4426,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a603f0c1-156e-4adc-eab8-a46e9ba5da08"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 0.8109622001647949\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 0.8109650611877441\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 0.8109645843505859\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 0.8109612464904785\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 0.8109622001647949\n","\n"," Total corr logit:  4.054815292358398\n"]}]},{"cell_type":"markdown","source":["## ablate 4.4, 7.11, 9.1 and mlp 9"],"metadata":{"id":"pJ804aWuhqu8"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7Y8FTbHkJjt","executionInfo":{"status":"ok","timestamp":1716842192393,"user_tz":240,"elapsed":3909,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"76b32457-a325-4ec1-963d-d86b016d58f1"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 3'\n","1 2 3 3\n","5 3 9 3\n","\n","\n","Sequence so far: '1 2 3 3'\n","corr logit of new char: -1.0452260971069336\n","5th char = ' 3'\n","1 2 3 3 3\n","5 3 9 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3'\n","corr logit of new char: -1.0452265739440918\n","6th char = ' 3'\n","1 2 3 3 3 3\n","5 3 9 3 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3 3'\n","corr logit of new char: -1.0452251434326172\n","7th char = ' 3'\n","1 2 3 3 3 3 3\n","5 3 9 3 3 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3 3 3'\n","corr logit of new char: -1.0452260971069336\n","8th char = ' 3'\n","1 2 3 3 3 3 3 3\n","5 3 9 3 3 3 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3 3 3 3'\n","corr logit of new char: -1.0452251434326172\n","\n"," Total corr logit:  -5.226129055023193\n"]}]},{"cell_type":"markdown","source":["## 6.2, 4.1, 7.1"],"metadata":{"id":"JSQkrPMHiJYI"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(6, 2), (4,1), (7,1)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npTQNLgIk5Pr","executionInfo":{"status":"ok","timestamp":1716842197848,"user_tz":240,"elapsed":5612,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8b268740-7ffc-45d6-877b-1d42d81a8b0b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 0.8091115951538086\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 0.8091144561767578\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 0.8091154098510742\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 0.809107780456543\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 0.8091120719909668\n","\n"," Total corr logit:  4.04556131362915\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","# heads_not_ablate = [(9, 1)]\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","len(heads_not_ablate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhE8CDftXmMj","executionInfo":{"status":"ok","timestamp":1716842197848,"user_tz":240,"elapsed":232,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e841a833-2519-4c03-a220-2385b8441c0a"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["141"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# M T, two days after is"],"metadata":{"id":"aB5OqTVcYigX"}},{"cell_type":"code","source":["clean_text = \"What comes after Monday is Tuesday, and two days after is\"\n","corr_text = \"What comes after X is Y, and two days after is\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842197848,"user_tz":240,"elapsed":231,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"syZM-USVlI20"},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## clean"],"metadata":{"id":"TVyYiX9DZh3V"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KX7SDCWZlaI1","executionInfo":{"status":"ok","timestamp":1716842201714,"user_tz":240,"elapsed":4096,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f37f047c-c72b-412a-c599-72602102ff2e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' Wednesday'\n","What comes after Monday is Tuesday, and two days after is Wednesday\n","What comes after X is Y, and two days after is Wednesday\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday'\n","corr logit of new char: -0.49404239654541016\n","14th char = '.'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.'\n","corr logit of new char: -0.49404239654541016\n","15th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n'\n","corr logit of new char: -0.49404239654541016\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n\\n'\n","corr logit of new char: -0.49404239654541016\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n\\n\\n'\n","corr logit of new char: -0.49404144287109375\n","\n"," Total corr logit:  -2.4702110290527344\n"]}]},{"cell_type":"markdown","source":["## corrupt the subcircuit"],"metadata":{"id":"-D7DD-WPZzQr"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842206395,"user_tz":240,"elapsed":4884,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5cbb0676-5b4d-4f89-a1bc-fa0ebb10de38","id":"II6bGt3vlQ3G"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' the'\n","What comes after Monday is Tuesday, and two days after is the\n","What comes after X is Y, and two days after is the\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the'\n","corr logit of new char: -0.890857458114624\n","14th char = ' day'\n","What comes after Monday is Tuesday, and two days after is the day\n","What comes after X is Y, and two days after is the day\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day'\n","corr logit of new char: -0.890857458114624\n","15th char = ' of'\n","What comes after Monday is Tuesday, and two days after is the day of\n","What comes after X is Y, and two days after is the day of\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day of'\n","corr logit of new char: -0.890857458114624\n","16th char = ' the'\n","What comes after Monday is Tuesday, and two days after is the day of the\n","What comes after X is Y, and two days after is the day of the\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day of the'\n","corr logit of new char: -0.8908569812774658\n","17th char = ' first'\n","What comes after Monday is Tuesday, and two days after is the day of the first\n","What comes after X is Y, and two days after is the day of the first\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day of the first'\n","corr logit of new char: -0.890857458114624\n","\n"," Total corr logit:  -4.454286575317383\n"]}]},{"cell_type":"markdown","source":["## ablate 4.4, 7.11, 9.1"],"metadata":{"id":"cTJHJVqQG7VO"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842211237,"user_tz":240,"elapsed":5002,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"605bf3f7-1f29-4e86-e36c-2b7708bb75c7","id":"7E35ogQIG7VR"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' Monday'\n","What comes after Monday is Tuesday, and two days after is Monday\n","What comes after X is Y, and two days after is Monday\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday'\n","corr logit of new char: -0.5167403221130371\n","14th char = ','\n","What comes after Monday is Tuesday, and two days after is Monday,\n","What comes after X is Y, and two days after is Monday,\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday,'\n","corr logit of new char: -0.5167403221130371\n","15th char = ' and'\n","What comes after Monday is Tuesday, and two days after is Monday, and\n","What comes after X is Y, and two days after is Monday, and\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday, and'\n","corr logit of new char: -0.5167403221130371\n","16th char = ' then'\n","What comes after Monday is Tuesday, and two days after is Monday, and then\n","What comes after X is Y, and two days after is Monday, and then\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday, and then'\n","corr logit of new char: -0.5167396068572998\n","17th char = ' Tuesday'\n","What comes after Monday is Tuesday, and two days after is Monday, and then Tuesday\n","What comes after X is Y, and two days after is Monday, and then Tuesday\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday, and then Tuesday'\n","corr logit of new char: -0.5167398452758789\n","\n"," Total corr logit:  -2.58370041847229\n"]}]},{"cell_type":"markdown","source":["## corrupt 9.1 and mlp9"],"metadata":{"id":"r6x7xHH0aa9T"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842216230,"user_tz":240,"elapsed":5186,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"360be435-a031-490d-cc5b-48860d8cf396","id":"XRWagncbmKuD"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' the'\n","What comes after Monday is Tuesday, and two days after is the\n","What comes after X is Y, and two days after is the\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the'\n","corr logit of new char: -0.8888349533081055\n","14th char = ' day'\n","What comes after Monday is Tuesday, and two days after is the day\n","What comes after X is Y, and two days after is the day\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day'\n","corr logit of new char: -0.8888349533081055\n","15th char = ' of'\n","What comes after Monday is Tuesday, and two days after is the day of\n","What comes after X is Y, and two days after is the day of\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day of'\n","corr logit of new char: -0.8888349533081055\n","16th char = ' the'\n","What comes after Monday is Tuesday, and two days after is the day of the\n","What comes after X is Y, and two days after is the day of the\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day of the'\n","corr logit of new char: -0.8888359069824219\n","17th char = ' first'\n","What comes after Monday is Tuesday, and two days after is the day of the first\n","What comes after X is Y, and two days after is the day of the first\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is the day of the first'\n","corr logit of new char: -0.8888354301452637\n","\n"," Total corr logit:  -4.444176197052002\n"]}]},{"cell_type":"markdown","source":["## ablate mlp 9"],"metadata":{"id":"eg9klRh8mick"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842221438,"user_tz":240,"elapsed":5360,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e2d4d63f-bd8a-46a2-8223-e190d888fb5c","id":"EWbw-PAgmick"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' Wednesday'\n","What comes after Monday is Tuesday, and two days after is Wednesday\n","What comes after X is Y, and two days after is Wednesday\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday'\n","corr logit of new char: -0.8782567977905273\n","14th char = '.'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.'\n","corr logit of new char: -0.8782567977905273\n","15th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n'\n","corr logit of new char: -0.8782567977905273\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n\\n'\n","corr logit of new char: -0.8782567977905273\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n\\n\\n'\n","corr logit of new char: -0.8782577514648438\n","\n"," Total corr logit:  -4.391284942626953\n"]}]},{"cell_type":"markdown","source":["## ablate just 9.1"],"metadata":{"id":"che-P0kUa0UK"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAN9D052mP-B","executionInfo":{"status":"ok","timestamp":1716842226451,"user_tz":240,"elapsed":5176,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c560b234-5907-426d-d194-f100bee11c5e"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' Monday'\n","What comes after Monday is Tuesday, and two days after is Monday\n","What comes after X is Y, and two days after is Monday\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday'\n","corr logit of new char: -0.49973201751708984\n","14th char = '.'\n","What comes after Monday is Tuesday, and two days after is Monday.\n","What comes after X is Y, and two days after is Monday.\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday.'\n","corr logit of new char: -0.49973201751708984\n","15th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Monday.\n","\n","What comes after X is Y, and two days after is Monday.\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday.\\n'\n","corr logit of new char: -0.49973201751708984\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Monday.\n","\n","\n","What comes after X is Y, and two days after is Monday.\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday.\\n\\n'\n","corr logit of new char: -0.49973201751708984\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Monday.\n","\n","\n","\n","What comes after X is Y, and two days after is Monday.\n","\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Monday.\\n\\n\\n'\n","corr logit of new char: -0.49973249435424805\n","\n"," Total corr logit:  -2.4986605644226074\n"]}]},{"cell_type":"markdown","source":["## ablate random head"],"metadata":{"id":"aJTIx8YobKLf"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iN-KEPUVmWTV","executionInfo":{"status":"ok","timestamp":1716842231163,"user_tz":240,"elapsed":4871,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7635fc0a-6887-4386-e654-6617021df85f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' Wednesday'\n","What comes after Monday is Tuesday, and two days after is Wednesday\n","What comes after X is Y, and two days after is Wednesday\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday'\n","corr logit of new char: -0.4928019046783447\n","14th char = '.'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.'\n","corr logit of new char: -0.4928019046783447\n","15th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n'\n","corr logit of new char: -0.4928019046783447\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n\\n'\n","corr logit of new char: -0.4928019046783447\n","16th char = '\\n'\n","What comes after Monday is Tuesday, and two days after is Wednesday.\n","\n","\n","\n","What comes after X is Y, and two days after is Wednesday.\n","\n","\n","\n","\n","\n","Sequence so far: 'What comes after Monday is Tuesday, and two days after is Wednesday.\\n\\n\\n'\n","corr logit of new char: -0.4928016662597656\n","\n"," Total corr logit:  -2.4640092849731445\n"]}]},{"cell_type":"markdown","source":["# test clean prompts"],"metadata":{"id":"NzaS2VB65KcX"}},{"cell_type":"code","source":["# clean_text = \"1\"\n","# tokens = model.to_tokens(clean_text).to(device)\n","# tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","# # tokens = model.tokenizer(clean_text)['input_ids']\n","# logits = model(tokens)\n","# next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","# next_char = model.to_string(next_token)\n","\n","clean_text = \"1\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842231163,"user_tz":240,"elapsed":176,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4751b00c-f774-4708-8430-cd90f8df7cdc","id":"QskNkr65Bqhy"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1'\n","logit diff of new char: tensor([10.5143], device='cuda:0')\n","2th char = '.'\n","Sequence so far: '1.'\n","logit diff of new char: tensor([11.9692], device='cuda:0')\n","3th char = '0'\n","Sequence so far: '1.0'\n","logit diff of new char: tensor([13.1672], device='cuda:0')\n","4th char = '.'\n","Sequence so far: '1.0.'\n","logit diff of new char: tensor([15.8012], device='cuda:0')\n","5th char = '0'\n","Sequence so far: '1.0.0'\n","logit diff of new char: tensor([14.2398], device='cuda:0')\n","6th char = '.'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["clean_text = \"two\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uU9Gdw8ZB1yi","executionInfo":{"status":"ok","timestamp":1716842231490,"user_tz":240,"elapsed":501,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ea541c01-da0d-4a1b-ca97-8afa8a4632b9"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'two'\n","logit diff of new char: tensor([9.6223], device='cuda:0')\n","2th char = ','\n","Sequence so far: 'two,'\n","logit diff of new char: tensor([10.2186], device='cuda:0')\n","3th char = ' and'\n","Sequence so far: 'two, and'\n","logit diff of new char: tensor([11.2373], device='cuda:0')\n","4th char = ' the'\n","Sequence so far: 'two, and the'\n","logit diff of new char: tensor([10.0012], device='cuda:0')\n","5th char = ' other'\n","Sequence so far: 'two, and the other'\n","logit diff of new char: tensor([12.4016], device='cuda:0')\n","6th char = ' two'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["clean_text = \"March\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_E-r4CmDQKj","executionInfo":{"status":"ok","timestamp":1716842231491,"user_tz":240,"elapsed":26,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"398be213-fb7f-4885-e020-c4d55a4772f4"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'March'\n","logit diff of new char: tensor([10.2301], device='cuda:0')\n","2th char = ','\n","Sequence so far: 'March,'\n","logit diff of new char: tensor([11.7677], device='cuda:0')\n","3th char = ' the'\n","Sequence so far: 'March, the'\n","logit diff of new char: tensor([10.4229], device='cuda:0')\n","4th char = ' U'\n","Sequence so far: 'March, the U'\n","logit diff of new char: tensor([19.0277], device='cuda:0')\n","5th char = '.'\n","Sequence so far: 'March, the U.'\n","logit diff of new char: tensor([20.5512], device='cuda:0')\n","6th char = 'S'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["clean_text = \"Bob is first. David is\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97-q7H6FDYcy","executionInfo":{"status":"ok","timestamp":1716842231790,"user_tz":240,"elapsed":319,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"645908c3-d643-45d5-b986-e4a11dcf7d27"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","logit diff of new char: tensor([15.9324], device='cuda:0')\n","7th char = ' second'\n","Sequence so far: 'Bob is first. David is second'\n","logit diff of new char: tensor([17.8772], device='cuda:0')\n","8th char = '.'\n","Sequence so far: 'Bob is first. David is second.'\n","logit diff of new char: tensor([16.3890], device='cuda:0')\n","9th char = '\\n'\n","Sequence so far: 'Bob is first. David is second.\\n'\n","logit diff of new char: tensor([22.0736], device='cuda:0')\n","10th char = '\\n'\n","Sequence so far: 'Bob is first. David is second.\\n\\n'\n","logit diff of new char: tensor([17.7922], device='cuda:0')\n","11th char = 'David'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["clean_text = \"Two days after Monday is\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842231791,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e11a129-b385-470f-ce18-f39cd64d052e","id":"4XlBEm6s5NVK"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Two days after Monday is'\n","logit diff of new char: tensor([13.7510], device='cuda:0')\n","6th char = ' when'\n","Sequence so far: 'Two days after Monday is when'\n","logit diff of new char: tensor([13.4375], device='cuda:0')\n","7th char = ' the'\n","Sequence so far: 'Two days after Monday is when the'\n","logit diff of new char: tensor([10.9209], device='cuda:0')\n","8th char = ' FBI'\n","Sequence so far: 'Two days after Monday is when the FBI'\n","logit diff of new char: tensor([15.5805], device='cuda:0')\n","9th char = ' announced'\n","Sequence so far: 'Two days after Monday is when the FBI announced'\n","logit diff of new char: tensor([16.2980], device='cuda:0')\n","10th char = ' it'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["clean_text = \"Bob is first in line. David is\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i11w8Rqo5SSm","executionInfo":{"status":"ok","timestamp":1716842232812,"user_tz":240,"elapsed":1038,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c9838b4e-d2cf-48e1-ff7a-85b80c3f72e2"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first in line. David is'\n","logit diff of new char: tensor([16.5300], device='cuda:0')\n","9th char = ' second'\n","Sequence so far: 'Bob is first in line. David is second'\n","logit diff of new char: tensor([18.4162], device='cuda:0')\n","10th char = '.'\n","Sequence so far: 'Bob is first in line. David is second.'\n","logit diff of new char: tensor([16.6176], device='cuda:0')\n","11th char = '\\n'\n","Sequence so far: 'Bob is first in line. David is second.\\n'\n","logit diff of new char: tensor([22.3888], device='cuda:0')\n","12th char = '\\n'\n","Sequence so far: 'Bob is first in line. David is second.\\n\\n'\n","logit diff of new char: tensor([18.9882], device='cuda:0')\n","13th char = 'David'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["clean_text = \"uno dos tres\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842232813,"user_tz":240,"elapsed":39,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fc0dafc9-b25e-4b2f-e4f4-186b021c8b4a","id":"m2SEHJ0K9HCm"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'uno dos tres'\n","logit diff of new char: tensor([11.3545], device='cuda:0')\n","5th char = ' un'\n","Sequence so far: 'uno dos tres un'\n","logit diff of new char: tensor([11.6727], device='cuda:0')\n","6th char = 'as'\n","Sequence so far: 'uno dos tres unas'\n","logit diff of new char: tensor([11.1833], device='cuda:0')\n","7th char = ' de'\n","Sequence so far: 'uno dos tres unas de'\n","logit diff of new char: tensor([10.9759], device='cuda:0')\n","8th char = ' la'\n","Sequence so far: 'uno dos tres unas de la'\n","logit diff of new char: tensor([11.1198], device='cuda:0')\n","9th char = ' v'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["clean_text = \"uno dos tres\"\n","corr_ans_tokLen = 3\n","\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"id":"lZF_IjOw9KcI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842232813,"user_tz":240,"elapsed":36,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7aca2d30-9a93-4ea9-9ef7-d1a086271dc7"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'uno dos tres'\n","logit diff of new char: tensor([11.3545], device='cuda:0')\n","5th char = ' un'\n","Sequence so far: 'uno dos tres un'\n","logit diff of new char: tensor([11.6727], device='cuda:0')\n","6th char = 'as'\n","Sequence so far: 'uno dos tres unas'\n","logit diff of new char: tensor([11.1833], device='cuda:0')\n","7th char = ' de'\n","Sequence so far: 'uno dos tres unas de'\n","logit diff of new char: tensor([10.9759], device='cuda:0')\n","8th char = ' la'\n","Sequence so far: 'uno dos tres unas de la'\n","logit diff of new char: tensor([11.1198], device='cuda:0')\n","9th char = ' v'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["# Bob is first. David is"],"metadata":{"id":"I7n8tg9X4S3f"}},{"cell_type":"code","source":["clean_text = \"Bob is first. David is\"\n","corr_text = \"Bob is X. David is\"\n","corr_ans_tokLen = 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842232813,"user_tz":240,"elapsed":32,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"EWbvPx0F4S3h"},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"-Sf4KRM24S3j"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842233863,"user_tz":240,"elapsed":1082,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"17c269fd-24de-4379-866c-ec7a4e53f4e4","id":"I8iCKfhw4S3j"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' second'\n","Bob is first. David is second\n","Bob is X. David is second\n","\n","\n","Sequence so far: 'Bob is first. David is second'\n","corr logit of new char: 0.4071230888366699\n","\n"," Total corr logit:  0.4071230888366699\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"iqvIYs3g4S3k"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842235719,"user_tz":240,"elapsed":1872,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"122bb0a0-4443-43ae-86a0-1c355ca0c9ae","id":"aM0sRA7H4S3k"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' second'\n","Bob is first. David is second\n","Bob is X. David is second\n","\n","\n","Sequence so far: 'Bob is first. David is second'\n","corr logit of new char: 0.6557116508483887\n","\n"," Total corr logit:  0.6557116508483887\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"4YW-N-otF6Si"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842237928,"user_tz":240,"elapsed":2362,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bbfcef9f-c765-4b0c-a1bd-684981c0540a","id":"RJG6na3WF6Sm"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' second'\n","Bob is first. David is second\n","Bob is X. David is second\n","\n","\n","Sequence so far: 'Bob is first. David is second'\n","corr logit of new char: 0.37902164459228516\n","\n"," Total corr logit:  0.37902164459228516\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"srZUTMcg4S3l"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842238444,"user_tz":240,"elapsed":671,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f17cc5f5-106c-42a7-aaa3-039cff8e1eb5","id":"aJiibmF04S3l"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' second'\n","Bob is first. David is second\n","Bob is X. David is second\n","\n","\n","Sequence so far: 'Bob is first. David is second'\n","corr logit of new char: 0.6732892990112305\n","\n"," Total corr logit:  0.6732892990112305\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"3Ebd3aBF4S3m"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842240482,"user_tz":240,"elapsed":2050,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5aec2051-359f-4f68-f872-4598e50380e9","id":"gw0gj-5i4S3m"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' second'\n","Bob is first. David is second\n","Bob is X. David is second\n","\n","\n","Sequence so far: 'Bob is first. David is second'\n","corr logit of new char: 0.6711874008178711\n","\n"," Total corr logit:  0.6711874008178711\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"GrfUIbqG4S3n"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842242056,"user_tz":240,"elapsed":1732,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9b483a12-dea1-4b1e-ef14-139849d1d79e","id":"dIgVbK4e4S3n"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' second'\n","Bob is first. David is second\n","Bob is X. David is second\n","\n","\n","Sequence so far: 'Bob is first. David is second'\n","corr logit of new char: 0.4114093780517578\n","\n"," Total corr logit:  0.4114093780517578\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"o0yXax2F4S3n"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842243280,"user_tz":240,"elapsed":1380,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"aff5c7ec-f474-483b-8cb5-3d5056190f3d","id":"1E5ImSrf4S3n"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' second'\n","Bob is first. David is second\n","Bob is X. David is second\n","\n","\n","Sequence so far: 'Bob is first. David is second'\n","corr logit of new char: 0.40241003036499023\n","\n"," Total corr logit:  0.40241003036499023\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"Be0EK8Yg8dKY"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842244813,"user_tz":240,"elapsed":1539,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"403c73f9-971b-44a9-a44c-fe02a35c02da","id":"nnJnQdEK8dKd"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'Bob is first. David is'\n","7th char = ' Y'\n","Bob is first. David is Y\n","Bob is X. David is Y\n","\n","\n","Sequence so far: 'Bob is first. David is Y'\n","corr logit of new char: 1.2515344619750977\n","\n"," Total corr logit:  1.2515344619750977\n"]}]},{"cell_type":"markdown","source":["# one two three"],"metadata":{"id":"APiwKoUD9MM6"}},{"cell_type":"code","source":["clean_text = \"one two three\"\n","corr_text = \"five nine two\"\n","corr_ans_tokLen = 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842244813,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"24_968909MM7"},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"dGxJvhEJ9MM8"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842246062,"user_tz":240,"elapsed":1259,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"298baae1-4873-4d4c-a659-d1e7ec606ea4","id":"VxCow5xf9MM8"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 5.505155086517334\n","\n"," Total corr logit:  5.505155086517334\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"TT8O39J29MM9"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842247365,"user_tz":240,"elapsed":1455,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"24877a65-cb7e-4829-d8f7-33f9d23f2dd0","id":"z3GcWDTc9MM9"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = '-'\n","one two three-\n","five nine two-\n","\n","\n","Sequence so far: 'one two three-'\n","corr logit of new char: -0.5595006942749023\n","\n"," Total corr logit:  -0.5595006942749023\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"sAzUkqoVGBn1"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842248609,"user_tz":240,"elapsed":1396,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f2e0eb14-41a1-4aeb-e382-620ca44beed1","id":"KrNA2cTQGBn4"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = '-'\n","one two three-\n","five nine two-\n","\n","\n","Sequence so far: 'one two three-'\n","corr logit of new char: -1.0319595336914062\n","\n"," Total corr logit:  -1.0319595336914062\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"NZQI29DW9MM-"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842249502,"user_tz":240,"elapsed":1052,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a749565a-79bf-40d9-c819-799109febb9e","id":"vnj-1qq79MM-"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 2.635061264038086\n","\n"," Total corr logit:  2.635061264038086\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"WX2JdPiN9MM-"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842250411,"user_tz":240,"elapsed":915,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"00beec79-a07f-4ca6-f235-7c90d9d6a47e","id":"gVHSuZuP9MM-"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 3.019651412963867\n","\n"," Total corr logit:  3.019651412963867\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"oKOlOISe9MM_"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842251783,"user_tz":240,"elapsed":1378,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4b04554f-26cf-498a-9a9a-cf5afdee65bc","id":"chuCtE9w9MM_"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 5.045960903167725\n","\n"," Total corr logit:  5.045960903167725\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"jKLK1cG-9MM_"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842252571,"user_tz":240,"elapsed":932,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e5a0d47d-ae40-473a-e6bf-8734ea7a95b2","id":"A0TkDv0Z9MM_"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 5.4420366287231445\n","\n"," Total corr logit:  5.4420366287231445\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"z1CwiVib9MM_"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842253337,"user_tz":240,"elapsed":780,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4b26f03c-f392-4ab0-b984-092ddd4b4475","id":"IhDpClAM9MNA"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' five'\n","one two three five\n","five nine two five\n","\n","\n","Sequence so far: 'one two three five'\n","corr logit of new char: -0.12970507144927979\n","\n"," Total corr logit:  -0.12970507144927979\n"]}]},{"cell_type":"markdown","source":["# January February March"],"metadata":{"id":"YNb5u__D-mho"}},{"cell_type":"code","source":["clean_text = \"January February March\"\n","corr_text = \"April July July\"\n","corr_ans_tokLen = 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842253338,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"NKMrT7AM-mhu"},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"Ntg-NYMI-mhw"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842254360,"user_tz":240,"elapsed":1034,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a7bff45c-9962-4771-9b09-e7687f3e3ce8","id":"nqempkAq-mhx"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 9.440199851989746\n","\n"," Total corr logit:  9.440199851989746\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"4bBGK0fT-mhz"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842255835,"user_tz":240,"elapsed":1489,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f943f4c3-03b9-45f8-b4ef-f93fedbe3e8f","id":"sYwo-hbN-mhz"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' August'\n","January February March August\n","April July July August\n","\n","\n","Sequence so far: 'January February March August'\n","corr logit of new char: -1.1505086421966553\n","\n"," Total corr logit:  -1.1505086421966553\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"IW9C9na0GlWw"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842256956,"user_tz":240,"elapsed":1259,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c7c72f13-a45a-4940-b37d-e639b92e7971","id":"LHkMwhk2GlWz"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 0.5852069854736328\n","\n"," Total corr logit:  0.5852069854736328\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"glwEPyTQ-mh0"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842258007,"user_tz":240,"elapsed":1199,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"42f40d32-894a-433d-d973-04c5ec1ce2e1","id":"FmRYyq8i-mh2"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: -3.3458361625671387\n","\n"," Total corr logit:  -3.3458361625671387\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"0aqu4XD4-mh3"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842258568,"user_tz":240,"elapsed":580,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c5e22a32-50e1-48dc-bbf4-4de0d2e9a73a","id":"6nVsvIfx-mh3"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: -0.9824318885803223\n","\n"," Total corr logit:  -0.9824318885803223\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"r9hYFKPu-mh3"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842259475,"user_tz":240,"elapsed":917,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"57ec3d61-b297-4c50-b63d-c0352b8b508c","id":"ft2EwL5Q-mh4"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 8.566516876220703\n","\n"," Total corr logit:  8.566516876220703\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"SBYrnRrf-mh6"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842262736,"user_tz":240,"elapsed":3277,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b4007dd5-d30e-4ec7-9652-e1aece131c87","id":"zWIkcejk-mh6"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 9.635494232177734\n","\n"," Total corr logit:  9.635494232177734\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"OSLJ4_sa-mh7"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842263671,"user_tz":240,"elapsed":944,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"33ed036f-e552-4fe1-ec57-0a112fb1ccdb","id":"eYGW8TdI-mh7"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' August'\n","January February March August\n","April July July August\n","\n","\n","Sequence so far: 'January February March August'\n","corr logit of new char: -1.855480670928955\n","\n"," Total corr logit:  -1.855480670928955\n"]}]},{"cell_type":"markdown","source":["# 1 2 3 4 5 6"],"metadata":{"id":"RSAG_kolBerZ"}},{"cell_type":"code","source":["clean_text = \"1 2 3 4 5 6\"\n","corr_text = \"8 5 9 4 2 4\"\n","corr_ans_tokLen = 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842263672,"user_tz":240,"elapsed":26,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"XS22bRVGBerj"},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"HF-SJFShBerl"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842263672,"user_tz":240,"elapsed":26,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bb6a8e67-79f1-4db9-e4db-1787803c2479","id":"-LnT-30TBerl"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","8 5 9 4 2 4 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 6.063086032867432\n","\n"," Total corr logit:  6.063086032867432\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"JHusG_QZBern"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842265227,"user_tz":240,"elapsed":1579,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6b45974e-d137-48d5-8db1-bd1da193fa0d","id":"iIVynkS2Bern"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 6'\n","1 2 3 4 5 6 6\n","8 5 9 4 2 4 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6 6'\n","corr logit of new char: -0.3448066711425781\n","\n"," Total corr logit:  -0.3448066711425781\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"yZCVHsRJFGen"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6gcobzzFHuC","executionInfo":{"status":"ok","timestamp":1716842266342,"user_tz":240,"elapsed":1320,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e59120a5-70d8-4448-f8d0-369332dc4542"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","8 5 9 4 2 4 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 1.3072271347045898\n","\n"," Total corr logit:  1.3072271347045898\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"shvANOBKBero"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842267947,"user_tz":240,"elapsed":1618,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b273fbab-105d-41c0-c826-fc7aa6f69280","id":"I935E0K-Bero"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","8 5 9 4 2 4 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: -0.2949347496032715\n","\n"," Total corr logit:  -0.2949347496032715\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"HwQp-f5yBerp"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842269593,"user_tz":240,"elapsed":1796,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0e374fb4-be5c-4be3-f0ac-7da7dde80de9","id":"wfAGvDzkBerp"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","8 5 9 4 2 4 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 0.2177433967590332\n","\n"," Total corr logit:  0.2177433967590332\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"MYiRGaUzBerp"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842271274,"user_tz":240,"elapsed":1826,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"895aa569-980b-4424-b50c-be39af7d4ae0","id":"dm9e36SbBerq"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","8 5 9 4 2 4 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 5.689393997192383\n","\n"," Total corr logit:  5.689393997192383\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"2el7wAiiBerq"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842273347,"user_tz":240,"elapsed":2086,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2d61af24-9f4f-4422-c435-846585ad10d6","id":"O7jkbtslBerq"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","8 5 9 4 2 4 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 6.105478763580322\n","\n"," Total corr logit:  6.105478763580322\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"R_L7vZmFBerr"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842274446,"user_tz":240,"elapsed":1246,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f7384111-ae59-48a8-90cd-bebb7826aefe","id":"C8n_qEL3Berr"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6'\n","7th char = ' 3'\n","1 2 3 4 5 6 3\n","8 5 9 4 2 4 3\n","\n","\n","Sequence so far: '1 2 3 4 5 6 3'\n","corr logit of new char: -0.07252740859985352\n","\n"," Total corr logit:  -0.07252740859985352\n"]}]},{"cell_type":"markdown","source":["# 1 to 50"],"metadata":{"id":"uig6LghNHpvV"}},{"cell_type":"code","source":["import random\n","\n","# Generate a string of numbers from 1 to 50\n","sequence_string = ' '.join(map(str, range(1, 51)))\n","\n","# Generate a string of random numbers picked from 1 to 50\n","random_numbers = [random.randint(1, 50) for _ in range(50)]\n","random_string = ' '.join(map(str, random_numbers))\n","\n","print(\"Sequence String: \", sequence_string)\n","print(\"Random Numbers String: \", random_string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kizd0_-2H7sD","executionInfo":{"status":"ok","timestamp":1716842274446,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"736c0834-9a74-4be2-ca31-d053c438fb77"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence String:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n","Random Numbers String:  34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49\n"]}]},{"cell_type":"code","source":["clean_text = sequence_string\n","corr_text = random_string\n","corr_ans_tokLen = 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842274446,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"HoDIMqspHpvX"},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"RMEnB8YRHpvY"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842276727,"user_tz":240,"elapsed":2296,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d22c08cc-97fb-471a-f02b-91740c354588","id":"tI4pzGJxHpvZ"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 51'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 51\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51'\n","corr logit of new char: 6.063088417053223\n","\n"," Total corr logit:  6.063088417053223\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"qgX3fFgRHpvZ"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842278985,"user_tz":240,"elapsed":2403,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3b279a69-34c0-4adb-ae79-834c5920fc55","id":"qZYDqfkKHpva"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 51'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 51\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51'\n","corr logit of new char: -3.1905994415283203\n","\n"," Total corr logit:  -3.1905994415283203\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"A0MgPHxcHpva"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842281038,"user_tz":240,"elapsed":2196,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8b4c1e24-e3ae-4a46-c275-5b724f97a116","id":"rvgUPMNAHpva"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 51'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 51\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51'\n","corr logit of new char: 2.5344972610473633\n","\n"," Total corr logit:  2.5344972610473633\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"PT_dK_CjHpvb"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842283585,"user_tz":240,"elapsed":2693,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e8f68a4b-f12b-4a61-e1aa-302f909e7178","id":"_YVi7jnAHpvb"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 51'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 51\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51'\n","corr logit of new char: -3.2330355644226074\n","\n"," Total corr logit:  -3.2330355644226074\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"m6_Of2sjHpvb"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842285790,"user_tz":240,"elapsed":2397,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e4724cdf-bf41-4479-da72-fd735d713daa","id":"jJEwzes4Hpvb"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 51'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 51\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51'\n","corr logit of new char: -1.9877004623413086\n","\n"," Total corr logit:  -1.9877004623413086\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"feehsdazHpvc"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842287925,"user_tz":240,"elapsed":2381,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2cf30478-d0d4-4abc-cb1a-0bfc55394440","id":"5dcmUOvGHpvc"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 51'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 51\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51'\n","corr logit of new char: 2.6247963905334473\n","\n"," Total corr logit:  2.6247963905334473\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"s2KMjM-iHpvc"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842290298,"user_tz":240,"elapsed":2517,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cc2c10ec-1ec3-4831-a35b-3fa124f6a86d","id":"QeSanPS5Hpvc"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 51'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 51\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51'\n","corr logit of new char: 6.098381042480469\n","\n"," Total corr logit:  6.098381042480469\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"V4tRA246Hpvc"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842292248,"user_tz":240,"elapsed":2107,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"12123d0d-723f-464f-e5dc-9b35b0d11b51","id":"IM1lP0npHpvd"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50'\n","51th char = ' 25'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 25\n","34 32 3 33 41 8 27 25 35 29 27 18 27 29 11 42 5 13 20 5 2 45 8 3 30 35 28 33 32 1 47 12 31 48 20 8 27 25 24 50 25 3 19 50 48 22 50 8 7 49 25\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 25'\n","corr logit of new char: -3.4891464710235596\n","\n"," Total corr logit:  -3.4891464710235596\n"]}]},{"cell_type":"markdown","source":["# 1 to 20"],"metadata":{"id":"J2QOISady5hH"}},{"cell_type":"code","source":["import random\n","\n","# Generate a string of numbers from 1 to 50\n","sequence_string = ' '.join(map(str, range(1, 21)))\n","\n","# Generate a string of random numbers picked from 1 to 50\n","random_numbers = [random.randint(1, 20) for _ in range(20)]\n","random_string = ' '.join(map(str, random_numbers))\n","\n","print(\"Sequence String: \", sequence_string)\n","print(\"Random Numbers String: \", random_string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842687402,"user_tz":240,"elapsed":616,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d566f632-7980-4543-fa0e-4ed2af1ddc59","id":"YVWMH1-Hy5hO"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence String:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\n","Random Numbers String:  19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19\n"]}]},{"cell_type":"code","source":["clean_text = sequence_string\n","corr_text = random_string\n","corr_ans_tokLen = 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842687974,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"VZw1uQF0y5hO"},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"sNFa0sMSy5hO"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842689827,"user_tz":240,"elapsed":1867,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b4904bdf-e3de-46d8-ee68-786a14fcf4c3","id":"DJ0qF6Fjy5hO"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 21'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 21\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21'\n","corr logit of new char: 6.063088417053223\n","\n"," Total corr logit:  6.063088417053223\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"Nd_YsBaKy5hO"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842691615,"user_tz":240,"elapsed":1807,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bbde604a-a25b-4f93-f955-da1deb121207","id":"WADePlAYy5hO"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 20'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 20\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 20\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 20'\n","corr logit of new char: -0.41758298873901367\n","\n"," Total corr logit:  -0.41758298873901367\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"NCRKkeYhy5hP"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842693312,"user_tz":240,"elapsed":1718,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"38901c84-112c-409b-9db8-8c6299af8dbe","id":"DUMdu1yKy5hP"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 21'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 21\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21'\n","corr logit of new char: 1.1238365173339844\n","\n"," Total corr logit:  1.1238365173339844\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"0F5P4Q-oy5hP"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842695321,"user_tz":240,"elapsed":2026,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"808bb6fe-6069-456b-f38b-a3eecae689bd","id":"xeL6nD0Zy5hP"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 21'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 21\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21'\n","corr logit of new char: -0.5075206756591797\n","\n"," Total corr logit:  -0.5075206756591797\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"CtY9UCWay5hP"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842698305,"user_tz":240,"elapsed":3004,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cb7094cf-1236-4628-cf76-dc1fe2c72e30","id":"M-FonHFHy5hP"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 21'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 21\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21'\n","corr logit of new char: 0.18439197540283203\n","\n"," Total corr logit:  0.18439197540283203\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"ejKtftGYy5hP"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842698896,"user_tz":240,"elapsed":618,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"67ec861f-383f-45b1-c12f-05ebea52c5b0","id":"tizt0Y54y5hP"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 21'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 21\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21'\n","corr logit of new char: 5.55417537689209\n","\n"," Total corr logit:  5.55417537689209\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"8QOT5xvFy5hQ"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842700616,"user_tz":240,"elapsed":1733,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"26d27613-51c6-4aec-9e48-1768057f2f48","id":"1QYIQ3wdy5hQ"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 21'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 21\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21'\n","corr logit of new char: 6.122335433959961\n","\n"," Total corr logit:  6.122335433959961\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"MNi34ttFy5hQ"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842702314,"user_tz":240,"elapsed":1722,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"013940e3-669a-47ca-87e6-8564516878a3","id":"9rT0faEKy5hQ"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20'\n","21th char = ' 20'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 20\n","19 17 16 3 19 10 19 18 18 6 16 8 12 1 18 15 5 20 18 19 20\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 20'\n","corr logit of new char: -0.2929258346557617\n","\n"," Total corr logit:  -0.2929258346557617\n"]}]},{"cell_type":"markdown","source":["# 1 to 100"],"metadata":{"id":"l3Rrz-r7yuGS"}},{"cell_type":"code","source":["import random\n","\n","# Generate a string of numbers from 1 to 50\n","sequence_string = ' '.join(map(str, range(1, 101)))\n","\n","# Generate a string of random numbers picked from 1 to 50\n","random_numbers = [random.randint(1, 100) for _ in range(100)]\n","random_string = ' '.join(map(str, random_numbers))\n","\n","print(\"Sequence String: \", sequence_string)\n","print(\"Random Numbers String: \", random_string)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842740666,"user_tz":240,"elapsed":359,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6c95e0df-8291-449c-c4e6-7ff3eb8ff3ca","id":"9CaYfZs6yuGT"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence String:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","Random Numbers String:  17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n"]}]},{"cell_type":"code","source":["clean_text = sequence_string\n","corr_text = random_string\n","corr_ans_tokLen = 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716842741532,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"QVUDnF1CyuGT"},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"kg-RuflzyuGU"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842743112,"user_tz":240,"elapsed":1597,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9b7e6a00-33cf-4924-cc8b-c488fc44a2d5","id":"nxCTe3cMyuGU"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = '\\n'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n","\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\n'\n","corr logit of new char: 6.063076019287109\n","\n"," Total corr logit:  6.063076019287109\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"ehKzt7xjyuGU"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842745582,"user_tz":240,"elapsed":2487,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f483b286-b7d3-4a1b-85a7-bd68c0a86657","id":"vNpjmIXgyuGV"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = '\\n'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n","\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\n'\n","corr logit of new char: -0.5152492523193359\n","\n"," Total corr logit:  -0.5152492523193359\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"pXYkuAemyuGV"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842748251,"user_tz":240,"elapsed":2915,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9e1a5172-4b61-438b-b7ae-201c92ce8d0b","id":"w6ZWV5K0yuGV"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = '\\n'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n","\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\n'\n","corr logit of new char: 1.6735329627990723\n","\n"," Total corr logit:  1.6735329627990723\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"m_s7bFk-yuGV"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842749512,"user_tz":240,"elapsed":1276,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6b350e8d-35bb-4fd1-cd87-9648b27acc44","id":"rv54UO-9yuGW"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = '\\n'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n","\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\n'\n","corr logit of new char: -0.6491785049438477\n","\n"," Total corr logit:  -0.6491785049438477\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"GvrJWNsNyuGW"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842751570,"user_tz":240,"elapsed":2072,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7002cc51-4818-4c31-b4fa-55b83e312eaf","id":"j1JnyUdLyuGW"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = '\\n'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n","\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\n'\n","corr logit of new char: -0.055047035217285156\n","\n"," Total corr logit:  -0.055047035217285156\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"FF42aW3NyuGW"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842753645,"user_tz":240,"elapsed":2092,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"db4224c1-88e0-4d01-cb03-1e5e9354b92a","id":"KZoHv0H6yuGW"},"execution_count":125,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = '\\n'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n","\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\n'\n","corr logit of new char: 5.786046981811523\n","\n"," Total corr logit:  5.786046981811523\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"fF_i6xwPyuGX"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842755584,"user_tz":240,"elapsed":1956,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9ebbdac7-7711-4696-e415-75c6f3056f9c","id":"TNAm4YZEyuGX"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = '\\n'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n","\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62\n","\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\n'\n","corr logit of new char: 6.09390926361084\n","\n"," Total corr logit:  6.09390926361084\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"H0k6NJEEyuGX"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842757506,"user_tz":240,"elapsed":1936,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a46cd78c-c6e4-4b90-aee0-9735ac06ee2c","id":"j2kyCqK5yuGX"},"execution_count":127,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100'\n","101th char = ' 65'\n","1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 65\n","17 50 98 49 40 17 48 29 11 61 99 97 66 54 12 1 90 99 24 29 24 54 60 95 85 75 24 1 11 63 78 84 46 26 15 4 83 50 62 54 98 75 15 80 39 63 73 48 68 64 95 62 26 94 39 86 15 16 85 78 72 13 84 84 42 77 97 63 26 6 10 47 91 31 1 36 15 31 49 51 13 80 69 79 55 3 20 24 44 54 17 45 82 95 96 36 81 26 62 62 65\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 65'\n","corr logit of new char: -0.8393421173095703\n","\n"," Total corr logit:  -0.8393421173095703\n"]}]}]}