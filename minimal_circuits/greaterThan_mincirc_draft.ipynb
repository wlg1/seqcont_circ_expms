{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DcZG9rm2IAiA","OLkInsdjyHMx","DQF0lzuokQer","6aByCOwUxQm7","o56Altbhz7i6"],"gpuType":"T4","authorship_tag":"ABX9TyOIx6b0+8zkWhERFpsOINuR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"97af0a163ed7487f94ebdee46ac2b104":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84d55543a98842e6a6c4b2bdb64812e3","IPY_MODEL_9ca7dd76a4184b9fa88ad184e70a6d58","IPY_MODEL_4414b8631e374f49a9b89a85c781626c"],"layout":"IPY_MODEL_4870724d5acc4b93bc0b5a2f9334c07a"}},"84d55543a98842e6a6c4b2bdb64812e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb41f0cd20084915ba74884a3d917b27","placeholder":"​","style":"IPY_MODEL_6feaa880919f4c058a8dc761e62d045c","value":"Downloading (…)lve/main/config.json: 100%"}},"9ca7dd76a4184b9fa88ad184e70a6d58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd19add567094cabbd9a270710aae9d4","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9ba87e06c374469beaf91f072601dbe","value":665}},"4414b8631e374f49a9b89a85c781626c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b52f8c2463664629a7ca848e72468806","placeholder":"​","style":"IPY_MODEL_642c570849b34c3eaee9bcd2c1e42fce","value":" 665/665 [00:00&lt;00:00, 46.4kB/s]"}},"4870724d5acc4b93bc0b5a2f9334c07a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb41f0cd20084915ba74884a3d917b27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6feaa880919f4c058a8dc761e62d045c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd19add567094cabbd9a270710aae9d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9ba87e06c374469beaf91f072601dbe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b52f8c2463664629a7ca848e72468806":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642c570849b34c3eaee9bcd2c1e42fce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5be2b67186594af2861742a4f67e9157":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5f5036afa674431b3e5c6fc68bc1ae9","IPY_MODEL_4e15ebcaf79d49f49139f4754b5241a5","IPY_MODEL_cc3239d17c5b4afeaeb3f23b2387c90d"],"layout":"IPY_MODEL_9a8b5bf8230f4e75ac397755d0ca4c60"}},"b5f5036afa674431b3e5c6fc68bc1ae9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b33108896a34d6eb1881628ac5970da","placeholder":"​","style":"IPY_MODEL_387d8ce4df4f4fc6859f43d87359d395","value":"Downloading model.safetensors: 100%"}},"4e15ebcaf79d49f49139f4754b5241a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_890d81184fbd451d95a7bf64a7c55fd3","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fbd882d35354b77947019eff9119319","value":548105171}},"cc3239d17c5b4afeaeb3f23b2387c90d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bb17612368242d8a99a6ac51575eee4","placeholder":"​","style":"IPY_MODEL_96a95353771f43f78d6fa482d8467678","value":" 548M/548M [00:05&lt;00:00, 136MB/s]"}},"9a8b5bf8230f4e75ac397755d0ca4c60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b33108896a34d6eb1881628ac5970da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"387d8ce4df4f4fc6859f43d87359d395":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"890d81184fbd451d95a7bf64a7c55fd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fbd882d35354b77947019eff9119319":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bb17612368242d8a99a6ac51575eee4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96a95353771f43f78d6fa482d8467678":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"009b4cb8a02f4e26af998f62479327b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca2edbdb3b4c42d19823cb50515e837b","IPY_MODEL_7469aa9a640b433db61e7d0e52d7adc4","IPY_MODEL_63a47566121643f2ac5a676b8292645c"],"layout":"IPY_MODEL_42983323c6ef4dc486cbf46e5c419eb0"}},"ca2edbdb3b4c42d19823cb50515e837b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1c9fda63a9a4871bbfbb6c74b2bbd68","placeholder":"​","style":"IPY_MODEL_9fcff072dfaf4b6cba4f1f1829b90a81","value":"Downloading (…)neration_config.json: 100%"}},"7469aa9a640b433db61e7d0e52d7adc4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9609cbfc8ce746f2913b92880f1ee58a","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffb597a39ae14275805934e28de59bcd","value":124}},"63a47566121643f2ac5a676b8292645c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d88ef946dbc492aa91f1f4ec608ab5a","placeholder":"​","style":"IPY_MODEL_2fbb4a8430a1477aa366ebbf297cb225","value":" 124/124 [00:00&lt;00:00, 2.82kB/s]"}},"42983323c6ef4dc486cbf46e5c419eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c9fda63a9a4871bbfbb6c74b2bbd68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fcff072dfaf4b6cba4f1f1829b90a81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9609cbfc8ce746f2913b92880f1ee58a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffb597a39ae14275805934e28de59bcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d88ef946dbc492aa91f1f4ec608ab5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fbb4a8430a1477aa366ebbf297cb225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d6c1598b42c4db29b972d843fa547de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40e104a573f24d8e9e03195e826854ff","IPY_MODEL_843fe838d1a94b9e96ce1d77b5f01c4d","IPY_MODEL_e664f522e29b49218e0ff2ff9289ca8b"],"layout":"IPY_MODEL_7c2ad2ced20847ecb5f1e463a9488ab3"}},"40e104a573f24d8e9e03195e826854ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a29edc9e1b88430b9de902c47c039919","placeholder":"​","style":"IPY_MODEL_5a86757b9608455281345f577514368f","value":"Downloading (…)olve/main/vocab.json: 100%"}},"843fe838d1a94b9e96ce1d77b5f01c4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35dddb671ac54735b175ccf7a4442dbf","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12443f40247e43aa866a2f6fffe71c32","value":1042301}},"e664f522e29b49218e0ff2ff9289ca8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cff99288cfa4cb88628ada15b02c07c","placeholder":"​","style":"IPY_MODEL_c5130f0094b44953a3595515e4c1b9ec","value":" 1.04M/1.04M [00:00&lt;00:00, 4.21MB/s]"}},"7c2ad2ced20847ecb5f1e463a9488ab3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a29edc9e1b88430b9de902c47c039919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a86757b9608455281345f577514368f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35dddb671ac54735b175ccf7a4442dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12443f40247e43aa866a2f6fffe71c32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cff99288cfa4cb88628ada15b02c07c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5130f0094b44953a3595515e4c1b9ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74ca248701ed4abd9fdb80afdb9ffd58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc61a7bccd1045b1a70bcb9ee7de0741","IPY_MODEL_638bbb81c42146e3a0cb0bd42d8f43a3","IPY_MODEL_dca7f24e48094c14a861c6cd2d555036"],"layout":"IPY_MODEL_2b4e0289bd204ee4b40501948a0e803c"}},"cc61a7bccd1045b1a70bcb9ee7de0741":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da629d4bee7149d59e09f45bd2ed9b69","placeholder":"​","style":"IPY_MODEL_79243a55fbf54b94a8343d867759b162","value":"Downloading (…)olve/main/merges.txt: 100%"}},"638bbb81c42146e3a0cb0bd42d8f43a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d61e3fd50095404f98ed9a1181d234d1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_000ac1bd0ab049a99031699feba6dfca","value":456318}},"dca7f24e48094c14a861c6cd2d555036":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2240595bfdd447eaa27a93c19386ea4f","placeholder":"​","style":"IPY_MODEL_203cca3578d740d08c88d290105b48d5","value":" 456k/456k [00:00&lt;00:00, 7.97MB/s]"}},"2b4e0289bd204ee4b40501948a0e803c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da629d4bee7149d59e09f45bd2ed9b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79243a55fbf54b94a8343d867759b162":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d61e3fd50095404f98ed9a1181d234d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"000ac1bd0ab049a99031699feba6dfca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2240595bfdd447eaa27a93c19386ea4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"203cca3578d740d08c88d290105b48d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"859d6996882542c9851df11bb1a7c5f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b8e24a5b3ee4f3f9ea1ea807ca30423","IPY_MODEL_5195f5c443b243fc8f96ad8e8aed5bf4","IPY_MODEL_5571c542c0604808a3ab8538bc6adea2"],"layout":"IPY_MODEL_f1729d4dd03c491a82b28d64266961ec"}},"7b8e24a5b3ee4f3f9ea1ea807ca30423":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07d6599a3446485880d9a3fbc92f83db","placeholder":"​","style":"IPY_MODEL_fdcfe08751234db5b361b067f8f3d492","value":"Downloading (…)/main/tokenizer.json: 100%"}},"5195f5c443b243fc8f96ad8e8aed5bf4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98559b0d2f0a478a89cfb11712523a91","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d30fe378aa84287b487012fafabe1a2","value":1355256}},"5571c542c0604808a3ab8538bc6adea2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20d9bc95c11d484da66766acb9b92ee2","placeholder":"​","style":"IPY_MODEL_0558d6def14a4da7845ac754ecb8c78b","value":" 1.36M/1.36M [00:00&lt;00:00, 10.2MB/s]"}},"f1729d4dd03c491a82b28d64266961ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d6599a3446485880d9a3fbc92f83db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdcfe08751234db5b361b067f8f3d492":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98559b0d2f0a478a89cfb11712523a91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d30fe378aa84287b487012fafabe1a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20d9bc95c11d484da66766acb9b92ee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0558d6def14a4da7845ac754ecb8c78b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"b13177b7"},"source":["<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698591592619,"user_tz":240,"elapsed":207120,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"014060ef-75f6-43d0-ec57-2f8792aa81e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-o3tsl1as\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-o3tsl1as\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit fa287750606075574df2c538058e67d648e2f952\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate>=0.23.0 (from transformer-lens==0.0.0)\n","  Downloading accelerate-0.24.0-py3-none-any.whl (260 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n","Collecting numpy>=1.24 (from transformer-lens==0.0.0)\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cublas_cu12-12.3.2.9-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (24.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl (720.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.1/720.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cufft_cu12-11.0.11.19-py3-none-manylinux1_x86_64.whl (98.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_curand_cu12-10.3.4.52-py3-none-manylinux1_x86_64.whl (56.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusolver_cu12-11.5.3.52-py3-none-manylinux1_x86_64.whl (125.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusparse_cu12-12.1.3.153-py3-none-manylinux1_x86_64.whl (195.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nvtx_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.6)\n","Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens==0.0.0)\n","  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=116432 sha256=c797ec6c169bd4dd3b94c94a6a6e6c77438ff526c16d7937b5c638131c77e4db\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_oiiux69/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=f9aa9e5f24a21bde841ec2dd20851a459112d24dfb0a0de207e28706c63272e4\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, huggingface-hub, gitdb, tokenizers, nvidia-cusolver-cu12, GitPython, accelerate, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.24.0 beartype-0.14.1 datasets-2.14.6 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 huggingface-hub-0.17.3 jaxtyping-0.2.23 multiprocess-0.70.15 numpy-1.26.1 nvidia-cublas-cu12-12.3.2.9 nvidia-cuda-cupti-cu12-12.3.52 nvidia-cuda-nvrtc-cu12-12.3.52 nvidia-cuda-runtime-cu12-12.3.52 nvidia-cudnn-cu12-8.9.4.25 nvidia-cufft-cu12-11.0.11.19 nvidia-curand-cu12-10.3.4.52 nvidia-cusolver-cu12-11.5.3.52 nvidia-cusparse-cu12-12.1.3.153 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.3.52 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.34.1 typeguard-2.13.3 wandb-0.15.12\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n","\n","  \n","  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n","  install Node.js is deprecated now and will eventually be made inactive.\n","\n","  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n","  instructions to migrate your repo.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n","  information about which versions of Node.js and which Linux distributions\n","  are supported and how to install it.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","\n","                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n","Continuing in 60 seconds (press Ctrl-C to abort) ...\n","\n","\n","## Installing the NodeSource Node.js 16.x repo...\n","\n","\n","## Populating apt-get cache...\n","\n","+ apt-get update\n","Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [44.8 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n","Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,131 kB]\n","Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,009 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,274 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,400 kB]\n","Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,231 kB]\n","Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,145 kB]\n","Fetched 8,594 kB in 4s (2,197 kB/s)\n","Reading package lists... Done\n","\n","## Confirming \"jammy\" is supported...\n","\n","+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n","\n","## Adding the NodeSource signing key to your keyring...\n","\n","+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n","\n","## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n","\n","+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n","+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n","\n","## Running `apt-get update` for you...\n","\n","+ apt-get update\n","Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:4 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Get:9 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [776 B]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 5,359 B in 2s (3,201 B/s)\n","Reading package lists... Done\n","\n","## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n","## You may also need development tools to build native addons:\n","     sudo apt-get install gcc g++ make\n","## To install the Yarn package manager, run:\n","     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n","     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n","     sudo apt-get update && sudo apt-get install yarn\n","\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  nodejs\n","0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n","Need to get 27.2 MB of archives.\n","After this operation, 128 MB of additional disk space will be used.\n","Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.2-deb-1nodesource1 [27.2 MB]\n","Fetched 27.2 MB in 1s (51.5 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package nodejs.\n","(Reading database ... 120874 files and directories currently installed.)\n","Preparing to unpack .../nodejs_16.20.2-deb-1nodesource1_amd64.deb ...\n","Unpacking nodejs (16.20.2-deb-1nodesource1) ...\n","Setting up nodejs (16.20.2-deb-1nodesource1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Collecting git+https://github.com/neelnanda-io/PySvelte.git\n","  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-4x6o5hua\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-4x6o5hua\n","  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1698591592620,"user_tz":240,"elapsed":56,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","import plotly.io as pio\n","\n","if IN_COLAB or not DEBUG_MODE:\n","    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","    pio.renderers.default = \"colab\"\n","else:\n","    pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1698591605033,"user_tz":240,"elapsed":12461,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1698591607002,"user_tz":240,"elapsed":1992,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","outputId":"02cce4d8-1cba-44f7-e636-13617bf21d15","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698591607002,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7b415bb10c70>"]},"metadata":{},"execution_count":5}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KFs9BrbzIAiH","executionInfo":{"status":"ok","timestamp":1698591607003,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def imshow(tensor, renderer=None, **kwargs):\n","    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","def line(tensor, renderer=None, **kwargs):\n","    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","    x = utils.to_numpy(x)\n","    y = utils.to_numpy(y)\n","    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"markdown","source":["Decide which model to use (eg. gpt2-small vs -medium)"],"metadata":{"id":"ssJgoKr2yI8O"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"xLwDyosvIAiJ","executionInfo":{"status":"ok","timestamp":1698591634338,"user_tz":240,"elapsed":27341,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["97af0a163ed7487f94ebdee46ac2b104","84d55543a98842e6a6c4b2bdb64812e3","9ca7dd76a4184b9fa88ad184e70a6d58","4414b8631e374f49a9b89a85c781626c","4870724d5acc4b93bc0b5a2f9334c07a","bb41f0cd20084915ba74884a3d917b27","6feaa880919f4c058a8dc761e62d045c","bd19add567094cabbd9a270710aae9d4","e9ba87e06c374469beaf91f072601dbe","b52f8c2463664629a7ca848e72468806","642c570849b34c3eaee9bcd2c1e42fce","5be2b67186594af2861742a4f67e9157","b5f5036afa674431b3e5c6fc68bc1ae9","4e15ebcaf79d49f49139f4754b5241a5","cc3239d17c5b4afeaeb3f23b2387c90d","9a8b5bf8230f4e75ac397755d0ca4c60","8b33108896a34d6eb1881628ac5970da","387d8ce4df4f4fc6859f43d87359d395","890d81184fbd451d95a7bf64a7c55fd3","2fbd882d35354b77947019eff9119319","2bb17612368242d8a99a6ac51575eee4","96a95353771f43f78d6fa482d8467678","009b4cb8a02f4e26af998f62479327b9","ca2edbdb3b4c42d19823cb50515e837b","7469aa9a640b433db61e7d0e52d7adc4","63a47566121643f2ac5a676b8292645c","42983323c6ef4dc486cbf46e5c419eb0","b1c9fda63a9a4871bbfbb6c74b2bbd68","9fcff072dfaf4b6cba4f1f1829b90a81","9609cbfc8ce746f2913b92880f1ee58a","ffb597a39ae14275805934e28de59bcd","9d88ef946dbc492aa91f1f4ec608ab5a","2fbb4a8430a1477aa366ebbf297cb225","4d6c1598b42c4db29b972d843fa547de","40e104a573f24d8e9e03195e826854ff","843fe838d1a94b9e96ce1d77b5f01c4d","e664f522e29b49218e0ff2ff9289ca8b","7c2ad2ced20847ecb5f1e463a9488ab3","a29edc9e1b88430b9de902c47c039919","5a86757b9608455281345f577514368f","35dddb671ac54735b175ccf7a4442dbf","12443f40247e43aa866a2f6fffe71c32","9cff99288cfa4cb88628ada15b02c07c","c5130f0094b44953a3595515e4c1b9ec","74ca248701ed4abd9fdb80afdb9ffd58","cc61a7bccd1045b1a70bcb9ee7de0741","638bbb81c42146e3a0cb0bd42d8f43a3","dca7f24e48094c14a861c6cd2d555036","2b4e0289bd204ee4b40501948a0e803c","da629d4bee7149d59e09f45bd2ed9b69","79243a55fbf54b94a8343d867759b162","d61e3fd50095404f98ed9a1181d234d1","000ac1bd0ab049a99031699feba6dfca","2240595bfdd447eaa27a93c19386ea4f","203cca3578d740d08c88d290105b48d5","859d6996882542c9851df11bb1a7c5f8","7b8e24a5b3ee4f3f9ea1ea807ca30423","5195f5c443b243fc8f96ad8e8aed5bf4","5571c542c0604808a3ab8538bc6adea2","f1729d4dd03c491a82b28d64266961ec","07d6599a3446485880d9a3fbc92f83db","fdcfe08751234db5b361b067f8f3d492","98559b0d2f0a478a89cfb11712523a91","9d30fe378aa84287b487012fafabe1a2","20d9bc95c11d484da66766acb9b92ee2","0558d6def14a4da7845ac754ecb8c78b"],"height":0},"outputId":"aae80315-e819-4b76-a5d0-adf152c74299"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97af0a163ed7487f94ebdee46ac2b104"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5be2b67186594af2861742a4f67e9157"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"009b4cb8a02f4e26af998f62479327b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d6c1598b42c4db29b972d843fa547de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ca248701ed4abd9fdb80afdb9ffd58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859d6996882542c9851df11bb1a7c5f8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fdh5--MfYw7-","executionInfo":{"status":"ok","timestamp":1698591643618,"user_tz":240,"elapsed":9360,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dc6749ae-006b-46d5-bea5-d7d982823117"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9100, done.\u001b[K\n","remote: Counting objects: 100% (1812/1812), done.\u001b[K\n","remote: Compressing objects: 100% (287/287), done.\u001b[K\n","remote: Total 9100 (delta 1606), reused 1601 (delta 1522), pack-reused 7288\u001b[K\n","Receiving objects: 100% (9100/9100), 155.60 MiB | 29.20 MiB/s, done.\n","Resolving deltas: 100% (5501/5501), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ4C_bsXZFfj","executionInfo":{"status":"ok","timestamp":1698591643618,"user_tz":240,"elapsed":23,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b719c498-c932-4f6b-cfb5-4b12b011c252"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV","executionInfo":{"status":"ok","timestamp":1698591643619,"user_tz":240,"elapsed":22,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"markdown","source":["### test prompts"],"metadata":{"id":"DQF0lzuokQer"}},{"cell_type":"code","source":["modeltest = HookedTransformer.from_pretrained(\"gpt2-small\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FW7ZRS0wtqs4","executionInfo":{"status":"ok","timestamp":1698588583907,"user_tz":240,"elapsed":11963,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"318c5bcf-71dc-42c4-d051-ae4f64112871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}]},{"cell_type":"code","source":["example_prompt = \"The war lasted from the year 1750 to the year 17\"\n","example_answer = \" 51\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"OQpqlEjwED7b","executionInfo":{"status":"ok","timestamp":1698588637916,"user_tz":240,"elapsed":451,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bb2070a6-f0c3-4e25-ce0c-ba83599418ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'The', ' war', ' lasted', ' from', ' the', ' year', ' 17', '50', ' to', ' the', ' year', ' 17']\n","Tokenized answer: [' 51']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m1096\u001b[0m\u001b[1m     Logit: \u001b[0m\u001b[1;36m11.83\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m51\u001b[0m\u001b[1m|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1096</span><span style=\"font-weight: bold\">     Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.83</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"font-weight: bold\">|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 30.08 Prob: 26.90% Token: |60|\n","Top 1th token. Logit: 29.10 Prob: 10.12% Token: |75|\n","Top 2th token. Logit: 29.02 Prob:  9.33% Token: |70|\n","Top 3th token. Logit: 28.62 Prob:  6.29% Token: |90|\n","Top 4th token. Logit: 28.43 Prob:  5.19% Token: |80|\n","Top 5th token. Logit: 28.28 Prob:  4.45% Token: |50|\n","Top 6th token. Logit: 27.82 Prob:  2.83% Token: |55|\n","Top 7th token. Logit: 27.41 Prob:  1.87% Token: |65|\n","Top 8th token. Logit: 27.34 Prob:  1.75% Token: |76|\n","Top 9th token. Logit: 27.17 Prob:  1.47% Token: |71|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 51'\u001b[0m, \u001b[1;36m1096\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 51'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1096</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"The war lasted from the year 1701 to the year 17\"\n","example_answer = \" 51\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"mkYf2ymhxc2o","executionInfo":{"status":"ok","timestamp":1698588650796,"user_tz":240,"elapsed":358,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1b465a84-72d5-4dcd-a73d-6b12ba15b766"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'The', ' war', ' lasted', ' from', ' the', ' year', ' 17', '01', ' to', ' the', ' year', ' 17']\n","Tokenized answer: [' 51']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m1548\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m9.81\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m51\u001b[0m\u001b[1m|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1548</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.81</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"font-weight: bold\">|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 26.03 Prob:  5.33% Token: |20|\n","Top 1th token. Logit: 26.00 Prob:  5.19% Token: |15|\n","Top 2th token. Logit: 25.89 Prob:  4.62% Token: |02|\n","Top 3th token. Logit: 25.85 Prob:  4.45% Token: |12|\n","Top 4th token. Logit: 25.75 Prob:  4.02% Token: |10|\n","Top 5th token. Logit: 25.64 Prob:  3.62% Token: |18|\n","Top 6th token. Logit: 25.58 Prob:  3.38% Token: |05|\n","Top 7th token. Logit: 25.56 Prob:  3.32% Token: |03|\n","Top 8th token. Logit: 25.53 Prob:  3.23% Token: |16|\n","Top 9th token. Logit: 25.52 Prob:  3.20% Token: |04|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 51'\u001b[0m, \u001b[1;36m1548\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 51'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1548</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["#### less-than using in-context"],"metadata":{"id":"9Sk0G61l4Vlh"}},{"cell_type":"markdown","source":["See pg22 of greater-than paper: we address the tasks “The <noun> ended in the year 17YY\n","and started in the year 17” and “The <noun> lasted from the year 7YY BC to the year 7”, which do\n","use our circuit, but should not do so.\n","\n","These complete it with 'greater-than'"],"metadata":{"id":"4cyG3zqJ4mSX"}},{"cell_type":"code","source":["example_prompt = \"The war ended in the year 1750 and started in the year 17\"\n","example_answer = \" 49\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"oF4OEHDt4W0l","executionInfo":{"status":"ok","timestamp":1698590507696,"user_tz":240,"elapsed":1245,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e5c55557-b915-40af-e3a7-b65988843e4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'The', ' war', ' ended', ' in', ' the', ' year', ' 17', '50', ' and', ' started', ' in', ' the', ' year', ' 17']\n","Tokenized answer: [' 49']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m1134\u001b[0m\u001b[1m     Logit: \u001b[0m\u001b[1;36m10.12\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m49\u001b[0m\u001b[1m|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1134</span><span style=\"font-weight: bold\">     Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.12</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span><span style=\"font-weight: bold\">|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 26.42 Prob: 18.75% Token: |60|\n","Top 1th token. Logit: 25.20 Prob:  5.55% Token: |50|\n","Top 2th token. Logit: 25.19 Prob:  5.51% Token: |61|\n","Top 3th token. Logit: 25.03 Prob:  4.66% Token: |51|\n","Top 4th token. Logit: 24.97 Prob:  4.38% Token: |55|\n","Top 5th token. Logit: 24.74 Prob:  3.51% Token: |52|\n","Top 6th token. Logit: 24.68 Prob:  3.30% Token: |75|\n","Top 7th token. Logit: 24.62 Prob:  3.10% Token: |59|\n","Top 8th token. Logit: 24.62 Prob:  3.10% Token: |70|\n","Top 9th token. Logit: 24.60 Prob:  3.05% Token: |56|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 49'\u001b[0m, \u001b[1;36m1134\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 49'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1134</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"The war ended in the year 1790 and started in the year 1780. The war ended in the year 1750 and started in the year 17\"\n","example_answer = \" 49\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"tv_bcxQL4rvC","executionInfo":{"status":"ok","timestamp":1698590563898,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8eeb3290-410a-499f-bc39-aaaf579451e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'The', ' war', ' ended', ' in', ' the', ' year', ' 17', '90', ' and', ' started', ' in', ' the', ' year', ' 17', '80', '.', ' The', ' war', ' ended', ' in', ' the', ' year', ' 17', '50', ' and', ' started', ' in', ' the', ' year', ' 17']\n","Tokenized answer: [' 49']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m1161\u001b[0m\u001b[1m     Logit: \u001b[0m\u001b[1;36m10.34\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m49\u001b[0m\u001b[1m|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1161</span><span style=\"font-weight: bold\">     Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.34</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span><span style=\"font-weight: bold\">|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 26.13 Prob: 16.52% Token: |80|\n","Top 1th token. Logit: 25.79 Prob: 11.82% Token: |60|\n","Top 2th token. Logit: 25.79 Prob: 11.77% Token: |70|\n","Top 3th token. Logit: 25.65 Prob: 10.25% Token: |90|\n","Top 4th token. Logit: 25.36 Prob:  7.65% Token: |50|\n","Top 5th token. Logit: 24.92 Prob:  4.94% Token: |75|\n","Top 6th token. Logit: 24.43 Prob:  3.01% Token: |85|\n","Top 7th token. Logit: 24.25 Prob:  2.53% Token: |40|\n","Top 8th token. Logit: 24.04 Prob:  2.04% Token: |55|\n","Top 9th token. Logit: 24.00 Prob:  1.97% Token: |65|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 49'\u001b[0m, \u001b[1;36m1161\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 49'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1161</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"90 is less than 100. 80 is less than 90. 70 is less than\"\n","example_answer = \" 80\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"t1wIMQE94zRM","executionInfo":{"status":"ok","timestamp":1698590600848,"user_tz":240,"elapsed":984,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"47f7ec05-e1b7-425f-a7ef-c904dc106511"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', '90', ' is', ' less', ' than', ' 100', '.', ' 80', ' is', ' less', ' than', ' 90', '.', ' 70', ' is', ' less', ' than']\n","Tokenized answer: [' 80']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m17.60\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m1.15\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m80\u001b[0m\u001b[1m|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.60</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.15</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span><span style=\"font-weight: bold\">|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 22.02 Prob: 95.21% Token: | 70|\n","Top 1th token. Logit: 17.60 Prob:  1.15% Token: | 90|\n","Top 2th token. Logit: 17.60 Prob:  1.15% Token: | 80|\n","Top 3th token. Logit: 16.81 Prob:  0.52% Token: | 75|\n","Top 4th token. Logit: 16.29 Prob:  0.31% Token: | 20|\n","Top 5th token. Logit: 16.06 Prob:  0.25% Token: | 65|\n","Top 6th token. Logit: 15.80 Prob:  0.19% Token: | 50|\n","Top 7th token. Logit: 15.63 Prob:  0.16% Token: | 60|\n","Top 8th token. Logit: 15.00 Prob:  0.08% Token: | 40|\n","Top 9th token. Logit: 14.66 Prob:  0.06% Token: | 85|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 80'\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 80'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## test tokenizer to make pos_dict, prompt_dict"],"metadata":{"id":"IK_8tj2_xN3B"}},{"cell_type":"code","source":["model.tokenizer('1701')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FgAMmablGUD","executionInfo":{"status":"ok","timestamp":1698585421600,"user_tz":240,"elapsed":445,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1f8c3353-86ed-455e-e9b9-f8c154bb9dce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [1558, 486], 'attention_mask': [1, 1]}"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["model.tokenizer('01')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OpQPaWj8lLH5","executionInfo":{"status":"ok","timestamp":1698585429618,"user_tz":240,"elapsed":419,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"48e0a15c-0c17-43ac-b639-fcdaa5b3c12e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [486], 'attention_mask': [1]}"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["model.tokenizer.convert_tokens_to_string(model.tokenizer.convert_ids_to_tokens(model.tokenizer('1701')['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"dVtPScHGlz0u","executionInfo":{"status":"ok","timestamp":1698585638519,"user_tz":240,"elapsed":457,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"436785e1-555f-456d-9154-011106b4d7e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1701'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# model.tokenizer.decode(486)\n","model.tokenizer.decode([486])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"C_q7hfw-mE9_","executionInfo":{"status":"ok","timestamp":1698586354335,"user_tz":240,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"738f6dd3-5258-494b-a2f0-81fc0a2e29fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'01'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["len(model.tokenizer()['input_ids'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MsXbxrlhlWM1","executionInfo":{"status":"ok","timestamp":1698585504932,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9f3f9736-7566-4b5a-8ee8-0644f579ee0c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["### get rid of \"Ġ\" +"],"metadata":{"id":"5FnwoB_OwDPu"}},{"cell_type":"code","source":["model.tokenizer(\"1711\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDIf7a8Dvlm_","executionInfo":{"status":"ok","timestamp":1696390342567,"user_tz":240,"elapsed":30,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6c025c84-148f-4d70-f208-6207d95054e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [1558, 1157], 'attention_mask': [1, 1]}"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["model.tokenizer.tokenize(\"1711\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EztMlBtpvEON","executionInfo":{"status":"ok","timestamp":1696390332388,"user_tz":240,"elapsed":322,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4258ecaa-8ea2-4267-8749-09ab848f299a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['17', '11']"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["B/c 11 is after 17 and doesn't have a space in front, get rid of \"Ġ\" +"],"metadata":{"id":"fX-WO3z2vy0u"}},{"cell_type":"code","source":["def get_prompts_pos_dicts(input_text, YY):\n","    pos_dict = {}\n","    prompt_dict = {}\n","    tokens_list = model.tokenizer(input_text)['input_ids']\n","\n","    for index, token in enumerate(tokens_list):\n","        token_as_string = model.tokenizer.decode(token)\n","        # if token_as_string == YY:\n","        #     key = 'YY'\n","        # else:\n","        #     key = 'T'+str(index)\n","        key = 'T'+str(index)\n","        pos_dict[key] = index\n","        prompt_dict[key] = token_as_string\n","    prompt_dict['text'] = input_text\n","\n","    return pos_dict, prompt_dict"],"metadata":{"id":"DLmqcJXklmWV","executionInfo":{"status":"ok","timestamp":1698591643619,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["input_text = 'The war lasted from the year 1750 to the year 17'\n","get_prompts_pos_dicts(input_text, '50')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJMt8azbpNaA","executionInfo":{"status":"ok","timestamp":1698590848446,"user_tz":240,"elapsed":347,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"da36537f-dcc8-49dc-99e6-ad0a472cdb79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'T0': 0,\n","  'T1': 1,\n","  'T2': 2,\n","  'T3': 3,\n","  'T4': 4,\n","  'T5': 5,\n","  'T6': 6,\n","  'T7': 7,\n","  'T8': 8,\n","  'T9': 9,\n","  'T10': 10,\n","  'T11': 11},\n"," {'T0': 'The',\n","  'T1': ' war',\n","  'T2': ' lasted',\n","  'T3': ' from',\n","  'T4': ' the',\n","  'T5': ' year',\n","  'T6': ' 17',\n","  'T7': '50',\n","  'T8': ' to',\n","  'T9': ' the',\n","  'T10': ' year',\n","  'T11': ' 17',\n","  'text': 'The war lasted from the year 1750 to the year 17'})"]},"metadata":{},"execution_count":186}]},{"cell_type":"markdown","source":["## make datasets"],"metadata":{"id":"6aByCOwUxQm7"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        # self.io_tokenIDs = [\n","        #     self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        # ]\n","        # self.s_tokenIDs = [\n","        #     self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        # ]\n","\n","        # self.YY = int()\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn","executionInfo":{"status":"ok","timestamp":1698591643619,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x, y):\n","    prompts_list = []\n","    for YY in range(x, y):\n","        input_text = f'The war lasted from the year 17{YY} to the year 17'\n","        pos_dict, prompt_dict = get_prompts_pos_dicts(input_text, YY)\n","        prompts_list.append(prompt_dict)\n","    return pos_dict, prompts_list\n","\n","# prompts_list = generate_prompts_list(45, 55)\n","pos_dict, prompts_list = generate_prompts_list(50, 51)\n","# prompts_list\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"u0NPSKcZ1iDe","executionInfo":{"status":"ok","timestamp":1698591646154,"user_tz":240,"elapsed":2555,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_corr(x, y):\n","    prompts_list = []\n","    # for YY in range(x, y):\n","    YY = '01'\n","    input_text = f'The war lasted from the year 17{YY} to the year 17'\n","    pos_dict, prompt_dict = get_prompts_pos_dicts(input_text, YY)\n","    prompts_list.append(prompt_dict)\n","    return pos_dict, prompts_list\n","\n","# prompts_list = generate_prompts_list(45, 55)\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(50, 51)\n","# prompts_list_2\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"ViiKAFwBvmEG","executionInfo":{"status":"ok","timestamp":1698591646155,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## obtain the logits of each number between YY and 99"],"metadata":{"id":"A0W-GaM6Vfm-"}},{"cell_type":"code","source":["logits = torch.randn(32, 100, 256)  # [batch size, seq len, vocab size]\n","logits[range(logits.size(0)), [99]*logits.size(0), [5]*logits.size(0)] == logits[range(logits.size(0)), 99, 5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8y8oMWtPfyfj","executionInfo":{"status":"ok","timestamp":1698584676515,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4f357603-f221-431d-a4e2-2fd9d774fa33"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True, True, True, True, True,\n","        True, True, True, True, True, True, True, True])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["logits[range(logits.size(0)), 99, 5].size() # logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90HU1KXxiXFu","executionInfo":{"status":"ok","timestamp":1698584689662,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f6127e1f-8d13-42d8-cb03-a6ff9ffc8814"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# obtain the logits of each number between YY and 99, where YY is a two digit integer\n","\n","import torch\n","\n","def get_logits_for_range(logits, start_num, end_num, vocab):\n","    \"\"\"\n","    :param tensor: The logits tensor with dimensions [batch size, seq len, vocab size]\n","    :param start_num: The starting number\n","    :param end_num: The ending number\n","    :param vocab: A list or dictionary mapping of the vocabulary\n","    :return: A tensor containing logits for numbers between start_num and end_num\n","    \"\"\"\n","    # Getting indices for numbers between start_num and end_num\n","    # indices = [vocab[str(num)] for num in range(start_num, end_num+1)]\n","    indices = []\n","    for num in range(start_num, end_num+1):\n","        num_as_vocabID = model.tokenizer(str(num))['input_ids'][0]\n","        indices.append(num_as_vocabID)\n","\n","    # Extract logits for these indices\n","    logits_for_range = logits[:, logits.size(1)-1, indices]\n","\n","    return logits_for_range\n","\n","# Example usage:\n","tensor = torch.randn(32, 100, 50000)  # [batch size, seq len, vocab size]\n","vocab = {str(i): i for i in range(50000)}  # Example vocab mapping\n","YY = 87\n","logits_greaterThan = get_logits_for_range(tensor, YY, 99, vocab)\n","print(logits_greaterThan.shape)  # Should be [batch size, seq len, (99-YY+1)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tD_ZaBNug7l1","executionInfo":{"status":"ok","timestamp":1698591648490,"user_tz":240,"elapsed":2345,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"900fb922-a94a-48ab-d60c-4eb206c56469"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 13])\n"]}]},{"cell_type":"code","source":["logits_greaterThan_sum = logits_greaterThan.sum(dim=1)\n","logits_greaterThan_sum.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoCg3CGsiuoC","executionInfo":{"status":"ok","timestamp":1698589446079,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8ca7df7a-18f7-4cbf-dffe-c405c8789c4b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32])"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":["logits_greaterThan_sum.mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEWYNyHhhFqx","executionInfo":{"status":"ok","timestamp":1698589446489,"user_tz":240,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bc775a4b-5a73-489e-88c3-d56f4e4022f0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.2856)"]},"metadata":{},"execution_count":146}]},{"cell_type":"code","source":["# int(prompts[input_ind]['YY'])  # YY in an input\n","# we want the first token > int(prompts[batch_ind]['YY'])\n","# search thru entire vocab space until find token > int(prompts[input_ind]['YY'])\n","# how do we convert index in vocab space to the token it represents?\n","\n","# greater_than_Y_idx = (io_logits > Y).nonzero(as_tuple=True)[0].item()\n","# first_token_greater_than_Y = dataset.io_tokenIDs[greater_than_Y_idx]"],"metadata":{"id":"pqActCNEgOYD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"GCCCoO0V7L7J"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Get the right logits; anything greater than YY\n","    # range(logits.size(0)) for every input in the batch\n","    # dataset.word_idx[\"end\"]: at the last pos, so \"what's the next prediction after end?\"\n","    # what's the logit of the YY token (whose pos at an input seq is recorded in the dataset by dataset.YY_tokenIDs)\n","\n","    # YY = dataset.YY  # only correct dataset indices of corr and incorr tokens matters\n","    YY = 50\n","\n","    logits_greaterThan = get_logits_for_range(logits, YY, 99, vocab)\n","    logits_greaterThan_sum = logits_greaterThan.sum(dim=1)\n","\n","    # get the wrong logits; anything less than YY\n","    logits_lessThan = get_logits_for_range(logits, 00, YY-1, vocab)\n","    logits_lessThan_sum = logits_lessThan.sum(dim=1)\n","\n","    # Find logit difference of corr minus incorr; sum up all tokens between YY and 99, minus sum of all YY and 00\n","    answer_logit_diff = logits_greaterThan_sum - logits_lessThan_sum\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"CgD41x5nbKKP","executionInfo":{"status":"ok","timestamp":1698591648491,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, print_output=True):\n","    # CIRCUIT = {\n","    #     \"number mover\": lst,\n","    #     \"number mover 2\": lst,\n","    # }\n","\n","    # SEQ_POS_TO_KEEP = {\n","    #     \"number mover\": \"end\",\n","    #     \"number mover 2\": \"YY\",\n","    # }\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","\n","    for ind, key in enumerate(pos_dict.keys()):\n","        headName = \"head\" + str(ind)\n","        CIRCUIT[headName] = lst\n","        SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return (100 * new_score / orig_score)"],"metadata":{"id":"LqsdFmbVMntG","executionInfo":{"status":"ok","timestamp":1698592274999,"user_tz":240,"elapsed":135,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## test fns"],"metadata":{"id":"o56Altbhz7i6"}},{"cell_type":"code","source":["CIRCUIT = {}\n","SEQ_POS_TO_KEEP = {}\n","\n","for ind, key in enumerate(pos_dict.keys()):\n","    headName = \"head\" + str(ind)\n","    CIRCUIT[headName] = [(layer, head) for layer in range(12) for head in range(12)]\n","    SEQ_POS_TO_KEEP[headName] = key"],"metadata":{"id":"AeWAW2p00Egu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)"],"metadata":{"id":"DvmK4HFx0As0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["YY = 50\n","\n","logits_greaterThan = get_logits_for_range(ioi_logits_original, YY, 99, vocab)\n","logits_greaterThan_sum = logits_greaterThan.sum(dim=1)\n","\n","# get the wrong logits; anything less than YY\n","logits_lessThan = get_logits_for_range(ioi_logits_original, 00, YY-1, vocab)\n","logits_lessThan_sum = logits_lessThan.sum(dim=1)\n","\n","# Find logit difference of corr minus incorr; sum up all tokens between YY and 99, minus sum of all YY and 00\n","answer_logit_diff = logits_greaterThan_sum - logits_lessThan_sum"],"metadata":{"id":"sJRHYC1nyax_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits_greaterThan.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Rvqf5cLyg4u","executionInfo":{"status":"ok","timestamp":1698589713438,"user_tz":240,"elapsed":448,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0d01132f-bf90-416c-e13a-9707f43d8b52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 50])"]},"metadata":{},"execution_count":160}]},{"cell_type":"markdown","source":["# Ablate the model tests"],"metadata":{"id":"Lk3bffnCYq-p"}},{"cell_type":"markdown","source":["## Test Greater-Than vs other circuits"],"metadata":{"id":"GyMsBAOg5kEj"}},{"cell_type":"markdown","source":["See how greater-than circuit performs on the greater-than task; it should be similar to the paper. Else, either greater-than paper has issues (less likely) or this mean ablation code/setup was not generalized correctly (more likely)."],"metadata":{"id":"Y1JSjFGW4sSw"}},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)\n","new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBXAXcFN_UxT","executionInfo":{"status":"ok","timestamp":1698592287955,"user_tz":240,"elapsed":2160,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"52aef60f-c103-4360-802c-03a885c5ab51"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.1862\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(85.1862, device='cuda:0')"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["Did it get right? Let's try an incompelte circuit for sanity check."],"metadata":{"id":"49nxie05eRMF"}},{"cell_type":"code","source":["greater_than = []\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sy7MVh7jkpND","executionInfo":{"status":"ok","timestamp":1698589731690,"user_tz":240,"elapsed":1152,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"436fd368-58d9-4af3-c8fc-15ef24179f0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 1.8475\n"]}]},{"cell_type":"markdown","source":["Likely still has score due to MLPs"],"metadata":{"id":"KmMRkLIc204W"}},{"cell_type":"code","source":["greater_than = [(0, 1)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmnL1aG4eas5","executionInfo":{"status":"ok","timestamp":1698589735684,"user_tz":240,"elapsed":1380,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"988696ef-01de-4690-9d51-6c0d13a7b086"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 1.8473\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (9,1)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMcTXbkveQeD","executionInfo":{"status":"ok","timestamp":1698589738110,"user_tz":240,"elapsed":936,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"355ea8b9-8a60-404a-99c8-1b91e3b87833"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 30.9436\n"]}]},{"cell_type":"code","source":["import random\n","num_of_tuples = 9  # Number of tuples you want\n","greater_than = [(random.randint(0, 9), random.randint(0, 9)) for _ in range(num_of_tuples)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsxdwJCEyCs5","executionInfo":{"status":"ok","timestamp":1698589924354,"user_tz":240,"elapsed":1638,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b3262f5c-6fd9-47f1-d784-9f400e7819e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 2.1236\n"]}]},{"cell_type":"code","source":["greater_than = [(layer, head) for layer in range(12) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0iD62A1k2Gtf","executionInfo":{"status":"ok","timestamp":1698589883479,"user_tz":240,"elapsed":1398,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fe9ac576-dbea-4453-a9ad-6f1ee7dcacc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 100.0000\n"]}]},{"cell_type":"markdown","source":["### add heads to orig paper circ"],"metadata":{"id":"7Hl3NU_i29Sa"}},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(10, 7)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52p8CGbg2_h3","executionInfo":{"status":"ok","timestamp":1698590186309,"user_tz":240,"elapsed":1894,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9a4d6f37-6be1-4295-a502-a4c048d7a397"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 84.0478\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqonWDSj3yby","executionInfo":{"status":"ok","timestamp":1698590335787,"user_tz":240,"elapsed":2227,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a5c0e49-e788-4d0f-d9e2-198e4ddf9465"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.1862\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0, 4) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjyqSN0p361x","executionInfo":{"status":"ok","timestamp":1698590354545,"user_tz":240,"elapsed":2400,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a8a7158c-aaa4-456b-e2ba-ac7648eed80e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 81.5903\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0, 6) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6AGUcI73_8u","executionInfo":{"status":"ok","timestamp":1698590372089,"user_tz":240,"elapsed":2787,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7e235d38-f1a8-4c35-dc51-62c01f832ca8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 88.9415\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0, 9) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdKTtmOO4EHQ","executionInfo":{"status":"ok","timestamp":1698590387390,"user_tz":240,"elapsed":1825,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cfd93fcd-10fd-4ef2-d170-415ff5639242"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0480\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(8, 9) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4M-CxPxP4IJf","executionInfo":{"status":"ok","timestamp":1698590402640,"user_tz":240,"elapsed":2126,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"933c4d60-4e63-4ac5-9ad9-ec991d8287b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 92.0383\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(5, 9) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBM_g-Eu4NZf","executionInfo":{"status":"ok","timestamp":1698590422803,"user_tz":240,"elapsed":1299,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8883c9f7-27f7-43e7-f8dc-825b403382ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0697\n"]}]},{"cell_type":"markdown","source":["# Ablate by seq pos"],"metadata":{"id":"o7d6V0Cz5hV3"}},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    # CIRCUIT = {\n","    #     \"number mover\": lst,\n","    #     \"number mover 2\": lst,\n","    # }\n","\n","    # SEQ_POS_TO_KEEP = {\n","    #     \"number mover\": \"end\",\n","    #     \"number mover 2\": \"YY\",\n","    # }\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","\n","    # for ind, key in enumerate(pos_dict.keys()):\n","    # ind = 7\n","    # key = \"T7\"\n","\n","    for ind, key in enumerate([\"T7\", \"end\"]):\n","        headName = \"head\" + str(ind)\n","        CIRCUIT[headName] = lst\n","        SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"_4hXcIcZ5jOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxYqvBnr5vIr","executionInfo":{"status":"ok","timestamp":1698590903797,"user_tz":240,"elapsed":2405,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"330886ab-16e9-40bc-ae79-d16ec1ad6363"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.1939\n"]}]},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"end\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)],\n","        \"YY\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9)],\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"end\": \"end\",\n","        \"YY\": \"T7\",\n","    }\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","\n","    # # for ind, key in enumerate(pos_dict.keys()):\n","    # # ind = 7\n","    # # key = \"T7\"\n","\n","    # for ind, key in enumerate([\"T7\", \"end\"]):\n","    #     headName = \"head\" + str(ind)\n","    #     CIRCUIT[headName] = lst\n","    #     SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"nFwZO0nq6J94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698591031785,"user_tz":240,"elapsed":465,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"92ee5345-3c4d-47c5-acc3-b50dfdd417bc","id":"sWYJpyBB6J95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.3446\n"]}]},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"end\": [(9, 1)],\n","        \"YY\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11)],\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"end\": \"end\",\n","        \"YY\": \"T7\",\n","    }\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","\n","    # # for ind, key in enumerate(pos_dict.keys()):\n","    # # ind = 7\n","    # # key = \"T7\"\n","\n","    # for ind, key in enumerate([\"T7\", \"end\"]):\n","    #     headName = \"head\" + str(ind)\n","    #     CIRCUIT[headName] = lst\n","    #     SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"CffrMRgt6klD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698591089292,"user_tz":240,"elapsed":1426,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6c38a523-242d-4bcb-dea3-d324d01fbe22","id":"OO0m6DkS6klE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 43.3762\n"]}]},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"end\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)],\n","        # \"YY\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11)],\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"end\": \"end\",\n","        # \"YY\": \"T7\",\n","    }\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","\n","    # # for ind, key in enumerate(pos_dict.keys()):\n","    # # ind = 7\n","    # # key = \"T7\"\n","\n","    # for ind, key in enumerate([\"T7\", \"end\"]):\n","    #     headName = \"head\" + str(ind)\n","    #     CIRCUIT[headName] = lst\n","    #     SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"pQ-PxR5663gS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698591137002,"user_tz":240,"elapsed":4421,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fd99831b-d504-43fc-9568-4d81f409a465","id":"SMkzD9rd63gg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 72.7873\n"]}]},{"cell_type":"markdown","source":["# Prune backwards"],"metadata":{"id":"e6N5MU1wRZog"}},{"cell_type":"markdown","source":["You need to modify this because the prev \"scores\" were just of ONE token, whereas here they are sums of MULTIPLE tokens so they will be greater than 100 at times. So can't do 100-new_score if return raw score, must return newscore/oldscore as percentage."],"metadata":{"id":"NHh8OSXa_EbY"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bfiwe5d3SgVP","executionInfo":{"status":"ok","timestamp":1698592487635,"user_tz":240,"elapsed":123895,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1bb8af23-f486-4450-ba02-ef22d2feeaa6"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","100.28197479248047\n","\n","\n","Removed: (11, 1)\n","100.20474243164062\n","\n","\n","Removed: (11, 2)\n","100.18450164794922\n","\n","\n","Removed: (11, 3)\n","100.1889877319336\n","\n","\n","Removed: (11, 4)\n","100.14933013916016\n","\n","\n","Removed: (11, 5)\n","100.13788604736328\n","\n","\n","Removed: (11, 6)\n","100.19379425048828\n","\n","\n","Removed: (11, 7)\n","100.1530990600586\n","\n","\n","Removed: (11, 8)\n","98.56027221679688\n","\n","\n","Removed: (11, 9)\n","98.58362579345703\n","\n","\n","Removed: (11, 10)\n","97.84908294677734\n","\n","\n","Removed: (11, 11)\n","97.87332916259766\n","\n","\n","Removed: (10, 0)\n","97.72073364257812\n","\n","\n","Removed: (10, 1)\n","97.74042510986328\n","\n","\n","Removed: (10, 2)\n","97.5237808227539\n","\n","\n","Removed: (10, 3)\n","97.4166259765625\n","\n","\n","Removed: (10, 5)\n","97.43634033203125\n","\n","\n","Removed: (10, 6)\n","97.43019104003906\n","\n","\n","Removed: (10, 7)\n","97.65335845947266\n","\n","\n","Removed: (10, 8)\n","97.8172378540039\n","\n","\n","Removed: (10, 9)\n","97.86212158203125\n","\n","\n","Removed: (10, 10)\n","97.59696197509766\n","\n","\n","Removed: (10, 11)\n","97.59223937988281\n","\n","\n","Removed: (9, 0)\n","97.64034271240234\n","\n","\n","Removed: (9, 2)\n","97.73179626464844\n","\n","\n","Removed: (9, 3)\n","97.62444305419922\n","\n","\n","Removed: (9, 4)\n","97.70822143554688\n","\n","\n","Removed: (9, 5)\n","98.69759368896484\n","\n","\n","Removed: (9, 6)\n","101.50251770019531\n","\n","\n","Removed: (9, 7)\n","101.12593078613281\n","\n","\n","Removed: (9, 8)\n","101.08072662353516\n","\n","\n","Removed: (9, 9)\n","101.15216827392578\n","\n","\n","Removed: (9, 10)\n","101.25702667236328\n","\n","\n","Removed: (9, 11)\n","101.26045989990234\n","\n","\n","Removed: (8, 0)\n","101.54271697998047\n","\n","\n","Removed: (8, 1)\n","101.4235610961914\n","\n","\n","Removed: (8, 2)\n","101.40348052978516\n","\n","\n","Removed: (8, 3)\n","101.35187530517578\n","\n","\n","Removed: (8, 4)\n","101.39521026611328\n","\n","\n","Removed: (8, 5)\n","100.95925903320312\n","\n","\n","Removed: (8, 6)\n","100.81123352050781\n","\n","\n","Removed: (8, 7)\n","100.69032287597656\n","\n","\n","Removed: (8, 9)\n","100.91807556152344\n","\n","\n","Removed: (8, 10)\n","100.26468658447266\n","\n","\n","Removed: (7, 0)\n","100.59001922607422\n","\n","\n","Removed: (7, 1)\n","100.34004974365234\n","\n","\n","Removed: (7, 2)\n","100.20984649658203\n","\n","\n","Removed: (7, 3)\n","100.9314193725586\n","\n","\n","Removed: (7, 4)\n","100.80028533935547\n","\n","\n","Removed: (7, 5)\n","100.39962005615234\n","\n","\n","Removed: (7, 6)\n","100.19705200195312\n","\n","\n","Removed: (7, 7)\n","100.11871337890625\n","\n","\n","Removed: (7, 8)\n","100.26716613769531\n","\n","\n","Removed: (7, 9)\n","100.53839111328125\n","\n","\n","Removed: (7, 11)\n","100.56867218017578\n","\n","\n","Removed: (6, 0)\n","100.677490234375\n","\n","\n","Removed: (6, 1)\n","100.87483978271484\n","\n","\n","Removed: (6, 2)\n","100.99386596679688\n","\n","\n","Removed: (6, 3)\n","101.01890563964844\n","\n","\n","Removed: (6, 4)\n","100.0516586303711\n","\n","\n","Removed: (6, 5)\n","99.98507690429688\n","\n","\n","Removed: (6, 6)\n","100.81855773925781\n","\n","\n","Removed: (6, 7)\n","100.75892639160156\n","\n","\n","Removed: (6, 8)\n","100.522216796875\n","\n","\n","Removed: (6, 10)\n","100.52157592773438\n","\n","\n","Removed: (6, 11)\n","100.1690673828125\n","\n","\n","Removed: (5, 0)\n","98.68396759033203\n","\n","\n","Removed: (5, 2)\n","98.47362518310547\n","\n","\n","Removed: (5, 3)\n","98.42742919921875\n","\n","\n","Removed: (5, 4)\n","98.13575744628906\n","\n","\n","Removed: (5, 6)\n","98.10385131835938\n","\n","\n","Removed: (5, 7)\n","98.15841674804688\n","\n","\n","Removed: (5, 8)\n","97.48551177978516\n","\n","\n","Removed: (5, 9)\n","97.41819763183594\n","\n","\n","Removed: (5, 10)\n","97.65989685058594\n","\n","\n","Removed: (5, 11)\n","97.18470764160156\n","\n","\n","Removed: (4, 0)\n","97.17675018310547\n","\n","\n","Removed: (4, 1)\n","97.42085266113281\n","\n","\n","Removed: (4, 2)\n","97.39924621582031\n","\n","\n","Removed: (4, 3)\n","97.40025329589844\n","\n","\n","Removed: (4, 4)\n","98.19881439208984\n","\n","\n","Removed: (4, 5)\n","97.02593994140625\n","\n","\n","Removed: (4, 6)\n","98.08993530273438\n","\n","\n","Removed: (4, 7)\n","98.32418823242188\n","\n","\n","Removed: (4, 8)\n","98.69463348388672\n","\n","\n","Removed: (4, 9)\n","98.71583557128906\n","\n","\n","Removed: (4, 10)\n","99.74185180664062\n","\n","\n","Removed: (4, 11)\n","99.35852813720703\n","\n","\n","Removed: (3, 0)\n","99.29438781738281\n","\n","\n","Removed: (3, 1)\n","99.35530853271484\n","\n","\n","Removed: (3, 2)\n","99.34190368652344\n","\n","\n","Removed: (3, 3)\n","98.87967681884766\n","\n","\n","Removed: (3, 4)\n","98.77397918701172\n","\n","\n","Removed: (3, 5)\n","98.28901672363281\n","\n","\n","Removed: (3, 6)\n","98.09556579589844\n","\n","\n","Removed: (3, 7)\n","98.11113739013672\n","\n","\n","Removed: (3, 8)\n","98.5070571899414\n","\n","\n","Removed: (3, 9)\n","98.2041244506836\n","\n","\n","Removed: (3, 10)\n","98.54584503173828\n","\n","\n","Removed: (3, 11)\n","98.28789520263672\n","\n","\n","Removed: (2, 0)\n","98.18673706054688\n","\n","\n","Removed: (2, 1)\n","99.82734680175781\n","\n","\n","Removed: (2, 2)\n","100.01150512695312\n","\n","\n","Removed: (2, 3)\n","100.05319213867188\n","\n","\n","Removed: (2, 4)\n","98.63150024414062\n","\n","\n","Removed: (2, 5)\n","98.03034210205078\n","\n","\n","Removed: (2, 6)\n","98.2033920288086\n","\n","\n","Removed: (2, 7)\n","98.15680694580078\n","\n","\n","Removed: (2, 8)\n","98.07186889648438\n","\n","\n","Removed: (2, 9)\n","97.89974212646484\n","\n","\n","Removed: (2, 10)\n","97.43457794189453\n","\n","\n","Removed: (2, 11)\n","97.54417419433594\n","\n","\n","Removed: (1, 0)\n","97.6570816040039\n","\n","\n","Removed: (1, 1)\n","97.82059478759766\n","\n","\n","Removed: (1, 2)\n","97.71102905273438\n","\n","\n","Removed: (1, 3)\n","97.81556701660156\n","\n","\n","Removed: (1, 4)\n","98.00869750976562\n","\n","\n","Removed: (1, 5)\n","100.44673156738281\n","\n","\n","Removed: (1, 6)\n","100.50250244140625\n","\n","\n","Removed: (1, 7)\n","100.70661926269531\n","\n","\n","Removed: (1, 8)\n","100.83951568603516\n","\n","\n","Removed: (1, 9)\n","100.85615539550781\n","\n","\n","Removed: (1, 10)\n","100.79839324951172\n","\n","\n","Removed: (1, 11)\n","99.27505493164062\n","\n","\n","Removed: (0, 0)\n","99.15838623046875\n","\n","\n","Removed: (0, 2)\n","100.11624145507812\n","\n","\n","Removed: (0, 4)\n","99.92472076416016\n","\n","\n","Removed: (0, 5)\n","99.41437530517578\n","\n","\n","Removed: (0, 6)\n","99.58939361572266\n","\n","\n","Removed: (0, 7)\n","98.66212463378906\n","\n","\n","Removed: (0, 8)\n","98.71688842773438\n","\n","\n","Removed: (0, 9)\n","98.91476440429688\n","\n","\n","Removed: (0, 10)\n","101.00994110107422\n","\n","\n","Removed: (0, 11)\n","100.63505554199219\n","\n","\n"]}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True)"],"metadata":{"id":"qgpGMTWLbibq","executionInfo":{"status":"ok","timestamp":1698592488497,"user_tz":240,"elapsed":885,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6764d5c-5b0a-4a82-cafe-ce6024eb72d8"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 100.6351\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(100.6351, device='cuda:0')"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["backw_3 = curr_circuit.copy()\n","backw_3"],"metadata":{"id":"7_ZC4-k2blg2","executionInfo":{"status":"ok","timestamp":1698592488498,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d0be22d-2525-444d-dfef-f2aa50461d2d"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 3),\n"," (5, 1),\n"," (5, 5),\n"," (6, 9),\n"," (7, 10),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (10, 4)]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["len(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dry8ANsOMgvg","executionInfo":{"status":"ok","timestamp":1698592488685,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"58c0ee4d-88d0-4146-ef1d-23bedabee4e5"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["## prune by 10% threshold"],"metadata":{"id":"Gt7Vv4939hfR"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 10  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698592608396,"user_tz":240,"elapsed":119725,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0eb4d817-38c4-4b4f-dcce-376ed11372a7","id":"OEYO88Hv9jZ-"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","100.28197479248047\n","\n","\n","Removed: (11, 1)\n","100.20474243164062\n","\n","\n","Removed: (11, 2)\n","100.18450164794922\n","\n","\n","Removed: (11, 3)\n","100.1889877319336\n","\n","\n","Removed: (11, 4)\n","100.14933013916016\n","\n","\n","Removed: (11, 5)\n","100.13788604736328\n","\n","\n","Removed: (11, 6)\n","100.19379425048828\n","\n","\n","Removed: (11, 7)\n","100.1530990600586\n","\n","\n","Removed: (11, 8)\n","98.56027221679688\n","\n","\n","Removed: (11, 9)\n","98.58362579345703\n","\n","\n","Removed: (11, 10)\n","97.84908294677734\n","\n","\n","Removed: (11, 11)\n","97.87332916259766\n","\n","\n","Removed: (10, 0)\n","97.72073364257812\n","\n","\n","Removed: (10, 1)\n","97.74042510986328\n","\n","\n","Removed: (10, 2)\n","97.5237808227539\n","\n","\n","Removed: (10, 3)\n","97.4166259765625\n","\n","\n","Removed: (10, 4)\n","93.64924621582031\n","\n","\n","Removed: (10, 5)\n","93.67503356933594\n","\n","\n","Removed: (10, 6)\n","93.65045166015625\n","\n","\n","Removed: (10, 7)\n","93.87191009521484\n","\n","\n","Removed: (10, 8)\n","94.0074691772461\n","\n","\n","Removed: (10, 9)\n","94.06966400146484\n","\n","\n","Removed: (10, 10)\n","93.88985443115234\n","\n","\n","Removed: (10, 11)\n","93.88555145263672\n","\n","\n","Removed: (9, 0)\n","93.92167663574219\n","\n","\n","Removed: (9, 2)\n","94.0120849609375\n","\n","\n","Removed: (9, 3)\n","93.87323760986328\n","\n","\n","Removed: (9, 4)\n","93.950927734375\n","\n","\n","Removed: (9, 5)\n","94.9315185546875\n","\n","\n","Removed: (9, 6)\n","97.35507202148438\n","\n","\n","Removed: (9, 7)\n","96.93553161621094\n","\n","\n","Removed: (9, 8)\n","96.89192199707031\n","\n","\n","Removed: (9, 9)\n","96.93476867675781\n","\n","\n","Removed: (9, 10)\n","97.03781127929688\n","\n","\n","Removed: (9, 11)\n","97.0479965209961\n","\n","\n","Removed: (8, 0)\n","97.39610290527344\n","\n","\n","Removed: (8, 1)\n","97.23046112060547\n","\n","\n","Removed: (8, 2)\n","97.2171401977539\n","\n","\n","Removed: (8, 3)\n","97.17473602294922\n","\n","\n","Removed: (8, 4)\n","97.21766662597656\n","\n","\n","Removed: (8, 5)\n","96.80194854736328\n","\n","\n","Removed: (8, 6)\n","96.68453979492188\n","\n","\n","Removed: (8, 7)\n","96.58705139160156\n","\n","\n","Removed: (8, 9)\n","96.8423843383789\n","\n","\n","Removed: (8, 10)\n","96.2842025756836\n","\n","\n","Removed: (7, 0)\n","96.59566497802734\n","\n","\n","Removed: (7, 1)\n","96.38381958007812\n","\n","\n","Removed: (7, 2)\n","96.24484252929688\n","\n","\n","Removed: (7, 3)\n","96.86627960205078\n","\n","\n","Removed: (7, 4)\n","96.7380599975586\n","\n","\n","Removed: (7, 5)\n","96.34382629394531\n","\n","\n","Removed: (7, 6)\n","96.2051773071289\n","\n","\n","Removed: (7, 7)\n","96.10957336425781\n","\n","\n","Removed: (7, 8)\n","96.2608642578125\n","\n","\n","Removed: (7, 9)\n","96.54042053222656\n","\n","\n","Removed: (7, 11)\n","96.63219451904297\n","\n","\n","Removed: (6, 0)\n","96.725341796875\n","\n","\n","Removed: (6, 1)\n","96.84122467041016\n","\n","\n","Removed: (6, 2)\n","96.96280670166016\n","\n","\n","Removed: (6, 3)\n","97.00373077392578\n","\n","\n","Removed: (6, 4)\n","96.0138931274414\n","\n","\n","Removed: (6, 5)\n","95.95330047607422\n","\n","\n","Removed: (6, 6)\n","96.7596206665039\n","\n","\n","Removed: (6, 7)\n","96.7042236328125\n","\n","\n","Removed: (6, 8)\n","96.47994232177734\n","\n","\n","Removed: (6, 10)\n","96.47576141357422\n","\n","\n","Removed: (6, 11)\n","96.10051727294922\n","\n","\n","Removed: (5, 0)\n","94.74055480957031\n","\n","\n","Removed: (5, 2)\n","94.54972076416016\n","\n","\n","Removed: (5, 3)\n","94.49656677246094\n","\n","\n","Removed: (5, 4)\n","94.2362060546875\n","\n","\n","Removed: (5, 6)\n","94.22344970703125\n","\n","\n","Removed: (5, 7)\n","94.26251220703125\n","\n","\n","Removed: (5, 8)\n","93.7581558227539\n","\n","\n","Removed: (5, 9)\n","93.73676300048828\n","\n","\n","Removed: (5, 10)\n","93.9133071899414\n","\n","\n","Removed: (5, 11)\n","93.51884460449219\n","\n","\n","Removed: (4, 0)\n","93.50386810302734\n","\n","\n","Removed: (4, 1)\n","93.64602661132812\n","\n","\n","Removed: (4, 2)\n","93.6321029663086\n","\n","\n","Removed: (4, 3)\n","93.64144134521484\n","\n","\n","Removed: (4, 4)\n","94.34439849853516\n","\n","\n","Removed: (4, 5)\n","93.33187103271484\n","\n","\n","Removed: (4, 6)\n","94.23515319824219\n","\n","\n","Removed: (4, 7)\n","94.39727020263672\n","\n","\n","Removed: (4, 8)\n","94.73621368408203\n","\n","\n","Removed: (4, 9)\n","94.77008819580078\n","\n","\n","Removed: (4, 10)\n","95.6999740600586\n","\n","\n","Removed: (4, 11)\n","95.3687973022461\n","\n","\n","Removed: (3, 0)\n","95.3076400756836\n","\n","\n","Removed: (3, 1)\n","95.36392974853516\n","\n","\n","Removed: (3, 2)\n","95.40283966064453\n","\n","\n","Removed: (3, 3)\n","94.91533660888672\n","\n","\n","Removed: (3, 4)\n","94.75274658203125\n","\n","\n","Removed: (3, 5)\n","94.35698699951172\n","\n","\n","Removed: (3, 6)\n","94.13472747802734\n","\n","\n","Removed: (3, 7)\n","94.17093658447266\n","\n","\n","Removed: (3, 8)\n","94.55546569824219\n","\n","\n","Removed: (3, 9)\n","94.34230041503906\n","\n","\n","Removed: (3, 10)\n","94.55321502685547\n","\n","\n","Removed: (3, 11)\n","94.29788208007812\n","\n","\n","Removed: (2, 0)\n","94.25189208984375\n","\n","\n","Removed: (2, 1)\n","95.81661224365234\n","\n","\n","Removed: (2, 2)\n","95.97225189208984\n","\n","\n","Removed: (2, 3)\n","96.02025604248047\n","\n","\n","Removed: (2, 4)\n","94.71910858154297\n","\n","\n","Removed: (2, 5)\n","94.22557830810547\n","\n","\n","Removed: (2, 6)\n","94.41987609863281\n","\n","\n","Removed: (2, 7)\n","94.37055206298828\n","\n","\n","Removed: (2, 8)\n","94.27334594726562\n","\n","\n","Removed: (2, 9)\n","94.12699890136719\n","\n","\n","Removed: (2, 10)\n","93.69173431396484\n","\n","\n","Removed: (2, 11)\n","93.75300598144531\n","\n","\n","Removed: (1, 0)\n","93.83026123046875\n","\n","\n","Removed: (1, 1)\n","93.95918273925781\n","\n","\n","Removed: (1, 2)\n","93.85191345214844\n","\n","\n","Removed: (1, 3)\n","93.95596313476562\n","\n","\n","Removed: (1, 4)\n","94.12124633789062\n","\n","\n","Removed: (1, 5)\n","96.39512634277344\n","\n","\n","Removed: (1, 6)\n","96.4314193725586\n","\n","\n","Removed: (1, 7)\n","96.58817291259766\n","\n","\n","Removed: (1, 8)\n","96.71162414550781\n","\n","\n","Removed: (1, 9)\n","96.71624755859375\n","\n","\n","Removed: (1, 10)\n","96.64640045166016\n","\n","\n","Removed: (1, 11)\n","95.41180419921875\n","\n","\n","Removed: (0, 0)\n","95.3204345703125\n","\n","\n","Removed: (0, 2)\n","96.20203399658203\n","\n","\n","Removed: (0, 3)\n","92.0005874633789\n","\n","\n","Removed: (0, 4)\n","92.08238983154297\n","\n","\n","Removed: (0, 5)\n","91.37129974365234\n","\n","\n","Removed: (0, 6)\n","91.6117935180664\n","\n","\n","Removed: (0, 7)\n","90.85210418701172\n","\n","\n","Removed: (0, 8)\n","90.94110107421875\n","\n","\n","Removed: (0, 9)\n","91.14219665527344\n","\n","\n","Removed: (0, 10)\n","93.48979187011719\n","\n","\n","Removed: (0, 11)\n","93.10015106201172\n","\n","\n"]}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698592609356,"user_tz":240,"elapsed":978,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f7bb08f-39de-4f14-e33b-ca4d52c41c90","id":"saFoB5jJ9jaI"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 93.1002\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(93.1002, device='cuda:0')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["backw_10 = curr_circuit.copy()\n","backw_10"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698592609357,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"435e2b93-900c-4c75-9779-35a134025ac3","id":"7zLXLcBP9jaI"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1), (5, 1), (5, 5), (6, 9), (7, 10), (8, 8), (8, 11), (9, 1)]"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["len(backw_10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698592609357,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"640f7f9a-0cd8-4626-e6c9-f775f3764b9c","id":"ksCz3a539jaJ"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]"],"metadata":{"id":"WZl2yDK9BPtA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Remember,this is only on one data sample. So need to try on more data samples to see how much it matches paper's, or what alternate route circuits are found."],"metadata":{"id":"6oLrf1_1BSPt"}},{"cell_type":"markdown","source":["# just rmv last two or three layers"],"metadata":{"id":"pmmqxyXD9-iI"}}]}