{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["DcZG9rm2IAiA","cGX9iHAz_UKX","LyPMS_Gkrrx2","EpQyRtS2rrx2"],"gpuType":"T4","authorship_tag":"ABX9TyNsFXwvWyXD2YVe3ILvn2hV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"01be7de4ac2d426a9b94bcc1a8da9cb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c8e78eb5a244c559fbd250ab5abadef","IPY_MODEL_eca2ef3067ab489c9ee6207f124fc3fa","IPY_MODEL_cbba4d176be4441595d90c809a26604c"],"layout":"IPY_MODEL_da2e54b301cc45dabffeba58e083031e"}},"7c8e78eb5a244c559fbd250ab5abadef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12cf007dd30f4f07a26be8e0f83c2103","placeholder":"​","style":"IPY_MODEL_86d0abad404a4f558364f8dddf1921c0","value":"Downloading (…)neration_config.json: 100%"}},"eca2ef3067ab489c9ee6207f124fc3fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7824a3dd2fa94ce38d9d08d59aec13ce","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa3fdd9fbf0d45cb8d91e39a1d7689a5","value":124}},"cbba4d176be4441595d90c809a26604c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61918dda3e854b1abea3df0240658063","placeholder":"​","style":"IPY_MODEL_59063732f6de47f1a05f437af1579d70","value":" 124/124 [00:00&lt;00:00, 7.55kB/s]"}},"da2e54b301cc45dabffeba58e083031e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12cf007dd30f4f07a26be8e0f83c2103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86d0abad404a4f558364f8dddf1921c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7824a3dd2fa94ce38d9d08d59aec13ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa3fdd9fbf0d45cb8d91e39a1d7689a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61918dda3e854b1abea3df0240658063":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59063732f6de47f1a05f437af1579d70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35e43a2c1c5848b694055e99e2a47ad9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34945c3982aa420d905b66f6087d94a6","IPY_MODEL_63e05b144a624db2b55aa3bf4564615d","IPY_MODEL_0fb3035cee864d7fb064c8ba1b3d01b0"],"layout":"IPY_MODEL_ab84974ecd794535b4c694405f0cfac4"}},"34945c3982aa420d905b66f6087d94a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48497d4bb7fe483e90ff26fa6cfc40bf","placeholder":"​","style":"IPY_MODEL_d3b0bd8277504c898e646ecdca443572","value":"Downloading (…)olve/main/vocab.json: 100%"}},"63e05b144a624db2b55aa3bf4564615d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8cc80c6ae09433c8af0c8de49909f25","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bc025cd5bbd488a921db497516c9779","value":1042301}},"0fb3035cee864d7fb064c8ba1b3d01b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ee44df87df4589bfc1ce176276d3b0","placeholder":"​","style":"IPY_MODEL_07d4c1887fd94516ae0c5df0d74d6857","value":" 1.04M/1.04M [00:00&lt;00:00, 5.28MB/s]"}},"ab84974ecd794535b4c694405f0cfac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48497d4bb7fe483e90ff26fa6cfc40bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b0bd8277504c898e646ecdca443572":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8cc80c6ae09433c8af0c8de49909f25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bc025cd5bbd488a921db497516c9779":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15ee44df87df4589bfc1ce176276d3b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d4c1887fd94516ae0c5df0d74d6857":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c820a267f4ab4db9ab47ccdb7f09823a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_779802630e12480993356374da7b7f3c","IPY_MODEL_cbea60b8b2e143db98260073eae6bacc","IPY_MODEL_2ff4bf24db8f4f80978fe9cee9d0460e"],"layout":"IPY_MODEL_b727782f3b874e4eb33000f9bfdfefe0"}},"779802630e12480993356374da7b7f3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57c6f647e96e4a3ca6ea6ce03a1b5730","placeholder":"​","style":"IPY_MODEL_60dea74a80fe41fb830be99f132f405f","value":"Downloading (…)olve/main/merges.txt: 100%"}},"cbea60b8b2e143db98260073eae6bacc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_168f782d4aca4651998ae23a38593397","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03f4f104d3f84a4ab03bb28fcf59aad3","value":456318}},"2ff4bf24db8f4f80978fe9cee9d0460e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf301e6c1b55410aa3247ce0388b4479","placeholder":"​","style":"IPY_MODEL_3f6648ec2159444fa74b10090280bba5","value":" 456k/456k [00:00&lt;00:00, 3.46MB/s]"}},"b727782f3b874e4eb33000f9bfdfefe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57c6f647e96e4a3ca6ea6ce03a1b5730":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60dea74a80fe41fb830be99f132f405f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"168f782d4aca4651998ae23a38593397":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03f4f104d3f84a4ab03bb28fcf59aad3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf301e6c1b55410aa3247ce0388b4479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f6648ec2159444fa74b10090280bba5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"346e7941573e457fa5dfbc31228b0285":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d59c13027cd46b6b14e2ddf67b85a8c","IPY_MODEL_82d8073591aa428c8ec6aacf9c5ab4b3","IPY_MODEL_b08dc5ce865e48078c689b2265839c09"],"layout":"IPY_MODEL_f7fd541d804d4da39f8416a90e02981c"}},"4d59c13027cd46b6b14e2ddf67b85a8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d6c5d30a4bf4fd4bfeabcd41692c312","placeholder":"​","style":"IPY_MODEL_dfe5d3d3d86c490aa061db1a081dcb26","value":"Downloading (…)/main/tokenizer.json: 100%"}},"82d8073591aa428c8ec6aacf9c5ab4b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3a6b8bf27284c7a962e5a4287247a9e","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2fd541a33e7440ea0ab95f8a2d6ec60","value":1355256}},"b08dc5ce865e48078c689b2265839c09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1be9302b5f3e4591ac844d0354a0af60","placeholder":"​","style":"IPY_MODEL_ff9bba5ccaa5400b92822b026f339cba","value":" 1.36M/1.36M [00:00&lt;00:00, 6.66MB/s]"}},"f7fd541d804d4da39f8416a90e02981c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d6c5d30a4bf4fd4bfeabcd41692c312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfe5d3d3d86c490aa061db1a081dcb26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3a6b8bf27284c7a962e5a4287247a9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2fd541a33e7440ea0ab95f8a2d6ec60":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1be9302b5f3e4591ac844d0354a0af60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff9bba5ccaa5400b92822b026f339cba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a0f4305-989b-4d80-ccb7-60519358d3d9","executionInfo":{"status":"ok","timestamp":1698863643096,"user_tz":240,"elapsed":107228,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-z4wfcmr6\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-z4wfcmr6\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit fa287750606075574df2c538058e67d648e2f952\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate>=0.23.0 (from transformer-lens==0.0.0)\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n","Collecting numpy>=1.24 (from transformer-lens==0.0.0)\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cublas_cu12-12.3.2.9-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (24.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cudnn_cu12-8.9.5.30-py3-none-manylinux1_x86_64.whl (701.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.6/701.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cufft_cu12-11.0.11.19-py3-none-manylinux1_x86_64.whl (98.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_curand_cu12-10.3.4.52-py3-none-manylinux1_x86_64.whl (56.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusolver_cu12-11.5.3.52-py3-none-manylinux1_x86_64.whl (125.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusparse_cu12-12.1.3.153-py3-none-manylinux1_x86_64.whl (195.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nvtx_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.6)\n","Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens==0.0.0)\n","  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.33.1-py2.py3-none-any.whl (243 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=116436 sha256=303c258b4ff833ed9eeb722f1ee890c64ad784434a6e8fcdd12952925d99a48c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-e5nhrvr7/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=08b7d52397b9552363d132cc0b240c21f31b2c9deac720882d10dc71d490b6c0\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, huggingface-hub, gitdb, tokenizers, nvidia-cusolver-cu12, GitPython, accelerate, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.24.1 beartype-0.14.1 datasets-2.14.6 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 huggingface-hub-0.17.3 jaxtyping-0.2.23 multiprocess-0.70.15 numpy-1.26.1 nvidia-cublas-cu12-12.3.2.9 nvidia-cuda-cupti-cu12-12.3.52 nvidia-cuda-nvrtc-cu12-12.3.52 nvidia-cuda-runtime-cu12-12.3.52 nvidia-cudnn-cu12-8.9.5.30 nvidia-cufft-cu12-11.0.11.19 nvidia-curand-cu12-10.3.4.52 nvidia-cusolver-cu12-11.5.3.52 nvidia-cusparse-cu12-12.1.3.153 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.3.52 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.33.1 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.34.1 typeguard-2.13.3 wandb-0.15.12\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1698863643096,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# # Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","# import plotly.io as pio\n","\n","# if IN_COLAB or not DEBUG_MODE:\n","#     # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","#     pio.renderers.default = \"colab\"\n","# else:\n","#     pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1698863654144,"user_tz":240,"elapsed":11064,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1698863655752,"user_tz":240,"elapsed":1614,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698863655752,"user_tz":240,"elapsed":13,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b89438e2-64ff-4f99-ac8c-3c31e4f37b85"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7a73cfdc8640>"]},"metadata":{},"execution_count":5}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KFs9BrbzIAiH","executionInfo":{"status":"ok","timestamp":1698863655752,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# def imshow(tensor, renderer=None, **kwargs):\n","#     px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","# def line(tensor, renderer=None, **kwargs):\n","#     px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","# def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","#     x = utils.to_numpy(x)\n","#     y = utils.to_numpy(y)\n","#     px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"xLwDyosvIAiJ","colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["01be7de4ac2d426a9b94bcc1a8da9cb4","7c8e78eb5a244c559fbd250ab5abadef","eca2ef3067ab489c9ee6207f124fc3fa","cbba4d176be4441595d90c809a26604c","da2e54b301cc45dabffeba58e083031e","12cf007dd30f4f07a26be8e0f83c2103","86d0abad404a4f558364f8dddf1921c0","7824a3dd2fa94ce38d9d08d59aec13ce","fa3fdd9fbf0d45cb8d91e39a1d7689a5","61918dda3e854b1abea3df0240658063","59063732f6de47f1a05f437af1579d70","35e43a2c1c5848b694055e99e2a47ad9","34945c3982aa420d905b66f6087d94a6","63e05b144a624db2b55aa3bf4564615d","0fb3035cee864d7fb064c8ba1b3d01b0","ab84974ecd794535b4c694405f0cfac4","48497d4bb7fe483e90ff26fa6cfc40bf","d3b0bd8277504c898e646ecdca443572","d8cc80c6ae09433c8af0c8de49909f25","6bc025cd5bbd488a921db497516c9779","15ee44df87df4589bfc1ce176276d3b0","07d4c1887fd94516ae0c5df0d74d6857","c820a267f4ab4db9ab47ccdb7f09823a","779802630e12480993356374da7b7f3c","cbea60b8b2e143db98260073eae6bacc","2ff4bf24db8f4f80978fe9cee9d0460e","b727782f3b874e4eb33000f9bfdfefe0","57c6f647e96e4a3ca6ea6ce03a1b5730","60dea74a80fe41fb830be99f132f405f","168f782d4aca4651998ae23a38593397","03f4f104d3f84a4ab03bb28fcf59aad3","cf301e6c1b55410aa3247ce0388b4479","3f6648ec2159444fa74b10090280bba5","346e7941573e457fa5dfbc31228b0285","4d59c13027cd46b6b14e2ddf67b85a8c","82d8073591aa428c8ec6aacf9c5ab4b3","b08dc5ce865e48078c689b2265839c09","f7fd541d804d4da39f8416a90e02981c","1d6c5d30a4bf4fd4bfeabcd41692c312","dfe5d3d3d86c490aa061db1a081dcb26","c3a6b8bf27284c7a962e5a4287247a9e","c2fd541a33e7440ea0ab95f8a2d6ec60","1be9302b5f3e4591ac844d0354a0af60","ff9bba5ccaa5400b92822b026f339cba"]},"executionInfo":{"status":"ok","timestamp":1698863714470,"user_tz":240,"elapsed":13204,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0949550b-f21b-458e-cdb9-f5b5f1ef6e83"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01be7de4ac2d426a9b94bcc1a8da9cb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e43a2c1c5848b694055e99e2a47ad9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c820a267f4ab4db9ab47ccdb7f09823a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"346e7941573e457fa5dfbc31228b0285"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"id":"Fdh5--MfYw7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698863724384,"user_tz":240,"elapsed":9973,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d9916770-2ea1-474a-facc-1e300ae53dd2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9106, done.\u001b[K\n","remote: Counting objects: 100% (1820/1820), done.\u001b[K\n","remote: Compressing objects: 100% (289/289), done.\u001b[K\n","remote: Total 9106 (delta 1614), reused 1608 (delta 1528), pack-reused 7286\u001b[K\n","Receiving objects: 100% (9106/9106), 155.60 MiB | 30.04 MiB/s, done.\n","Resolving deltas: 100% (5507/5507), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"id":"iZ4C_bsXZFfj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698863724385,"user_tz":240,"elapsed":138,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d4734d2a-51aa-4781-872a-020629cca5bf"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV","executionInfo":{"status":"ok","timestamp":1698863724385,"user_tz":240,"elapsed":116,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"8cDWqgJTRWjT","executionInfo":{"status":"ok","timestamp":1698863724385,"user_tz":240,"elapsed":115,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["pos_dict = {\n","    'S1': 0,\n","    'S2': 1,\n","    'S3': 2,\n","    'S4': 3,\n","}"],"metadata":{"id":"sGHl4RZTE98L","executionInfo":{"status":"ok","timestamp":1698863724385,"user_tz":240,"elapsed":101,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        prompt_dict = {\n","            'S1': months[i],\n","            'S2': months[i+1],\n","            'S3': months[i+2],\n","            'S4': months[i+3],\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{months[i]} {months[i+1]} {months[i+2]} {months[i+2]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 11)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"Eu7ZChRPRWjU","executionInfo":{"status":"ok","timestamp":1698863724386,"user_tz":240,"elapsed":102,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        r1 = random.choice(months)\n","        r2 = random.choice(months)\n","        while True:\n","            r3_ind = random.randint(0,len(months)-1)\n","            r4_ind = random.randint(0,len(months)-1)\n","            if months[r3_ind] != months[r4_ind-1]:\n","                break\n","        r3 = months[r3_ind]\n","        r4 = months[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(1, 11)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list_2"],"metadata":{"id":"enLc-f0aRWjV","executionInfo":{"status":"ok","timestamp":1698863724386,"user_tz":240,"elapsed":101,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd783b1f-57ee-4542-a9ee-b5c25fa2083e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': 'October',\n","  'S2': 'July',\n","  'S3': 'February',\n","  'S4': 'May',\n","  'corr': 'May',\n","  'incorr': 'April',\n","  'text': 'October July February May'},\n"," {'S1': 'August',\n","  'S2': 'March',\n","  'S3': 'March',\n","  'S4': 'March',\n","  'corr': 'June',\n","  'incorr': 'May',\n","  'text': 'August March March March'},\n"," {'S1': 'May',\n","  'S2': 'August',\n","  'S3': 'October',\n","  'S4': 'July',\n","  'corr': 'July',\n","  'incorr': 'June',\n","  'text': 'May August October July'},\n"," {'S1': 'October',\n","  'S2': 'April',\n","  'S3': 'February',\n","  'S4': 'February',\n","  'corr': 'August',\n","  'incorr': 'July',\n","  'text': 'October April February February'},\n"," {'S1': 'April',\n","  'S2': 'March',\n","  'S3': 'June',\n","  'S4': 'September',\n","  'corr': 'September',\n","  'incorr': 'August',\n","  'text': 'April March June September'},\n"," {'S1': 'April',\n","  'S2': 'March',\n","  'S3': 'March',\n","  'S4': 'August',\n","  'corr': 'October',\n","  'incorr': 'September',\n","  'text': 'April March March August'},\n"," {'S1': 'August',\n","  'S2': 'February',\n","  'S3': 'December',\n","  'S4': 'September',\n","  'corr': 'November',\n","  'incorr': 'October',\n","  'text': 'August February December September'},\n"," {'S1': 'November',\n","  'S2': 'August',\n","  'S3': 'March',\n","  'S4': 'December',\n","  'corr': 'December',\n","  'incorr': 'November',\n","  'text': 'November August March December'}]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["prompts_list_2 = [{'S1': 'October',\n","  'S2': 'July',\n","  'S3': 'February',\n","  'S4': 'May',\n","  'corr': 'May',\n","  'incorr': 'April',\n","  'text': 'October July February May'},\n"," {'S1': 'August',\n","  'S2': 'March',\n","  'S3': 'March',\n","  'S4': 'March',\n","  'corr': 'June',\n","  'incorr': 'May',\n","  'text': 'August March March March'},\n"," {'S1': 'May',\n","  'S2': 'August',\n","  'S3': 'October',\n","  'S4': 'July',\n","  'corr': 'July',\n","  'incorr': 'June',\n","  'text': 'May August October July'},\n"," {'S1': 'October',\n","  'S2': 'April',\n","  'S3': 'February',\n","  'S4': 'February',\n","  'corr': 'August',\n","  'incorr': 'July',\n","  'text': 'October April February February'},\n"," {'S1': 'April',\n","  'S2': 'March',\n","  'S3': 'June',\n","  'S4': 'September',\n","  'corr': 'September',\n","  'incorr': 'August',\n","  'text': 'April March June September'},\n"," {'S1': 'April',\n","  'S2': 'March',\n","  'S3': 'March',\n","  'S4': 'August',\n","  'corr': 'October',\n","  'incorr': 'September',\n","  'text': 'April March March August'},\n"," {'S1': 'August',\n","  'S2': 'February',\n","  'S3': 'December',\n","  'S4': 'September',\n","  'corr': 'November',\n","  'incorr': 'October',\n","  'text': 'August February December September'},\n"," {'S1': 'November',\n","  'S2': 'August',\n","  'S3': 'March',\n","  'S4': 'December',\n","  'corr': 'December',\n","  'incorr': 'November',\n","  'text': 'November August March December'}]\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"2CkR822QWwZp","executionInfo":{"status":"ok","timestamp":1698866886539,"user_tz":240,"elapsed":176,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"BHHvz84w70vh"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"AFYffMoP70vh","executionInfo":{"status":"ok","timestamp":1698863724522,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"id":"OI3FcmpMaNxB","executionInfo":{"status":"ok","timestamp":1698867017420,"user_tz":240,"elapsed":146,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, orig_score, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        # \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        # \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    # ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    # orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"QLK5m1Ps70vh","executionInfo":{"status":"ok","timestamp":1698863727026,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"ybrqaAul70vi","executionInfo":{"status":"ok","timestamp":1698863727026,"user_tz":240,"elapsed":18,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"p7jLJcMH70vi","executionInfo":{"status":"ok","timestamp":1698863727026,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# iter backw fwd, threshold 3"],"metadata":{"id":"0NYZB-G19liQ"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698864250920,"user_tz":240,"elapsed":523909,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d04bc958-ed40-4ad7-c69a-02f92332a373","id":"-r7d7uel9liR"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","99.86515808105469\n","\n","Removed: (11, 1)\n","99.70606231689453\n","\n","Removed: (11, 2)\n","99.49992370605469\n","\n","Removed: (11, 3)\n","99.38542938232422\n","\n","Removed: (11, 4)\n","99.53096008300781\n","\n","Removed: (11, 5)\n","99.47246551513672\n","\n","Removed: (11, 6)\n","98.66363525390625\n","\n","Removed: (11, 7)\n","98.82321166992188\n","\n","Removed: (11, 9)\n","98.42066955566406\n","\n","Removed: (11, 10)\n","97.1253662109375\n","\n","Removed: (11, 11)\n","97.68685150146484\n","\n","Removed: (10, 0)\n","97.6208724975586\n","\n","Removed: (10, 1)\n","97.27182006835938\n","\n","Removed: (10, 4)\n","97.25872039794922\n","\n","Removed: (10, 5)\n","97.16763305664062\n","\n","Removed: (10, 7)\n","98.66638946533203\n","\n","Removed: (10, 8)\n","98.82259368896484\n","\n","Removed: (10, 9)\n","98.74352264404297\n","\n","Removed: (10, 10)\n","97.57072448730469\n","\n","Removed: (10, 11)\n","97.70975494384766\n","\n","Removed: (9, 0)\n","97.74153137207031\n","\n","Removed: (9, 1)\n","105.21685791015625\n","\n","Removed: (9, 2)\n","104.90479278564453\n","\n","Removed: (9, 3)\n","103.66998291015625\n","\n","Removed: (9, 4)\n","103.63906860351562\n","\n","Removed: (9, 5)\n","110.19441223144531\n","\n","Removed: (9, 6)\n","109.9915542602539\n","\n","Removed: (9, 7)\n","108.26524353027344\n","\n","Removed: (9, 8)\n","108.28204345703125\n","\n","Removed: (9, 9)\n","106.68913269042969\n","\n","Removed: (9, 10)\n","106.58171081542969\n","\n","Removed: (9, 11)\n","103.0827407836914\n","\n","Removed: (8, 0)\n","105.71223449707031\n","\n","Removed: (8, 1)\n","101.04597473144531\n","\n","Removed: (8, 2)\n","100.24053192138672\n","\n","Removed: (8, 3)\n","100.06781768798828\n","\n","Removed: (8, 4)\n","100.05077362060547\n","\n","Removed: (8, 5)\n","100.01148223876953\n","\n","Removed: (8, 7)\n","99.85475158691406\n","\n","Removed: (8, 9)\n","97.89384460449219\n","\n","Removed: (8, 10)\n","98.88445281982422\n","\n","Removed: (7, 0)\n","99.03631591796875\n","\n","Removed: (7, 1)\n","99.02143096923828\n","\n","Removed: (7, 2)\n","98.20072937011719\n","\n","Removed: (7, 3)\n","98.5347900390625\n","\n","Removed: (7, 4)\n","98.52735137939453\n","\n","Removed: (7, 5)\n","97.813232421875\n","\n","Removed: (7, 6)\n","97.33908081054688\n","\n","Removed: (7, 7)\n","97.52716064453125\n","\n","Removed: (7, 8)\n","97.2000503540039\n","\n","Removed: (7, 9)\n","97.15987396240234\n","\n","Removed: (6, 2)\n","97.32890319824219\n","\n","Removed: (6, 3)\n","97.25093841552734\n","\n","Removed: (6, 4)\n","97.24279022216797\n","\n","Removed: (6, 6)\n","97.30945587158203\n","\n","Removed: (6, 7)\n","97.22103118896484\n","\n","Removed: (6, 8)\n","97.81580352783203\n","\n","Removed: (6, 11)\n","97.58025360107422\n","\n","Removed: (5, 2)\n","97.51708221435547\n","\n","Removed: (5, 3)\n","97.28436279296875\n","\n","Removed: (5, 5)\n","98.51979064941406\n","\n","Removed: (5, 6)\n","100.35521697998047\n","\n","Removed: (5, 7)\n","100.31343078613281\n","\n","Removed: (5, 9)\n","100.4271240234375\n","\n","Removed: (5, 10)\n","101.48290252685547\n","\n","Removed: (5, 11)\n","99.20173645019531\n","\n","Removed: (4, 0)\n","99.66248321533203\n","\n","Removed: (4, 1)\n","99.6325454711914\n","\n","Removed: (4, 2)\n","99.7059555053711\n","\n","Removed: (4, 3)\n","99.7529296875\n","\n","Removed: (4, 5)\n","99.81338500976562\n","\n","Removed: (4, 6)\n","99.18519592285156\n","\n","Removed: (4, 7)\n","98.8156509399414\n","\n","Removed: (4, 8)\n","98.7540512084961\n","\n","Removed: (4, 9)\n","98.66223907470703\n","\n","Removed: (4, 10)\n","98.99163055419922\n","\n","Removed: (4, 11)\n","98.23118591308594\n","\n","Removed: (3, 0)\n","98.66072082519531\n","\n","Removed: (3, 1)\n","98.4151611328125\n","\n","Removed: (3, 2)\n","98.81522369384766\n","\n","Removed: (3, 3)\n","98.59254455566406\n","\n","Removed: (3, 4)\n","98.47972106933594\n","\n","Removed: (3, 5)\n","98.43270874023438\n","\n","Removed: (3, 6)\n","98.2032470703125\n","\n","Removed: (3, 8)\n","97.77738189697266\n","\n","Removed: (3, 9)\n","97.65203094482422\n","\n","Removed: (3, 11)\n","97.5272216796875\n","\n","Removed: (2, 0)\n","97.70133972167969\n","\n","Removed: (2, 1)\n","97.63310241699219\n","\n","Removed: (2, 3)\n","97.34881591796875\n","\n","Removed: (2, 4)\n","97.21691131591797\n","\n","Removed: (2, 6)\n","97.0937728881836\n","\n","Removed: (2, 8)\n","97.29627227783203\n","\n","Removed: (2, 10)\n","97.31609344482422\n","\n","Removed: (2, 11)\n","97.4222640991211\n","\n","Removed: (1, 1)\n","97.51689147949219\n","\n","Removed: (1, 2)\n","97.63140869140625\n","\n","Removed: (1, 3)\n","97.7210464477539\n","\n","Removed: (1, 4)\n","97.60981750488281\n","\n","Removed: (1, 6)\n","97.53196716308594\n","\n","Removed: (1, 7)\n","97.46855163574219\n","\n","Removed: (1, 8)\n","97.5976791381836\n","\n","Removed: (1, 9)\n","97.30552673339844\n","\n","Removed: (1, 10)\n","97.43289184570312\n","\n","Removed: (1, 11)\n","97.90592956542969\n","\n","Removed: (0, 2)\n","98.10641479492188\n","\n","Removed: (0, 4)\n","98.04987335205078\n","\n","Removed: (0, 6)\n","98.2245101928711\n","\n","Removed: (0, 7)\n","99.02149200439453\n","\n","Removed: (0, 8)\n","99.51190948486328\n","\n","Removed: (0, 9)\n","99.8602066040039\n","\n","Removed: (0, 10)\n","99.8405990600586\n","\n","Removed: (0, 11)\n","99.43394470214844\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","98.60706329345703\n","\n","Removed: (0, 3)\n","97.32479095458984\n","\n","Removed: (2, 5)\n","97.15216064453125\n","\n","Removed: (10, 6)\n","97.02217102050781\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698864250921,"user_tz":240,"elapsed":27,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b338a53-2d9d-4e20-ca26-def8fc3a8c56","id":"JBXczdVO9liR"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 5),\n"," (1, 0),\n"," (1, 5),\n"," (2, 2),\n"," (2, 7),\n"," (2, 9),\n"," (3, 7),\n"," (3, 10),\n"," (4, 4),\n"," (5, 0),\n"," (5, 1),\n"," (5, 4),\n"," (5, 8),\n"," (6, 0),\n"," (6, 1),\n"," (6, 5),\n"," (6, 9),\n"," (6, 10),\n"," (7, 10),\n"," (7, 11),\n"," (8, 6),\n"," (8, 8),\n"," (8, 11),\n"," (10, 2),\n"," (10, 3),\n"," (11, 8)]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864250921,"user_tz":240,"elapsed":23,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"acfcef36-d072-453c-acb0-5eb33dd70754","id":"5oCXGBxj9liS"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## loop rmv and check for most impt heads"],"metadata":{"id":"8At2Kqx69liS"}},{"cell_type":"code","source":["circ = bf_3\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864252925,"user_tz":240,"elapsed":2026,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c63cebab-b98e-42fd-8af6-40fd46165952","id":"ivoDzNKY9liS"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0222\n"]}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864323666,"user_tz":240,"elapsed":70746,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3d8e7189-eae2-4246-c30c-9626a9973465","id":"vsUtHR-y9liS"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 90.5230\n","removed: (0, 5)\n","Average logit difference (circuit / full) %: 95.8878\n","removed: (1, 0)\n","Average logit difference (circuit / full) %: 95.7988\n","removed: (1, 5)\n","Average logit difference (circuit / full) %: 92.9287\n","removed: (2, 2)\n","Average logit difference (circuit / full) %: 95.9326\n","removed: (2, 7)\n","Average logit difference (circuit / full) %: 96.7999\n","removed: (2, 9)\n","Average logit difference (circuit / full) %: 96.4289\n","removed: (3, 7)\n","Average logit difference (circuit / full) %: 95.0207\n","removed: (3, 10)\n","Average logit difference (circuit / full) %: 96.1482\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 41.1407\n","removed: (5, 0)\n","Average logit difference (circuit / full) %: 93.3619\n","removed: (5, 1)\n","Average logit difference (circuit / full) %: 96.0624\n","removed: (5, 4)\n","Average logit difference (circuit / full) %: 96.5859\n","removed: (5, 8)\n","Average logit difference (circuit / full) %: 90.8191\n","removed: (6, 0)\n","Average logit difference (circuit / full) %: 96.6470\n","removed: (6, 1)\n","Average logit difference (circuit / full) %: 95.3798\n","removed: (6, 5)\n","Average logit difference (circuit / full) %: 96.2903\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 94.6375\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 81.4386\n","removed: (7, 10)\n","Average logit difference (circuit / full) %: 91.1558\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 82.6383\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 90.7607\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 92.8269\n","removed: (8, 11)\n","Average logit difference (circuit / full) %: 84.3821\n","removed: (10, 2)\n","Average logit difference (circuit / full) %: 95.4302\n","removed: (10, 3)\n","Average logit difference (circuit / full) %: 96.0380\n","removed: (11, 8)\n","Average logit difference (circuit / full) %: 92.7269\n"]}]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864323666,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"08266ac1-68e2-4e62-a9c4-1fb31accdbcc","id":"MNzdWLFj9liT"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 41.14067840576172,\n"," (6, 10): 81.43862915039062,\n"," (7, 11): 82.63829803466797,\n"," (8, 11): 84.38214111328125,\n"," (0, 1): 90.52302551269531,\n"," (8, 6): 90.76065826416016,\n"," (5, 8): 90.81907653808594,\n"," (7, 10): 91.15576171875,\n"," (11, 8): 92.72691345214844,\n"," (8, 8): 92.82693481445312,\n"," (1, 5): 92.92874145507812,\n"," (5, 0): 93.36192321777344,\n"," (6, 9): 94.63748168945312,\n"," (3, 7): 95.02069091796875,\n"," (6, 1): 95.37979888916016,\n"," (10, 2): 95.4301986694336,\n"," (1, 0): 95.79875183105469,\n"," (0, 5): 95.88780212402344,\n"," (2, 2): 95.9326400756836,\n"," (10, 3): 96.03795623779297,\n"," (5, 1): 96.06241607666016,\n"," (3, 10): 96.148193359375,\n"," (6, 5): 96.29025268554688,\n"," (2, 9): 96.42891693115234,\n"," (5, 4): 96.58585357666016,\n"," (6, 0): 96.64701080322266,\n"," (2, 7): 96.79991149902344}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864323666,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ae12ab82-a9c8-4f91-b7c5-d397388b5fed","id":"RPCynBNH9liT"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4) -55.88\n","(6, 10) -15.58\n","(7, 11) -14.38\n","(8, 11) -12.64\n","(0, 1) -6.5\n","(8, 6) -6.26\n","(5, 8) -6.2\n","(7, 10) -5.87\n","(11, 8) -4.3\n","(8, 8) -4.2\n","(1, 5) -4.09\n","(5, 0) -3.66\n","(6, 9) -2.38\n","(3, 7) -2.0\n","(6, 1) -1.64\n","(10, 2) -1.59\n","(1, 0) -1.22\n","(0, 5) -1.13\n","(2, 2) -1.09\n","(10, 3) -0.98\n","(5, 1) -0.96\n","(3, 10) -0.87\n","(6, 5) -0.73\n","(2, 9) -0.59\n","(5, 4) -0.44\n","(6, 0) -0.38\n","(2, 7) -0.22\n"]}]},{"cell_type":"markdown","source":["# try other tasks circs"],"metadata":{"id":"xbZkzn0nrrxt"}},{"cell_type":"markdown","source":["### gt, IOI"],"metadata":{"id":"LyPMS_Gkrrx2"}},{"cell_type":"code","source":["# greater-than\n","circuit = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864326131,"user_tz":240,"elapsed":2472,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"30c1c1f0-7015-4f8b-b048-a8245af6f831","id":"XHXv_LqIrrx2"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 36.6119\n"]},{"output_type":"execute_result","data":{"text/plain":["36.61189651489258"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# IOI\n","circuit = [(0, 1), (0, 10), (2, 2), (3, 0), (4, 11), (5, 5), (5, 8), (5, 9), (6, 9), (7, 3), (7, 9), (8, 6), (8, 10), (9, 0), (9, 6), (9, 7), (9, 9), (10, 0), (10, 1), (10, 2), (10, 6), (10, 7), (10, 10), (11, 2), (11, 9), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864329815,"user_tz":240,"elapsed":3703,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ffc6a2d6-d638-4d76-d0cb-65d0e5d439ba","id":"5_jk2DSIrrx2"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 11.5647\n"]},{"output_type":"execute_result","data":{"text/plain":["11.56466007232666"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["### bf 80"],"metadata":{"id":"EpQyRtS2rrx2"}},{"cell_type":"code","source":["# # fb 80, digits incr\n","# # https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\n","# circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"id":"mLUWQCDwrrx2","executionInfo":{"status":"ok","timestamp":1698864329816,"user_tz":240,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# # fb 80, numwords\n","# # https://colab.research.google.com/drive/1QTv-4osLHadCAay0beew-xlXszPCG88s#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","# circuit = [(3, 2), (4, 4), (4, 8), (4, 10), (4, 11), (5, 5), (5, 6), (5, 7), (5, 8), (6, 1), (6, 7), (6, 9), (6, 10), (7, 0), (7, 2), (7, 5), (7, 6), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 11), (9, 1), (10, 2)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"id":"LBLrjLNDrrx3","executionInfo":{"status":"ok","timestamp":1698864329818,"user_tz":240,"elapsed":67,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# # fb 80, months\n","# # https://colab.research.google.com/drive/1lhQqlizYGMC11vzp6I9mJ3dyxIr8tV3l#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","# circuit = [(4, 4), (7, 11), (8, 6), (8, 9), (8, 11), (9, 1), (9, 5), (11, 10)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"id":"mN4s4m3frrx3","executionInfo":{"status":"ok","timestamp":1698864329818,"user_tz":240,"elapsed":64,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["### bf 97"],"metadata":{"id":"ud0Sbmlprrx3"}},{"cell_type":"code","source":["# digits incr\n","circuit = [(0, 1), (0, 2), (0, 5), (0, 7), (0, 8), (0, 10), (1, 0), (1, 1), (1, 3), (1, 5), (1, 7), (1, 11), (2, 0), (2, 1), (2, 2), (2, 3), (2, 5), (2, 6), (2, 8), (2, 9), (2, 10), (3, 3), (3, 7), (3, 8), (3, 10), (3, 11), (4, 2), (4, 4), (4, 6), (4, 10), (4, 11), (5, 1), (5, 4), (5, 8), (5, 10), (5, 11), (6, 2), (6, 3), (6, 4), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (7, 11), (8, 6), (8, 8), (9, 1), (10, 7), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864332665,"user_tz":240,"elapsed":2908,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"55cd6902-10aa-4150-8230-ed08c80e949c","id":"zI9JKq-frrx3"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 60.5582\n"]},{"output_type":"execute_result","data":{"text/plain":["60.55823516845703"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# numwords\n","circuit = [(0, 1), (0, 6), (0, 7), (0, 9), (0, 10), (1, 0), (1, 5), (3, 3), (4, 4), (4, 10), (5, 4), (5, 6), (5, 8), (6, 6), (6, 10), (7, 6), (7, 10), (7, 11), (8, 8), (9, 1), (10, 7)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864334988,"user_tz":240,"elapsed":2339,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9c617007-d78a-4271-a497-ccd0c33172a3","id":"XgtbBeiarrx3"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 52.9796\n"]},{"output_type":"execute_result","data":{"text/plain":["52.97957229614258"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# months\n","# https://colab.research.google.com/drive/1lhQqlizYGMC11vzp6I9mJ3dyxIr8tV3l#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","# circuit = [(4, 4), (7, 11), (8, 6), (8, 9), (8, 11), (9, 1), (9, 5), (11, 10)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"id":"IYcsLUjIrrx3","executionInfo":{"status":"ok","timestamp":1698864334988,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["# try again using incorr logit i"],"metadata":{"id":"jd3YYf6dNzDm"}},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        prompt_dict = {\n","            'S1': months[i],\n","            'S2': months[i+1],\n","            'S3': months[i+2],\n","            'S4': months[i+3],\n","            'corr': months[i+4],\n","            'incorr': months[i],\n","            'text': f\"{months[i]} {months[i+1]} {months[i+2]} {months[i+2]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 11)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"woWuxNIKN1OJ","executionInfo":{"status":"ok","timestamp":1698867116258,"user_tz":240,"elapsed":186,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"id":"n1QTujmwRMQx","executionInfo":{"status":"ok","timestamp":1698867117739,"user_tz":240,"elapsed":184,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":["## iter backw fwd, threshold 3"],"metadata":{"id":"KVw7I5BQN7AO"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698865899559,"user_tz":240,"elapsed":494085,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6a3ed31-012b-499c-f3f0-6a0515877c93","id":"3zRyTSrqN7AO"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","100.27477264404297\n","\n","Removed: (11, 1)\n","100.23351287841797\n","\n","Removed: (11, 2)\n","100.46318817138672\n","\n","Removed: (11, 3)\n","100.17131042480469\n","\n","Removed: (11, 4)\n","100.55448150634766\n","\n","Removed: (11, 5)\n","100.61019134521484\n","\n","Removed: (11, 6)\n","101.81040954589844\n","\n","Removed: (11, 7)\n","101.80139923095703\n","\n","Removed: (11, 8)\n","98.91886138916016\n","\n","Removed: (11, 9)\n","98.89364624023438\n","\n","Removed: (11, 11)\n","99.15338134765625\n","\n","Removed: (10, 0)\n","99.13613891601562\n","\n","Removed: (10, 1)\n","100.12897491455078\n","\n","Removed: (10, 2)\n","100.70376586914062\n","\n","Removed: (10, 3)\n","101.1800308227539\n","\n","Removed: (10, 4)\n","101.31055450439453\n","\n","Removed: (10, 5)\n","101.12251281738281\n","\n","Removed: (10, 6)\n","100.38468933105469\n","\n","Removed: (10, 8)\n","100.62175750732422\n","\n","Removed: (10, 9)\n","100.5606689453125\n","\n","Removed: (10, 10)\n","99.8133544921875\n","\n","Removed: (10, 11)\n","99.99896240234375\n","\n","Removed: (9, 0)\n","100.01261901855469\n","\n","Removed: (9, 2)\n","99.6978530883789\n","\n","Removed: (9, 3)\n","98.97310638427734\n","\n","Removed: (9, 4)\n","99.01006317138672\n","\n","Removed: (9, 5)\n","98.32669830322266\n","\n","Removed: (9, 6)\n","98.0379638671875\n","\n","Removed: (9, 8)\n","98.02532958984375\n","\n","Removed: (9, 9)\n","97.29544067382812\n","\n","Removed: (9, 10)\n","97.25281524658203\n","\n","Removed: (8, 0)\n","98.64603424072266\n","\n","Removed: (8, 2)\n","98.29534149169922\n","\n","Removed: (8, 3)\n","98.02164459228516\n","\n","Removed: (8, 4)\n","98.00370788574219\n","\n","Removed: (8, 5)\n","97.98628997802734\n","\n","Removed: (8, 7)\n","97.99247741699219\n","\n","Removed: (8, 10)\n","99.04789733886719\n","\n","Removed: (8, 11)\n","99.68678283691406\n","\n","Removed: (7, 0)\n","100.27881622314453\n","\n","Removed: (7, 1)\n","100.26317596435547\n","\n","Removed: (7, 2)\n","99.81619262695312\n","\n","Removed: (7, 3)\n","99.64189147949219\n","\n","Removed: (7, 4)\n","99.66586303710938\n","\n","Removed: (7, 5)\n","99.04739379882812\n","\n","Removed: (7, 6)\n","97.87159729003906\n","\n","Removed: (7, 7)\n","97.15158081054688\n","\n","Removed: (7, 9)\n","97.18389892578125\n","\n","Removed: (7, 10)\n","98.15860748291016\n","\n","Removed: (6, 0)\n","97.75288391113281\n","\n","Removed: (6, 1)\n","99.24651336669922\n","\n","Removed: (6, 2)\n","99.20854187011719\n","\n","Removed: (6, 3)\n","99.19878387451172\n","\n","Removed: (6, 4)\n","99.10107421875\n","\n","Removed: (6, 5)\n","99.02191925048828\n","\n","Removed: (6, 6)\n","98.5276870727539\n","\n","Removed: (6, 7)\n","98.27660369873047\n","\n","Removed: (6, 8)\n","98.61332702636719\n","\n","Removed: (6, 11)\n","98.45637512207031\n","\n","Removed: (5, 1)\n","97.66431427001953\n","\n","Removed: (5, 2)\n","97.7006607055664\n","\n","Removed: (5, 3)\n","97.65064239501953\n","\n","Removed: (5, 4)\n","97.1858901977539\n","\n","Removed: (5, 5)\n","98.51045989990234\n","\n","Removed: (5, 7)\n","98.5235824584961\n","\n","Removed: (5, 8)\n","101.39987182617188\n","\n","Removed: (5, 9)\n","101.502685546875\n","\n","Removed: (5, 10)\n","101.99901580810547\n","\n","Removed: (5, 11)\n","101.2509536743164\n","\n","Removed: (4, 0)\n","100.84490203857422\n","\n","Removed: (4, 1)\n","100.8598861694336\n","\n","Removed: (4, 2)\n","100.74022674560547\n","\n","Removed: (4, 3)\n","100.18172454833984\n","\n","Removed: (4, 5)\n","100.19821166992188\n","\n","Removed: (4, 6)\n","100.5010986328125\n","\n","Removed: (4, 7)\n","100.22283935546875\n","\n","Removed: (4, 8)\n","100.64716339111328\n","\n","Removed: (4, 9)\n","100.64530944824219\n","\n","Removed: (4, 10)\n","99.49542999267578\n","\n","Removed: (4, 11)\n","98.6583023071289\n","\n","Removed: (3, 0)\n","99.02839660644531\n","\n","Removed: (3, 1)\n","99.25535583496094\n","\n","Removed: (3, 2)\n","100.05171966552734\n","\n","Removed: (3, 3)\n","99.6327133178711\n","\n","Removed: (3, 4)\n","100.84308624267578\n","\n","Removed: (3, 5)\n","100.88224029541016\n","\n","Removed: (3, 6)\n","100.16543579101562\n","\n","Removed: (3, 7)\n","99.39244842529297\n","\n","Removed: (3, 8)\n","98.56494140625\n","\n","Removed: (3, 9)\n","98.00251007080078\n","\n","Removed: (3, 10)\n","97.1229248046875\n","\n","Removed: (3, 11)\n","97.00479125976562\n","\n","Removed: (2, 0)\n","97.01956939697266\n","\n","Removed: (2, 1)\n","97.05145263671875\n","\n","Removed: (2, 4)\n","97.04536437988281\n","\n","Removed: (2, 6)\n","97.1332778930664\n","\n","Removed: (2, 10)\n","97.61698913574219\n","\n","Removed: (2, 11)\n","97.5558090209961\n","\n","Removed: (1, 0)\n","97.2438735961914\n","\n","Removed: (1, 1)\n","97.54288482666016\n","\n","Removed: (1, 2)\n","97.8648910522461\n","\n","Removed: (1, 3)\n","97.64124298095703\n","\n","Removed: (1, 4)\n","97.425537109375\n","\n","Removed: (1, 5)\n","99.27580261230469\n","\n","Removed: (1, 6)\n","99.59795379638672\n","\n","Removed: (1, 7)\n","99.34895324707031\n","\n","Removed: (1, 8)\n","99.5550308227539\n","\n","Removed: (1, 9)\n","99.1781005859375\n","\n","Removed: (1, 10)\n","99.46469116210938\n","\n","Removed: (1, 11)\n","99.58702087402344\n","\n","Removed: (0, 0)\n","99.10199737548828\n","\n","Removed: (0, 2)\n","98.86730194091797\n","\n","Removed: (0, 3)\n","97.80921936035156\n","\n","Removed: (0, 4)\n","98.07965087890625\n","\n","Removed: (0, 5)\n","97.06893920898438\n","\n","Removed: (0, 6)\n","97.3018798828125\n","\n","Removed: (0, 7)\n","97.49102020263672\n","\n","Removed: (0, 8)\n","97.2193832397461\n","\n","Removed: (0, 10)\n","99.70881652832031\n","\n","Removed: (0, 11)\n","99.64701080322266\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 9)\n","99.06260681152344\n","\n","Removed: (2, 2)\n","97.02288055419922\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698865899559,"user_tz":240,"elapsed":23,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d34b225d-8224-4479-af2d-22510058a201","id":"b_fMrKD5N7AP"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (2, 3),\n"," (2, 5),\n"," (2, 7),\n"," (2, 8),\n"," (2, 9),\n"," (4, 4),\n"," (5, 0),\n"," (5, 6),\n"," (6, 9),\n"," (6, 10),\n"," (7, 8),\n"," (7, 11),\n"," (8, 1),\n"," (8, 6),\n"," (8, 8),\n"," (8, 9),\n"," (9, 1),\n"," (9, 7),\n"," (9, 11),\n"," (10, 7),\n"," (11, 10)]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865899559,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7c12c357-491e-4c34-c712-8496c5a78e9f","id":"_UR3P5ZtN7AP"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["## loop rmv and check for most impt heads"],"metadata":{"id":"TvUXAq0lN7AP"}},{"cell_type":"code","source":["circ = bf_3\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865901963,"user_tz":240,"elapsed":2421,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"97210e45-215a-488e-f95f-31f217f4fa7e","id":"SH8u_sXXN7AP"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0229\n"]}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865959235,"user_tz":240,"elapsed":57276,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"40cc0d91-539d-4834-d470-306970ee919a","id":"Z61lZ7rsN7AQ"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 89.3814\n","removed: (2, 3)\n","Average logit difference (circuit / full) %: 96.9478\n","removed: (2, 5)\n","Average logit difference (circuit / full) %: 96.8179\n","removed: (2, 7)\n","Average logit difference (circuit / full) %: 96.6588\n","removed: (2, 8)\n","Average logit difference (circuit / full) %: 96.6361\n","removed: (2, 9)\n","Average logit difference (circuit / full) %: 96.5452\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 24.7081\n","removed: (5, 0)\n","Average logit difference (circuit / full) %: 93.0373\n","removed: (5, 6)\n","Average logit difference (circuit / full) %: 94.2867\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 94.3910\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 88.5307\n","removed: (7, 8)\n","Average logit difference (circuit / full) %: 96.6392\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 82.5906\n","removed: (8, 1)\n","Average logit difference (circuit / full) %: 93.5788\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 92.0341\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 94.9877\n","removed: (8, 9)\n","Average logit difference (circuit / full) %: 93.6339\n","removed: (9, 1)\n","Average logit difference (circuit / full) %: 35.3323\n","removed: (9, 7)\n","Average logit difference (circuit / full) %: 94.7443\n","removed: (9, 11)\n","Average logit difference (circuit / full) %: 94.2776\n","removed: (10, 7)\n","Average logit difference (circuit / full) %: 91.8446\n","removed: (11, 10)\n","Average logit difference (circuit / full) %: 95.5536\n"]}]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865959235,"user_tz":240,"elapsed":22,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"372dd408-7311-4e65-ec44-981e442986ed","id":"8EyMfrgiN7AQ"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 24.708080291748047,\n"," (9, 1): 35.33229064941406,\n"," (7, 11): 82.59058380126953,\n"," (6, 10): 88.53067016601562,\n"," (0, 1): 89.3814468383789,\n"," (10, 7): 91.84457397460938,\n"," (8, 6): 92.03407287597656,\n"," (5, 0): 93.03734588623047,\n"," (8, 1): 93.57878875732422,\n"," (8, 9): 93.63392639160156,\n"," (9, 11): 94.2775650024414,\n"," (5, 6): 94.28670501708984,\n"," (6, 9): 94.3909683227539,\n"," (9, 7): 94.74427032470703,\n"," (8, 8): 94.98773193359375,\n"," (11, 10): 95.5536117553711,\n"," (2, 9): 96.54518127441406,\n"," (2, 8): 96.63613891601562,\n"," (7, 8): 96.63919067382812,\n"," (2, 7): 96.65879821777344,\n"," (2, 5): 96.81787109375,\n"," (2, 3): 96.94779205322266}"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865959235,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"172bd801-8fa0-40e9-83e1-8f18f5d5fdb4","id":"uJKt-0nLN7AR"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4) -72.31\n","(9, 1) -61.69\n","(7, 11) -14.43\n","(6, 10) -8.49\n","(0, 1) -7.64\n","(10, 7) -5.18\n","(8, 6) -4.99\n","(5, 0) -3.99\n","(8, 1) -3.44\n","(8, 9) -3.39\n","(9, 11) -2.75\n","(5, 6) -2.74\n","(6, 9) -2.63\n","(9, 7) -2.28\n","(8, 8) -2.04\n","(11, 10) -1.47\n","(2, 9) -0.48\n","(2, 8) -0.39\n","(7, 8) -0.38\n","(2, 7) -0.36\n","(2, 5) -0.21\n","(2, 3) -0.08\n"]}]},{"cell_type":"markdown","source":["## try other tasks circs"],"metadata":{"id":"us1d5RRwN7AT"}},{"cell_type":"markdown","source":["### gt, IOI"],"metadata":{"id":"QZqbx0eNN7AT"}},{"cell_type":"code","source":["# greater-than\n","circuit = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867133143,"user_tz":240,"elapsed":2614,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7806b903-6e1b-4466-c5af-677d10c9745f","id":"vXU_R6dwN7AU"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 27.5909\n"]},{"output_type":"execute_result","data":{"text/plain":["27.590892791748047"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["# IOI\n","circuit = [(0, 1), (0, 10), (2, 2), (3, 0), (4, 11), (5, 5), (5, 8), (5, 9), (6, 9), (7, 3), (7, 9), (8, 6), (8, 10), (9, 0), (9, 6), (9, 7), (9, 9), (10, 0), (10, 1), (10, 2), (10, 6), (10, 7), (10, 10), (11, 2), (11, 9), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867152420,"user_tz":240,"elapsed":3376,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4910e12c-69a5-4043-b3c7-df306bee6bf1","id":"LVTf-5xWN7AU"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 4.3136\n"]},{"output_type":"execute_result","data":{"text/plain":["4.313619613647461"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","source":["### bf 80"],"metadata":{"id":"RXnzj2mNN7AU"}},{"cell_type":"code","source":["# # fb 80, digits incr\n","# # https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\n","# circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698865963940,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"Yna0p1akN7AV"},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# # fb 80, numwords\n","# # https://colab.research.google.com/drive/1QTv-4osLHadCAay0beew-xlXszPCG88s#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","# circuit = [(3, 2), (4, 4), (4, 8), (4, 10), (4, 11), (5, 5), (5, 6), (5, 7), (5, 8), (6, 1), (6, 7), (6, 9), (6, 10), (7, 0), (7, 2), (7, 5), (7, 6), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 11), (9, 1), (10, 2)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698865963941,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"vGe3Ll2MN7AV"},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# # fb 80, months\n","# # https://colab.research.google.com/drive/1lhQqlizYGMC11vzp6I9mJ3dyxIr8tV3l#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","# circuit = [(4, 4), (7, 11), (8, 6), (8, 9), (8, 11), (9, 1), (9, 5), (11, 10)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698865963941,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"yjL4DER0N7AW"},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["### bf 97"],"metadata":{"id":"50eM-EzBN7AX"}},{"cell_type":"code","source":["# digits incr\n","# incorr i+3\n","circuit = [(0, 1), (0, 2), (0, 5), (0, 7), (0, 8), (0, 10), (1, 0), (1, 1), (1, 3), (1, 5), (1, 7), (1, 11), (2, 0), (2, 1), (2, 2), (2, 3), (2, 5), (2, 6), (2, 8), (2, 9), (2, 10), (3, 3), (3, 7), (3, 8), (3, 10), (3, 11), (4, 2), (4, 4), (4, 6), (4, 10), (4, 11), (5, 1), (5, 4), (5, 8), (5, 10), (5, 11), (6, 2), (6, 3), (6, 4), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (7, 11), (8, 6), (8, 8), (9, 1), (10, 7), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867158384,"user_tz":240,"elapsed":2303,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"32f07cb9-4daa-4b1b-dbe3-cfbb3ac32ec2","id":"DwwDm1_SN7AX"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 82.0537\n"]},{"output_type":"execute_result","data":{"text/plain":["82.05374145507812"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["# numwords\n","# incorr i+3\n","circuit = [(0, 1), (0, 6), (0, 7), (0, 9), (0, 10), (1, 0), (1, 5), (3, 3), (4, 4), (4, 10), (5, 4), (5, 6), (5, 8), (6, 6), (6, 10), (7, 6), (7, 10), (7, 11), (8, 8), (9, 1), (10, 7)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867160977,"user_tz":240,"elapsed":2614,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"83f017fe-3da5-4d59-a1bf-2bb63e7cf8b8","id":"QWNHoRklN7AX"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 70.6149\n"]},{"output_type":"execute_result","data":{"text/plain":["70.61485290527344"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["# months\n","# incorr i\n","circuit = [(0, 1), (2, 3), (2, 5), (2, 7), (2, 8), (2, 9), (4, 4), (5, 0), (5, 6), (6, 9), (6, 10), (7, 8), (7, 11), (8, 1), (8, 6), (8, 8), (8, 9), (9, 1), (9, 7), (9, 11), (10, 7), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698867125134,"user_tz":240,"elapsed":2278,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"dWxR-ZVVN7AY","outputId":"f41689b6-41b5-476f-addf-9a6f4b3a408c"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 96.5812\n"]},{"output_type":"execute_result","data":{"text/plain":["96.5811996459961"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","source":["# try incorr i+3 again"],"metadata":{"id":"UCsBj6jxUlnY"}},{"cell_type":"markdown","source":["## Generate dataset with multiple prompts"],"metadata":{"id":"cYwtu-K-UneI"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322236,"user_tz":240,"elapsed":166,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"lvqq7DttUneQ"},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["pos_dict = {\n","    'S1': 0,\n","    'S2': 1,\n","    'S3': 2,\n","    'S4': 3,\n","}"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322421,"user_tz":240,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"dhkFFx2LUneR"},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        prompt_dict = {\n","            'S1': months[i],\n","            'S2': months[i+1],\n","            'S3': months[i+2],\n","            'S4': months[i+3],\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{months[i]} {months[i+1]} {months[i+2]} {months[i+2]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 11)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322421,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"1Tvj5HECUneR"},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        r1 = random.choice(months)\n","        r2 = random.choice(months)\n","        while True:\n","            r3_ind = random.randint(0,len(months)-1)\n","            r4_ind = random.randint(0,len(months)-1)\n","            if months[r3_ind] != months[r4_ind-1]:\n","                break\n","        r3 = months[r3_ind]\n","        r4 = months[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(1, 11)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list_2"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322661,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a844a321-00ab-4967-e941-91e4af6bfd3b","id":"HIYRruzHUneR"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': 'June',\n","  'S2': 'December',\n","  'S3': 'April',\n","  'S4': 'November',\n","  'corr': 'May',\n","  'incorr': 'April',\n","  'text': 'June December April November'},\n"," {'S1': 'July',\n","  'S2': 'June',\n","  'S3': 'November',\n","  'S4': 'February',\n","  'corr': 'June',\n","  'incorr': 'May',\n","  'text': 'July June November February'},\n"," {'S1': 'February',\n","  'S2': 'October',\n","  'S3': 'September',\n","  'S4': 'July',\n","  'corr': 'July',\n","  'incorr': 'June',\n","  'text': 'February October September July'},\n"," {'S1': 'January',\n","  'S2': 'November',\n","  'S3': 'August',\n","  'S4': 'March',\n","  'corr': 'August',\n","  'incorr': 'July',\n","  'text': 'January November August March'},\n"," {'S1': 'January',\n","  'S2': 'December',\n","  'S3': 'March',\n","  'S4': 'August',\n","  'corr': 'September',\n","  'incorr': 'August',\n","  'text': 'January December March August'},\n"," {'S1': 'July',\n","  'S2': 'July',\n","  'S3': 'September',\n","  'S4': 'February',\n","  'corr': 'October',\n","  'incorr': 'September',\n","  'text': 'July July September February'},\n"," {'S1': 'July',\n","  'S2': 'October',\n","  'S3': 'January',\n","  'S4': 'July',\n","  'corr': 'November',\n","  'incorr': 'October',\n","  'text': 'July October January July'},\n"," {'S1': 'May',\n","  'S2': 'June',\n","  'S3': 'July',\n","  'S4': 'November',\n","  'corr': 'December',\n","  'incorr': 'November',\n","  'text': 'May June July November'}]"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["## Ablation Expm Functions"],"metadata":{"id":"EVxTYHXEUneS"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322662,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"-UlxBGiHUneS"},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322662,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"F9AvkRfVUneS"},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, orig_score, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        # \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        # \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    # ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    # orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322662,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"vZmic9i9UneT"},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322662,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"eW51m3ZsUneT"},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322663,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"Rig2XCKxUneT"},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["## iter backw fwd, threshold 3"],"metadata":{"id":"n0h7PHSEUneT"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"error","timestamp":1698866464068,"user_tz":240,"elapsed":141412,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1aeaecbc-25af-48bc-9e51-8e1a1aa4ede3","id":"3X9ObWncUneU"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","187.2841339111328\n","\n","Removed: (11, 1)\n","186.7925262451172\n","\n","Removed: (11, 2)\n","186.4005126953125\n","\n","Removed: (11, 3)\n","186.14523315429688\n","\n","Removed: (11, 4)\n","186.22230529785156\n","\n","Removed: (11, 5)\n","186.20193481445312\n","\n","Removed: (11, 6)\n","183.9085235595703\n","\n","Removed: (11, 7)\n","184.41839599609375\n","\n","Removed: (11, 8)\n","181.02496337890625\n","\n","Removed: (11, 9)\n","180.13568115234375\n","\n","Removed: (11, 10)\n","178.2689666748047\n","\n","Removed: (11, 11)\n","179.22093200683594\n","\n","Removed: (10, 0)\n","179.03067016601562\n","\n","Removed: (10, 1)\n","179.2295684814453\n","\n","Removed: (10, 2)\n","175.9254150390625\n","\n","Removed: (10, 3)\n","173.44964599609375\n","\n","Removed: (10, 4)\n","173.47613525390625\n","\n","Removed: (10, 5)\n","173.3822021484375\n","\n","Removed: (10, 6)\n","173.35984802246094\n","\n","Removed: (10, 7)\n","177.2030487060547\n","\n","Removed: (10, 8)\n","177.2852783203125\n","\n","Removed: (10, 9)\n","177.1464385986328\n","\n","Removed: (10, 10)\n","176.1490020751953\n","\n","Removed: (10, 11)\n","176.11376953125\n","\n","Removed: (9, 0)\n","176.1731719970703\n","\n","Removed: (9, 1)\n","179.74916076660156\n","\n","Removed: (9, 2)\n","179.41571044921875\n","\n","Removed: (9, 3)\n","178.2351531982422\n","\n","Removed: (9, 4)\n","178.22581481933594\n","\n","Removed: (9, 5)\n","192.50941467285156\n","\n","Removed: (9, 6)\n","192.15103149414062\n","\n","Removed: (9, 7)\n","189.66514587402344\n","\n","Removed: (9, 8)\n","189.71932983398438\n","\n","Removed: (9, 9)\n","186.24066162109375\n","\n","Removed: (9, 10)\n","186.14337158203125\n","\n","Removed: (9, 11)\n","181.2935028076172\n","\n","Removed: (8, 0)\n","183.14523315429688\n","\n","Removed: (8, 1)\n","174.85647583007812\n","\n","Removed: (8, 2)\n","174.5783233642578\n","\n","Removed: (8, 3)\n","174.2814178466797\n","\n","Removed: (8, 4)\n","174.2689971923828\n","\n","Removed: (8, 5)\n","174.23858642578125\n","\n","Removed: (8, 6)\n","167.22935485839844\n","\n","Removed: (8, 7)\n","167.0890655517578\n","\n","Removed: (8, 8)\n","158.5823516845703\n","\n","Removed: (8, 9)\n","155.63206481933594\n","\n","Removed: (8, 10)\n","159.5412139892578\n","\n","Removed: (8, 11)\n","136.0602264404297\n","\n","Removed: (7, 0)\n","136.0953369140625\n","\n","Removed: (7, 1)\n","135.97268676757812\n","\n","Removed: (7, 2)\n","134.2304229736328\n","\n","Removed: (7, 3)\n","135.75765991210938\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-d1b782a87c4c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# prev_score = new_score # save old score before finding new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mold_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save old before finding new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcurr_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_circuit_backw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_circuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurr_circuit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mold_circuit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-e0ef3a87cd53>\u001b[0m in \u001b[0;36mfind_circuit_backw\u001b[0;34m(curr_circuit, orig_score, threshold)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcopy_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_ablate_by_lst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# If the result is less than the threshold, remove the tuple from the original list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-67-9d6e9137c5d5>\u001b[0m in \u001b[0;36mmean_ablate_by_lst\u001b[0;34m(lst, model, orig_score, print_output)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_circuit_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mean_ablation_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mioi_logits_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36madd_mean_ablation_hook\u001b[0;34m(model, means_dataset, circuit, seq_pos_to_keep, is_permanent)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# Compute the mean of each head's output on the ABC dataset, grouped by template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_means_by_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Convert this into a boolean map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mcompute_means_by_template\u001b[0;34m(means_dataset, model)\u001b[0m\n\u001b[1;32m    123\u001b[0m     '''\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Cache the outputs of every head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     _, means_cache = model.run_with_cache(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mHookedRootModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m--> 630\u001b[0;31m         out, cache_dict = super().run_with_cache(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mclear_contexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_contexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         ):\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincl_bwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mmodel_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;31m# Eg: start_at_layer==None + stop_at_layer==0 means to only run the embed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# Eg: start_at_layer==3 + stop_at_layer==-1 means to run from layer 3 until the end of the PENULTIMATE layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mblocks_and_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks_and_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_at_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop_at_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;31m# Note that each block includes skip connections, so we don't need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1698866464070,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"2gT3PhdmUneU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1698866464070,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"vKbg8wJRUneU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## loop rmv and check for most impt heads"],"metadata":{"id":"WlWlM4D_UneU"}},{"cell_type":"code","source":["circ = bf_3\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1698866464070,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"ZdbmU4nsUnea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1698866464071,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"rEa8EhGZUnea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1698866464071,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"e8Qbb5PqUnea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1698866464071,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"h2Y8-x3WUneb"},"execution_count":null,"outputs":[]}]}