{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["vKYgaZ9JjihZ"],"machine_shape":"hm","authorship_tag":"ABX9TyMvpITFL+n6iA4lmlDu3c+O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"de766d5af62b4d85af37465201c5bfb5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03b1c2ebcb1448c78e0b25d5647a11f8","IPY_MODEL_cfcdc5ecdb1a4458927a3b37b3e5ee71","IPY_MODEL_4a16214242ba45e0928a431c024e4172"],"layout":"IPY_MODEL_37688fffd8fd40699e660d30c85221c6"}},"03b1c2ebcb1448c78e0b25d5647a11f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_460570cea8df4a59aed27c76e0ad121d","placeholder":"​","style":"IPY_MODEL_e093a74dc1294436977005e5fbabc0c3","value":"config.json: 100%"}},"cfcdc5ecdb1a4458927a3b37b3e5ee71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ab8fd8b4cbc459cb3b9ab1ac7e595e9","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8d32dfac2f848dc848a726d8b3a3b39","value":665}},"4a16214242ba45e0928a431c024e4172":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a2a26c95491435f98a343cd7ba5d619","placeholder":"​","style":"IPY_MODEL_4ed6260a6e4741e293fc4295f28ec6cd","value":" 665/665 [00:00&lt;00:00, 53.3kB/s]"}},"37688fffd8fd40699e660d30c85221c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"460570cea8df4a59aed27c76e0ad121d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e093a74dc1294436977005e5fbabc0c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ab8fd8b4cbc459cb3b9ab1ac7e595e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8d32dfac2f848dc848a726d8b3a3b39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a2a26c95491435f98a343cd7ba5d619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ed6260a6e4741e293fc4295f28ec6cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e2af76eaac04ce3bbaf6f4e037f1574":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_583e1ef0d0f546d6a3c7352982b63469","IPY_MODEL_8efb632d0b5e49289093bb88d0f6fbde","IPY_MODEL_9329fed92b2d4075a2bfbe723ddffdce"],"layout":"IPY_MODEL_94918e921f7d4a45b9ca7790b3b85d93"}},"583e1ef0d0f546d6a3c7352982b63469":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39017cc77c734f3eafd8a3e05e9b7b9d","placeholder":"​","style":"IPY_MODEL_ab457ddc55e54ccc85c29f9e2510dc66","value":"model.safetensors: 100%"}},"8efb632d0b5e49289093bb88d0f6fbde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c989ea25b204aca8510d031942686b5","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c84046bee02a41d6b9bc9e7ac19ff3f1","value":548105171}},"9329fed92b2d4075a2bfbe723ddffdce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c277d706a5c546b5a9a5c1164388ee9d","placeholder":"​","style":"IPY_MODEL_94bcd07098d046b3b2e93b57ce7785ee","value":" 548M/548M [00:01&lt;00:00, 302MB/s]"}},"94918e921f7d4a45b9ca7790b3b85d93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39017cc77c734f3eafd8a3e05e9b7b9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab457ddc55e54ccc85c29f9e2510dc66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c989ea25b204aca8510d031942686b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84046bee02a41d6b9bc9e7ac19ff3f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c277d706a5c546b5a9a5c1164388ee9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94bcd07098d046b3b2e93b57ce7785ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c0aeeb3078843b999efa494cfd814ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8dbc081915cc4b3f986fa1026748d897","IPY_MODEL_63ce2ca059414047b005a59fab9ef140","IPY_MODEL_7d9ed3138b404ff7b09baaf8912a2b87"],"layout":"IPY_MODEL_bd0dd21b12ed403eb4f3942239832981"}},"8dbc081915cc4b3f986fa1026748d897":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80e4a8d3ff2e41f8b4af54918ec1c7f0","placeholder":"​","style":"IPY_MODEL_5c488eaa28aa4589ba7ed9bf1b7a7e1c","value":"generation_config.json: 100%"}},"63ce2ca059414047b005a59fab9ef140":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc543d5176674bb48562cd5bfb321fc1","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2537d3f1d2304f02a557705ca0ec7588","value":124}},"7d9ed3138b404ff7b09baaf8912a2b87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2817db0a97f842f38a2bd2f70db7de86","placeholder":"​","style":"IPY_MODEL_27623707045240c89701ba581757de92","value":" 124/124 [00:00&lt;00:00, 12.3kB/s]"}},"bd0dd21b12ed403eb4f3942239832981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80e4a8d3ff2e41f8b4af54918ec1c7f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c488eaa28aa4589ba7ed9bf1b7a7e1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc543d5176674bb48562cd5bfb321fc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2537d3f1d2304f02a557705ca0ec7588":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2817db0a97f842f38a2bd2f70db7de86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27623707045240c89701ba581757de92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e76207e733144ee196062f3d1c5d7061":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f1c24c8d14d4d4aabe6dfdc77fb4123","IPY_MODEL_49a5754a7e2742d9ad730e9d479ffb93","IPY_MODEL_6817cc9b18cd457e9a875d43a901ecae"],"layout":"IPY_MODEL_c87dd3b236ee4163bd70201f3df7c5f6"}},"1f1c24c8d14d4d4aabe6dfdc77fb4123":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d22c186b783d47cdae87b3eab5466c0d","placeholder":"​","style":"IPY_MODEL_632cbab5abc147d394ee73f4a032336b","value":"tokenizer_config.json: 100%"}},"49a5754a7e2742d9ad730e9d479ffb93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d75583815045fa8c37964862c76892","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c95effecedc463c8b973f04d42cfbc7","value":26}},"6817cc9b18cd457e9a875d43a901ecae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fcfc82eda57497395c5ab51e1cd3699","placeholder":"​","style":"IPY_MODEL_0eef07a9a26b4703a993a560eed4022b","value":" 26.0/26.0 [00:00&lt;00:00, 2.28kB/s]"}},"c87dd3b236ee4163bd70201f3df7c5f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d22c186b783d47cdae87b3eab5466c0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"632cbab5abc147d394ee73f4a032336b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d75583815045fa8c37964862c76892":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c95effecedc463c8b973f04d42cfbc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0fcfc82eda57497395c5ab51e1cd3699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eef07a9a26b4703a993a560eed4022b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a87b0f08346c43a3888a9faa3b5e1552":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed2adf94c1534eb498e108cf012db6f8","IPY_MODEL_be10ad45f81244f789356d466a34cf27","IPY_MODEL_094c4d22e771459fa217e1d432acca46"],"layout":"IPY_MODEL_b1021e4fd8794be28fd719a745f17dc2"}},"ed2adf94c1534eb498e108cf012db6f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d35cfa69b2664748970297a03b992aa3","placeholder":"​","style":"IPY_MODEL_15cb3635719d4cc286707c371b6bbf97","value":"vocab.json: 100%"}},"be10ad45f81244f789356d466a34cf27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_972323a32a50426aa7cb5c58c6b76138","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be0b3cc7443647df93b010ddcd621a62","value":1042301}},"094c4d22e771459fa217e1d432acca46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddd5168d88aa4e199eebcfe7827accf9","placeholder":"​","style":"IPY_MODEL_1eaefed507364e159ea85f2a5dc4e218","value":" 1.04M/1.04M [00:00&lt;00:00, 17.8MB/s]"}},"b1021e4fd8794be28fd719a745f17dc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d35cfa69b2664748970297a03b992aa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15cb3635719d4cc286707c371b6bbf97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"972323a32a50426aa7cb5c58c6b76138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be0b3cc7443647df93b010ddcd621a62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ddd5168d88aa4e199eebcfe7827accf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eaefed507364e159ea85f2a5dc4e218":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a2e144305574b61ab43a70e127bb306":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e731ee70ed34c7d9903aee001a59c13","IPY_MODEL_727877ccbf1440cdb1ff371262a2b40b","IPY_MODEL_acfcc4ec94da4439b6e8ab2e26cafb1b"],"layout":"IPY_MODEL_5f0c158263064aef8af38f5197f4d627"}},"7e731ee70ed34c7d9903aee001a59c13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28f8c22fb4264341b2985f6944292c9d","placeholder":"​","style":"IPY_MODEL_e2274a474ec5459d882ddb3c24da2cba","value":"merges.txt: 100%"}},"727877ccbf1440cdb1ff371262a2b40b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06d9665f379f4a9ebc7df9ea17f6cae8","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_463112a2f1754c90b2a579ae80264bab","value":456318}},"acfcc4ec94da4439b6e8ab2e26cafb1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8869ff42ffc14955b3ab56872562f249","placeholder":"​","style":"IPY_MODEL_36f001733dcf43a8a6a04ce60713e55f","value":" 456k/456k [00:00&lt;00:00, 35.4MB/s]"}},"5f0c158263064aef8af38f5197f4d627":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28f8c22fb4264341b2985f6944292c9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2274a474ec5459d882ddb3c24da2cba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06d9665f379f4a9ebc7df9ea17f6cae8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"463112a2f1754c90b2a579ae80264bab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8869ff42ffc14955b3ab56872562f249":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36f001733dcf43a8a6a04ce60713e55f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"681a26927eb4492cb5ac3274b13606f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd280be5260e47209aa70607b36349ee","IPY_MODEL_6c1e2b0fe9b9400589af16faf5aea20a","IPY_MODEL_44289f87abc64d458e6b001780b32a45"],"layout":"IPY_MODEL_9a83a22270f7488ba4bbe50000903e33"}},"dd280be5260e47209aa70607b36349ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb8cf092d7a34a52a8a91476adda4022","placeholder":"​","style":"IPY_MODEL_f312bb787cd84c7fa98937f55430472d","value":"tokenizer.json: 100%"}},"6c1e2b0fe9b9400589af16faf5aea20a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_168203849075455a95cf4bb3bb89e4f2","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8490ed7347ef4b938bf8d3faafbede58","value":1355256}},"44289f87abc64d458e6b001780b32a45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14da80139aa844d492473a8b1193ea61","placeholder":"​","style":"IPY_MODEL_cbbf18e006d643a6bb9576e3d296da30","value":" 1.36M/1.36M [00:00&lt;00:00, 39.2MB/s]"}},"9a83a22270f7488ba4bbe50000903e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb8cf092d7a34a52a8a91476adda4022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f312bb787cd84c7fa98937f55430472d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"168203849075455a95cf4bb3bb89e4f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8490ed7347ef4b938bf8d3faafbede58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14da80139aa844d492473a8b1193ea61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbbf18e006d643a6bb9576e3d296da30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Change Inputs Here"],"metadata":{"id":"vKYgaZ9JjihZ"}},{"cell_type":"code","source":["task = \"numerals\"  # choose: numerals, numwords, months\n","prompt_types = ['done', 'lost', 'names']\n","num_samps_per_ptype = 512 #768 512\n","\n","model_name = \"gpt2-small\"\n","\n","save_files = True\n","run_on_other_tasks = True"],"metadata":{"id":"KSKP_OsTDki6","executionInfo":{"status":"ok","timestamp":1716165243266,"user_tz":240,"elapsed":22,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0","executionInfo":{"status":"ok","timestamp":1716165309045,"user_tz":240,"elapsed":65800,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1716165312687,"user_tz":240,"elapsed":4669,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1716165314984,"user_tz":240,"elapsed":2327,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","executionInfo":{"status":"ok","timestamp":1716165314986,"user_tz":240,"elapsed":45,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"xLwDyosvIAiJ","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["de766d5af62b4d85af37465201c5bfb5","03b1c2ebcb1448c78e0b25d5647a11f8","cfcdc5ecdb1a4458927a3b37b3e5ee71","4a16214242ba45e0928a431c024e4172","37688fffd8fd40699e660d30c85221c6","460570cea8df4a59aed27c76e0ad121d","e093a74dc1294436977005e5fbabc0c3","0ab8fd8b4cbc459cb3b9ab1ac7e595e9","f8d32dfac2f848dc848a726d8b3a3b39","8a2a26c95491435f98a343cd7ba5d619","4ed6260a6e4741e293fc4295f28ec6cd","2e2af76eaac04ce3bbaf6f4e037f1574","583e1ef0d0f546d6a3c7352982b63469","8efb632d0b5e49289093bb88d0f6fbde","9329fed92b2d4075a2bfbe723ddffdce","94918e921f7d4a45b9ca7790b3b85d93","39017cc77c734f3eafd8a3e05e9b7b9d","ab457ddc55e54ccc85c29f9e2510dc66","9c989ea25b204aca8510d031942686b5","c84046bee02a41d6b9bc9e7ac19ff3f1","c277d706a5c546b5a9a5c1164388ee9d","94bcd07098d046b3b2e93b57ce7785ee","6c0aeeb3078843b999efa494cfd814ab","8dbc081915cc4b3f986fa1026748d897","63ce2ca059414047b005a59fab9ef140","7d9ed3138b404ff7b09baaf8912a2b87","bd0dd21b12ed403eb4f3942239832981","80e4a8d3ff2e41f8b4af54918ec1c7f0","5c488eaa28aa4589ba7ed9bf1b7a7e1c","fc543d5176674bb48562cd5bfb321fc1","2537d3f1d2304f02a557705ca0ec7588","2817db0a97f842f38a2bd2f70db7de86","27623707045240c89701ba581757de92","e76207e733144ee196062f3d1c5d7061","1f1c24c8d14d4d4aabe6dfdc77fb4123","49a5754a7e2742d9ad730e9d479ffb93","6817cc9b18cd457e9a875d43a901ecae","c87dd3b236ee4163bd70201f3df7c5f6","d22c186b783d47cdae87b3eab5466c0d","632cbab5abc147d394ee73f4a032336b","54d75583815045fa8c37964862c76892","9c95effecedc463c8b973f04d42cfbc7","0fcfc82eda57497395c5ab51e1cd3699","0eef07a9a26b4703a993a560eed4022b","a87b0f08346c43a3888a9faa3b5e1552","ed2adf94c1534eb498e108cf012db6f8","be10ad45f81244f789356d466a34cf27","094c4d22e771459fa217e1d432acca46","b1021e4fd8794be28fd719a745f17dc2","d35cfa69b2664748970297a03b992aa3","15cb3635719d4cc286707c371b6bbf97","972323a32a50426aa7cb5c58c6b76138","be0b3cc7443647df93b010ddcd621a62","ddd5168d88aa4e199eebcfe7827accf9","1eaefed507364e159ea85f2a5dc4e218","1a2e144305574b61ab43a70e127bb306","7e731ee70ed34c7d9903aee001a59c13","727877ccbf1440cdb1ff371262a2b40b","acfcc4ec94da4439b6e8ab2e26cafb1b","5f0c158263064aef8af38f5197f4d627","28f8c22fb4264341b2985f6944292c9d","e2274a474ec5459d882ddb3c24da2cba","06d9665f379f4a9ebc7df9ea17f6cae8","463112a2f1754c90b2a579ae80264bab","8869ff42ffc14955b3ab56872562f249","36f001733dcf43a8a6a04ce60713e55f","681a26927eb4492cb5ac3274b13606f0","dd280be5260e47209aa70607b36349ee","6c1e2b0fe9b9400589af16faf5aea20a","44289f87abc64d458e6b001780b32a45","9a83a22270f7488ba4bbe50000903e33","bb8cf092d7a34a52a8a91476adda4022","f312bb787cd84c7fa98937f55430472d","168203849075455a95cf4bb3bb89e4f2","8490ed7347ef4b938bf8d3faafbede58","14da80139aa844d492473a8b1193ea61","cbbf18e006d643a6bb9576e3d296da30"],"height":422},"executionInfo":{"status":"ok","timestamp":1716165321372,"user_tz":240,"elapsed":6429,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5190ecff-75d0-4708-8c79-6d03eaf2c8f3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de766d5af62b4d85af37465201c5bfb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e2af76eaac04ce3bbaf6f4e037f1574"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c0aeeb3078843b999efa494cfd814ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e76207e733144ee196062f3d1c5d7061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a87b0f08346c43a3888a9faa3b5e1552"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a2e144305574b61ab43a70e127bb306"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681a26927eb4492cb5ac3274b13606f0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    model_name,\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716165323049,"user_tz":240,"elapsed":1727,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e6e6e131-f621-41a0-f250-6c3c59710951","id":"F8TXMRL3CoPd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 803, done.\u001b[K\n","remote: Counting objects: 100% (269/269), done.\u001b[K\n","remote: Compressing objects: 100% (179/179), done.\u001b[K\n","remote: Total 803 (delta 146), reused 199 (delta 79), pack-reused 534\u001b[K\n","Receiving objects: 100% (803/803), 16.33 MiB | 43.00 MiB/s, done.\n","Resolving deltas: 100% (509/509), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","from dataset import Dataset\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ","executionInfo":{"status":"ok","timestamp":1716169904048,"user_tz":240,"elapsed":172,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["# Load datasets"],"metadata":{"id":"6Fuq8XW770vX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R","executionInfo":{"status":"ok","timestamp":1716168652731,"user_tz":240,"elapsed":184,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# prompts_list = []\n","\n","# for i in prompt_types:\n","#     file_name = f'/content/seqcont_circuits/data/{task}/{task}_prompts_{i}.pkl'\n","#     with open(file_name, 'rb') as file:\n","#         filelist = pickle.load(file)\n","\n","#     print(filelist[0]['text'])\n","#     prompts_list += filelist [:num_samps_per_ptype]\n","\n","# len(prompts_list)"],"metadata":{"id":"CIe5yXuDhgEK","executionInfo":{"status":"ok","timestamp":1716168652953,"user_tz":240,"elapsed":45,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': str(i),\n","            'S2': str(i+1),\n","            'S3': str(i+2),\n","            'S4': str(i+3),\n","            'corr': str(i+4),\n","            'incorr': str(i+3),\n","            'text': f\"{i} {i+1} {i+2} {i+3}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 2)\n","prompts_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvAkKJI06Vt5","executionInfo":{"status":"ok","timestamp":1716168652953,"user_tz":240,"elapsed":44,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"317e48eb-8cb6-4bba-cbfd-0e29cdb263ee"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': '1',\n","  'S2': '2',\n","  'S3': '3',\n","  'S4': '4',\n","  'corr': '5',\n","  'incorr': '4',\n","  'text': '1 2 3 4'}]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["pos_dict = {}\n","for i in range(len(model.tokenizer.tokenize(prompts_list[0]['text']))):\n","    pos_dict['S'+str(i)] = i"],"metadata":{"id":"kS_Tlrb_70vg","executionInfo":{"status":"ok","timestamp":1716168652954,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["dataset = Dataset(prompts_list, pos_dict, model.tokenizer)"],"metadata":{"id":"u0NPSKcZ1iDe","executionInfo":{"status":"ok","timestamp":1716168652954,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# file_name = f'/content/seqcont_circuits/data/{task}/randDS_{task}.pkl'\n","# with open(file_name, 'rb') as file:\n","#     prompts_list_2 = pickle.load(file)"],"metadata":{"id":"-GJ_ZC48FB1i","executionInfo":{"status":"ok","timestamp":1716168652954,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(prompt_list):\n","    outlist = []\n","    # for i in range(100):\n","    for prompt_dict in prompts_list:\n","        r1 = random.randint(1, 12)\n","        r2 = random.randint(1, 12)\n","        while True:\n","            r3 = random.randint(1, 12)\n","            r4 = random.randint(1, 12)\n","            if r4 - 1 != r3:\n","                break\n","        new_text = prompt_dict['text'].replace(prompt_dict['S1'], str(r1)).replace(prompt_dict['S2'], str(r2)).replace(prompt_dict['S3'], str(r3)).replace(prompt_dict['S4'], str(r4))\n","        new_prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': prompt_dict['corr'],\n","            'incorr': prompt_dict['incorr'],\n","            'text': new_text\n","        }\n","        outlist.append(new_prompt_dict)\n","    return outlist\n","prompts_list_2 = generate_prompts_list_corr(prompts_list)\n","len(prompts_list_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Jtstw1o7Gkj","executionInfo":{"status":"ok","timestamp":1716168652954,"user_tz":240,"elapsed":42,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0f9db7c8-1476-426a-f928-ffc56a34e42a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)"],"metadata":{"id":"msu6D4p_feW5","executionInfo":{"status":"ok","timestamp":1716168652954,"user_tz":240,"elapsed":41,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Get orig score"],"metadata":{"id":"BHHvz84w70vh"}},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","logits_original = model(dataset.toks)\n","orig_score = get_logit_diff(logits_original, dataset)\n","orig_score"],"metadata":{"id":"OI3FcmpMaNxB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716168653182,"user_tz":240,"elapsed":269,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"722578aa-8276-4ff0-8fcf-a4c17f7fc925"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.0631)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import gc\n","\n","del(logits_original)\n","torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716168653378,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"A-TjmW5PUwGC","outputId":"1787485f-4ee0-4ae8-beca-0e3696083934"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["66"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# Generate- Unablated"],"metadata":{"id":"UbR3j-75oLqU"}},{"cell_type":"markdown","source":["Generate output in GPT-2 ()"],"metadata":{"id":"lp8XaAfuntDE"}},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":516,"status":"ok","timestamp":1716123414016,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"mommexyJm4R3"},"outputs":[],"source":["reference_text = \"What comes after Monday is Tuesday, and two days after is\"\n","tokens = model.to_tokens(reference_text).to(device)\n","\n","logits, cache = model.run_with_cache(tokens)\n","# probs = logits.softmax(dim=-1)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1716123414414,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"Pp9PB99Mm4R4","outputId":"12a0cade-aa5c-42bb-8020-22db7094f956"},"outputs":[{"output_type":"stream","name":"stdout","text":["' Wednesday'\n"]}],"source":["next_token = logits[0, -1].argmax(dim=-1)  # logits have shape [1, sequence_length, vocab_size]\n","next_char = model.to_string(next_token)\n","print(repr(next_char))"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1008,"status":"ok","timestamp":1716124055865,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"dpgN-auXm4R6","outputId":"1029677b-4b0f-4187-af30-bca1b9267f5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<|endoftext|>What comes after Monday is Tuesday, and two days after is Wednesday.\\n\\nThe first is the day after the the'\n","26th char = ' the'\n","27th char = ' first'\n","28th char = ' of'\n","29th char = ' the'\n","30th char = ' week'\n","31th char = ','\n","32th char = ' and'\n","33th char = ' the'\n","34th char = ' second'\n","35th char = ' is'\n"]}],"source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","\n","for i in range(10):\n","    print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","    # Define new input sequence, by appending the previously generated token\n","    tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n","    # Pass our new sequence through the model, to get new output\n","    logits = model(tokens)\n","    # Get the predicted token at the end of our sequence\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    # Decode and print the result\n","    next_char = model.to_string(next_token)"]},{"cell_type":"markdown","source":["# Generate- Ablated"],"metadata":{"id":"MLIHcn-gJUc-"}},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy","executionInfo":{"status":"ok","timestamp":1716168985685,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["from transformer_lens import HookedTransformer, utils\n","from transformer_lens.hook_points import HookPoint\n","import einops\n","from functools import partial\n","import torch as t\n","from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool"],"metadata":{"id":"9zH9yt-Z395D","executionInfo":{"status":"ok","timestamp":1716168659323,"user_tz":240,"elapsed":51,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"nza97Rs635O0","executionInfo":{"status":"ok","timestamp":1716168659323,"user_tz":240,"elapsed":50,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def get_logit_diff(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    '''\n","    corr_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.corr_tokenIDs]\n","    incorr_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.incorr_tokenIDs]\n","    answer_logit_diff = corr_logits - incorr_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"sh01hn4v4A18","executionInfo":{"status":"ok","timestamp":1716168659323,"user_tz":240,"elapsed":50,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def get_heads_actv_mean(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Output: The mean activations of a head's output\n","    '''\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    for layer in range(model.cfg.n_layers):\n","        z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","        for template_group in means_dataset.groups:\n","            z_for_this_template = z_for_this_layer[template_group]\n","            z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","            means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means\n","\n","def mask_circ_heads(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Output: for each layer, a mask of circuit components that should not be ablated\n","    '''\n","    heads_and_posns_to_keep = {}\n","    batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    mask[:, indices, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep\n","\n","def hook_func_mask_head(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    components_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    means: Float[Tensor, \"layer batch seq head d_head\"],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Use this to not mask components\n","    '''\n","    # print(hook.layer())\n","    # print(z.shape)\n","    # print(means[hook.layer()].shape)\n","\n","    mask_for_this_layer = components_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","    z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    return z\n","\n","def add_ablation_hook_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Ablate the model, except as components and positions to keep\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","    means = get_heads_actv_mean(means_dataset, model)\n","    components_to_keep = mask_circ_heads(means_dataset, model, circuit, seq_pos_to_keep)\n","    # pdb.set_trace()\n","\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        components_to_keep=components_to_keep,\n","        means=means\n","    )\n","\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","    return model\n","\n","def ablate_head_from_full(\n","        lst: List[Tuple[int, int]],\n","        model: HookedTransformer,\n","        dataset: Dataset,\n","        dataset_2: Dataset,\n","        orig_score: float,\n","        print_output: bool = True,\n",") -> float:\n","    # CIRCUIT contains the components to not ablate\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    for i in range(len(model.tokenizer.tokenize(dataset_2.prompts[0]['text']))):\n","        CIRCUIT['S'+str(i)] = lst\n","        if i == len(model.tokenizer.tokenize(dataset_2.prompts[0]['text'])) - 1:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        else:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    model = add_ablation_hook_head(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    logits_minimal = model(dataset.toks)\n","\n","    new_score = get_logit_diff(logits_minimal, dataset)\n","    if print_output:\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return 100 * new_score / orig_score\n"],"metadata":{"id":"vxS06MvQJWlu","executionInfo":{"status":"ok","timestamp":1716169836276,"user_tz":240,"elapsed":217,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["circ = [(layer, head) for layer in range(12) for head in range(12)]\n","to_loop = [(9, 1)]\n","\n","lh_scores = {}\n","for lh in to_loop:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = ablate_head_from_full(copy_circuit, model, dataset, dataset_2, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WB1EYT33YMT","executionInfo":{"status":"ok","timestamp":1716168659669,"user_tz":240,"elapsed":395,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"551eca5c-bb2c-48f2-d4ab-d6b59afe9e9b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (9, 1)\n","Average logit difference (circuit / full) %: 88.0251\n"]}]},{"cell_type":"markdown","source":["## new"],"metadata":{"id":"KenbMVMP7ZcY"}},{"cell_type":"code","source":["## heads_not_ablate is components to keep\n","# heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","# heads_not_ablate = [(9, 1)]\n","heads_not_ablate = []  # ablate all heads but not MLPs\n","mlps_not_ablate = []  # ablate all MLPs\n","\n","# CIRCUIT = {}\n","# SEQ_POS_TO_KEEP = {}\n","# for i in range(len(model.tokenizer.tokenize(dataset_2.prompts[0]['text']))):\n","#     CIRCUIT['S'+str(i)] = lst\n","#     if i == len(model.tokenizer.tokenize(dataset_2.prompts[0]['text'])) - 1:\n","#         SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","#     else:\n","#         SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","# model = add_ablation_hook_head(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","logits_minimal = model(dataset.toks)\n","\n","new_score = get_logit_diff(logits_minimal, dataset)\n","new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wJGVCAt7XX9","executionInfo":{"status":"ok","timestamp":1716131395807,"user_tz":240,"elapsed":3345,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"245cd47a-ca15-4340-d442-3f2c44dfd8b9"},"execution_count":189,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.1431, device='cuda:0', grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":189}]},{"cell_type":"code","source":["# reference_text = \"What comes after Monday is Tuesday, and two days after is\"\n","reference_text = '1 2 3 4'\n","tokens = model.to_tokens(reference_text).to(device)\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLUKkQ2zT7e_","executionInfo":{"status":"ok","timestamp":1716131027941,"user_tz":240,"elapsed":532,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"16352eef-0679-45eb-e3f5-69a54c2356a0"},"execution_count":167,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[50256,    16,   362,   513,   604]], device='cuda:0')"]},"metadata":{},"execution_count":167}]},{"cell_type":"code","source":["tokens = tokens[:, 1:]\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"roR0FcvMT9fq","executionInfo":{"status":"ok","timestamp":1716131028805,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7afd9226-ee9a-47d0-d882-f96a8f58a528"},"execution_count":168,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 16, 362, 513, 604]], device='cuda:0')"]},"metadata":{},"execution_count":168}]},{"cell_type":"code","source":["print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","for i in range(1):\n","    # Define new input sequence, by appending the previously generated token\n","    # tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n","    # Pass our new sequence through the model, to get new output\n","    logits = model(tokens)\n","    # Get the predicted token at the end of our sequence\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    # Decode and print the result\n","    next_char = model.to_string(next_token)\n","    print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vM0CTQy9cJ1","executionInfo":{"status":"ok","timestamp":1716131397244,"user_tz":240,"elapsed":59,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3d921b72-2c06-4a25-a151-8d33ec8c5188"},"execution_count":190,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4'\n","5th char = '.'\n"]}]},{"cell_type":"code","source":["# example_prompt = \"1 2 3\"\n","# example_answer = \" 4\"\n","# # need prepend_bos=False to prev adding EOS token in front\n","# utils.test_prompt(example_prompt, example_answer, model, prepend_bos=False)"],"metadata":{"id":"JQok2e8YN4ZK","executionInfo":{"status":"ok","timestamp":1716131447257,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":193,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  # reset to unablated\n","\n","print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","for i in range(1):\n","    # Define new input sequence, by appending the previously generated token\n","    # tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n","    # Pass our new sequence through the model, to get new output\n","    logits_unabl = model(tokens)\n","    # Get the predicted token at the end of our sequence\n","    next_token = logits_unabl[0, -1].argmax(dim=-1)\n","    # Decode and print the result\n","    next_char = model.to_string(next_token)\n","    print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_KJPSUAUaR5","executionInfo":{"status":"ok","timestamp":1716131382531,"user_tz":240,"elapsed":419,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f81655df-6ba4-4aee-dc28-1810de5d91cb"},"execution_count":188,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4'\n","5th char = ' 5'\n"]}]},{"cell_type":"code","source":["logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOIL2K_qYr9x","executionInfo":{"status":"ok","timestamp":1716131451905,"user_tz":240,"elapsed":366,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0667b666-590c-4460-f200-1dc2bea1a624"},"execution_count":194,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 4, 50257])"]},"metadata":{},"execution_count":194}]},{"cell_type":"code","source":["logits_unabl.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wwx2sp-hYqMO","executionInfo":{"status":"ok","timestamp":1716131453972,"user_tz":240,"elapsed":488,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ed5dde68-6a55-4853-d702-62a2572aeefc"},"execution_count":195,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 4, 50257])"]},"metadata":{},"execution_count":195}]},{"cell_type":"code","source":["logits == logits_unabl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6pD-EiG9UgRo","executionInfo":{"status":"ok","timestamp":1716131090436,"user_tz":240,"elapsed":423,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a697347f-9a36-4b95-b7ac-424557cc256b"},"execution_count":176,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False]],\n","\n","        [[False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False]],\n","\n","        [[False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False]],\n","\n","        ...,\n","\n","        [[False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False]],\n","\n","        [[False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False]],\n","\n","        [[False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False],\n","         [False, False, False,  ..., False, False, False]]], device='cuda:0')"]},"metadata":{},"execution_count":176}]},{"cell_type":"code","source":["# model.reset_hooks(including_permanent=True)\n","\n","# example_prompt = \"1 2 3\"\n","# example_answer = \" 4\"\n","# # need prepend_bos=False to prev adding EOS token in front\n","# utils.test_prompt(example_prompt, example_answer, model, prepend_bos=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"KljXuqsRUkGW","executionInfo":{"status":"ok","timestamp":1716131099479,"user_tz":240,"elapsed":754,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"84150e73-133b-4805-aebd-59201691ba10"},"execution_count":177,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['1', ' 2', ' 3']\n","Tokenized answer: [' 4']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m14.21\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m54.55\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.21</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54.55</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 14.21 Prob: 54.55% Token: | 4|\n","Top 1th token. Logit: 11.32 Prob:  3.03% Token: | 2|\n","Top 2th token. Logit: 11.30 Prob:  2.98% Token: | 1|\n","Top 3th token. Logit: 11.17 Prob:  2.61% Token: |.|\n","Top 4th token. Logit: 11.15 Prob:  2.55% Token: | 3|\n","Top 5th token. Logit: 11.06 Prob:  2.33% Token: | 5|\n","Top 6th token. Logit: 10.79 Prob:  1.78% Token: | 0|\n","Top 7th token. Logit: 10.57 Prob:  1.43% Token: | 6|\n","Top 8th token. Logit: 10.54 Prob:  1.38% Token: |/|\n","Top 9th token. Logit:  9.81 Prob:  0.67% Token: |\n","|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 4'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 4'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## ablate head 9.1 and mlp 9 and see if corr"],"metadata":{"id":"nz_PIb7-a33I"}},{"cell_type":"markdown","source":["This is necessary (AND) beacuse is seeing if components are essential (no backups)"],"metadata":{"id":"vuE6mbM3bFPn"}},{"cell_type":"code","source":["## heads_not_ablate is components to keep\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","# heads_not_ablate = [(9, 1)]\n","heads_not_ablate.remove((9, 1))\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","logits_minimal = model(dataset.toks)\n","\n","new_score = get_logit_diff(logits_minimal, dataset)\n","new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvVrQx8Za6Ai","executionInfo":{"status":"ok","timestamp":1716132021259,"user_tz":240,"elapsed":3560,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"efa931b4-fa76-4f68-d60c-5d139b4a2dd7"},"execution_count":197,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.3680, device='cuda:0', grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":197}]},{"cell_type":"code","source":["print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","for i in range(1):\n","    # Define new input sequence, by appending the previously generated token\n","    # tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n","    # Pass our new sequence through the model, to get new output\n","    logits = model(tokens)\n","    # Get the predicted token at the end of our sequence\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    # Decode and print the result\n","    next_char = model.to_string(next_token)\n","    print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVM5ZLmqcJTk","executionInfo":{"status":"ok","timestamp":1716132039222,"user_tz":240,"elapsed":802,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"50a2096a-704e-43bc-f906-9c0e54eca565"},"execution_count":198,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4'\n","5th char = ' 4'\n"]}]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  # reset to unablated\n","\n","print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","for i in range(1):\n","    # Define new input sequence, by appending the previously generated token\n","    # tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n","    # Pass our new sequence through the model, to get new output\n","    logits_unabl = model(tokens)\n","    # Get the predicted token at the end of our sequence\n","    next_token = logits_unabl[0, -1].argmax(dim=-1)\n","    # Decode and print the result\n","    next_char = model.to_string(next_token)\n","    print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nzgc_EbHcPhf","executionInfo":{"status":"ok","timestamp":1716132055879,"user_tz":240,"elapsed":736,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"53f110d4-877d-41a9-cca7-78ee76b3e6b3"},"execution_count":199,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4'\n","5th char = ' 5'\n"]}]},{"cell_type":"markdown","source":["# Explora tests- debug means code for diff seq lens"],"metadata":{"id":"ecUNF1uRd7hk"}},{"cell_type":"markdown","source":["Explore internals of `get_MLPs_actv_mean()`"],"metadata":{"id":"zBIqSW7FeGeP"}},{"cell_type":"code","source":["means_dataset = dataset_2"],"metadata":{"id":"XGliyUq-eQK0","executionInfo":{"status":"ok","timestamp":1716132605411,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":201,"outputs":[]},{"cell_type":"code","source":["_, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"mlp_out\"),\n","    )\n","n_layers, d_model = model.cfg.n_layers, model.cfg.d_model\n","batch, seq_len = len(means_dataset), means_dataset.max_len\n","means = t.zeros(size=(n_layers, batch, seq_len, d_model), device=model.cfg.device)\n","\n","for layer in range(n_layers):\n","    mlp_output_for_this_layer: Float[Tensor, \"batch seq d_model\"] = means_cache[utils.get_act_name(\"mlp_out\", layer)]\n","    for template_group in means_dataset.groups:  # here, we only have one group\n","        mlp_output_for_this_template = mlp_output_for_this_layer[template_group]\n","        # aggregate all batches\n","        mlp_output_means_for_this_template = einops.reduce(mlp_output_for_this_template, \"batch seq d_model -> seq d_model\", \"mean\")\n","        means[layer, template_group] = mlp_output_means_for_this_template\n","        # at layer, each batch ind is tempalte group (a tensor of size seq d_model)\n","        # is assigned the SAME mean, \"mlp_output_means_for_this_template\""],"metadata":{"id":"ybYpTNFHd-37","executionInfo":{"status":"ok","timestamp":1716132606783,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":202,"outputs":[]},{"cell_type":"code","source":["means.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdJsvklUeX4v","executionInfo":{"status":"ok","timestamp":1716132620588,"user_tz":240,"elapsed":80,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b72101c5-399b-498c-f683-162eb4805187"},"execution_count":204,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 100, 4, 768])"]},"metadata":{},"execution_count":204}]},{"cell_type":"markdown","source":["Instead of making means shape be `n_layers, batch, seq_len, d_model`, using seq_len from means dataset, we should create a means for the specific current input. That means using a new means dataset based on the current input len. (Eg. if \"1 2 3 4 5 6\", make new means dataset that's len 6). This is needed since we need to get a means value for each pos of the input.\n","\n","Thus, define and pass in new dataset, and change this: `batch, seq_len = len(means_dataset), means_dataset.max_len`\n","\n","Then add a NEW HOOK using new dataset. So if generating, need to do this every loop\n","\n","Alt, use zero ablation"],"metadata":{"id":"p3L0E8cPec7s"}},{"cell_type":"markdown","source":["# means dataset for longer prompts"],"metadata":{"id":"6DDK7QaqELh1"}},{"cell_type":"markdown","source":["What does pos dict have to do with mean ablation? Nothing. But SEQ_POS_TO_KEEP is the token pos to NOT ablate."],"metadata":{"id":"zgJJ9q92UNH2"}},{"cell_type":"code","source":["def generate_prompts_list(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text}\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","reference_text = \"What comes after Monday is Tuesday, and two days after is\"\n","tokens = model.to_tokens(reference_text).to(device)\n","prompts_list = generate_prompts_list(reference_text, tokens)\n","prompts_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZKVG778QYyn","executionInfo":{"status":"ok","timestamp":1716173232430,"user_tz":240,"elapsed":176,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e92997f0-2eb9-46b6-95b8-246b182e883d"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'corr': '1',\n","  'incorr': '2',\n","  'text': 'What comes after Monday is Tuesday, and two days after is',\n","  'S0': 'What',\n","  'S1': 'Ġcomes',\n","  'S2': 'Ġafter',\n","  'S3': 'ĠMonday',\n","  'S4': 'Ġis',\n","  'S5': 'ĠTuesday',\n","  'S6': ',',\n","  'S7': 'Ġand',\n","  'S8': 'Ġtwo',\n","  'S9': 'Ġdays',\n","  'S10': 'Ġafter',\n","  'S11': 'Ġis'}]"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["model.tokenizer.tokenize(reference_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFjX0Tjx4x89","executionInfo":{"status":"ok","timestamp":1716173095336,"user_tz":240,"elapsed":129,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1a52a414-aefa-4df1-9ae7-f2685b1d3274"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['What',\n"," 'Ġcomes',\n"," 'Ġafter',\n"," 'ĠMonday',\n"," 'Ġis',\n"," 'ĠTuesday',\n"," ',',\n"," 'Ġand',\n"," 'Ġtwo',\n"," 'Ġdays',\n"," 'Ġafter',\n"," 'Ġis']"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["model.to_tokens(reference_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1y5AC3ql409H","executionInfo":{"status":"ok","timestamp":1716173108491,"user_tz":240,"elapsed":196,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"269b4f65-b668-44a3-cf68-c68c377eb54f"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[50256,  2061,  2058,   706,  3321,   318,  3431,    11,   290,   734,\n","          1528,   706,   318]])"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["# pos_dict = {}\n","# for i in range(tokens.shape[1]):\n","#     pos_dict['S'+str(i)] = i\n","# prompts_list_2 = generate_prompts_list_corr(prompts_list)\n","\n","corr_text = \"What comes after X is Y, and two days after is\"\n","corr_tokens = model.to_tokens(corr_text).to(device)\n","prompts_list_2 = generate_prompts_list(corr_text, corr_tokens)\n","prompts_list_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNMju-7TTavw","executionInfo":{"status":"ok","timestamp":1716172591354,"user_tz":240,"elapsed":269,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"df7ff56c-ec22-4324-8438-a9a7ff06bc92"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'corr': '1',\n","  'incorr': '2',\n","  'text': 'What comes after X is Y, and two days after is',\n","  'S0': 'What',\n","  'S1': 'Ġcomes',\n","  'S2': 'Ġafter',\n","  'S3': 'ĠX',\n","  'S4': 'Ġis',\n","  'S5': 'ĠY',\n","  'S6': ',',\n","  'S7': 'Ġand',\n","  'S8': 'Ġtwo',\n","  'S9': 'Ġdays',\n","  'S10': 'Ġafter',\n","  'S11': 'Ġis'}]"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["len(model.tokenizer.tokenize(dataset_2.prompts[0]['text']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F0QsCG16VXBR","executionInfo":{"status":"ok","timestamp":1716171652467,"user_tz":240,"elapsed":521,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5833fb3b-9c47-45ee-d0b9-2d2cef3cf1d5"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["model.tokenizer.tokenize(dataset_2.prompts[0]['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnTmrQWgVlwZ","executionInfo":{"status":"ok","timestamp":1716172598475,"user_tz":240,"elapsed":274,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ae976836-6121-4c9a-9ee2-dc7fc353b3c3"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['What',\n"," 'Ġcomes',\n"," 'Ġafter',\n"," 'ĠX',\n"," 'Ġis',\n"," 'ĠY',\n"," ',',\n"," 'Ġand',\n"," 'Ġtwo',\n"," 'Ġdays',\n"," 'Ġafter',\n"," 'Ġis']"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["dataset_2.max_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDqvR7l0Xja1","executionInfo":{"status":"ok","timestamp":1716172602009,"user_tz":240,"elapsed":328,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5de53e44-2bdb-4d66-8a23-96596b2e1bb3"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["tokens.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJN3Sa-wr8g3","executionInfo":{"status":"ok","timestamp":1716171677399,"user_tz":240,"elapsed":222,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1655f99f-4f36-4e9f-d840-f4a1bde3817b"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 13])"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["corr_tokens.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JuDTjBO83Lqp","executionInfo":{"status":"ok","timestamp":1716172670623,"user_tz":240,"elapsed":186,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f980a16b-f454-42dc-ebba-075da3a52ccb"},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 13])"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["dataset_2.toks.long().shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4zUAULKyOvK","executionInfo":{"status":"ok","timestamp":1716171679163,"user_tz":240,"elapsed":271,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a02f3a5-45db-448d-bd79-b8d2e6c2b733"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 12])"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["tokens = tokens[:, 1:]"],"metadata":{"id":"QPQ0WXKor-d5","executionInfo":{"status":"ok","timestamp":1716172613308,"user_tz":240,"elapsed":321,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["## heads_not_ablate is components to keep\n","# heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","# heads_not_ablate = [(9, 1)]\n","heads_not_ablate = []  # ablate all heads but not MLPs\n","mlps_not_ablate = []  # ablate all MLPs\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","\n","# CIRCUIT = {}\n","# SEQ_POS_TO_KEEP = {}\n","# for i in range(len(model.tokenizer.tokenize(dataset_2.prompts[0]['text']))):\n","#     CIRCUIT['S'+str(i)] = heads_not_ablate\n","#     if i == len(model.tokenizer.tokenize(dataset_2.prompts[0]['text'])) - 1:\n","#         SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","#     else:\n","#         SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","# model = add_ablation_hook_head(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","# logits = model(dataset.toks)\n","logits = model(tokens)\n","next_token = logits[0, -1].argmax(dim=-1)\n","next_char = model.to_string(next_token)\n","next_char"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"ubcTjRDf6ETO","executionInfo":{"status":"ok","timestamp":1716172617631,"user_tz":240,"elapsed":18,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2992910a-3779-48a8-998e-767eab9c0107"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Z'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["model.to_string(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3ps_U-OzjHB","executionInfo":{"status":"ok","timestamp":1716172620320,"user_tz":240,"elapsed":193,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9e8ce0fd-43ea-4337-c878-2c05a289d098"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['What comes after Monday is Tuesday, and two days after is']"]},"metadata":{},"execution_count":84}]},{"cell_type":"markdown","source":["# Mean ablate for model generation"],"metadata":{"id":"SW9uBUML2gc4"}},{"cell_type":"markdown","source":["\n","\n","```\n","# this turns string into LIST OF TOKEN IDS\n","tokens = model.to_tokens(reference_text).to(device)\n","tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","# this turns it INTO LIST OF STRINGS WITH SPACE CHAR IN FRONT\n","# each string in list correspond to tokens from token id list\n","model.tokenizer.tokenize(text) # this doesn't use prepend bos\n","```\n","\n"],"metadata":{"id":"aQ9aHRYr5ebD"}},{"cell_type":"code","source":["next_char"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"n6UuwO5M6Av2","executionInfo":{"status":"ok","timestamp":1716173410923,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"54aa756a-7bc3-4fce-eda5-c4d173d317d8"},"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Z'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["reference_text = \"What comes after Monday is Tuesday, and two days after is\"\n","tokens = model.to_tokens(reference_text).to(device)\n","prompts_list = generate_prompts_list(reference_text, tokens)\n","\n","corr_text = \"What comes after X is Y, and two days after is\"\n","corr_tokens = model.to_tokens(corr_text).to(device)\n","prompts_list_2 = generate_prompts_list(corr_text, corr_tokens)\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","heads_not_ablate = []  # ablate all heads but not MLPs\n","mlps_not_ablate = []  # ablate all MLPs\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","logits = model(tokens)\n","next_token = logits[0, -1].argmax(dim=-1)\n","next_char = model.to_string(next_token)\n","\n","print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","for i in range(5):\n","    print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","    # Define new input sequence, by appending the previously generated token\n","    tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n","    print(tokens.shape)\n","\n","    ##\n","    # get new ablation dataset\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    corr_text = corr_text + next_char\n","    corr_tokens = model.to_tokens(reference_text).to(device)\n","    prompts_list_2 = generate_prompts_list(corr_text, corr_tokens)\n","\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    ##\n","\n","    # Pass our new sequence through the model, to get new output\n","    logits = model(tokens)\n","    # Get the predicted token at the end of our sequence\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    # Decode and print the result\n","    next_char = model.to_string(next_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"9XNF5Yx7eYSt","executionInfo":{"status":"error","timestamp":1716173749110,"user_tz":240,"elapsed":1697,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"82dee0c9-826d-4e5f-b3e0-11469df10b33"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'What comes after Monday is Tuesday, and two days after is'\n","13th char = ' Z'\n","torch.Size([1, 13])\n","14th char = '?'\n","torch.Size([1, 14])\n","15th char = '\\n'\n","torch.Size([1, 15])\n"]},{"output_type":"error","ename":"KeyError","evalue":"'S13'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-102-267db3716070>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdataset_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts_list_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_ablation_hook_MLP_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads_not_ablate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlps_not_ablate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/seqcont_circuits/src/iter_node_pruning/node_ablation_fns.py\u001b[0m in \u001b[0;36madd_ablation_hook_MLP_head\u001b[0;34m(model, means_dataset, heads_lst, mlp_lst, is_permanent)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Convert this into a boolean map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcomponents_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_circ_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Get a hook function which will patch in the mean z values for each head, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/seqcont_circuits/src/iter_node_pruning/head_ablation_fns.py\u001b[0m in \u001b[0;36mmask_circ_heads\u001b[0;34m(means_dataset, model, circuit, seq_pos_to_keep)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhead_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mseq_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_pos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# modify this for key vs query pos. curr, this is query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhead_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'S13'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"puNIooy80i2p"},"execution_count":null,"outputs":[]}]}