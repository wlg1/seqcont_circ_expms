{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["9R_g1Ghv7cGE","PDP2cpaiZpPX","dsdvChbcvgp5","jtaV1q3SBHow","OBo0IKv80oM7","85Iqlq_c_lQv","0Fllcm_N50Zu","16CQTjZ77wci","JsT_qlx49FQT"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"010262e872ad4182838b7b8844f921ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41f87329aace4405b4a3dcb5717ca65b","IPY_MODEL_8146945de7314425b6d5654eeb6c6da7","IPY_MODEL_bda1afdfcb40403295c0eb0132469dca"],"layout":"IPY_MODEL_37282edab5e8423b8fc69e8cf752af75"}},"41f87329aace4405b4a3dcb5717ca65b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_644ed6151ec94fe197a6729785abb97f","placeholder":"​","style":"IPY_MODEL_863317b775774f988b6e9c409c23800d","value":"tokenizer_config.json: 100%"}},"8146945de7314425b6d5654eeb6c6da7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa15e0ab99254671bc4a877bc4fe744c","max":1618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40f3e098bc654f279c9c55182c9d8eb6","value":1618}},"bda1afdfcb40403295c0eb0132469dca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0332d1472a88480cbd20ffa4270dea6b","placeholder":"​","style":"IPY_MODEL_d9e2a2ea671947a183b1fe391af087e9","value":" 1.62k/1.62k [00:00&lt;00:00, 137kB/s]"}},"37282edab5e8423b8fc69e8cf752af75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"644ed6151ec94fe197a6729785abb97f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"863317b775774f988b6e9c409c23800d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa15e0ab99254671bc4a877bc4fe744c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40f3e098bc654f279c9c55182c9d8eb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0332d1472a88480cbd20ffa4270dea6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e2a2ea671947a183b1fe391af087e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e888b188f00d4e0b8c9a454a3a324820":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e096b1c1d47544f8ae7f680bc177a459","IPY_MODEL_decefd90088b485fb2255daed387360d","IPY_MODEL_5b7f7df5bb314a858680baa52243d268"],"layout":"IPY_MODEL_3b69f08348ac4db5ba41dbc75bed1c93"}},"e096b1c1d47544f8ae7f680bc177a459":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0371764c6caa4e588a6c77cd61e29df2","placeholder":"​","style":"IPY_MODEL_70d8fd138fbf43fe98155db902195e36","value":"tokenizer.model: 100%"}},"decefd90088b485fb2255daed387360d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92c24048193b416b818fbf168d72877f","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1953dd430134cfc9dd962ba32f02500","value":499723}},"5b7f7df5bb314a858680baa52243d268":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d606e41b42e64e43b3b74c550855dffd","placeholder":"​","style":"IPY_MODEL_eb2e74ab49d44a45ac3e9b3f60ce527b","value":" 500k/500k [00:00&lt;00:00, 12.3MB/s]"}},"3b69f08348ac4db5ba41dbc75bed1c93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0371764c6caa4e588a6c77cd61e29df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70d8fd138fbf43fe98155db902195e36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92c24048193b416b818fbf168d72877f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1953dd430134cfc9dd962ba32f02500":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d606e41b42e64e43b3b74c550855dffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb2e74ab49d44a45ac3e9b3f60ce527b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a1bace63145442bada61f666f2adfd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f547a2323224a099a7ce95d90005b0a","IPY_MODEL_cab7f09d9fec4f26ae55bc8cfd8c0071","IPY_MODEL_76c9013acb5d430d88b21dbad0cc3c2d"],"layout":"IPY_MODEL_a6308bbdc3344c91a738644061fb207b"}},"9f547a2323224a099a7ce95d90005b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a9b808753e24a8babc85f4526fd6990","placeholder":"​","style":"IPY_MODEL_c377faca2aea45b69808a0b120f3948b","value":"special_tokens_map.json: 100%"}},"cab7f09d9fec4f26ae55bc8cfd8c0071":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa522904ec554f54bd57bdd5d0825e7c","max":414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38cdcbadad56491eab31e148a5595531","value":414}},"76c9013acb5d430d88b21dbad0cc3c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f27f148bc9824ab99ee719f1bc3b7391","placeholder":"​","style":"IPY_MODEL_ec3a9730621b43bb9116df017be49c67","value":" 414/414 [00:00&lt;00:00, 39.9kB/s]"}},"a6308bbdc3344c91a738644061fb207b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a9b808753e24a8babc85f4526fd6990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c377faca2aea45b69808a0b120f3948b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa522904ec554f54bd57bdd5d0825e7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38cdcbadad56491eab31e148a5595531":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f27f148bc9824ab99ee719f1bc3b7391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec3a9730621b43bb9116df017be49c67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f19d9ab8f8444a287760662685314ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fe7e283528642c4b9cf8ca05dbdb1e2","IPY_MODEL_fcf4bc2c99614c8a9607922bcbccf2bf","IPY_MODEL_1b7a6bf278a44723bdd94bfe1d40f9b5"],"layout":"IPY_MODEL_66a1d4996d9945a2be12c8d6813a3027"}},"6fe7e283528642c4b9cf8ca05dbdb1e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da0175d6c7d495081d0957b5af07504","placeholder":"​","style":"IPY_MODEL_ce4439651a474eb6a95aa91631c9c95a","value":"tokenizer.json: 100%"}},"fcf4bc2c99614c8a9607922bcbccf2bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aaeedacd6a543b2b6f9b30b4d4401f3","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d24f16ac6f44e7bb1016a6bc79a29fd","value":1842767}},"1b7a6bf278a44723bdd94bfe1d40f9b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39f308a0126e4ed7af4ab15e1c528435","placeholder":"​","style":"IPY_MODEL_ba03ae82d9de4329bc483a834ca95602","value":" 1.84M/1.84M [00:00&lt;00:00, 6.58MB/s]"}},"66a1d4996d9945a2be12c8d6813a3027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1da0175d6c7d495081d0957b5af07504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce4439651a474eb6a95aa91631c9c95a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aaeedacd6a543b2b6f9b30b4d4401f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d24f16ac6f44e7bb1016a6bc79a29fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39f308a0126e4ed7af4ab15e1c528435":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba03ae82d9de4329bc483a834ca95602":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"977d955eebd148a9b27bfb07f79190cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ceb9c3b562c4a30a2727d81f519d3da","IPY_MODEL_34bfcd6a1cab4065bccf16bfc5afe3b7","IPY_MODEL_fed6f1b9eef34011a5250de3d783fee4"],"layout":"IPY_MODEL_19042487084f4d88a538956356cca746"}},"2ceb9c3b562c4a30a2727d81f519d3da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18247d2bed1e42b4afafc4b105039244","placeholder":"​","style":"IPY_MODEL_3f6e1c12bef445c3b711ad4f43e7dc6e","value":"config.json: 100%"}},"34bfcd6a1cab4065bccf16bfc5afe3b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cec0fda621344a669b7b1904a8b321a8","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5a37c0d94be435d912b27f6481aec00","value":614}},"fed6f1b9eef34011a5250de3d783fee4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a981845cfda241109509125dc480df5c","placeholder":"​","style":"IPY_MODEL_b3124063d4b34fef8be46811cfad4a7d","value":" 614/614 [00:00&lt;00:00, 53.5kB/s]"}},"19042487084f4d88a538956356cca746":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18247d2bed1e42b4afafc4b105039244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f6e1c12bef445c3b711ad4f43e7dc6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cec0fda621344a669b7b1904a8b321a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5a37c0d94be435d912b27f6481aec00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a981845cfda241109509125dc480df5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3124063d4b34fef8be46811cfad4a7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f8e557e029449b78c585bd449133663":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fd78d0cbfa24167aa70ead501ff06d3","IPY_MODEL_5a894a09afe24f36b85e65a415930373","IPY_MODEL_6e5e2b795f484a55bb2b619bcef52414"],"layout":"IPY_MODEL_bc7de2032d274f27ac3512c29a39ae23"}},"0fd78d0cbfa24167aa70ead501ff06d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb5b3d88173243828a90d0fbe4af6126","placeholder":"​","style":"IPY_MODEL_1274ebfb2686437eb861d464772559fd","value":"model.safetensors.index.json: 100%"}},"5a894a09afe24f36b85e65a415930373":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5e88f4e57504a3ab47531b3c4e274b7","max":26788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1afa2bf22fd84958ac0a58c2b571d066","value":26788}},"6e5e2b795f484a55bb2b619bcef52414":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd18aa15f5964fcf89d8bd55dac60d93","placeholder":"​","style":"IPY_MODEL_9b7358d73f6c4b9081339c6fd397fef0","value":" 26.8k/26.8k [00:00&lt;00:00, 2.38MB/s]"}},"bc7de2032d274f27ac3512c29a39ae23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb5b3d88173243828a90d0fbe4af6126":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1274ebfb2686437eb861d464772559fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5e88f4e57504a3ab47531b3c4e274b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1afa2bf22fd84958ac0a58c2b571d066":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd18aa15f5964fcf89d8bd55dac60d93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b7358d73f6c4b9081339c6fd397fef0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e5c885b2b6041bcaaf20c2026b64702":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb9b357a74144d15ba4e868008266d0e","IPY_MODEL_cf0670bd899644d6bba1ffd24d6325be","IPY_MODEL_329e6ed124b3483da70f8e0957f1ad7d"],"layout":"IPY_MODEL_4f42a51712a141afb8000bf1e357a188"}},"eb9b357a74144d15ba4e868008266d0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b23508b23ee44aa1b7a91de34b36a756","placeholder":"​","style":"IPY_MODEL_b2dc6f6a6e2a4ab7a58ad2c8185329f3","value":"Downloading shards: 100%"}},"cf0670bd899644d6bba1ffd24d6325be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d97b9493ff6f4e468dcf47ea0e62fda4","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7b12aabdcd440729714d35282f1018c","value":2}},"329e6ed124b3483da70f8e0957f1ad7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1a0156644b647d09b02b5656465b8e5","placeholder":"​","style":"IPY_MODEL_7585522627a54d2a897abf6b1d4e12bd","value":" 2/2 [02:34&lt;00:00, 68.68s/it]"}},"4f42a51712a141afb8000bf1e357a188":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b23508b23ee44aa1b7a91de34b36a756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2dc6f6a6e2a4ab7a58ad2c8185329f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d97b9493ff6f4e468dcf47ea0e62fda4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7b12aabdcd440729714d35282f1018c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1a0156644b647d09b02b5656465b8e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7585522627a54d2a897abf6b1d4e12bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adb3d96c5ad3419d91d628c3c3d73409":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8b9884cecf74d8a94cd01dd97ad033e","IPY_MODEL_c29d24b3cb3c49a990eaaa3335e4c4c7","IPY_MODEL_57c5efcde0d941809819eb652cea0aee"],"layout":"IPY_MODEL_5e4da8dd53254900853d6509b56b437d"}},"b8b9884cecf74d8a94cd01dd97ad033e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e402a1d8af94c9890fef25288a6164b","placeholder":"​","style":"IPY_MODEL_9ce051cfd9ac4e05905ff6fe1567f77a","value":"model-00001-of-00002.safetensors: 100%"}},"c29d24b3cb3c49a990eaaa3335e4c4c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec8d45124b904a5e875868cd4048fb75","max":9976576152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_708222ed963d403fa8ce2a00caf5ef80","value":9976576152}},"57c5efcde0d941809819eb652cea0aee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7528f74e273346b4b986a3d947e26415","placeholder":"​","style":"IPY_MODEL_fd3b4b499329425d93eacfedff2ee3da","value":" 9.98G/9.98G [02:06&lt;00:00, 136MB/s]"}},"5e4da8dd53254900853d6509b56b437d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e402a1d8af94c9890fef25288a6164b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ce051cfd9ac4e05905ff6fe1567f77a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec8d45124b904a5e875868cd4048fb75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708222ed963d403fa8ce2a00caf5ef80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7528f74e273346b4b986a3d947e26415":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3b4b499329425d93eacfedff2ee3da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d99a441f9664a6fadc6679f947a7d41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3489818b66d4620900c877752b76650","IPY_MODEL_479062dc6f8943e287b6aa249d575b07","IPY_MODEL_8b425d36df354780a12325308b7ce5a9"],"layout":"IPY_MODEL_d8f9e75f734b4f589cbe397ad4698215"}},"f3489818b66d4620900c877752b76650":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_868c3684fede433884853584ca9b3e9b","placeholder":"​","style":"IPY_MODEL_6c68da2e667a4ecea5f5470414e06377","value":"model-00002-of-00002.safetensors: 100%"}},"479062dc6f8943e287b6aa249d575b07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5b68eba89e34a47a66cf3428a4dab2d","max":3500296424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a548bbb68224548a69085ef6d5b1811","value":3500296424}},"8b425d36df354780a12325308b7ce5a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54ea01341e244453b240d522e19f6de7","placeholder":"​","style":"IPY_MODEL_c9280822c5df44378abee57e74aee3b7","value":" 3.50G/3.50G [00:28&lt;00:00, 138MB/s]"}},"d8f9e75f734b4f589cbe397ad4698215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"868c3684fede433884853584ca9b3e9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c68da2e667a4ecea5f5470414e06377":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5b68eba89e34a47a66cf3428a4dab2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a548bbb68224548a69085ef6d5b1811":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54ea01341e244453b240d522e19f6de7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9280822c5df44378abee57e74aee3b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bce1dc6036f14670a21f55b1c4c81be4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_695e81973a2f44fdafede44f70946e7a","IPY_MODEL_66b42455a0654fd7889a1375bcfeb9ad","IPY_MODEL_c263f0cec65345ea9e30b0bf4039a912"],"layout":"IPY_MODEL_5745185874db41e1854152b03df7869f"}},"695e81973a2f44fdafede44f70946e7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c0f57f157c84624bfb2d813177348d3","placeholder":"​","style":"IPY_MODEL_49a5b61bc18543edada8f905e4e3fa19","value":"Loading checkpoint shards: 100%"}},"66b42455a0654fd7889a1375bcfeb9ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f29ed0a549a4a289bcf566615c66d45","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90b24457f3404dad963cd0f48dc81213","value":2}},"c263f0cec65345ea9e30b0bf4039a912":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4763436ac1cb43eebb58d2b666aafaea","placeholder":"​","style":"IPY_MODEL_de4c050c30cb45718db6618c2357452a","value":" 2/2 [00:04&lt;00:00,  1.99s/it]"}},"5745185874db41e1854152b03df7869f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c0f57f157c84624bfb2d813177348d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49a5b61bc18543edada8f905e4e3fa19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f29ed0a549a4a289bcf566615c66d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b24457f3404dad963cd0f48dc81213":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4763436ac1cb43eebb58d2b666aafaea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de4c050c30cb45718db6618c2357452a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7297b3e1f4134f76b873d2c61378a30d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1219f19df544296b5c0a121577b3bef","IPY_MODEL_4533295424c44c5b9fd7ddd23161cc60","IPY_MODEL_8bb8d848e0ec4e1887a224425a3031e3"],"layout":"IPY_MODEL_f04d746f106e40c29eed9f4871d258ce"}},"c1219f19df544296b5c0a121577b3bef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8888c2d2d164c4e96faec6916d0c996","placeholder":"​","style":"IPY_MODEL_c84dcb89fe6a4a85907a287bc22b7e63","value":"generation_config.json: 100%"}},"4533295424c44c5b9fd7ddd23161cc60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_74a53f19106d480fbd46c35edfd3ded7","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2d7d9e006864b0da61c0bee801996af","value":188}},"8bb8d848e0ec4e1887a224425a3031e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2ed5d5ae82a422fb8969e3f876b670f","placeholder":"​","style":"IPY_MODEL_fcff768bebe34401af2c9d62a2d5f01b","value":" 188/188 [00:00&lt;00:00, 15.6kB/s]"}},"f04d746f106e40c29eed9f4871d258ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8888c2d2d164c4e96faec6916d0c996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84dcb89fe6a4a85907a287bc22b7e63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74a53f19106d480fbd46c35edfd3ded7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2d7d9e006864b0da61c0bee801996af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2ed5d5ae82a422fb8969e3f876b670f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcff768bebe34401af2c9d62a2d5f01b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"code","source":["save_files = True"],"metadata":{"id":"KSKP_OsTDki6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6b1n2tvIAiD"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuhzYxbsIAiE"},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer #, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFMTUcQiIAiF"},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718402287479,"user_tz":-60,"elapsed":3140,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"09631194-b331-4b6b-f8a2-c1a765e225ee","id":"F8TXMRL3CoPd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 1022, done.\u001b[K\n","remote: Counting objects: 100% (488/488), done.\u001b[K\n","remote: Compressing objects: 100% (287/287), done.\u001b[K\n","remote: Total 1022 (delta 296), reused 378 (delta 190), pack-reused 534\u001b[K\n","Receiving objects: 100% (1022/1022), 18.76 MiB | 16.59 MiB/s, done.\n","Resolving deltas: 100% (659/659), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","# don't improt this\n","# # from dataset import Dataset\n","\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["import random\n"],"metadata":{"id":"jsJmCq-C2Zu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a dict whose values are tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_longer(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text\n","        # 'text': model.to_string(tokens)[0]\n","        }\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    # for i, tok in enumerate(tokens):\n","    #     prompt_dict['S'+str(i)] = model.to_string(tok)\n","\n","    # prompt_dict = {\n","    #     'corr': '4',\n","    #     'incorr': '3',\n","    #     'text': model.to_string(tokens)[0]\n","    # }\n","    # # list_tokens = tokenizer.tokenize('1 2 3 ')\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i, tok_as_str in enumerate(tokens_as_strs):\n","    #     if tok_as_str == '▁':\n","    #         prompt_dict['S'+str(i)] = ' '\n","    #     else:\n","    #         prompt_dict['S'+str(i)] = tok_as_str\n","    prompts_list.append(prompt_dict)\n","    return prompts_list"],"metadata":{"id":"VZKVG778QYyn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDP2cpaiZpPX"},"source":["# Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGCiZUPpJUsD"},"outputs":[],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CocJpgjsf_M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718402395167,"user_tz":-60,"elapsed":8884,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7e0ad307-74e0-4e92-b992-ab5f9c2354a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLgpia0tI6O8","colab":{"base_uri":"https://localhost:8080/","height":493,"referenced_widgets":["010262e872ad4182838b7b8844f921ad","41f87329aace4405b4a3dcb5717ca65b","8146945de7314425b6d5654eeb6c6da7","bda1afdfcb40403295c0eb0132469dca","37282edab5e8423b8fc69e8cf752af75","644ed6151ec94fe197a6729785abb97f","863317b775774f988b6e9c409c23800d","aa15e0ab99254671bc4a877bc4fe744c","40f3e098bc654f279c9c55182c9d8eb6","0332d1472a88480cbd20ffa4270dea6b","d9e2a2ea671947a183b1fe391af087e9","e888b188f00d4e0b8c9a454a3a324820","e096b1c1d47544f8ae7f680bc177a459","decefd90088b485fb2255daed387360d","5b7f7df5bb314a858680baa52243d268","3b69f08348ac4db5ba41dbc75bed1c93","0371764c6caa4e588a6c77cd61e29df2","70d8fd138fbf43fe98155db902195e36","92c24048193b416b818fbf168d72877f","b1953dd430134cfc9dd962ba32f02500","d606e41b42e64e43b3b74c550855dffd","eb2e74ab49d44a45ac3e9b3f60ce527b","4a1bace63145442bada61f666f2adfd6","9f547a2323224a099a7ce95d90005b0a","cab7f09d9fec4f26ae55bc8cfd8c0071","76c9013acb5d430d88b21dbad0cc3c2d","a6308bbdc3344c91a738644061fb207b","6a9b808753e24a8babc85f4526fd6990","c377faca2aea45b69808a0b120f3948b","aa522904ec554f54bd57bdd5d0825e7c","38cdcbadad56491eab31e148a5595531","f27f148bc9824ab99ee719f1bc3b7391","ec3a9730621b43bb9116df017be49c67","3f19d9ab8f8444a287760662685314ce","6fe7e283528642c4b9cf8ca05dbdb1e2","fcf4bc2c99614c8a9607922bcbccf2bf","1b7a6bf278a44723bdd94bfe1d40f9b5","66a1d4996d9945a2be12c8d6813a3027","1da0175d6c7d495081d0957b5af07504","ce4439651a474eb6a95aa91631c9c95a","7aaeedacd6a543b2b6f9b30b4d4401f3","5d24f16ac6f44e7bb1016a6bc79a29fd","39f308a0126e4ed7af4ab15e1c528435","ba03ae82d9de4329bc483a834ca95602","977d955eebd148a9b27bfb07f79190cd","2ceb9c3b562c4a30a2727d81f519d3da","34bfcd6a1cab4065bccf16bfc5afe3b7","fed6f1b9eef34011a5250de3d783fee4","19042487084f4d88a538956356cca746","18247d2bed1e42b4afafc4b105039244","3f6e1c12bef445c3b711ad4f43e7dc6e","cec0fda621344a669b7b1904a8b321a8","a5a37c0d94be435d912b27f6481aec00","a981845cfda241109509125dc480df5c","b3124063d4b34fef8be46811cfad4a7d","0f8e557e029449b78c585bd449133663","0fd78d0cbfa24167aa70ead501ff06d3","5a894a09afe24f36b85e65a415930373","6e5e2b795f484a55bb2b619bcef52414","bc7de2032d274f27ac3512c29a39ae23","bb5b3d88173243828a90d0fbe4af6126","1274ebfb2686437eb861d464772559fd","a5e88f4e57504a3ab47531b3c4e274b7","1afa2bf22fd84958ac0a58c2b571d066","bd18aa15f5964fcf89d8bd55dac60d93","9b7358d73f6c4b9081339c6fd397fef0","9e5c885b2b6041bcaaf20c2026b64702","eb9b357a74144d15ba4e868008266d0e","cf0670bd899644d6bba1ffd24d6325be","329e6ed124b3483da70f8e0957f1ad7d","4f42a51712a141afb8000bf1e357a188","b23508b23ee44aa1b7a91de34b36a756","b2dc6f6a6e2a4ab7a58ad2c8185329f3","d97b9493ff6f4e468dcf47ea0e62fda4","c7b12aabdcd440729714d35282f1018c","c1a0156644b647d09b02b5656465b8e5","7585522627a54d2a897abf6b1d4e12bd","adb3d96c5ad3419d91d628c3c3d73409","b8b9884cecf74d8a94cd01dd97ad033e","c29d24b3cb3c49a990eaaa3335e4c4c7","57c5efcde0d941809819eb652cea0aee","5e4da8dd53254900853d6509b56b437d","2e402a1d8af94c9890fef25288a6164b","9ce051cfd9ac4e05905ff6fe1567f77a","ec8d45124b904a5e875868cd4048fb75","708222ed963d403fa8ce2a00caf5ef80","7528f74e273346b4b986a3d947e26415","fd3b4b499329425d93eacfedff2ee3da","0d99a441f9664a6fadc6679f947a7d41","f3489818b66d4620900c877752b76650","479062dc6f8943e287b6aa249d575b07","8b425d36df354780a12325308b7ce5a9","d8f9e75f734b4f589cbe397ad4698215","868c3684fede433884853584ca9b3e9b","6c68da2e667a4ecea5f5470414e06377","f5b68eba89e34a47a66cf3428a4dab2d","1a548bbb68224548a69085ef6d5b1811","54ea01341e244453b240d522e19f6de7","c9280822c5df44378abee57e74aee3b7","bce1dc6036f14670a21f55b1c4c81be4","695e81973a2f44fdafede44f70946e7a","66b42455a0654fd7889a1375bcfeb9ad","c263f0cec65345ea9e30b0bf4039a912","5745185874db41e1854152b03df7869f","0c0f57f157c84624bfb2d813177348d3","49a5b61bc18543edada8f905e4e3fa19","9f29ed0a549a4a289bcf566615c66d45","90b24457f3404dad963cd0f48dc81213","4763436ac1cb43eebb58d2b666aafaea","de4c050c30cb45718db6618c2357452a","7297b3e1f4134f76b873d2c61378a30d","c1219f19df544296b5c0a121577b3bef","4533295424c44c5b9fd7ddd23161cc60","8bb8d848e0ec4e1887a224425a3031e3","f04d746f106e40c29eed9f4871d258ce","e8888c2d2d164c4e96faec6916d0c996","c84dcb89fe6a4a85907a287bc22b7e63","74a53f19106d480fbd46c35edfd3ded7","b2d7d9e006864b0da61c0bee801996af","c2ed5d5ae82a422fb8969e3f876b670f","fcff768bebe34401af2c9d62a2d5f01b"]},"executionInfo":{"status":"ok","timestamp":1718402557638,"user_tz":-60,"elapsed":162494,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"213a989b-0e43-4755-8479-5803338047ac"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"010262e872ad4182838b7b8844f921ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e888b188f00d4e0b8c9a454a3a324820"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a1bace63145442bada61f666f2adfd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f19d9ab8f8444a287760662685314ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977d955eebd148a9b27bfb07f79190cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f8e557e029449b78c585bd449133663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e5c885b2b6041bcaaf20c2026b64702"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb3d96c5ad3419d91d628c3c3d73409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d99a441f9664a6fadc6679f947a7d41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce1dc6036f14670a21f55b1c4c81be4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7297b3e1f4134f76b873d2c61378a30d"}},"metadata":{}}],"source":["LLAMA_2_7B_CHAT_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n","\n","tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH)\n","# tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH, use_fast= False, add_prefix_space= False)\n","hf_model = LlamaForCausalLM.from_pretrained(LLAMA_2_7B_CHAT_PATH, low_cpu_mem_usage=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rtZ2e3sMY5S"},"outputs":[],"source":["import transformer_lens.utils as utils\n","from transformer_lens.hook_points import HookPoint\n","from transformer_lens import HookedTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUnSHvA-Myx8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718402588274,"user_tz":-60,"elapsed":30734,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b1d149ff-e53b-4980-ad4b-326cbac79879"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n","Moving model to device:  cuda\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    LLAMA_2_7B_CHAT_PATH,\n","    hf_model = hf_model,\n","    tokenizer = tokenizer,\n","    device = \"cpu\",\n","    fold_ln = False,\n","    center_writing_weights = False,\n","    center_unembed = False,\n",")\n","\n","del hf_model\n","\n","model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["# Define circs"],"metadata":{"id":"JPKiYdKTAMni"}},{"cell_type":"code","source":["# from Llama2_numerals_1to10.ipynb\n","nums_1to9 = [(0, 2), (0, 5), (0, 6), (0, 15), (1, 15), (1, 28), (2, 13), (2, 24), (3, 24), (4, 3), (4, 16), (5, 11), (5, 13), (5, 15), (5, 16), (5, 23), (5, 25), (5, 27), (6, 11), (6, 14), (6, 20), (6, 23), (6, 24), (6, 26), (6, 28), (6, 30), (6, 31), (7, 0), (7, 13), (7, 21), (7, 30), (8, 0), (8, 2), (8, 12), (8, 15), (8, 26), (8, 27), (8, 30), (8, 31), (9, 15), (9, 16), (9, 23), (9, 26), (9, 27), (9, 29), (9, 31), (10, 1), (10, 13), (10, 18), (10, 23), (10, 29), (11, 7), (11, 8), (11, 9), (11, 17), (11, 18), (11, 25), (11, 28), (12, 18), (12, 19), (12, 23), (12, 27), (13, 6), (13, 11), (13, 20), (14, 18), (14, 19), (14, 20), (14, 21), (16, 0), (18, 19), (18, 21), (18, 25), (18, 26), (18, 31), (19, 28), (20, 17), (21, 0), (21, 2), (22, 18), (22, 20), (22, 25), (23, 27), (26, 2)]\n","len(nums_1to9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YId1M9rIroEe","executionInfo":{"status":"ok","timestamp":1718402612058,"user_tz":-60,"elapsed":322,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ec42bf86-e7ef-4278-d9ca-844fe79e8245"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["84"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# nw_circ = [(0, 1), (0, 4), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (1, 16), (1, 24), (1, 27), (1, 28), (2, 2), (2, 5), (2, 8), (2, 24), (2, 30), (3, 7), (3, 14), (3, 19), (3, 23), (4, 3), (5, 16), (5, 25), (6, 11), (6, 14), (7, 0), (7, 30), (8, 0), (8, 2), (8, 3), (8, 4), (8, 6), (8, 21), (8, 31), (9, 1), (9, 3), (9, 7), (9, 11), (9, 29), (9, 31), (10, 13), (10, 18), (10, 23), (10, 24), (10, 25), (10, 27), (11, 18), (11, 28), (12, 18), (12, 26), (13, 11), (13, 17), (13, 18), (13, 19), (13, 20), (13, 21), (13, 23), (14, 7), (14, 14), (15, 25), (15, 28), (16, 0), (16, 12), (16, 14), (16, 15), (16, 16), (16, 19), (16, 24), (16, 29), (17, 17), (17, 23), (17, 31), (18, 31), (19, 12), (20, 17), (27, 20), (27, 25), (27, 27), (27, 31), (28, 5), (29, 5)]\n","# in order from most impt to least based on how much changes perf when ablated\n","nw_circ = [(20, 17), (5, 25), (16, 0), (29, 5), (3, 19), (6, 11), (15, 25), (8, 0), (16, 24), (8, 4), (7, 0), (6, 14), (16, 29), (5, 16), (12, 26), (4, 3), (3, 7), (7, 30), (11, 28), (28, 5), (17, 31), (13, 11), (13, 20), (12, 18), (1, 27), (10, 13), (18, 31), (8, 6), (9, 1), (0, 4), (2, 2), (9, 11), (19, 12), (1, 16), (13, 17), (9, 7), (11, 18), (2, 24), (10, 18), (9, 31), (9, 29), (2, 30), (2, 5), (1, 24), (2, 8), (15, 28), (27, 31), (16, 14), (3, 23), (3, 14), (10, 23), (27, 20), (8, 3), (14, 7), (14, 14), (16, 15), (8, 2), (17, 17), (0, 1), (10, 27), (16, 19), (0, 8), (0, 12), (1, 28), (0, 11), (17, 23), (0, 10), (0, 6), (13, 19), (8, 31), (10, 24), (16, 12), (13, 23), (13, 21), (27, 27), (9, 3), (27, 25), (16, 16), (8, 21), (0, 7), (13, 18), (10, 25)]\n","len(nw_circ)"],"metadata":{"id":"wzTeD-OvAOwC","executionInfo":{"status":"ok","timestamp":1718402612548,"user_tz":-60,"elapsed":68,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12da694d-f084-4d35-ec7c-cdd9d9e331c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["82"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# impt_months_heads = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","months_circ = [(20, 17), (6, 11), (16, 0), (5, 15), (17, 11), (23, 16), (5, 25), (7, 0), (26, 14), (6, 14), (12, 22), (8, 4), (12, 15), (16, 29), (15, 25), (5, 16), (18, 31), (14, 7), (11, 18), (4, 12), (3, 19), (12, 2), (11, 28), (4, 3), (18, 9), (8, 14), (12, 3), (11, 2), (10, 13), (4, 16), (1, 22), (11, 16), (3, 15), (13, 31), (2, 4), (2, 16), (8, 13), (0, 13), (8, 15), (12, 28), (1, 5), (0, 4), (0, 25), (3, 24), (13, 11), (1, 24), (8, 16), (13, 8), (3, 26), (0, 6), (3, 23), (1, 3), (14, 3), (8, 19), (8, 12), (14, 2), (8, 5), (1, 28), (8, 20), (2, 30), (8, 6), (10, 1), (13, 20), (19, 27)]\n","len(months_circ)"],"metadata":{"id":"a8zrblGeHiND","executionInfo":{"status":"ok","timestamp":1718402612548,"user_tz":-60,"elapsed":64,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22a00b87-2047-4a0c-c463-b6b69c6cf9c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["intersect_all = list(set(nums_1to9) & set(nw_circ) & set(months_circ))\n","len(intersect_all)"],"metadata":{"id":"e2XFugMsd3BY","executionInfo":{"status":"ok","timestamp":1718402612549,"user_tz":-60,"elapsed":63,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa0ac056-0ca0-4367-dfc0-59dee8619a70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["union_all = list(set(nums_1to9) | set(nw_circ) | set(months_circ))\n","len(union_all)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2CL3XqQ4E7R","executionInfo":{"status":"ok","timestamp":1718402612549,"user_tz":-60,"elapsed":62,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4b3b6a50-83d6-4687-8fae-ec7d8af0c1f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["172"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# new ablation functions"],"metadata":{"id":"dsdvChbcvgp5"}},{"cell_type":"code","source":["def get_heads_actv_mean(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Output: The mean activations of a head's output\n","    '''\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    # for layer in range(model.cfg.n_layers):\n","    #     z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","    #     for template_group in means_dataset.groups:\n","    #         z_for_this_template = z_for_this_layer[template_group]\n","    #         z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","    #         if z_means_for_this_template.shape[0] == 5:\n","    #             pdb.set_trace()\n","    #         means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means"],"metadata":{"id":"6KlWYoEy72Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def mask_circ_heads(\n","#     means_dataset: Dataset,\n","#     model: HookedTransformer,\n","#     circuit: Dict[str, List[Tuple[int, int]]],\n","#     seq_pos_to_keep: Dict[str, str],\n","# ) -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","#     '''\n","#     Output: for each layer, a mask of circuit components that should not be ablated\n","#     '''\n","#     heads_and_posns_to_keep = {}\n","#     batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","#     for layer in range(model.cfg.n_layers):\n","\n","#         mask = t.zeros(size=(batch, seq, n_heads))\n","\n","#         for (head_type, head_list) in circuit.items():\n","#             seq_pos = seq_pos_to_keep[head_type]\n","#             # if seq_pos == 'S7':\n","#             #     pdb.set_trace()\n","#             indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","#             for (layer_idx, head_idx) in head_list:\n","#                 if layer_idx == layer:\n","#                     # if indices.item() == 7:\n","#                     #     pdb.set_trace()\n","#                     mask[:, indices, head_idx] = 1\n","#                     # mask[:, :, head_idx] = 1  # keep L.H at all pos\n","\n","#         heads_and_posns_to_keep[layer] = mask.bool()\n","#     # pdb.set_trace()\n","#     return heads_and_posns_to_keep"],"metadata":{"id":"bFDQMOt9CyVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mask_circ_heads(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Output: for each layer, a mask of circuit components that should not be ablated\n","    '''\n","    heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","    batch, seq, n_heads = len(means_dataset), len(circuit.keys()), model.cfg.n_heads\n","    # print(seq)\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    # mask[:, indices, head_idx] = 1\n","                    mask[:, :, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep"],"metadata":{"id":"E1boH1469_HI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def hook_func_mask_head(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    # components_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    # means: Float[Tensor, \"layer batch seq head d_head\"],\n","    circuit: Dict[str, List[Tuple[int, int]]],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Use this to not mask components\n","    '''\n","    # mask_for_this_layer = components_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","    # z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    ###\n","    # heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = z.shape[0], z.shape[1], model.cfg.n_heads  # components_to_keep[0].shape[0] is batch\n","\n","    # for layer in range(model.cfg.n_layers):\n","\n","    #     mask = t.zeros(size=(batch, seq, n_heads))\n","\n","    #     for (head_type, head_list) in circuit.items():\n","    #         # seq_pos = seq_pos_to_keep[head_type]\n","    #         # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","    #         for (layer_idx, head_idx) in head_list:\n","    #             if layer_idx == layer:\n","    #                 # mask[:, indices, head_idx] = 1\n","    #                 mask[:, :, head_idx] = 1\n","\n","    #     heads_and_posns_to_keep[layer] = mask.bool()\n","    ###\n","    mask_for_this_layer = t.zeros(size=(z.shape[0], z.shape[1], z.shape[2]))\n","    for (head_type, head_list) in circuit.items():\n","        # seq_pos = seq_pos_to_keep[head_type]\n","        # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","        for (layer_idx, head_idx) in head_list:\n","            if layer_idx == hook.layer():\n","                # mask[:, indices, head_idx] = 1\n","                mask_for_this_layer[:, :, head_idx] = 1\n","\n","    mask_for_this_layer = mask_for_this_layer.bool()\n","    mask_for_this_layer = mask_for_this_layer.unsqueeze(-1).to(z.device)  # d_model is 1; then is broadcast in where\n","\n","    z = t.where(mask_for_this_layer, z, 0)\n","\n","    return z"],"metadata":{"id":"KdxeNJ5C9tHx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_ablation_hook_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Ablate the model, except as components and positions to keep\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","    means = get_heads_actv_mean(means_dataset, model)\n","    components_to_keep = mask_circ_heads(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=circuit,\n","    )\n","\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","    return model"],"metadata":{"id":"dg3XuWScAVvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from dataset import Dataset\n","from transformer_lens import HookedTransformer, utils\n","from transformer_lens.hook_points import HookPoint\n","import einops\n","from functools import partial\n","import torch as t\n","from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool\n","\n","# from head_ablation_fns import *\n","# from mlp_ablation_fns import *\n","\n","def add_ablation_hook_MLP_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    heads_lst, mlp_lst,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        CIRCUIT['S'+str(i)] = heads_lst\n","        # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","        # if i == num_pos - 1:\n","        #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        # else:\n","        SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = get_heads_actv_mean(means_dataset, model)\n","    # Convert this into a boolean map\n","    components_to_keep = mask_circ_heads(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=CIRCUIT,\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    # if all_entries_true(components_to_keep) == False:\n","    #     pdb.set_trace()\n","    ########################\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","    # # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    # num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    # for i in range(num_pos ):\n","    #     CIRCUIT['S'+str(i)] = mlp_lst\n","    #     # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","    #     # if i == num_pos - 1:\n","    #     #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","    #     # else:\n","    #     SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    # # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    # means = get_MLPs_actv_mean(means_dataset, model)\n","\n","    # # Convert this into a boolean map\n","    # components_to_keep = mask_circ_MLPs(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # # Get a hook function which will patch in the mean z values for each head, at\n","    # # all positions which aren't important for the circuit\n","    # hook_fn = partial(\n","    #     hook_func_mask_mlp_out,\n","    #     components_to_keep=components_to_keep,\n","    #     means=means\n","    # )\n","\n","    # model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"6ILjxwH9YUYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def all_entries_true(tensor_dict):\n","    for key, tensor in tensor_dict.items():\n","        if not torch.all(tensor).item():\n","            return False\n","    return True"],"metadata":{"id":"u-YuOEDieLgE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ablation fns mult tok answers"],"metadata":{"id":"jtaV1q3SBHow"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    # tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","        # if next_char == '':\n","        #     next_char = ' '\n","        # clean_text = clean_text + next_char\n","        # tokens = model.to_tokens(clean_text).to(device)\n","    return corr_ans_tokLen"],"metadata":{"id":"WgbtY5fFPb71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    for i in range(corr_ans_tokLen):\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        # if i == corr_ans_tokLen - 1:\n","        #     print(model.to_string(tokens))\n","            # print(f\"Sequence so far: {clean_text}\")\n","            # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","        # pos_dict = {}\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())\n","    return model.to_string(tokens)"],"metadata":{"id":"lp4MyZ52cUTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ablate_auto_score(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, correct_ans):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    # logits = model(tokens)\n","    # next_token = logits[0, -1].argmax(dim=-1)\n","    # next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","    ans_so_far = ''\n","    ans_str_tok = tokenizer.tokenize(correct_ans)[1:] # correct_ans is str\n","    corr_tokenIDs = []\n","    for correct_ansPos in range(len(ans_str_tok)):\n","        tokID = model.tokenizer.encode(ans_str_tok[correct_ansPos])[2:][0] # 2: to skip padding <s> and ''\n","        corr_tokenIDs.append(tokID)\n","    correct_ans_tokLen = len(corr_tokenIDs)\n","    for ansPos in range(correct_ans_tokLen):\n","        # if next_char == '':\n","        #     next_char = ' '\n","\n","        # clean_text = clean_text + next_char\n","        # if i == correct_ans_tokLen - 1:\n","        #     print(model.to_string(tokens))\n","        #     # print(f\"Sequence so far: {clean_text}\")\n","        #     # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        # tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","        # pos_dict = {}\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        # if i == correct_ans_tokLen - 1:\n","            # print(model.to_string(tokens))\n","            # print(f\"Sequence so far: {clean_text}\")\n","            # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        ans_so_far += next_char\n","        correct_ans_tokLen += 1\n","        # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        ansTok_IDs = torch.tensor(corr_tokenIDs[ansPos])\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # corrTok_logits = logits[:, -1, next_token]\n","        corrTok_logits = logits[range(logits.size(0)), -1, ansTok_IDs]  # not next_token, as that's what's pred, not the token to measure\n","        # pdb.set_trace()\n","        total_score += corrTok_logits\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())\n","    # return ans_so_far, total_score.item()\n","    return ans_so_far"],"metadata":{"id":"-kvPgb12oYLi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCVySrfhk-YH"},"source":["# auto measure fns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Njf4fDdk_k9"},"outputs":[],"source":["def ablate_circ_autoScore(model, circuit, sequences_as_str, next_members):\n","    corr_text = \"5 3 9\"\n","    list_outputs = []\n","    score = 0\n","    for clean_text, correct_ans in zip(sequences_as_str, next_members):\n","        correct_ans_tokLen = clean_gen(model, clean_text, correct_ans)\n","\n","        heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","        head_to_remove = circuit\n","        heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","        mlps_not_ablate = [layer for layer in range(32)]\n","\n","        output_after_ablate = ablate_auto_score(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, correct_ans_tokLen)\n","        list_outputs.append(output_after_ablate)\n","        print(correct_ans, output_after_ablate)\n","        if correct_ans == output_after_ablate:\n","            score += 1\n","    perc_score = score / len(next_members)\n","    return perc_score, list_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CswxAMn4oRfW"},"outputs":[],"source":["def ablate_randcirc_autoScore(model, sequences_as_str, next_members, num_rand_runs, heads_not_overlap, num_heads_rand, num_not_overlap):\n","    corr_text = \"5 3 9\"\n","    list_outputs = []\n","    all_scores = []\n","    for clean_text, correct_ans in zip(sequences_as_str, next_members):\n","        prompt_score = 0\n","        correct_ans_tokLen = clean_gen(model, clean_text, correct_ans)\n","        for j in range(num_rand_runs):\n","            all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","            filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_not_overlap] # Filter out heads_not_overlap from all_possible_pairs\n","\n","            # Randomly choose num_heads_rand pairs ensuring less than num_not_overlap overlaps with heads_not_overlap\n","            head_to_remove = choose_heads_to_remove(filtered_pairs, heads_not_overlap, num_heads_rand, num_not_overlap)\n","\n","            heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","            mlps_not_ablate = [layer for layer in range(32)]\n","\n","            output_after_ablate = ablate_auto_score(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, correct_ans_tokLen)\n","            # list_outputs.append(output_after_ablate)\n","            # print(correct_ans, output_after_ablate)\n","            if correct_ans == output_after_ablate:\n","                prompt_score += 1\n","        print(prompt_score / num_rand_runs)\n","        all_scores.append(prompt_score / num_rand_runs)\n","\n","    perc_score = sum(all_scores) / len(next_members)\n","    return perc_score, list_outputs"]},{"cell_type":"markdown","source":["# chose rand circs"],"metadata":{"id":"9DrK9_jZ8eXB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8KYb2BBSm-G"},"outputs":[],"source":["# Function to randomly choose 50 pairs ensuring less than 10 overlap with heads_of_circ\n","def choose_heads_to_remove(filtered_pairs, heads_of_circ, num_pairs=50, max_overlap=10):\n","    while True:\n","        head_to_remove = random.sample(filtered_pairs, num_pairs)\n","        overlap_count = len([head for head in head_to_remove if head in heads_of_circ])\n","        if overlap_count < max_overlap:\n","            return head_to_remove"]},{"cell_type":"code","source":["import random\n","num_rand_runs = 50\n","lst_rand_head_to_remove = []\n","\n","heads_not_overlap = intersect_all\n","num_heads_rand = 100\n","num_not_overlap = len(intersect_all)\n","for j in range(num_rand_runs):\n","    all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","    filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_not_overlap] # Filter out heads_not_overlap from all_possible_pairs\n","    head_to_remove = choose_heads_to_remove(filtered_pairs, heads_not_overlap, num_heads_rand, num_not_overlap)\n","    # heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","    lst_rand_head_to_remove.append(head_to_remove)"],"metadata":{"id":"4E01rwZM8fpa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V93FIJs2MiU9","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1718356330395,"user_tz":-60,"elapsed":31,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"da28f58d-c82f-4fe8-ec4b-bf48f9b11e00"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e275ab85-78d5-45a3-bebe-a0070c234199\", \"lst_rand_head_to_remove.pkl\", 30216)"]},"metadata":{}}],"source":["import pickle\n","from google.colab import files\n","with open('lst_rand_head_to_remove.pkl', 'wb') as file:\n","    pickle.dump(lst_rand_head_to_remove, file)\n","files.download('lst_rand_head_to_remove.pkl')"]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"L650jirTpIyN","executionInfo":{"status":"ok","timestamp":1718383581850,"user_tz":-60,"elapsed":656,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c15d627b-a4d7-45a3-d96c-d77978aca9cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/seqcont_circuits/src/iter_node_pruning'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["import pickle\n","with open('/content/lst_rand_head_to_remove.pkl', 'rb') as file:\n","    lst_rand_head_to_remove = pickle.load(file)"],"metadata":{"id":"xhB1iXYNo_rV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for lst in lst_rand_head_to_remove:\n","    print(lst)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LckxoViC_q-7","executionInfo":{"status":"ok","timestamp":1718383627274,"user_tz":-60,"elapsed":639,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3db20262-24ac-48f5-dab4-5edddeb1a438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(13, 24), (28, 4), (26, 31), (12, 14), (27, 29), (27, 4), (21, 14), (0, 13), (10, 24), (5, 27), (4, 26), (16, 27), (13, 26), (5, 9), (30, 5), (11, 9), (12, 17), (22, 10), (4, 12), (4, 6), (15, 18), (2, 26), (16, 11), (23, 31), (5, 14), (27, 23), (28, 3), (0, 18), (8, 17), (4, 11), (9, 14), (23, 19), (12, 7), (19, 29), (13, 4), (25, 27), (6, 10), (26, 17), (8, 11), (2, 27), (27, 8), (22, 2), (1, 27), (1, 3), (8, 27), (11, 10), (25, 13), (14, 21), (25, 7), (1, 16), (12, 10), (8, 28), (25, 19), (1, 11), (3, 3), (5, 11), (4, 31), (28, 8), (19, 20), (20, 23), (10, 7), (22, 17), (18, 13), (6, 26), (27, 20), (2, 4), (13, 14), (22, 27), (27, 28), (6, 16), (19, 16), (7, 10), (13, 3), (12, 15), (5, 20), (28, 24), (14, 26), (13, 21), (24, 29), (29, 29), (3, 23), (22, 6), (27, 19), (7, 31), (19, 19), (20, 0), (13, 29), (7, 17), (3, 31), (22, 8), (21, 30), (3, 21), (23, 17), (25, 4), (6, 24), (30, 28), (25, 26), (18, 23), (26, 12), (10, 17)]\n","[(11, 14), (7, 19), (29, 25), (21, 4), (19, 4), (27, 17), (27, 26), (6, 29), (4, 11), (25, 21), (11, 6), (8, 14), (16, 18), (14, 6), (24, 2), (30, 20), (8, 2), (12, 6), (5, 8), (15, 11), (4, 29), (15, 22), (23, 1), (2, 16), (23, 29), (22, 14), (31, 21), (15, 18), (5, 6), (12, 24), (6, 2), (8, 25), (3, 24), (17, 5), (22, 6), (26, 11), (24, 15), (9, 3), (14, 28), (21, 14), (24, 21), (15, 1), (19, 31), (23, 14), (13, 30), (17, 20), (20, 0), (27, 30), (9, 25), (12, 15), (3, 21), (27, 12), (22, 5), (11, 12), (2, 25), (18, 9), (12, 16), (15, 29), (10, 23), (12, 2), (22, 11), (6, 3), (16, 24), (13, 2), (31, 30), (13, 12), (17, 7), (22, 28), (21, 0), (24, 20), (31, 12), (18, 24), (8, 28), (12, 7), (13, 28), (6, 8), (23, 24), (10, 17), (23, 8), (1, 21), (16, 23), (30, 18), (27, 0), (28, 10), (18, 7), (7, 6), (26, 21), (17, 10), (10, 29), (21, 16), (6, 1), (3, 15), (1, 6), (2, 7), (13, 4), (5, 28), (22, 8), (18, 12), (25, 9), (20, 30)]\n","[(30, 7), (24, 22), (31, 13), (24, 18), (3, 30), (12, 11), (4, 16), (7, 17), (18, 2), (26, 31), (1, 2), (11, 2), (18, 24), (5, 12), (13, 6), (7, 22), (29, 17), (26, 18), (14, 19), (6, 29), (5, 17), (17, 22), (18, 15), (1, 14), (0, 31), (27, 12), (25, 18), (15, 29), (30, 3), (5, 4), (20, 10), (3, 21), (30, 4), (28, 0), (30, 25), (7, 26), (29, 13), (2, 25), (24, 4), (10, 14), (21, 30), (11, 3), (23, 13), (16, 1), (24, 17), (25, 16), (24, 20), (27, 0), (17, 28), (9, 28), (12, 16), (1, 27), (11, 22), (15, 12), (6, 9), (15, 10), (2, 21), (17, 2), (30, 31), (13, 23), (0, 17), (27, 19), (24, 31), (25, 9), (7, 6), (28, 29), (10, 6), (15, 18), (27, 5), (21, 26), (10, 31), (23, 5), (26, 11), (8, 7), (20, 11), (25, 22), (26, 7), (13, 28), (25, 27), (4, 13), (7, 20), (2, 23), (17, 31), (24, 27), (1, 18), (15, 24), (23, 30), (5, 5), (7, 16), (24, 5), (16, 17), (11, 4), (31, 29), (28, 26), (30, 1), (25, 0), (24, 14), (21, 16), (13, 30), (16, 19)]\n","[(24, 22), (0, 24), (27, 4), (5, 4), (6, 3), (0, 23), (1, 14), (19, 2), (28, 16), (10, 27), (18, 10), (6, 4), (7, 31), (30, 26), (30, 12), (29, 26), (21, 12), (2, 9), (28, 4), (31, 27), (18, 2), (12, 9), (21, 14), (7, 30), (16, 6), (12, 7), (31, 22), (3, 0), (23, 7), (18, 1), (24, 27), (7, 13), (7, 16), (5, 3), (26, 11), (16, 1), (1, 17), (24, 12), (8, 27), (29, 21), (14, 28), (20, 31), (10, 31), (3, 10), (2, 5), (11, 20), (14, 2), (23, 6), (7, 25), (6, 28), (30, 10), (12, 22), (30, 19), (12, 14), (16, 10), (16, 16), (24, 4), (3, 26), (29, 20), (14, 10), (23, 22), (12, 31), (14, 27), (16, 13), (27, 1), (31, 12), (25, 14), (17, 2), (19, 13), (4, 27), (15, 11), (9, 23), (8, 6), (8, 1), (18, 0), (16, 18), (15, 26), (25, 24), (25, 22), (28, 5), (19, 21), (22, 8), (25, 23), (2, 6), (30, 23), (6, 29), (5, 13), (19, 10), (19, 31), (26, 26), (16, 15), (14, 15), (6, 9), (14, 24), (4, 21), (30, 0), (21, 8), (25, 2), (6, 12), (20, 10)]\n","[(18, 28), (20, 8), (24, 27), (21, 29), (13, 10), (9, 15), (14, 14), (7, 16), (24, 30), (24, 5), (25, 14), (31, 22), (28, 20), (29, 1), (24, 7), (8, 15), (25, 18), (15, 13), (28, 14), (17, 22), (30, 6), (16, 31), (26, 24), (5, 14), (16, 15), (24, 14), (24, 6), (5, 13), (28, 1), (2, 21), (29, 11), (19, 24), (13, 17), (23, 16), (3, 17), (11, 16), (3, 23), (19, 31), (31, 4), (26, 15), (24, 3), (30, 18), (8, 16), (9, 17), (7, 24), (7, 4), (23, 24), (19, 2), (22, 5), (8, 30), (1, 1), (11, 26), (8, 7), (27, 26), (21, 9), (20, 9), (19, 23), (10, 26), (27, 2), (8, 18), (11, 0), (25, 21), (26, 12), (13, 13), (14, 28), (24, 16), (10, 0), (16, 8), (13, 3), (16, 18), (15, 21), (0, 30), (29, 27), (23, 7), (7, 8), (30, 3), (12, 1), (27, 17), (30, 14), (22, 21), (0, 2), (12, 2), (15, 12), (21, 24), (13, 14), (24, 26), (26, 16), (9, 22), (9, 21), (3, 30), (2, 19), (30, 2), (10, 22), (3, 11), (14, 9), (9, 5), (25, 13), (13, 2), (23, 13), (5, 23)]\n","[(16, 17), (5, 19), (30, 29), (5, 29), (27, 31), (18, 19), (16, 25), (25, 0), (31, 13), (28, 29), (23, 18), (5, 1), (25, 27), (8, 7), (29, 30), (4, 14), (12, 22), (7, 7), (5, 20), (26, 16), (19, 25), (17, 31), (22, 3), (13, 27), (24, 22), (21, 5), (3, 21), (21, 28), (26, 29), (15, 7), (21, 20), (13, 10), (4, 6), (24, 9), (9, 16), (13, 8), (26, 12), (22, 26), (1, 11), (25, 9), (0, 13), (31, 14), (3, 16), (25, 21), (14, 14), (3, 14), (20, 5), (6, 17), (2, 0), (23, 17), (2, 30), (23, 6), (5, 26), (8, 15), (18, 17), (7, 31), (27, 1), (24, 18), (24, 24), (29, 11), (26, 22), (27, 21), (26, 11), (8, 14), (6, 2), (22, 31), (7, 2), (24, 11), (3, 2), (24, 27), (29, 4), (8, 28), (2, 26), (27, 23), (23, 9), (23, 26), (18, 14), (23, 22), (16, 1), (6, 19), (2, 15), (14, 26), (31, 15), (2, 23), (4, 18), (21, 15), (28, 13), (2, 10), (9, 9), (2, 14), (13, 30), (24, 12), (25, 18), (23, 5), (9, 3), (24, 3), (21, 7), (12, 7), (14, 19), (0, 17)]\n","[(21, 14), (26, 25), (12, 23), (4, 27), (19, 7), (14, 4), (24, 26), (17, 10), (20, 24), (21, 22), (6, 24), (18, 8), (8, 8), (23, 18), (13, 28), (17, 21), (26, 20), (7, 19), (3, 6), (0, 10), (28, 14), (6, 10), (25, 20), (10, 23), (28, 6), (15, 7), (0, 21), (1, 11), (8, 10), (4, 15), (15, 30), (13, 9), (20, 15), (19, 30), (10, 8), (13, 19), (16, 26), (12, 17), (8, 28), (25, 13), (2, 14), (19, 5), (8, 0), (5, 1), (8, 16), (26, 6), (9, 30), (14, 29), (7, 8), (2, 26), (1, 15), (0, 11), (16, 13), (26, 28), (16, 2), (1, 8), (29, 11), (5, 11), (28, 7), (21, 31), (14, 9), (30, 4), (31, 23), (31, 28), (5, 19), (25, 5), (8, 9), (15, 4), (15, 5), (30, 18), (6, 18), (16, 11), (13, 3), (1, 3), (18, 7), (11, 4), (3, 28), (0, 22), (19, 24), (16, 7), (13, 7), (8, 26), (19, 23), (16, 30), (14, 8), (12, 15), (14, 28), (11, 6), (30, 2), (19, 15), (30, 21), (23, 10), (21, 23), (31, 21), (2, 27), (30, 6), (20, 2), (18, 2), (21, 25), (3, 21)]\n","[(6, 19), (6, 24), (19, 7), (23, 23), (2, 13), (2, 1), (24, 16), (14, 4), (30, 5), (13, 17), (10, 30), (20, 16), (14, 6), (11, 29), (27, 10), (29, 11), (1, 0), (9, 25), (19, 16), (2, 23), (26, 13), (22, 6), (26, 6), (27, 6), (8, 28), (22, 29), (8, 20), (26, 25), (6, 21), (12, 17), (16, 30), (16, 10), (1, 23), (17, 1), (16, 26), (8, 2), (15, 25), (6, 27), (11, 4), (2, 10), (26, 30), (12, 29), (24, 22), (9, 15), (2, 12), (16, 5), (7, 11), (9, 10), (19, 1), (21, 3), (28, 5), (17, 31), (9, 2), (28, 27), (27, 23), (30, 11), (25, 15), (29, 30), (9, 23), (30, 13), (25, 25), (13, 14), (24, 26), (27, 15), (16, 22), (4, 13), (21, 30), (10, 10), (7, 29), (13, 12), (10, 8), (18, 24), (19, 25), (16, 6), (16, 18), (29, 17), (27, 31), (0, 25), (25, 2), (17, 13), (17, 10), (17, 19), (2, 0), (21, 15), (9, 8), (23, 7), (22, 13), (14, 22), (1, 5), (4, 11), (13, 16), (30, 15), (12, 31), (1, 20), (8, 30), (0, 2), (31, 7), (6, 16), (22, 22), (20, 29)]\n","[(29, 29), (27, 10), (7, 24), (12, 4), (13, 17), (11, 31), (16, 25), (31, 14), (2, 24), (28, 28), (28, 18), (1, 12), (11, 21), (26, 3), (23, 19), (25, 16), (11, 23), (9, 31), (18, 17), (21, 3), (31, 7), (20, 25), (24, 4), (28, 21), (20, 30), (28, 3), (26, 0), (14, 16), (23, 11), (0, 3), (30, 29), (30, 28), (12, 27), (3, 26), (0, 7), (16, 19), (4, 20), (0, 2), (20, 5), (14, 7), (0, 19), (29, 2), (25, 15), (1, 6), (13, 25), (31, 5), (3, 16), (23, 8), (22, 3), (10, 26), (23, 26), (9, 13), (16, 23), (27, 19), (30, 18), (2, 10), (24, 5), (23, 2), (26, 30), (14, 11), (9, 22), (24, 27), (0, 26), (17, 4), (3, 31), (9, 12), (28, 15), (22, 26), (10, 24), (6, 24), (19, 19), (25, 18), (11, 9), (18, 10), (1, 21), (14, 12), (19, 12), (31, 21), (4, 0), (5, 13), (8, 4), (10, 6), (8, 27), (16, 21), (4, 10), (9, 8), (10, 7), (7, 14), (3, 2), (19, 27), (8, 15), (11, 11), (26, 14), (19, 4), (26, 7), (22, 4), (22, 21), (0, 5), (2, 31), (26, 20)]\n","[(25, 15), (17, 6), (12, 11), (24, 28), (23, 11), (20, 28), (31, 8), (24, 30), (15, 13), (6, 19), (14, 18), (22, 20), (23, 2), (11, 24), (10, 27), (8, 4), (25, 2), (3, 13), (15, 0), (27, 13), (10, 24), (17, 25), (27, 8), (24, 16), (3, 21), (5, 4), (19, 20), (30, 28), (25, 16), (5, 30), (27, 15), (23, 25), (9, 18), (8, 25), (4, 9), (3, 29), (0, 1), (16, 3), (19, 18), (15, 22), (15, 16), (30, 22), (29, 19), (2, 7), (7, 31), (30, 29), (2, 1), (7, 22), (20, 29), (16, 10), (22, 28), (10, 15), (22, 6), (29, 16), (9, 7), (9, 13), (1, 29), (27, 3), (26, 6), (4, 11), (6, 18), (10, 6), (0, 8), (4, 18), (11, 29), (8, 12), (28, 9), (8, 24), (21, 10), (8, 8), (13, 21), (7, 30), (17, 1), (22, 26), (20, 0), (31, 3), (5, 12), (11, 17), (16, 23), (30, 9), (10, 11), (28, 18), (6, 6), (13, 30), (10, 19), (3, 9), (9, 19), (28, 17), (22, 9), (14, 10), (10, 23), (1, 2), (29, 14), (22, 22), (28, 20), (3, 20), (28, 8), (4, 31), (15, 1), (21, 31)]\n","[(30, 16), (9, 12), (20, 1), (11, 20), (2, 9), (20, 6), (20, 18), (12, 22), (28, 17), (22, 31), (20, 13), (31, 20), (16, 11), (25, 19), (17, 16), (11, 9), (14, 30), (25, 15), (27, 27), (9, 0), (22, 17), (22, 19), (7, 5), (1, 21), (31, 1), (15, 24), (5, 3), (24, 11), (23, 15), (23, 28), (18, 1), (3, 22), (11, 13), (27, 12), (26, 5), (17, 0), (12, 25), (26, 25), (22, 8), (27, 28), (13, 31), (10, 19), (23, 5), (20, 14), (8, 2), (4, 8), (27, 30), (23, 25), (27, 15), (4, 25), (16, 12), (29, 1), (8, 24), (12, 8), (5, 5), (12, 28), (11, 17), (25, 5), (31, 19), (4, 10), (8, 9), (30, 13), (3, 15), (1, 29), (18, 9), (29, 11), (3, 31), (26, 11), (2, 18), (21, 31), (3, 5), (2, 25), (26, 18), (6, 2), (5, 22), (25, 3), (16, 13), (31, 28), (30, 19), (20, 2), (3, 4), (5, 14), (20, 20), (2, 6), (12, 1), (5, 9), (10, 0), (17, 3), (10, 27), (2, 2), (3, 10), (17, 27), (26, 19), (15, 18), (5, 23), (27, 18), (17, 18), (10, 20), (2, 27), (11, 19)]\n","[(25, 12), (15, 16), (29, 25), (12, 2), (4, 17), (9, 23), (20, 24), (7, 1), (18, 24), (24, 4), (18, 22), (28, 8), (29, 26), (2, 4), (23, 29), (22, 9), (15, 8), (27, 5), (10, 6), (10, 11), (15, 24), (24, 24), (30, 19), (26, 8), (31, 1), (29, 1), (24, 29), (3, 6), (24, 10), (29, 20), (10, 1), (22, 18), (18, 21), (6, 5), (11, 13), (8, 4), (9, 10), (7, 20), (22, 25), (15, 25), (26, 24), (6, 8), (29, 3), (6, 18), (22, 1), (1, 5), (12, 3), (23, 25), (13, 29), (14, 19), (25, 7), (7, 28), (21, 16), (26, 26), (21, 2), (31, 26), (17, 17), (23, 17), (2, 11), (27, 31), (18, 9), (8, 0), (21, 23), (23, 23), (4, 7), (13, 5), (19, 13), (15, 19), (10, 0), (22, 0), (25, 30), (17, 31), (16, 30), (16, 28), (29, 19), (6, 13), (28, 24), (2, 9), (12, 0), (10, 12), (13, 14), (5, 22), (16, 25), (8, 19), (11, 10), (30, 28), (15, 4), (26, 13), (1, 29), (30, 2), (5, 5), (30, 25), (6, 29), (12, 26), (24, 25), (5, 15), (28, 28), (28, 10), (9, 28), (0, 10)]\n","[(22, 25), (2, 24), (13, 26), (30, 17), (12, 0), (6, 16), (20, 2), (23, 8), (11, 0), (0, 15), (19, 21), (21, 18), (12, 21), (10, 6), (21, 28), (14, 12), (1, 26), (15, 4), (5, 21), (20, 8), (22, 28), (3, 29), (28, 24), (0, 23), (28, 29), (30, 6), (31, 20), (0, 5), (22, 26), (13, 4), (29, 10), (4, 26), (3, 30), (11, 17), (21, 17), (31, 3), (2, 3), (20, 28), (26, 1), (21, 14), (4, 14), (21, 30), (12, 10), (2, 2), (8, 14), (25, 13), (14, 1), (27, 18), (26, 14), (20, 5), (14, 16), (22, 12), (10, 30), (24, 20), (0, 29), (0, 1), (1, 13), (8, 4), (31, 26), (10, 23), (17, 15), (11, 29), (5, 30), (23, 2), (14, 20), (23, 13), (0, 12), (29, 24), (11, 4), (24, 18), (22, 27), (22, 4), (27, 9), (15, 8), (22, 17), (0, 18), (26, 12), (22, 15), (31, 21), (24, 19), (3, 22), (31, 4), (18, 9), (26, 3), (23, 4), (28, 12), (12, 11), (25, 16), (9, 14), (4, 1), (13, 3), (11, 8), (11, 5), (25, 30), (16, 11), (2, 9), (8, 12), (9, 13), (5, 18), (24, 7)]\n","[(14, 7), (20, 13), (27, 3), (29, 5), (17, 9), (11, 7), (6, 4), (17, 23), (24, 5), (25, 18), (8, 6), (7, 5), (22, 16), (14, 8), (6, 22), (21, 9), (27, 30), (12, 19), (26, 9), (3, 14), (20, 19), (29, 21), (8, 5), (23, 18), (27, 19), (0, 0), (6, 17), (7, 27), (15, 26), (13, 5), (30, 11), (19, 7), (9, 11), (28, 29), (10, 10), (12, 24), (17, 15), (13, 19), (3, 13), (11, 12), (4, 6), (12, 21), (6, 3), (10, 14), (30, 10), (0, 28), (7, 29), (31, 13), (12, 7), (18, 13), (13, 13), (25, 13), (18, 11), (27, 31), (26, 26), (6, 2), (19, 8), (16, 24), (10, 31), (31, 27), (20, 1), (0, 29), (21, 16), (5, 28), (3, 12), (3, 0), (2, 25), (29, 15), (1, 14), (16, 5), (23, 29), (20, 8), (30, 14), (15, 31), (21, 25), (9, 1), (29, 27), (4, 15), (6, 31), (14, 2), (12, 6), (29, 28), (4, 31), (19, 3), (5, 14), (17, 10), (0, 8), (31, 16), (1, 2), (26, 8), (29, 2), (16, 12), (15, 1), (0, 10), (10, 17), (14, 9), (24, 17), (16, 9), (16, 14), (5, 5)]\n","[(28, 3), (1, 19), (0, 1), (11, 31), (5, 9), (27, 3), (9, 26), (8, 13), (8, 26), (16, 26), (9, 18), (31, 24), (13, 15), (4, 14), (9, 29), (9, 0), (24, 20), (21, 26), (13, 28), (16, 29), (1, 13), (27, 4), (6, 26), (6, 22), (27, 0), (6, 31), (22, 30), (6, 20), (31, 2), (22, 7), (13, 8), (14, 31), (16, 23), (27, 16), (18, 8), (15, 1), (8, 12), (9, 23), (25, 4), (24, 8), (19, 19), (29, 19), (23, 1), (29, 2), (18, 15), (4, 19), (24, 5), (13, 21), (7, 30), (7, 9), (4, 13), (8, 30), (5, 6), (15, 14), (17, 11), (8, 17), (17, 0), (14, 28), (0, 25), (14, 27), (0, 22), (6, 8), (31, 7), (1, 9), (6, 25), (14, 18), (9, 8), (23, 28), (8, 24), (12, 22), (31, 29), (28, 30), (4, 11), (11, 23), (26, 16), (22, 13), (30, 23), (0, 28), (28, 27), (22, 14), (12, 16), (25, 30), (20, 15), (4, 7), (5, 4), (29, 16), (24, 4), (20, 22), (7, 14), (14, 21), (22, 9), (16, 31), (9, 31), (28, 31), (28, 2), (25, 21), (1, 14), (20, 7), (5, 10), (27, 15)]\n","[(23, 8), (10, 19), (23, 14), (23, 24), (7, 19), (21, 29), (28, 7), (17, 0), (0, 19), (26, 5), (31, 10), (25, 3), (0, 22), (9, 28), (13, 1), (13, 3), (30, 26), (16, 1), (28, 28), (12, 7), (16, 27), (10, 10), (8, 13), (20, 2), (29, 3), (7, 17), (28, 3), (30, 5), (15, 6), (3, 19), (7, 9), (0, 10), (9, 18), (31, 19), (26, 15), (10, 3), (17, 11), (24, 23), (29, 28), (24, 21), (30, 7), (31, 18), (14, 12), (19, 5), (2, 0), (14, 28), (11, 12), (21, 3), (31, 24), (16, 18), (24, 16), (12, 29), (8, 20), (30, 9), (18, 19), (12, 17), (12, 25), (17, 14), (19, 24), (14, 24), (23, 17), (28, 1), (30, 29), (9, 8), (16, 17), (16, 24), (23, 26), (14, 0), (15, 14), (7, 3), (17, 4), (11, 24), (5, 2), (17, 25), (10, 6), (18, 10), (19, 4), (2, 16), (12, 8), (20, 28), (4, 31), (3, 9), (29, 12), (11, 17), (16, 12), (4, 20), (30, 18), (28, 11), (29, 1), (8, 29), (30, 6), (0, 5), (2, 20), (20, 21), (6, 16), (27, 8), (7, 30), (31, 5), (25, 19), (25, 16)]\n","[(16, 3), (9, 24), (16, 25), (31, 9), (2, 3), (16, 4), (26, 9), (1, 27), (14, 2), (3, 0), (25, 9), (3, 4), (26, 23), (20, 28), (23, 31), (7, 15), (18, 0), (26, 28), (4, 13), (14, 31), (9, 29), (27, 15), (3, 21), (13, 25), (29, 31), (1, 7), (25, 14), (2, 8), (26, 11), (25, 4), (20, 5), (28, 24), (14, 16), (29, 6), (12, 4), (12, 7), (1, 31), (7, 29), (27, 13), (27, 25), (0, 30), (15, 7), (1, 1), (14, 5), (13, 6), (25, 18), (24, 24), (3, 23), (25, 21), (26, 8), (12, 17), (3, 8), (10, 24), (14, 0), (18, 10), (7, 1), (28, 8), (31, 30), (6, 2), (7, 14), (29, 3), (4, 10), (9, 1), (0, 28), (4, 7), (30, 23), (5, 11), (5, 31), (30, 22), (1, 14), (31, 12), (30, 1), (15, 0), (12, 29), (28, 15), (31, 20), (10, 17), (26, 6), (20, 2), (3, 20), (14, 20), (4, 25), (28, 21), (13, 21), (17, 1), (0, 8), (22, 13), (2, 9), (7, 9), (19, 7), (18, 24), (7, 18), (28, 27), (20, 18), (31, 2), (7, 23), (6, 27), (8, 16), (12, 16), (7, 31)]\n","[(31, 11), (2, 29), (28, 8), (15, 25), (18, 1), (22, 16), (6, 10), (12, 4), (2, 11), (31, 15), (26, 20), (16, 7), (27, 29), (24, 17), (31, 7), (12, 11), (19, 24), (20, 3), (27, 20), (4, 26), (12, 3), (3, 23), (19, 29), (28, 25), (5, 12), (28, 20), (17, 29), (13, 16), (22, 8), (12, 1), (23, 3), (2, 23), (26, 9), (29, 19), (26, 30), (14, 4), (6, 4), (5, 15), (1, 1), (30, 10), (20, 6), (24, 29), (29, 26), (8, 11), (31, 18), (20, 9), (10, 22), (22, 7), (5, 13), (2, 25), (13, 31), (10, 1), (20, 4), (16, 2), (19, 10), (2, 26), (3, 3), (25, 13), (19, 2), (20, 7), (4, 24), (15, 22), (10, 27), (21, 24), (29, 8), (15, 21), (19, 1), (20, 30), (27, 30), (20, 31), (14, 23), (4, 19), (1, 27), (10, 20), (8, 9), (27, 12), (7, 9), (2, 15), (18, 2), (29, 15), (12, 8), (19, 27), (25, 6), (5, 22), (26, 31), (8, 0), (26, 17), (7, 31), (31, 2), (19, 8), (9, 8), (17, 3), (2, 17), (21, 19), (30, 17), (23, 12), (21, 22), (26, 1), (21, 2), (19, 23)]\n","[(0, 28), (5, 18), (8, 19), (9, 24), (29, 25), (15, 0), (1, 12), (30, 10), (28, 14), (18, 7), (11, 4), (31, 17), (8, 20), (22, 2), (10, 21), (11, 10), (2, 6), (28, 0), (26, 2), (17, 7), (14, 21), (16, 6), (25, 3), (17, 18), (23, 7), (1, 7), (15, 23), (18, 8), (13, 18), (21, 29), (15, 19), (5, 29), (23, 20), (18, 10), (12, 24), (7, 27), (27, 7), (16, 28), (6, 10), (27, 0), (9, 22), (18, 24), (12, 28), (16, 11), (13, 13), (15, 12), (12, 11), (22, 24), (26, 20), (2, 1), (22, 6), (7, 23), (4, 4), (9, 4), (27, 14), (6, 28), (18, 29), (14, 29), (30, 27), (22, 31), (13, 3), (3, 2), (24, 3), (10, 16), (22, 27), (21, 15), (2, 13), (28, 5), (18, 1), (27, 30), (17, 13), (17, 10), (6, 29), (22, 11), (6, 9), (19, 7), (14, 18), (15, 17), (4, 9), (16, 21), (19, 21), (29, 23), (27, 13), (15, 20), (1, 29), (29, 30), (6, 2), (5, 2), (4, 12), (10, 29), (1, 0), (25, 24), (21, 11), (25, 12), (15, 5), (23, 4), (13, 26), (15, 11), (28, 28), (7, 28)]\n","[(1, 3), (16, 2), (17, 16), (2, 23), (8, 22), (10, 17), (21, 0), (8, 8), (13, 1), (11, 15), (5, 3), (0, 27), (13, 0), (19, 18), (24, 17), (24, 5), (12, 12), (2, 8), (11, 21), (5, 6), (17, 25), (18, 20), (1, 22), (18, 27), (14, 4), (9, 19), (18, 26), (21, 14), (2, 20), (10, 22), (12, 16), (26, 10), (13, 13), (12, 21), (9, 28), (11, 24), (16, 8), (7, 17), (15, 11), (26, 17), (12, 13), (13, 19), (26, 30), (29, 25), (7, 19), (23, 23), (30, 21), (3, 2), (7, 14), (0, 15), (16, 28), (15, 8), (28, 11), (2, 30), (28, 1), (22, 5), (29, 12), (14, 3), (9, 16), (8, 1), (15, 2), (30, 28), (7, 26), (1, 2), (13, 12), (29, 10), (21, 2), (0, 10), (20, 1), (2, 1), (28, 2), (3, 7), (9, 26), (26, 1), (10, 26), (17, 30), (4, 0), (1, 15), (25, 13), (23, 28), (19, 2), (8, 30), (11, 29), (24, 22), (3, 4), (23, 3), (22, 20), (7, 11), (16, 27), (18, 13), (0, 23), (29, 7), (12, 26), (30, 19), (17, 27), (30, 5), (3, 13), (25, 5), (17, 11), (20, 0)]\n","[(15, 2), (3, 17), (10, 24), (17, 3), (9, 10), (13, 16), (31, 26), (21, 26), (19, 16), (2, 11), (31, 14), (2, 16), (6, 26), (11, 4), (1, 2), (29, 12), (9, 19), (13, 27), (26, 19), (6, 8), (2, 3), (18, 0), (6, 16), (4, 18), (5, 12), (29, 21), (28, 8), (7, 1), (12, 31), (22, 17), (13, 3), (21, 6), (12, 26), (26, 25), (0, 0), (8, 14), (1, 17), (13, 1), (28, 13), (21, 14), (24, 6), (9, 2), (10, 5), (5, 15), (23, 6), (1, 31), (23, 16), (15, 9), (3, 14), (27, 4), (18, 29), (27, 5), (15, 13), (1, 0), (20, 13), (25, 11), (12, 11), (19, 5), (15, 28), (31, 28), (9, 0), (6, 28), (7, 5), (19, 6), (31, 24), (21, 11), (28, 17), (21, 23), (8, 8), (2, 29), (9, 29), (12, 5), (0, 26), (18, 23), (29, 19), (26, 4), (5, 3), (10, 0), (29, 17), (6, 30), (21, 18), (5, 14), (21, 22), (19, 19), (9, 15), (27, 27), (18, 11), (22, 10), (12, 18), (1, 18), (25, 6), (13, 7), (17, 22), (26, 20), (13, 29), (27, 30), (27, 24), (5, 11), (16, 3), (16, 29)]\n","[(25, 1), (18, 18), (11, 12), (21, 14), (17, 2), (31, 12), (24, 29), (3, 15), (8, 15), (18, 11), (2, 24), (22, 31), (12, 2), (25, 21), (2, 29), (8, 31), (10, 8), (6, 4), (6, 9), (8, 22), (11, 27), (24, 11), (20, 6), (14, 8), (6, 10), (17, 22), (30, 3), (25, 17), (19, 3), (26, 27), (14, 5), (8, 14), (6, 15), (8, 18), (22, 4), (26, 0), (9, 20), (18, 23), (15, 30), (0, 14), (22, 27), (0, 13), (26, 21), (16, 28), (30, 1), (20, 8), (5, 13), (4, 0), (4, 31), (18, 27), (23, 20), (7, 18), (25, 29), (5, 12), (22, 17), (6, 23), (23, 19), (18, 15), (30, 2), (9, 2), (31, 15), (10, 17), (15, 13), (20, 31), (29, 17), (18, 3), (6, 31), (28, 24), (0, 3), (29, 12), (17, 11), (14, 27), (15, 22), (14, 28), (5, 17), (22, 18), (12, 21), (7, 9), (9, 4), (16, 24), (11, 11), (10, 14), (27, 26), (6, 2), (19, 23), (30, 20), (27, 28), (24, 17), (23, 23), (27, 11), (3, 12), (30, 21), (22, 1), (30, 29), (13, 4), (23, 26), (0, 22), (17, 13), (13, 18), (21, 16)]\n","[(18, 8), (13, 25), (28, 20), (7, 22), (21, 4), (7, 18), (4, 27), (1, 16), (15, 14), (27, 3), (26, 2), (7, 26), (6, 26), (26, 8), (31, 6), (19, 23), (18, 0), (6, 29), (20, 11), (12, 31), (25, 6), (29, 18), (6, 6), (26, 31), (7, 25), (26, 15), (15, 12), (27, 31), (29, 3), (21, 21), (2, 4), (3, 29), (7, 1), (20, 2), (24, 31), (16, 25), (22, 5), (16, 29), (31, 2), (30, 13), (28, 21), (28, 2), (13, 22), (17, 2), (27, 11), (10, 0), (25, 29), (4, 2), (16, 6), (18, 16), (17, 5), (16, 10), (31, 12), (3, 12), (12, 9), (9, 10), (24, 0), (22, 25), (7, 11), (27, 8), (4, 31), (22, 26), (23, 27), (3, 31), (15, 16), (25, 15), (12, 18), (24, 14), (8, 0), (30, 29), (15, 27), (18, 21), (26, 0), (23, 9), (22, 1), (22, 0), (28, 16), (2, 26), (25, 10), (18, 15), (5, 2), (12, 28), (8, 19), (1, 12), (25, 0), (18, 2), (10, 18), (11, 6), (3, 28), (13, 2), (12, 26), (17, 29), (5, 23), (29, 28), (31, 26), (31, 30), (15, 7), (16, 23), (18, 12), (15, 9)]\n","[(30, 20), (27, 9), (21, 4), (0, 25), (9, 0), (19, 13), (15, 23), (14, 11), (6, 27), (14, 2), (10, 0), (2, 28), (29, 20), (2, 14), (20, 30), (1, 13), (16, 17), (31, 26), (19, 24), (8, 23), (0, 0), (17, 7), (28, 20), (31, 25), (4, 10), (5, 8), (3, 22), (20, 25), (22, 4), (28, 31), (4, 29), (24, 16), (25, 23), (16, 11), (5, 2), (13, 0), (4, 25), (2, 9), (11, 9), (31, 29), (18, 0), (1, 1), (25, 27), (21, 26), (29, 7), (22, 28), (3, 17), (19, 5), (29, 15), (22, 30), (23, 9), (29, 14), (14, 5), (6, 12), (10, 16), (30, 18), (7, 24), (28, 1), (28, 16), (14, 16), (4, 24), (30, 31), (22, 22), (18, 20), (19, 18), (8, 3), (1, 10), (25, 25), (22, 18), (15, 29), (26, 30), (27, 5), (16, 24), (0, 11), (10, 11), (3, 0), (28, 17), (30, 27), (1, 19), (22, 0), (26, 15), (30, 24), (6, 3), (7, 22), (29, 16), (19, 25), (2, 18), (0, 30), (0, 19), (23, 1), (3, 6), (2, 27), (5, 19), (30, 7), (31, 9), (27, 4), (13, 14), (2, 21), (21, 24), (19, 16)]\n","[(22, 3), (16, 5), (6, 2), (10, 30), (7, 1), (28, 13), (29, 25), (23, 29), (16, 12), (11, 11), (4, 5), (13, 31), (11, 6), (6, 21), (29, 24), (1, 1), (5, 23), (24, 1), (2, 6), (30, 20), (27, 15), (22, 8), (15, 8), (7, 16), (20, 3), (14, 20), (11, 2), (20, 24), (23, 12), (4, 24), (26, 15), (6, 23), (5, 11), (14, 21), (25, 9), (17, 22), (5, 1), (3, 1), (30, 12), (31, 7), (11, 10), (7, 14), (23, 19), (19, 30), (10, 10), (22, 31), (25, 20), (9, 12), (25, 2), (21, 2), (13, 28), (29, 7), (14, 17), (9, 6), (28, 1), (2, 14), (11, 12), (18, 23), (28, 5), (25, 1), (5, 9), (23, 23), (0, 25), (8, 20), (9, 26), (31, 18), (1, 29), (9, 15), (6, 8), (18, 25), (1, 20), (15, 27), (26, 14), (27, 0), (0, 26), (14, 14), (30, 26), (7, 2), (26, 29), (24, 28), (21, 22), (4, 11), (9, 4), (19, 25), (7, 20), (6, 19), (16, 16), (27, 2), (1, 12), (13, 23), (3, 9), (22, 27), (5, 7), (3, 31), (30, 13), (18, 14), (8, 0), (26, 27), (31, 25), (31, 27)]\n","[(16, 2), (27, 11), (10, 27), (18, 3), (11, 17), (0, 31), (13, 17), (15, 28), (1, 19), (18, 9), (8, 12), (2, 15), (12, 15), (25, 24), (6, 31), (2, 18), (26, 6), (22, 11), (25, 2), (9, 8), (25, 11), (21, 28), (14, 20), (28, 8), (31, 16), (18, 11), (4, 11), (22, 8), (30, 15), (1, 30), (21, 4), (0, 15), (12, 14), (15, 16), (4, 0), (28, 25), (13, 24), (23, 7), (2, 7), (22, 5), (16, 23), (22, 9), (1, 14), (19, 25), (17, 2), (30, 26), (7, 27), (19, 19), (17, 10), (12, 20), (23, 20), (11, 15), (30, 9), (15, 10), (28, 2), (16, 30), (25, 31), (8, 15), (9, 6), (15, 11), (25, 20), (18, 22), (19, 24), (27, 16), (9, 17), (14, 15), (21, 13), (3, 22), (19, 5), (0, 17), (8, 16), (10, 7), (18, 29), (6, 13), (14, 23), (31, 5), (16, 25), (17, 25), (11, 24), (6, 4), (31, 29), (25, 6), (5, 28), (12, 1), (8, 6), (0, 30), (25, 15), (18, 21), (5, 14), (2, 24), (12, 26), (10, 12), (24, 0), (17, 28), (29, 8), (24, 10), (2, 23), (3, 18), (5, 15), (13, 3)]\n","[(3, 22), (28, 6), (29, 9), (0, 3), (2, 27), (19, 19), (29, 1), (20, 20), (8, 4), (30, 13), (18, 28), (12, 3), (20, 27), (11, 11), (8, 26), (27, 13), (0, 24), (31, 12), (30, 26), (23, 9), (5, 3), (11, 25), (16, 27), (15, 11), (9, 17), (19, 3), (23, 28), (28, 10), (23, 8), (26, 26), (10, 27), (13, 4), (14, 31), (9, 28), (23, 1), (12, 20), (11, 24), (10, 7), (10, 18), (14, 30), (0, 7), (19, 23), (1, 17), (18, 22), (15, 5), (7, 24), (6, 31), (28, 8), (5, 6), (24, 3), (10, 15), (15, 13), (31, 28), (20, 28), (7, 30), (19, 4), (12, 30), (9, 31), (21, 25), (10, 17), (12, 0), (0, 12), (0, 26), (26, 21), (29, 10), (1, 6), (24, 10), (20, 12), (14, 2), (4, 13), (0, 1), (22, 22), (17, 7), (13, 24), (5, 9), (24, 2), (0, 15), (0, 29), (5, 19), (16, 8), (13, 9), (30, 0), (23, 12), (21, 1), (16, 15), (9, 24), (28, 25), (8, 10), (17, 15), (5, 21), (22, 23), (13, 8), (12, 25), (30, 6), (5, 24), (14, 20), (4, 10), (12, 13), (18, 18), (24, 18)]\n","[(1, 9), (3, 22), (29, 6), (21, 17), (31, 19), (31, 22), (9, 8), (31, 30), (16, 27), (3, 10), (23, 19), (23, 18), (2, 16), (4, 13), (6, 27), (8, 2), (28, 0), (2, 5), (16, 28), (29, 16), (13, 29), (16, 3), (4, 5), (22, 18), (13, 6), (16, 16), (19, 6), (9, 20), (23, 28), (15, 9), (12, 19), (27, 2), (24, 29), (12, 24), (23, 25), (14, 22), (13, 8), (30, 20), (30, 12), (24, 12), (7, 26), (7, 28), (11, 15), (4, 28), (16, 25), (14, 1), (7, 29), (22, 28), (2, 3), (18, 11), (12, 7), (25, 3), (18, 17), (14, 5), (27, 9), (1, 21), (22, 22), (11, 29), (26, 29), (3, 16), (7, 31), (29, 11), (17, 0), (13, 30), (11, 11), (30, 11), (21, 5), (0, 25), (2, 8), (21, 6), (1, 17), (9, 24), (20, 23), (18, 3), (27, 1), (13, 15), (24, 21), (22, 10), (23, 1), (28, 15), (5, 24), (8, 8), (31, 12), (26, 1), (20, 4), (6, 9), (16, 23), (16, 2), (20, 3), (1, 5), (15, 20), (15, 24), (19, 20), (23, 3), (18, 8), (31, 18), (25, 5), (28, 21), (8, 29), (3, 30)]\n","[(27, 9), (10, 16), (18, 7), (22, 6), (28, 13), (22, 17), (9, 20), (0, 21), (29, 5), (0, 30), (20, 15), (10, 5), (20, 14), (30, 8), (26, 1), (18, 17), (28, 4), (15, 5), (18, 25), (27, 31), (23, 11), (2, 14), (14, 21), (31, 4), (8, 30), (8, 2), (26, 27), (23, 19), (19, 30), (0, 4), (9, 31), (6, 15), (23, 5), (25, 21), (22, 21), (11, 27), (21, 4), (22, 23), (27, 28), (15, 26), (19, 23), (9, 18), (6, 24), (13, 26), (23, 3), (2, 28), (8, 23), (12, 18), (23, 8), (12, 3), (12, 26), (21, 9), (9, 24), (7, 15), (23, 17), (17, 4), (19, 6), (10, 23), (28, 18), (22, 28), (31, 13), (0, 5), (22, 25), (8, 24), (21, 13), (8, 11), (15, 24), (4, 29), (22, 19), (25, 20), (3, 11), (14, 1), (30, 19), (5, 24), (13, 12), (25, 0), (28, 26), (25, 28), (6, 21), (16, 24), (12, 6), (24, 17), (4, 0), (6, 1), (31, 27), (27, 1), (23, 27), (26, 21), (13, 27), (3, 24), (20, 0), (15, 30), (14, 0), (5, 29), (3, 16), (31, 10), (14, 20), (10, 29), (19, 3), (15, 8)]\n","[(16, 7), (26, 17), (6, 31), (21, 23), (23, 8), (26, 29), (24, 25), (8, 21), (16, 30), (20, 2), (0, 13), (6, 8), (8, 16), (9, 11), (31, 23), (24, 14), (4, 28), (9, 20), (17, 17), (25, 13), (23, 23), (23, 24), (21, 9), (15, 23), (28, 7), (31, 21), (26, 28), (18, 5), (16, 24), (8, 24), (11, 1), (4, 27), (31, 4), (19, 5), (16, 2), (5, 15), (29, 28), (17, 27), (13, 26), (24, 21), (10, 0), (16, 22), (5, 0), (26, 6), (9, 30), (1, 0), (3, 11), (3, 18), (15, 18), (26, 15), (31, 26), (28, 18), (7, 3), (15, 21), (18, 15), (6, 22), (27, 12), (28, 5), (1, 11), (15, 0), (27, 26), (8, 12), (25, 15), (9, 2), (5, 31), (5, 21), (14, 24), (5, 11), (8, 18), (13, 8), (28, 4), (17, 18), (11, 11), (26, 7), (21, 28), (21, 10), (6, 4), (16, 21), (9, 29), (31, 0), (1, 15), (7, 17), (7, 20), (29, 16), (20, 5), (10, 15), (10, 2), (8, 25), (5, 7), (19, 3), (25, 9), (25, 14), (9, 28), (18, 19), (12, 24), (13, 31), (29, 29), (17, 20), (15, 10), (12, 17)]\n","[(15, 31), (27, 27), (30, 7), (23, 28), (6, 0), (22, 14), (24, 29), (27, 15), (4, 16), (17, 2), (13, 4), (21, 26), (15, 21), (27, 24), (28, 7), (10, 19), (10, 11), (26, 25), (15, 15), (7, 29), (9, 0), (16, 5), (1, 19), (19, 2), (31, 16), (31, 14), (23, 27), (9, 29), (3, 3), (7, 10), (21, 18), (30, 1), (29, 19), (17, 28), (11, 12), (6, 26), (24, 13), (15, 22), (30, 9), (19, 5), (2, 24), (25, 30), (6, 30), (24, 25), (17, 9), (3, 12), (29, 1), (18, 23), (2, 29), (19, 11), (12, 17), (24, 18), (1, 27), (17, 17), (15, 17), (12, 2), (6, 2), (24, 20), (25, 8), (29, 10), (3, 9), (21, 15), (5, 1), (22, 21), (0, 28), (14, 7), (3, 11), (14, 23), (4, 2), (23, 12), (29, 6), (26, 26), (19, 25), (9, 30), (7, 24), (23, 8), (19, 23), (14, 19), (13, 13), (21, 23), (12, 28), (6, 10), (22, 22), (8, 30), (3, 20), (29, 14), (0, 24), (28, 21), (26, 8), (28, 12), (21, 17), (1, 21), (1, 1), (28, 20), (26, 13), (26, 19), (18, 19), (4, 26), (18, 7), (9, 27)]\n","[(1, 1), (5, 0), (8, 16), (16, 29), (9, 23), (21, 9), (10, 0), (31, 17), (4, 23), (24, 4), (29, 15), (9, 12), (29, 1), (0, 27), (15, 2), (11, 22), (9, 29), (29, 7), (10, 17), (8, 5), (8, 12), (14, 20), (30, 26), (21, 6), (11, 6), (17, 20), (13, 1), (31, 18), (0, 19), (31, 6), (30, 22), (3, 22), (29, 26), (19, 3), (5, 3), (15, 19), (24, 24), (25, 3), (2, 4), (5, 2), (3, 24), (22, 30), (7, 3), (23, 13), (9, 2), (9, 14), (4, 8), (28, 17), (12, 24), (26, 8), (16, 31), (27, 2), (28, 11), (6, 29), (7, 19), (29, 10), (31, 3), (19, 23), (16, 4), (0, 29), (22, 6), (17, 10), (9, 31), (6, 26), (16, 18), (27, 18), (23, 23), (4, 4), (8, 29), (18, 3), (20, 0), (12, 5), (9, 11), (2, 5), (31, 15), (16, 16), (20, 3), (30, 13), (1, 6), (13, 19), (0, 25), (18, 4), (30, 23), (12, 15), (5, 21), (27, 30), (25, 11), (21, 25), (24, 30), (15, 6), (26, 4), (10, 19), (12, 29), (2, 19), (30, 1), (28, 1), (27, 21), (11, 12), (3, 3), (15, 26)]\n","[(28, 23), (26, 12), (21, 25), (30, 3), (6, 31), (30, 22), (18, 15), (0, 2), (17, 31), (23, 31), (11, 4), (26, 14), (4, 24), (31, 5), (18, 20), (30, 29), (27, 8), (2, 21), (10, 16), (15, 10), (11, 10), (15, 2), (3, 6), (19, 4), (3, 1), (11, 26), (27, 7), (16, 17), (15, 6), (4, 27), (19, 15), (20, 27), (25, 26), (20, 11), (0, 10), (2, 30), (4, 25), (19, 29), (13, 9), (10, 19), (0, 17), (18, 5), (11, 14), (0, 7), (4, 29), (22, 12), (28, 22), (13, 16), (9, 29), (12, 9), (21, 16), (21, 3), (16, 25), (31, 12), (9, 24), (31, 27), (4, 7), (21, 11), (16, 13), (2, 15), (17, 5), (24, 12), (2, 27), (21, 18), (15, 17), (26, 23), (12, 24), (11, 5), (3, 2), (31, 9), (19, 5), (3, 18), (12, 26), (31, 15), (16, 20), (1, 22), (5, 22), (24, 31), (14, 27), (4, 28), (14, 20), (15, 22), (31, 6), (1, 30), (4, 17), (13, 15), (6, 7), (18, 10), (16, 5), (6, 17), (16, 24), (21, 21), (27, 2), (18, 8), (31, 28), (29, 25), (8, 5), (19, 18), (11, 25), (8, 4)]\n","[(25, 9), (16, 14), (2, 31), (1, 30), (8, 16), (20, 21), (23, 12), (21, 31), (12, 30), (12, 8), (22, 11), (8, 1), (5, 18), (31, 26), (10, 18), (13, 9), (2, 0), (25, 30), (21, 13), (15, 4), (6, 18), (27, 1), (26, 10), (3, 12), (25, 15), (19, 9), (13, 26), (14, 22), (17, 18), (10, 31), (23, 1), (30, 10), (24, 20), (14, 6), (11, 16), (18, 8), (22, 22), (16, 20), (9, 2), (10, 1), (1, 7), (29, 9), (6, 24), (28, 26), (2, 28), (27, 23), (3, 20), (13, 17), (23, 17), (7, 3), (28, 6), (25, 0), (28, 4), (18, 13), (14, 3), (10, 24), (1, 18), (26, 5), (17, 17), (7, 5), (16, 21), (31, 29), (4, 30), (12, 22), (30, 0), (19, 23), (17, 21), (2, 15), (29, 29), (19, 28), (14, 26), (7, 7), (25, 20), (24, 15), (8, 7), (11, 1), (1, 0), (0, 4), (31, 9), (27, 18), (11, 24), (9, 27), (6, 30), (11, 30), (19, 17), (4, 22), (30, 12), (17, 29), (29, 22), (3, 16), (0, 19), (2, 26), (14, 0), (31, 6), (22, 20), (11, 29), (15, 21), (5, 26), (25, 5), (18, 11)]\n","[(24, 22), (13, 3), (20, 0), (3, 24), (29, 13), (22, 8), (31, 1), (15, 6), (25, 9), (0, 12), (10, 24), (18, 8), (8, 30), (14, 5), (9, 27), (1, 22), (17, 27), (3, 5), (0, 29), (18, 20), (21, 12), (13, 12), (1, 16), (6, 26), (2, 15), (17, 4), (12, 22), (20, 15), (7, 1), (21, 7), (29, 21), (0, 28), (26, 10), (11, 9), (28, 23), (11, 25), (4, 23), (2, 29), (16, 17), (10, 5), (8, 8), (10, 3), (30, 7), (10, 25), (15, 24), (24, 20), (26, 11), (13, 22), (25, 2), (4, 4), (30, 1), (24, 18), (6, 27), (11, 13), (21, 21), (19, 18), (25, 15), (16, 22), (26, 23), (16, 1), (11, 0), (13, 17), (27, 3), (1, 30), (18, 0), (17, 22), (3, 22), (29, 10), (20, 22), (4, 8), (13, 19), (12, 20), (11, 6), (15, 30), (6, 24), (23, 13), (2, 11), (11, 1), (16, 26), (19, 25), (7, 4), (0, 10), (25, 31), (29, 11), (28, 5), (2, 26), (2, 5), (29, 0), (29, 24), (5, 5), (24, 3), (10, 26), (2, 23), (4, 9), (4, 13), (11, 27), (12, 16), (26, 8), (22, 29), (24, 4)]\n","[(24, 0), (23, 23), (14, 12), (28, 23), (28, 9), (7, 3), (19, 29), (25, 9), (0, 28), (5, 11), (27, 31), (4, 29), (30, 24), (30, 18), (19, 2), (22, 0), (16, 14), (12, 22), (20, 20), (4, 4), (7, 6), (7, 23), (30, 11), (15, 5), (29, 12), (11, 19), (7, 16), (17, 14), (16, 26), (16, 15), (15, 29), (12, 3), (1, 15), (3, 18), (0, 7), (10, 9), (4, 1), (30, 26), (5, 1), (22, 12), (16, 27), (23, 28), (3, 12), (2, 7), (10, 16), (13, 4), (15, 22), (18, 13), (21, 3), (3, 9), (30, 28), (1, 5), (12, 15), (22, 20), (8, 17), (17, 17), (9, 21), (25, 30), (23, 19), (20, 28), (19, 9), (9, 20), (4, 27), (18, 14), (26, 13), (22, 21), (26, 28), (15, 16), (28, 5), (4, 10), (15, 19), (28, 2), (7, 8), (4, 8), (2, 20), (30, 22), (9, 9), (5, 26), (5, 22), (12, 21), (11, 14), (14, 26), (8, 13), (3, 15), (19, 21), (24, 29), (20, 30), (25, 4), (1, 23), (12, 4), (9, 12), (2, 0), (6, 31), (27, 25), (13, 15), (6, 27), (31, 8), (18, 8), (1, 8), (15, 30)]\n","[(11, 24), (0, 16), (7, 10), (23, 28), (23, 5), (1, 11), (23, 21), (4, 12), (15, 3), (22, 4), (25, 16), (10, 20), (20, 10), (10, 25), (5, 9), (15, 12), (20, 12), (23, 11), (19, 4), (10, 28), (24, 30), (26, 10), (0, 17), (24, 11), (3, 24), (15, 27), (14, 24), (3, 19), (21, 9), (31, 5), (13, 16), (23, 30), (1, 22), (1, 19), (17, 2), (6, 9), (5, 19), (28, 22), (22, 5), (24, 22), (24, 17), (20, 18), (0, 2), (1, 1), (10, 15), (11, 21), (29, 27), (15, 2), (16, 20), (8, 25), (15, 31), (14, 2), (19, 5), (28, 27), (26, 7), (5, 5), (14, 13), (5, 23), (5, 22), (4, 6), (5, 29), (8, 6), (8, 30), (8, 9), (31, 23), (22, 10), (25, 0), (28, 29), (5, 14), (1, 31), (2, 7), (10, 11), (9, 13), (3, 18), (30, 17), (18, 1), (19, 14), (30, 21), (30, 14), (2, 24), (11, 4), (2, 1), (0, 29), (21, 14), (5, 24), (22, 1), (17, 1), (22, 28), (12, 4), (29, 15), (0, 9), (5, 27), (22, 31), (26, 28), (24, 14), (5, 28), (8, 15), (30, 19), (2, 14), (16, 30)]\n","[(11, 16), (20, 9), (8, 11), (12, 17), (28, 25), (15, 5), (16, 28), (2, 4), (27, 21), (29, 4), (11, 19), (0, 5), (5, 31), (31, 24), (30, 22), (27, 28), (26, 21), (4, 25), (2, 15), (10, 20), (14, 24), (25, 3), (18, 1), (19, 15), (10, 9), (22, 15), (19, 20), (25, 26), (31, 12), (25, 10), (5, 27), (21, 20), (7, 9), (18, 6), (14, 12), (21, 16), (14, 11), (20, 13), (11, 14), (19, 21), (24, 17), (29, 30), (30, 9), (2, 11), (13, 13), (25, 9), (8, 30), (29, 8), (5, 18), (14, 21), (15, 2), (7, 13), (25, 31), (6, 6), (31, 25), (24, 23), (21, 18), (31, 29), (13, 5), (8, 9), (29, 18), (23, 30), (28, 30), (13, 7), (8, 14), (6, 24), (2, 0), (6, 10), (23, 13), (3, 21), (8, 1), (19, 31), (15, 27), (0, 10), (1, 23), (27, 15), (13, 6), (12, 5), (11, 0), (17, 8), (8, 16), (4, 26), (4, 5), (30, 31), (9, 18), (29, 24), (1, 15), (15, 21), (22, 18), (26, 6), (18, 7), (28, 20), (1, 31), (0, 27), (24, 7), (5, 3), (6, 17), (26, 7), (24, 12), (3, 14)]\n","[(27, 22), (25, 14), (21, 24), (3, 26), (13, 24), (29, 20), (14, 9), (27, 20), (1, 16), (18, 11), (23, 24), (8, 0), (14, 5), (9, 16), (1, 24), (2, 31), (16, 25), (14, 25), (1, 8), (1, 12), (15, 20), (15, 21), (8, 10), (27, 1), (4, 10), (17, 16), (23, 2), (23, 13), (19, 19), (8, 23), (13, 2), (24, 19), (27, 14), (4, 21), (18, 8), (19, 24), (12, 17), (9, 9), (7, 7), (19, 14), (29, 23), (12, 23), (8, 1), (25, 10), (22, 31), (1, 23), (0, 0), (30, 19), (20, 25), (12, 29), (30, 21), (4, 23), (9, 15), (23, 3), (19, 8), (31, 21), (3, 13), (11, 22), (28, 2), (18, 1), (7, 8), (7, 3), (29, 12), (29, 30), (31, 6), (24, 25), (2, 26), (31, 11), (29, 25), (6, 25), (5, 12), (16, 8), (4, 25), (23, 9), (16, 23), (31, 27), (27, 18), (20, 21), (27, 24), (19, 9), (22, 30), (15, 22), (20, 2), (26, 8), (20, 3), (9, 18), (19, 10), (7, 10), (26, 17), (8, 16), (8, 14), (19, 5), (3, 29), (15, 2), (4, 5), (29, 28), (17, 0), (14, 22), (13, 27), (10, 8)]\n","[(3, 31), (24, 16), (15, 6), (2, 24), (10, 14), (29, 29), (26, 25), (20, 3), (28, 6), (3, 23), (14, 17), (11, 4), (17, 11), (15, 15), (31, 24), (14, 11), (29, 4), (28, 26), (4, 19), (25, 6), (17, 28), (15, 28), (26, 26), (26, 8), (25, 19), (17, 17), (0, 29), (17, 7), (6, 7), (31, 29), (2, 8), (3, 25), (1, 26), (8, 3), (26, 14), (5, 11), (5, 4), (2, 28), (12, 6), (5, 18), (31, 22), (22, 23), (23, 20), (23, 5), (27, 4), (28, 17), (31, 18), (19, 9), (9, 13), (21, 29), (12, 19), (18, 11), (12, 22), (10, 17), (5, 9), (3, 21), (27, 9), (23, 30), (12, 12), (20, 14), (24, 22), (8, 27), (15, 5), (13, 2), (17, 13), (2, 5), (23, 17), (27, 10), (13, 5), (25, 10), (12, 1), (11, 17), (4, 12), (28, 13), (9, 12), (30, 11), (11, 30), (12, 20), (14, 15), (14, 25), (9, 28), (10, 16), (31, 0), (19, 3), (3, 20), (24, 28), (28, 21), (2, 27), (16, 28), (23, 1), (23, 11), (1, 29), (11, 1), (12, 14), (23, 28), (19, 7), (11, 16), (25, 1), (29, 14), (24, 14)]\n","[(25, 4), (16, 18), (8, 27), (5, 1), (8, 10), (14, 14), (5, 28), (3, 30), (28, 7), (11, 31), (30, 0), (25, 21), (12, 29), (26, 9), (2, 15), (1, 24), (17, 31), (28, 10), (30, 25), (19, 10), (22, 30), (21, 22), (8, 0), (15, 28), (11, 23), (7, 3), (19, 1), (7, 9), (20, 26), (6, 6), (8, 29), (17, 12), (31, 21), (30, 21), (20, 9), (20, 11), (15, 19), (1, 29), (16, 6), (8, 8), (20, 18), (8, 18), (0, 29), (13, 27), (23, 18), (20, 20), (15, 21), (26, 30), (26, 17), (11, 0), (21, 17), (11, 1), (11, 9), (23, 2), (3, 16), (14, 1), (1, 10), (12, 26), (15, 5), (24, 0), (2, 21), (25, 10), (14, 26), (12, 31), (16, 15), (26, 15), (6, 29), (19, 16), (27, 7), (10, 8), (10, 5), (2, 16), (27, 3), (20, 21), (2, 3), (17, 7), (19, 19), (19, 17), (15, 23), (9, 26), (5, 24), (5, 0), (0, 22), (10, 10), (12, 6), (14, 17), (13, 25), (0, 26), (28, 6), (22, 27), (15, 17), (11, 17), (16, 13), (4, 18), (18, 8), (29, 7), (5, 7), (23, 0), (28, 13), (31, 22)]\n","[(10, 12), (30, 16), (13, 29), (1, 27), (12, 2), (28, 20), (25, 1), (2, 11), (6, 16), (8, 2), (11, 3), (27, 12), (10, 26), (6, 23), (2, 6), (0, 10), (13, 22), (27, 1), (4, 26), (10, 27), (0, 25), (9, 8), (28, 30), (1, 25), (26, 20), (14, 9), (0, 18), (26, 24), (21, 1), (14, 11), (19, 12), (10, 24), (11, 12), (24, 2), (10, 3), (6, 30), (27, 29), (26, 2), (27, 2), (5, 28), (31, 0), (22, 16), (28, 19), (13, 31), (20, 24), (25, 20), (20, 14), (20, 27), (24, 4), (23, 21), (13, 3), (30, 11), (14, 26), (22, 29), (31, 31), (12, 18), (23, 13), (23, 2), (14, 16), (27, 19), (24, 16), (27, 31), (0, 19), (22, 23), (20, 20), (26, 19), (24, 12), (19, 25), (26, 5), (19, 9), (30, 22), (30, 26), (24, 15), (18, 21), (8, 29), (1, 11), (22, 8), (31, 6), (8, 21), (16, 3), (7, 15), (21, 7), (22, 0), (23, 7), (27, 8), (6, 2), (10, 19), (0, 7), (23, 29), (7, 11), (2, 7), (27, 0), (7, 10), (29, 9), (31, 24), (17, 28), (0, 1), (13, 24), (10, 8), (25, 9)]\n","[(23, 21), (17, 24), (22, 28), (30, 11), (11, 14), (11, 24), (8, 30), (14, 19), (28, 2), (31, 28), (15, 3), (22, 4), (19, 7), (24, 5), (24, 22), (16, 20), (3, 19), (30, 26), (8, 15), (30, 14), (7, 20), (26, 21), (3, 23), (11, 9), (20, 26), (9, 11), (19, 19), (7, 31), (0, 26), (15, 20), (27, 24), (29, 30), (0, 12), (18, 4), (27, 12), (14, 8), (18, 15), (17, 19), (8, 9), (5, 21), (6, 23), (5, 8), (27, 25), (10, 1), (15, 13), (6, 0), (22, 24), (2, 8), (21, 6), (19, 0), (12, 17), (24, 17), (21, 17), (5, 1), (0, 18), (14, 30), (22, 2), (17, 15), (1, 23), (1, 31), (7, 5), (28, 15), (12, 13), (20, 22), (29, 3), (0, 10), (0, 21), (11, 16), (30, 25), (11, 27), (27, 18), (9, 25), (21, 20), (13, 10), (8, 20), (14, 14), (29, 18), (23, 11), (3, 10), (16, 9), (25, 3), (10, 20), (12, 15), (29, 17), (9, 13), (26, 9), (1, 27), (13, 26), (17, 7), (16, 22), (21, 12), (23, 25), (16, 21), (6, 10), (28, 18), (12, 19), (7, 19), (6, 6), (6, 12), (19, 14)]\n","[(3, 12), (27, 8), (19, 31), (0, 24), (2, 14), (20, 25), (7, 28), (19, 4), (24, 4), (19, 23), (0, 1), (25, 1), (22, 18), (3, 11), (9, 7), (24, 17), (23, 0), (29, 16), (25, 8), (30, 9), (2, 16), (19, 17), (18, 13), (8, 2), (28, 25), (21, 1), (31, 28), (1, 10), (27, 30), (29, 13), (28, 18), (4, 31), (3, 15), (8, 23), (21, 9), (18, 4), (15, 10), (17, 1), (22, 17), (0, 29), (5, 24), (6, 15), (29, 26), (29, 15), (6, 24), (22, 24), (0, 10), (15, 7), (4, 1), (30, 20), (31, 12), (11, 1), (12, 28), (28, 11), (18, 9), (31, 7), (21, 20), (26, 4), (29, 7), (6, 23), (14, 2), (24, 28), (28, 23), (11, 5), (1, 26), (30, 14), (13, 17), (27, 7), (1, 3), (29, 27), (25, 14), (19, 19), (8, 22), (5, 8), (7, 1), (24, 18), (23, 25), (18, 1), (15, 31), (10, 17), (28, 14), (0, 2), (15, 8), (7, 7), (25, 3), (27, 3), (17, 23), (19, 0), (1, 0), (11, 0), (20, 23), (18, 20), (24, 10), (18, 16), (11, 9), (23, 27), (1, 27), (27, 27), (28, 22), (7, 13)]\n","[(31, 20), (20, 21), (3, 11), (4, 22), (0, 31), (25, 30), (14, 11), (25, 16), (12, 5), (2, 23), (7, 6), (14, 27), (3, 13), (4, 4), (21, 4), (5, 26), (26, 9), (13, 23), (7, 17), (3, 31), (25, 2), (18, 2), (31, 12), (24, 28), (24, 27), (21, 8), (23, 16), (27, 28), (1, 23), (10, 19), (31, 18), (9, 4), (26, 21), (9, 31), (30, 15), (31, 2), (12, 30), (25, 5), (18, 18), (26, 23), (3, 7), (14, 19), (16, 26), (10, 27), (27, 7), (9, 3), (9, 20), (3, 29), (19, 2), (7, 30), (8, 14), (19, 1), (18, 20), (17, 19), (2, 27), (0, 26), (18, 5), (15, 14), (2, 21), (28, 25), (1, 7), (29, 0), (13, 21), (22, 19), (3, 25), (27, 29), (27, 3), (6, 27), (1, 11), (18, 26), (14, 1), (21, 12), (7, 19), (7, 20), (3, 19), (10, 8), (7, 11), (22, 22), (31, 10), (7, 8), (14, 3), (25, 27), (19, 25), (7, 2), (12, 9), (0, 10), (13, 31), (1, 1), (17, 15), (11, 6), (2, 0), (13, 0), (31, 3), (22, 4), (3, 5), (10, 17), (29, 26), (21, 14), (13, 22), (22, 11)]\n","[(12, 19), (16, 8), (26, 16), (17, 26), (23, 16), (7, 12), (25, 18), (21, 2), (15, 1), (29, 4), (12, 3), (31, 11), (26, 15), (12, 26), (17, 7), (22, 18), (10, 10), (13, 2), (18, 5), (27, 29), (31, 28), (1, 22), (8, 29), (2, 1), (13, 16), (5, 24), (18, 0), (24, 31), (22, 30), (0, 15), (23, 7), (25, 22), (19, 28), (23, 3), (17, 27), (10, 11), (18, 18), (7, 19), (2, 8), (12, 14), (3, 30), (5, 3), (0, 20), (3, 31), (27, 0), (10, 18), (24, 26), (15, 12), (9, 6), (30, 19), (1, 17), (0, 0), (1, 12), (21, 21), (8, 10), (20, 12), (11, 27), (6, 5), (31, 27), (15, 16), (4, 24), (29, 9), (1, 30), (24, 4), (4, 22), (5, 30), (25, 8), (1, 19), (23, 2), (13, 7), (24, 0), (21, 11), (27, 7), (7, 1), (18, 30), (5, 22), (29, 6), (29, 10), (15, 22), (30, 27), (24, 5), (6, 8), (30, 15), (23, 24), (22, 11), (3, 11), (5, 23), (8, 0), (23, 15), (6, 28), (0, 10), (13, 19), (12, 0), (8, 22), (4, 16), (25, 6), (19, 9), (28, 31), (29, 17), (11, 14)]\n","[(16, 1), (23, 28), (18, 7), (25, 30), (22, 11), (31, 30), (29, 18), (16, 3), (27, 19), (26, 19), (28, 16), (20, 12), (0, 27), (19, 14), (0, 16), (2, 28), (16, 12), (24, 10), (25, 27), (1, 12), (14, 15), (4, 24), (3, 28), (13, 18), (9, 4), (23, 3), (22, 19), (27, 28), (8, 13), (7, 6), (30, 28), (16, 29), (8, 29), (26, 29), (14, 24), (0, 14), (6, 18), (20, 14), (29, 10), (7, 3), (8, 8), (17, 5), (13, 12), (22, 4), (18, 24), (0, 31), (28, 23), (7, 8), (7, 27), (10, 9), (30, 27), (22, 13), (29, 26), (9, 9), (14, 25), (26, 7), (9, 20), (9, 25), (24, 9), (13, 27), (5, 3), (31, 16), (9, 5), (5, 30), (6, 12), (25, 12), (22, 8), (23, 10), (20, 11), (17, 28), (14, 4), (12, 6), (27, 17), (28, 26), (5, 10), (11, 25), (25, 16), (29, 22), (9, 16), (20, 29), (5, 7), (4, 31), (23, 9), (3, 6), (9, 1), (4, 10), (16, 8), (1, 17), (15, 22), (9, 18), (11, 23), (22, 1), (17, 17), (0, 7), (1, 6), (3, 8), (26, 3), (16, 6), (19, 8), (0, 28)]\n","[(1, 13), (30, 20), (10, 17), (2, 21), (29, 16), (3, 15), (11, 24), (19, 1), (20, 21), (27, 1), (24, 18), (29, 31), (0, 4), (23, 22), (27, 8), (15, 18), (2, 1), (28, 9), (29, 19), (5, 10), (19, 21), (18, 18), (31, 31), (11, 7), (10, 29), (16, 31), (9, 4), (25, 8), (23, 12), (26, 3), (7, 9), (23, 9), (30, 10), (17, 2), (0, 24), (21, 17), (0, 31), (23, 10), (7, 16), (3, 1), (22, 30), (14, 31), (19, 8), (19, 18), (8, 0), (22, 9), (21, 8), (8, 11), (20, 29), (9, 23), (7, 17), (25, 1), (10, 24), (10, 4), (2, 18), (1, 24), (25, 12), (18, 21), (14, 10), (2, 0), (9, 28), (11, 10), (9, 21), (24, 28), (20, 18), (1, 9), (4, 14), (29, 27), (21, 7), (30, 24), (1, 19), (1, 21), (17, 6), (0, 15), (16, 3), (6, 31), (21, 28), (24, 12), (13, 5), (12, 15), (5, 2), (2, 28), (23, 8), (7, 27), (28, 29), (16, 26), (16, 18), (1, 0), (0, 1), (4, 15), (23, 7), (17, 16), (30, 18), (18, 29), (24, 10), (20, 16), (7, 15), (25, 10), (1, 8), (0, 29)]\n","[(15, 25), (27, 24), (24, 11), (19, 25), (26, 11), (26, 22), (4, 24), (2, 16), (14, 10), (27, 30), (12, 1), (3, 7), (26, 30), (21, 27), (28, 18), (20, 2), (5, 7), (14, 5), (23, 29), (7, 12), (27, 29), (26, 27), (12, 22), (2, 12), (2, 11), (24, 31), (16, 12), (16, 8), (18, 6), (27, 2), (0, 23), (6, 23), (25, 26), (21, 20), (20, 9), (21, 9), (5, 21), (11, 2), (8, 29), (4, 7), (1, 29), (8, 17), (29, 31), (1, 2), (29, 29), (23, 3), (18, 1), (20, 6), (13, 3), (15, 19), (30, 12), (20, 20), (27, 1), (7, 30), (28, 2), (15, 11), (15, 3), (22, 14), (31, 24), (11, 29), (3, 22), (3, 2), (8, 24), (13, 8), (31, 7), (18, 18), (10, 15), (8, 3), (8, 18), (7, 17), (12, 0), (10, 18), (10, 12), (3, 28), (7, 28), (4, 16), (13, 21), (9, 29), (4, 29), (3, 26), (1, 1), (7, 9), (14, 24), (6, 2), (23, 19), (22, 27), (17, 11), (27, 19), (15, 28), (19, 10), (26, 26), (15, 23), (0, 30), (15, 21), (4, 4), (6, 1), (26, 25), (28, 31), (19, 27), (17, 4)]\n","[(27, 2), (20, 1), (19, 10), (13, 13), (0, 9), (30, 27), (14, 6), (8, 12), (15, 9), (26, 15), (27, 17), (24, 0), (20, 20), (12, 4), (1, 2), (22, 7), (7, 19), (7, 25), (7, 18), (21, 15), (26, 26), (19, 28), (11, 4), (10, 6), (4, 16), (18, 13), (0, 19), (0, 12), (25, 4), (27, 27), (12, 28), (24, 19), (9, 28), (16, 23), (5, 12), (2, 2), (12, 2), (31, 4), (6, 21), (14, 28), (19, 0), (2, 30), (17, 24), (24, 22), (22, 8), (13, 7), (0, 25), (29, 22), (8, 22), (13, 21), (9, 3), (11, 14), (3, 0), (18, 10), (15, 18), (13, 17), (28, 15), (31, 22), (8, 30), (17, 13), (11, 21), (15, 14), (31, 14), (28, 1), (29, 20), (14, 16), (24, 6), (11, 22), (2, 15), (10, 31), (26, 27), (18, 30), (5, 4), (6, 16), (10, 5), (13, 15), (14, 0), (20, 29), (19, 2), (26, 3), (7, 22), (8, 8), (15, 8), (13, 28), (3, 24), (21, 14), (13, 16), (25, 8), (19, 18), (10, 30), (28, 11), (12, 1), (29, 5), (30, 6), (20, 12), (31, 28), (3, 28), (1, 11), (0, 24), (6, 19)]\n"]}]},{"cell_type":"markdown","source":["# test prompts"],"metadata":{"id":"oOoMYJ14bZcb"}},{"cell_type":"code","source":["instruction = \"Be concise. \"\n","clean_text =  \"If today is November 20th, then in 28 days it will be\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKHD7iN1CnWd","executionInfo":{"status":"ok","timestamp":1718382720498,"user_tz":-60,"elapsed":2386,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"28f4d1b7-2705-47a2-fdef-2cd400f43587"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is November 20th, then in 28 days it will be December 18']\n"]}]},{"cell_type":"markdown","source":["# If today is the Xth of month M, what date will it be in Y days?”"],"metadata":{"id":"GtnWjQT-j-bb"}},{"cell_type":"code","source":["from datetime import datetime, timedelta\n","import random\n","\n","def generate_prompts_and_correct_dates(N):\n","    months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n","              \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n","\n","    prompts = []\n","    correct_dates = []\n","\n","    for _ in range(N):\n","        month_index = random.randint(0, 11)\n","        day = random.randint(1, 28)  # to avoid issues with different month lengths\n","        days_to_add = random.randint(1, 28)\n","        current_date = datetime(2024, month_index + 1, day)\n","        future_date = current_date + timedelta(days=days_to_add)\n","        future_month = months[future_date.month - 1]\n","        prompt = f\"If today is {months[month_index]} {day}th, then in {days_to_add} days it will be \"\n","        correct_date = f\"{future_month} {future_date.day}th\"\n","\n","        prompts.append(prompt)\n","        correct_dates.append(correct_date)\n","\n","    return prompts, correct_dates\n","\n","N = 50\n","prompts, correct_dates = generate_prompts_and_correct_dates(50)\n","\n","# Printing the results\n","# print(\"Prompts:\")\n","# for prompt in prompts:\n","#     print(prompt)\n","# print(\"\\nCorrect Answers:\")\n","# for date in correct_dates:\n","#     print(date)"],"metadata":{"id":"Q3o2T17Uk7cq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# unablated\n","\n","outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in prompts:\n","    clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    outputs.append(prompt_out)"],"metadata":{"id":"0R0a7hU1Aq42","executionInfo":{"status":"error","timestamp":1718407710439,"user_tz":-60,"elapsed":264,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"5a889c84-f203-42d1-dc26-0fa0e3472ce4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'prompts' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-6cd12603046a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Be concise. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclean_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclean_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstruction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorr_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"uno uno uno\"\u001b[0m \u001b[0;31m# dos tres cinco seis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'prompts' is not defined"]}]},{"cell_type":"code","source":["from google.colab import files\n","with open('template_1_unablated.txt', 'w') as f:\n","    for line in outputs:\n","        f.write(f\"{line}\\n\")\n","files.download('template_1_unablated.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"HUZNXC98JZYm","executionInfo":{"status":"ok","timestamp":1718392246139,"user_tz":-60,"elapsed":682,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9d6b56af-8a56-4468-e20a-b7a4383ea887"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ab6eaddb-a9e8-459b-b41b-8206f11b653c\", \"template_1_unablated.txt\", 4134)"]},"metadata":{}}]},{"cell_type":"code","source":["outputs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poaKKTiZLrU-","executionInfo":{"status":"ok","timestamp":1718392637940,"user_tz":-60,"elapsed":775,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a99c944a-2a71-4b48-981c-6b9714ff2d2a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s> Be concise. If today is July 23th, then in 22 days it will be  August 14th']"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["file_path = '/content/template_1_unablated_correct.txt'\n","correct_prompts = []\n","with open(file_path, 'r') as file:\n","    for line in file:\n","        correct_prompts.append([line.strip()])\n","print(correct_prompts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTPmmtEOMGiu","executionInfo":{"status":"ok","timestamp":1718402715076,"user_tz":-60,"elapsed":330,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"590cb4f9-e861-4332-e603-de4b0d66f7d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Be concise. If today is July 23th, then in 22 days it will be'], ['Be concise. If today is April 19th, then in 25 days it will be'], ['Be concise. If today is March 21th, then in 16 days it will be'], ['Be concise. If today is June 28th, then in 18 days it will be'], ['Be concise. If today is April 14th, then in 11 days it will be'], ['Be concise. If today is April 7th, then in 20 days it will be'], ['Be concise. If today is October 28th, then in 10 days it will be'], ['Be concise. If today is May 26th, then in 5 days it will be'], ['Be concise. If today is April 17th, then in 28 days it will be'], ['Be concise. If today is September 16th, then in 12 days it will be'], ['Be concise. If today is October 21th, then in 17 days it will be'], ['Be concise. If today is July 12th, then in 23 days it will be'], ['Be concise. If today is January 27th, then in 11 days it will be'], ['Be concise. If today is May 18th, then in 18 days it will be'], ['Be concise. If today is August 18th, then in 22 days it will be'], ['Be concise. If today is July 26th, then in 19 days it will be'], ['Be concise. If today is February 27th, then in 28 days it will be'], ['Be concise. If today is July 23th, then in 11 days it will be'], ['Be concise. If today is March 21th, then in 27 days it will be'], ['Be concise. If today is January 27th, then in 1 days it will be'], ['Be concise. If today is November 16th, then in 12 days it will be'], ['Be concise. If today is June 13th, then in 13 days it will be'], ['Be concise. If today is March 18th, then in 25 days it will be'], ['Be concise. If today is March 20th, then in 23 days it will be'], ['Be concise. If today is May 4th, then in 4 days it will be'], ['Be concise. If today is April 8th, then in 19 days it will be'], ['Be concise. If today is April 21th, then in 8 days it will be'], ['Be concise. If today is April 11th, then in 27 days it will be'], ['Be concise. If today is June 6th, then in 26 days it will be'], ['Be concise. If today is November 20th, then in 1 days it will be'], ['Be concise. If today is December 17th, then in 8 days it will be'], ['Be concise. If today is May 20th, then in 16 days it will be'], ['Be concise. If today is November 25th, then in 24 days it will be']]\n"]}]},{"cell_type":"code","source":["# intersect_all\n","\n","outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = intersect_all\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    outputs.append(prompt_out)\n","\n","with open('template_1_intersectAll.txt', 'w') as f:\n","    for line in outputs:\n","        f.write(f\"{line}\\n\")\n","files.download('template_1_intersectAll.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"AtdWRy1DpvIA","executionInfo":{"status":"ok","timestamp":1718393175592,"user_tz":-60,"elapsed":59909,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"93f10295-211b-472b-8bb7-bb9d5bc35077"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_05e94b05-03b7-4023-96aa-3becb0b4d727\", \"template_1_intersectAll.txt\", 2735)"]},"metadata":{}}]},{"cell_type":"code","source":["# random- using len 100 presets\n","\n","def ablate_randcirc_autoScore_2(model, sequences_as_str, lst_rand_head_to_remove): # next_members,\n","    corr_text = \"5 3 9\"\n","    # list_outputs = []\n","    # all_scores = []\n","    all_prompt_outputs = []\n","    # for clean_text, correct_ans in zip(sequences_as_str, next_members):\n","    for i, clean_text in enumerate(sequences_as_str):\n","        clean_text = clean_text[0]\n","        prompt_score = 0\n","        output_for_a_prompt = []\n","        # correct_ans_tokLen = clean_gen(model, clean_text, correct_ans)\n","        # for j in range(num_rand_runs):\n","        for head_to_remove in lst_rand_head_to_remove:\n","            all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","            # filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_not_overlap] # Filter out heads_not_overlap from all_possible_pairs\n","\n","            # # Randomly choose num_heads_rand pairs ensuring less than num_not_overlap overlaps with heads_not_overlap\n","            # head_to_remove = choose_heads_to_remove(filtered_pairs, heads_not_overlap, num_heads_rand, num_not_overlap)\n","\n","            heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","            mlps_not_ablate = [layer for layer in range(32)]\n","\n","            output_after_ablate = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","\n","            # output_after_ablate = ablate_auto_score(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, correct_ans)\n","            # list_outputs.append(output_after_ablate)\n","            # print(correct_ans, output_after_ablate)\n","            # if correct_ans == output_after_ablate:\n","            #     prompt_score += 1\n","\n","            output_for_a_prompt.append(output_after_ablate)\n","        # print(prompt_score / num_rand_runs)\n","        # print(clean_text)\n","        # print(output_after_ablate)\n","        # all_scores.append(prompt_score / len(lst_rand_head_to_remove))\n","        all_prompt_outputs.append(output_for_a_prompt)\n","\n","        filename = 'template_1_rand_prompt' + str(i)\n","        with open(filename, 'w') as f:\n","            for line in randAbl_prompt_outputs:\n","                f.write(f\"{line}\\n\")\n","        files.download(filename)\n","    # perc_score = sum(all_scores) / len(next_members)\n","    # return perc_score #, list_outputs\n","    return all_prompt_outputs"],"metadata":{"id":"KrCcV3iipYOJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["randAbl_prompt_outputs = ablate_randcirc_autoScore_2(model, correct_prompts[0:2], lst_rand_head_to_remove[0:10])\n","randAbl_prompt_outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"BUYAFBOYpgeI","executionInfo":{"status":"ok","timestamp":1718394461474,"user_tz":-60,"elapsed":46184,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7a0e84e3-3b27-42eb-80a1-287c48cba80f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_0dc5495c-fcd0-4142-a103-aec3d6e5e289\", \"template_1_rand_prompt0\", 831)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_22c81866-42be-4829-8f55-787c44edd41d\", \"template_1_rand_prompt1\", 831)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[[['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 22nd'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 12th'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 22nd'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 12th'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 1st.'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th'],\n","  ['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th']],\n"," [['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 10th'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 19th'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 4th.'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 1st.'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 9th.'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 14th'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 14th'],\n","  ['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']]]"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["with open('template_1_rand_prompt1.txt', 'w') as f:\n","    for line in randAbl_prompt_outputs:\n","        f.write(f\"{line}\\n\")\n","files.download('template_1_rand_prompt1.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"iH8_zidKRgTK","executionInfo":{"status":"ok","timestamp":1718394178126,"user_tz":-60,"elapsed":18,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f595ede8-7e9f-4db5-ddf1-25185fad320e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_87e85878-6162-4f4c-b87a-719d8beeafd7\", \"template_1_rand_prompt1.txt\", 831)"]},"metadata":{}}]},{"cell_type":"code","source":["# random- len 100\n","\n","for i in range(10):\n","    heads_of_circ = intersect_all\n","    num_heads_rand = 100\n","    num_not_overlap = len(intersect_all)\n","\n","    all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","    # Filter out heads_of_circ from all_possible_pairs\n","    filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","    # Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","    head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, num_heads_rand, num_not_overlap)\n","\n","    heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","    mlps_not_ablate = [layer for layer in range(32)]\n","\n","    ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cVRLaigHo0hM","executionInfo":{"status":"ok","timestamp":1718383940167,"user_tz":-60,"elapsed":73138,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0bc9d2ca-286b-4139-f28d-5bd2d8d8fbd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise.If today is November 20th, then in 28 days it will be December 18th.\\n\\nIf today is November 20th, then in']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 18th.\\n\\nIf today is November 20th, then in']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 20th.\\n\\nBe specific.If you are asking for a specific date']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 18th.\\n\\nIn 28 days, December 18th']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 18th.\\n\\nSo, in 28 days, it will be']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 20th.\\n\\n1. If today is November 20th,']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 20th.\\n\\nAnswer:\\n\\nIn 28 days, it']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 20th.The difference between the two dates is 28 days.\\n']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 18th.\\n\\nSo, the answer is 28 days.\\n']\n","['<s> Be concise.If today is November 20th, then in 28 days it will be December 3rd.\\n\\nAnswer: 28 days from today is December 3']\n"]}]},{"cell_type":"code","source":["# random- len 16\n","\n","all_prompt_outputs = []\n","corr_text = \"0 0 0\"\n","for clean_text in correct_prompts[0:2]:\n","    clean_text = clean_text[0]\n","    output_for_a_prompt = []\n","    for i in range(10):\n","        heads_of_circ = intersect_all\n","        num_heads_rand = len(intersect_all)\n","        num_not_overlap = len(intersect_all)\n","\n","        all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","        # Filter out heads_of_circ from all_possible_pairs\n","        filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","        # Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","        head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, num_heads_rand, num_not_overlap)\n","\n","        heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","        mlps_not_ablate = [layer for layer in range(32)]\n","\n","        out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","        print(out)\n","        output_for_a_prompt.append(out)\n","    all_prompt_outputs.append(output_for_a_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718403052593,"user_tz":-60,"elapsed":48610,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"aa886fdc-fa51-4b7c-be6a-dd9877e06eef","id":"eOYfEhvGx2Wc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n"]}]},{"cell_type":"code","source":["# intersect_all , show first two results\n","\n","outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts[0:2]:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = intersect_all\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    print(prompt_out)\n","    outputs.append(prompt_out)\n","\n","# with open('template_1_intersectAll.txt', 'w') as f:\n","#     for line in outputs:\n","#         f.write(f\"{line}\\n\")\n","# files.download('template_1_intersectAll.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIUZfgB6zd_i","executionInfo":{"status":"ok","timestamp":1718403086598,"user_tz":-60,"elapsed":3764,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b83f2d14-37fc-4fde-e968-02ca29da5771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 1st.']\n"]}]},{"cell_type":"code","source":["# big 4 heads combos subsets\n","\n","outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts[0:2]:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = [(20,17)]\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    print(prompt_out)\n","    outputs.append(prompt_out)\n","\n","# with open('template_1_intersectAll.txt', 'w') as f:\n","#     for line in outputs:\n","#         f.write(f\"{line}\\n\")\n","# files.download('template_1_intersectAll.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdm7HeWvzokn","executionInfo":{"status":"ok","timestamp":1718403117504,"user_tz":-60,"elapsed":3886,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a84d6e7c-0364-4fe7-b20a-481c87488c0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n"]}]},{"cell_type":"code","source":["outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts[0:2]:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = [(6,11)]\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    print(prompt_out)\n","    outputs.append(prompt_out)\n","\n","# with open('template_1_intersectAll.txt', 'w') as f:\n","#     for line in outputs:\n","#         f.write(f\"{line}\\n\")\n","# files.download('template_1_intersectAll.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9RSfslU0WyB","executionInfo":{"status":"ok","timestamp":1718403305428,"user_tz":-60,"elapsed":4074,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f881436f-9292-4a39-c4c4-a018dd8aabee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n"]}]},{"cell_type":"code","source":["outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts[0:2]:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = [(20,17), (16,0), (5,25), (6,11)]\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    print(prompt_out)\n","    outputs.append(prompt_out)\n","\n","# with open('template_1_intersectAll.txt', 'w') as f:\n","#     for line in outputs:\n","#         f.write(f\"{line}\\n\")\n","# files.download('template_1_intersectAll.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGGEpQpVzrvs","executionInfo":{"status":"ok","timestamp":1718403135466,"user_tz":-60,"elapsed":3837,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ebbf8c8b-1251-4ba9-db93-728847e0e91d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 10th']\n"]}]},{"cell_type":"code","source":["outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts[0:2]:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = [(20,17), (5,25)]\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    print(prompt_out)\n","    outputs.append(prompt_out)\n","\n","# with open('template_1_intersectAll.txt', 'w') as f:\n","#     for line in outputs:\n","#         f.write(f\"{line}\\n\")\n","# files.download('template_1_intersectAll.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuwPGBzd0lhu","executionInfo":{"status":"ok","timestamp":1718403880333,"user_tz":-60,"elapsed":3781,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fcd57ac8-feef-41df-9ad6-b27a9b7f2e0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n"]}]},{"cell_type":"code","source":["outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = [(20,17), (16,0), (5,25)]\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    print(prompt_out)\n","    outputs.append(prompt_out)\n","\n","with open('template_1_big3.txt', 'w') as f:\n","    for line in outputs:\n","        f.write(f\"{line}\\n\")\n","files.download('template_1_big3.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"id":"ENeuuAfa0dDt","executionInfo":{"status":"ok","timestamp":1718403986813,"user_tz":-60,"elapsed":60403,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"431f2560-b6cb-4ecc-b0c1-ca2fd4199a37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 14th']\n","['<s> Be concise. If today is March 21th, then in 16 days it will be April 5th.']\n","['<s> Be concise. If today is June 28th, then in 18 days it will be July 20th']\n","['<s> Be concise. If today is April 14th, then in 11 days it will be April 25th']\n","['<s> Be concise. If today is April 7th, then in 20 days it will be April 27th']\n","['<s> Be concise. If today is October 28th, then in 10 days it will be November 7th.']\n","['<s> Be concise. If today is May 26th, then in 5 days it will be May 31st']\n","['<s> Be concise. If today is April 17th, then in 28 days it will be May 15th']\n","['<s> Be concise. If today is September 16th, then in 12 days it will be September 28th']\n","['<s> Be concise. If today is October 21th, then in 17 days it will be November 11th']\n","['<s> Be concise. If today is July 12th, then in 23 days it will be July 31st']\n","['<s> Be concise. If today is January 27th, then in 11 days it will be February 7th.']\n","['<s> Be concise. If today is May 18th, then in 18 days it will be May 31st']\n","['<s> Be concise. If today is August 18th, then in 22 days it will be September 1st.']\n","['<s> Be concise. If today is July 26th, then in 19 days it will be August 14th']\n","['<s> Be concise. If today is February 27th, then in 28 days it will be March 27th']\n","['<s> Be concise. If today is July 23th, then in 11 days it will be August 1st.']\n","['<s> Be concise. If today is March 21th, then in 27 days it will be April 18th']\n","['<s> Be concise. If today is January 27th, then in 1 days it will be January 28th']\n","['<s> Be concise. If today is November 16th, then in 12 days it will be November 28th']\n","['<s> Be concise. If today is June 13th, then in 13 days it will be June 26th']\n","['<s> Be concise. If today is March 18th, then in 25 days it will be April 15th']\n","['<s> Be concise. If today is March 20th, then in 23 days it will be April 10th']\n","['<s> Be concise. If today is May 4th, then in 4 days it will be May 8th.']\n","['<s> Be concise. If today is April 8th, then in 19 days it will be April 27th']\n","['<s> Be concise. If today is April 21th, then in 8 days it will be April 29th']\n","['<s> Be concise. If today is April 11th, then in 27 days it will be May 11th']\n","['<s> Be concise. If today is June 6th, then in 26 days it will be June 26th']\n","['<s> Be concise. If today is November 20th, then in 1 days it will be November 21st']\n","['<s> Be concise. If today is December 17th, then in 8 days it will be December 25th']\n","['<s> Be concise. If today is May 20th, then in 16 days it will be May 31st']\n","['<s> Be concise. If today is November 25th, then in 24 days it will be December 25th']\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9bf7f31a-7851-418e-bcf8-f6fba7d5633a\", \"template_1_big3.txt\", 2725)"]},"metadata":{}}]},{"cell_type":"code","source":["outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts:\n","    clean_text = clean_text[0]\n","    # clean_text = instruction + clean_text\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    head_to_remove = [(20,17), (16,0), (5,25), (6, 11)]\n","    heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    print(prompt_out)\n","    outputs.append(prompt_out)\n","\n","with open('template_1_big4.txt', 'w') as f:\n","    for line in outputs:\n","        f.write(f\"{line}\\n\")\n","files.download('template_1_big4.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"id":"BeqlkEFe3a6J","executionInfo":{"status":"ok","timestamp":1718404170398,"user_tz":-60,"elapsed":60606,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2ab199e8-c7d0-42fb-d0a3-75734bd8f372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 15th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 10th']\n","['<s> Be concise. If today is March 21th, then in 16 days it will be April 5th.']\n","['<s> Be concise. If today is June 28th, then in 18 days it will be July 20th']\n","['<s> Be concise. If today is April 14th, then in 11 days it will be April 25th']\n","['<s> Be concise. If today is April 7th, then in 20 days it will be April 27th']\n","['<s> Be concise. If today is October 28th, then in 10 days it will be November 7th.']\n","['<s> Be concise. If today is May 26th, then in 5 days it will be May 31st']\n","['<s> Be concise. If today is April 17th, then in 28 days it will be May 15th']\n","['<s> Be concise. If today is September 16th, then in 12 days it will be September 28th']\n","['<s> Be concise. If today is October 21th, then in 17 days it will be November 11th']\n","['<s> Be concise. If today is July 12th, then in 23 days it will be July 26th']\n","['<s> Be concise. If today is January 27th, then in 11 days it will be February 8th.']\n","['<s> Be concise. If today is May 18th, then in 18 days it will be May 31st']\n","['<s> Be concise. If today is August 18th, then in 22 days it will be September 1st.']\n","['<s> Be concise. If today is July 26th, then in 19 days it will be August 14th']\n","['<s> Be concise. If today is February 27th, then in 28 days it will be March 27th']\n","['<s> Be concise. If today is July 23th, then in 11 days it will be August 1st.']\n","['<s> Be concise. If today is March 21th, then in 27 days it will be April 17th']\n","['<s> Be concise. If today is January 27th, then in 1 days it will be January 28th']\n","['<s> Be concise. If today is November 16th, then in 12 days it will be November 28th']\n","['<s> Be concise. If today is June 13th, then in 13 days it will be June 26th']\n","['<s> Be concise. If today is March 18th, then in 25 days it will be April 15th']\n","['<s> Be concise. If today is March 20th, then in 23 days it will be April 15th']\n","['<s> Be concise. If today is May 4th, then in 4 days it will be May 8th.']\n","['<s> Be concise. If today is April 8th, then in 19 days it will be April 22nd']\n","['<s> Be concise. If today is April 21th, then in 8 days it will be April 29th']\n","['<s> Be concise. If today is April 11th, then in 27 days it will be May 11th']\n","['<s> Be concise. If today is June 6th, then in 26 days it will be June 26th']\n","['<s> Be concise. If today is November 20th, then in 1 days it will be November 21st']\n","['<s> Be concise. If today is December 17th, then in 8 days it will be December 25th']\n","['<s> Be concise. If today is May 20th, then in 16 days it will be May 31st']\n","['<s> Be concise. If today is November 25th, then in 24 days it will be December 25th']\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9226d02f-2288-45b7-aefb-55f0684d5eee\", \"template_1_big4.txt\", 2725)"]},"metadata":{}}]},{"cell_type":"code","source":["# random, len 4 (not from saved head combo presets) ; show first two results\n","\n","all_prompt_outputs = []\n","corr_text = \"0 0 0\"\n","for clean_text in correct_prompts[0:2]:\n","    clean_text = clean_text[0]\n","    output_for_a_prompt = []\n","    for i in range(10):\n","        heads_of_circ = intersect_all\n","        num_heads_rand = 4\n","        num_not_overlap = len(intersect_all)\n","\n","        all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","        # Filter out heads_of_circ from all_possible_pairs\n","        filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","        # Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","        head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, num_heads_rand, num_not_overlap)\n","\n","        heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","        mlps_not_ablate = [layer for layer in range(32)]\n","\n","        out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","        print(out)\n","        output_for_a_prompt.append(out)\n","    all_prompt_outputs.append(output_for_a_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_hQMSl5zygz","executionInfo":{"status":"ok","timestamp":1718403211677,"user_tz":-60,"elapsed":48687,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2382998b-a211-4ffe-cf9b-fa949eaacf59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n"]}]},{"cell_type":"code","source":["# random, len 4 (not from saved head combo presets) ; ssave all results\n","\n","all_prompt_outputs = []\n","corr_text = \"0 0 0\"\n","for clean_text in correct_prompts:\n","    clean_text = clean_text[0]\n","    output_for_a_prompt = []\n","    for i in range(10):\n","        heads_of_circ = intersect_all\n","        num_heads_rand = 4\n","        num_not_overlap = len(intersect_all)\n","\n","        all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","        # Filter out heads_of_circ from all_possible_pairs\n","        filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","        # Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","        head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, num_heads_rand, num_not_overlap)\n","\n","        heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","        mlps_not_ablate = [layer for layer in range(32)]\n","\n","        out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","        # print(out)\n","        output_for_a_prompt.append(out)\n","    print(out)\n","    all_prompt_outputs.append(output_for_a_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"id":"0H-UGAHf3jpj","executionInfo":{"status":"ok","timestamp":1718405261832,"user_tz":-60,"elapsed":227,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"deec7406-67d4-4a52-8030-6ec11b7b8894"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is March 21th, then in 16 days it will be April 6th.']\n","['<s> Be concise. If today is June 28th, then in 18 days it will be July 16th']\n","['<s> Be concise. If today is April 14th, then in 11 days it will be April 25th']\n","['<s> Be concise. If today is April 7th, then in 20 days it will be May 27th']\n","['<s> Be concise. If today is October 28th, then in 10 days it will be November 7th.']\n","['<s> Be concise. If today is May 26th, then in 5 days it will be June 1st.']\n","['<s> Be concise. If today is April 17th, then in 28 days it will be May 15th']\n","['<s> Be concise. If today is September 16th, then in 12 days it will be September 28th']\n","['<s> Be concise. If today is October 21th, then in 17 days it will be November 7th.']\n","['<s> Be concise. If today is July 12th, then in 23 days it will be August 1st.']\n","['<s> Be concise. If today is January 27th, then in 11 days it will be February 7th.']\n","['<s> Be concise. If today is May 18th, then in 18 days it will be June 6th.']\n","['<s> Be concise. If today is August 18th, then in 22 days it will be September 7th.']\n","['<s> Be concise. If today is July 26th, then in 19 days it will be August 14th']\n","['<s> Be concise. If today is February 27th, then in 28 days it will be March 26th']\n","['<s> Be concise. If today is July 23th, then in 11 days it will be August 4th.']\n","['<s> Be concise. If today is March 21th, then in 27 days it will be April 17th']\n","['<s> Be concise. If today is January 27th, then in 1 days it will be January 28th']\n","['<s> Be concise. If today is November 16th, then in 12 days it will be November 28th']\n","['<s> Be concise. If today is June 13th, then in 13 days it will be June 26th']\n","['<s> Be concise. If today is March 18th, then in 25 days it will be April 12th']\n","['<s> Be concise. If today is March 20th, then in 23 days it will be April 12th']\n","['<s> Be concise. If today is May 4th, then in 4 days it will be May 8th.']\n","['<s> Be concise. If today is April 8th, then in 19 days it will be May 1st.']\n","['<s> Be concise. If today is April 21th, then in 8 days it will be May 1st.']\n","['<s> Be concise. If today is April 11th, then in 27 days it will be May 9th.']\n","['<s> Be concise. If today is June 6th, then in 26 days it will be July 5th.']\n","['<s> Be concise. If today is November 20th, then in 1 days it will be November 21st']\n","['<s> Be concise. If today is December 17th, then in 8 days it will be December 25th']\n","['<s> Be concise. If today is May 20th, then in 16 days it will be June 5th.']\n","['<s> Be concise. If today is November 25th, then in 24 days it will be December 20th']\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_34a58dee-cf8d-4296-890a-4a5dd9715e84\", \"template_1_rand.txt\", 2725)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### debug why some ans are all 0% correct for rand"],"metadata":{"id":"cEjLwKYqB8Zb"}},{"cell_type":"markdown","source":["likely because they weren't correct even when unablated. we find they aren't; but why were they above? start anew in v3 to save these output reulsts."],"metadata":{"id":"PXIyZ_BMCAgP"}},{"cell_type":"code","source":["head_to_remove"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADiB5FbeBTVv","executionInfo":{"status":"ok","timestamp":1718406693156,"user_tz":-60,"elapsed":266,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9683f518-3a0f-4866-f2ee-e9299f0192dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(12, 9), (1, 4), (0, 17), (29, 8)]"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["clean_text = 'Be concise. If today is April 19th, then in 25 days it will be'\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Jr_bSJpBgdh","executionInfo":{"status":"ok","timestamp":1718406765966,"user_tz":-60,"elapsed":2772,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"75a2141e-fc5c-416c-8f8a-2106877225b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["clean_text = 'Be concise. If today is April 19th, then in 25 days it will be'\n","heads_not_ablate =  [(layer, head) for layer in range(32) for head in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GU3ZKBWqBolB","executionInfo":{"status":"ok","timestamp":1718406800933,"user_tz":-60,"elapsed":2750,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f903b7b6-47b5-44f5-c617-d2cc1bb2f037"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["len(correct_prompts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRH24vD1Agv3","executionInfo":{"status":"ok","timestamp":1718406487292,"user_tz":-60,"elapsed":311,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7fcdc765-0f1a-4170-c8ac-e275e5874879"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["with open('template_1_rand.txt', 'w') as f:\n","    for line in all_prompt_outputs:\n","        f.write(f\"{line}\\n\")\n","files.download('template_1_rand.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"gi_d6qCz-c3y","executionInfo":{"status":"ok","timestamp":1718405950964,"user_tz":-60,"elapsed":287,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c91e582f-b9ba-492a-f88f-dc4cc40197ad"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_bf3083d1-d29d-4921-9970-0654925b28af\", \"template_1_rand.txt\", 27601)"]},"metadata":{}}]},{"cell_type":"code","source":["clean_text = 'If today is April 19th, then in 25 days it will be'\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","prompt_out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93Eun7BCFA6B","executionInfo":{"status":"ok","timestamp":1718407693955,"user_tz":-60,"elapsed":2269,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"87fdf205-cd59-4057-c4ac-eab4a7017108"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["outputs = []\n","instruction = \"Be concise. \"\n","for clean_text in correct_prompts:\n","    # clean_text = instruction + clean_text\n","    clean_text = clean_text[0]\n","    corr_text = \"uno uno uno\" # dos tres cinco seis\n","    heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","    mlps_not_ablate = [layer for layer in range(32)]\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)\n","    outputs.append(prompt_out)\n","    print(prompt_out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWMul3loFTKr","executionInfo":{"status":"ok","timestamp":1718407846936,"user_tz":-60,"elapsed":60986,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a08f1b0e-660f-4094-b1e4-05846ca91c9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is July 23th, then in 22 days it will be August 14th']\n","['<s> Be concise. If today is April 19th, then in 25 days it will be May 13th']\n","['<s> Be concise. If today is March 21th, then in 16 days it will be April 6th.']\n","['<s> Be concise. If today is June 28th, then in 18 days it will be July 16th']\n","['<s> Be concise. If today is April 14th, then in 11 days it will be April 25th']\n","['<s> Be concise. If today is April 7th, then in 20 days it will be May 27th']\n","['<s> Be concise. If today is October 28th, then in 10 days it will be November 7th.']\n","['<s> Be concise. If today is May 26th, then in 5 days it will be June 1st.']\n","['<s> Be concise. If today is April 17th, then in 28 days it will be May 15th']\n","['<s> Be concise. If today is September 16th, then in 12 days it will be September 28th']\n","['<s> Be concise. If today is October 21th, then in 17 days it will be November 7th.']\n","['<s> Be concise. If today is July 12th, then in 23 days it will be August 1st.']\n","['<s> Be concise. If today is January 27th, then in 11 days it will be February 7th.']\n","['<s> Be concise. If today is May 18th, then in 18 days it will be June 6th.']\n","['<s> Be concise. If today is August 18th, then in 22 days it will be September 7th.']\n","['<s> Be concise. If today is July 26th, then in 19 days it will be August 15th']\n","['<s> Be concise. If today is February 27th, then in 28 days it will be March 25th']\n","['<s> Be concise. If today is July 23th, then in 11 days it will be August 4th.']\n","['<s> Be concise. If today is March 21th, then in 27 days it will be April 17th']\n","['<s> Be concise. If today is January 27th, then in 1 days it will be January 28th']\n","['<s> Be concise. If today is November 16th, then in 12 days it will be December 1st.']\n","['<s> Be concise. If today is June 13th, then in 13 days it will be June 26th']\n","['<s> Be concise. If today is March 18th, then in 25 days it will be April 12th']\n","['<s> Be concise. If today is March 20th, then in 23 days it will be April 12th']\n","['<s> Be concise. If today is May 4th, then in 4 days it will be May 8th.']\n","['<s> Be concise. If today is April 8th, then in 19 days it will be May 1st.']\n","['<s> Be concise. If today is April 21th, then in 8 days it will be May 1st.']\n","['<s> Be concise. If today is April 11th, then in 27 days it will be May 9th.']\n","['<s> Be concise. If today is June 6th, then in 26 days it will be July 6th.']\n","['<s> Be concise. If today is November 20th, then in 1 days it will be November 21st']\n","['<s> Be concise. If today is December 17th, then in 8 days it will be December 25th']\n","['<s> Be concise. If today is May 20th, then in 16 days it will be June 5th.']\n","['<s> Be concise. If today is November 25th, then in 24 days it will be December 20th']\n"]}]},{"cell_type":"markdown","source":["# If today is November 20th, then in 28 days it will be"],"metadata":{"id":"yxBV5u6GmxJm"}},{"cell_type":"code","source":["clean_text = \"Be concise.If today is November 20th, then in 28 days it will be\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 20"],"metadata":{"id":"He0WsDzsmxJt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718383050235,"user_tz":-60,"elapsed":7589,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d480befe-ee42-45c9-ea0a-f5c9536f6000","id":"cJR5vINVmxJt"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise.If today is November 20th, then in 28 days it will be December 20th.\\n\\nSo, the answer is 28 days.</s>']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718383057667,"user_tz":-60,"elapsed":7450,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"100f528e-5d08-4868-eef8-0e687d15dd09","id":"Xo4MxaJemxJu"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise.If today is November 20th, then in 28 days it will be December 1st.\\n\\nIf today is November 20th, then in ']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718383064822,"user_tz":-60,"elapsed":7191,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b6662fce-7669-4992-f1a2-d345400eb893","id":"qce33PBKmxJu"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise.If today is November 20th, then in 28 days it will be December 1sth.\\n\\nSo the answer is 8 days.</s><s> nobody']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718383073661,"user_tz":-60,"elapsed":8873,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"963c2771-bafb-459f-ccad-cfd3c994113e","id":"C9Wa89CDmxJu"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise.If today is November 20th, then in 28 days it will be December 20th.\\n\\n\\nAnswer:\\nThe answer is 28 days']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718383081438,"user_tz":-60,"elapsed":7868,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7031eabc-4bc9-4fce-e207-d09cf33fd344","id":"8ZBdeTTMmxJu"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise.If today is November 20th, then in 28 days it will be December 18th.\\n\\nAnswer:\\nThe correct answer is 28 days']\n"]}]},{"cell_type":"markdown","source":["# \"Be concise. If today is the 11th of a month, what date will it be in 6 days?”"],"metadata":{"id":"OBo0IKv80oM7"}},{"cell_type":"code","source":["clean_text = \"Be concise. If today is the 11th of a month, what date will it be in 6 days?\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 20"],"metadata":{"id":"Lil7lW9P0oM8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866548793,"user_tz":-60,"elapsed":7198,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3270e1b4-0284-4974-e8d9-a74640715022","id":"P8qvABGq0oM8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: 17th\\n\\nExplanation: If today is the ']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866556189,"user_tz":-60,"elapsed":7406,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1da6a085-29bf-4cc8-e78f-71362a250e0e","id":"RFdroLJ00oM9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: In 6 days, the date will be the 11th of']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866563599,"user_tz":-60,"elapsed":7442,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5fbedab1-5b34-4a1f-c669-2e91becb5be3","id":"SO0z5XOd0oM9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: If today is the 1st of a month, in 6 days']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717866571605,"user_tz":-60,"elapsed":8022,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b5128c53-244b-4861-f91b-08b91425c43f","id":"i9KDcTsI0oM-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\n\\n\\nAnswer: 6 days from today will be 6 days ago.\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y2g4pew42WWR","executionInfo":{"status":"ok","timestamp":1717867794437,"user_tz":-60,"elapsed":7380,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"121933f2-0e71-4f04-c607-58e832ce90ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If today is the 11th of a month, what date will it be in 6 days?\\n\\nAnswer: 17th\\n\\nExplanation: If today is the ']\n"]}]},{"cell_type":"markdown","source":["# What are the months in a year?"],"metadata":{"id":"85Iqlq_c_lQv"}},{"cell_type":"code","source":["clean_text = \"What are the months in a year? Give all of them as a list. Be concise.\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 50"],"metadata":{"id":"UEg9BhbH_lQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3mwqDRI_skN","executionInfo":{"status":"ok","timestamp":1717869700159,"user_tz":-60,"elapsed":18629,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f909a721-33a1-49f4-fec5-5c17287bec8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nThe months in a year are:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n6. June\\n7. July\\n8. August\\n9. September\\n10']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869718555,"user_tz":-60,"elapsed":18408,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"10c794e2-f9d4-4eaf-8fd1-c6b041a5b65c","id":"uk4dPlDW_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nAnswer:\\nThe months in a year are:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n6. June\\n7. July\\n8. August\\n9. September']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869735716,"user_tz":-60,"elapsed":17240,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cab28cc4-18b7-422e-e915-77b29b69db5b","id":"D5ZSEzzN_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nThe months of the year are:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n7. June\\n\\nSo there you have it, the months of the year in a']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869753486,"user_tz":-60,"elapsed":17800,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5fb6ce42-ae25-42b0-a3d8-ebc4935d1a74","id":"1YOcHosP_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nAnswer:\\nThe months in a year are:\\n\\n1. January\\n2. February\\n\\nNote: The list only includes the 124 months of the standard Gregorian calendar used in most of the world.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869770772,"user_tz":-60,"elapsed":17316,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a158e65c-7fcb-4b9d-abf0-43b9847cd059","id":"Zi_AzXVV_lQ7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\n\\nAnswer:\\nThe months of the year are:\\n\\n\\n1. January\\n2. February\\n2. February\\n3. March\\n3. April\\n3. May\\n3. August\\n3. August\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717869788511,"user_tz":-60,"elapsed":17779,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"adbcca1d-02bd-4ce2-b7bb-d4084ee2c026","id":"68BLgm07_lQ7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year? Give all of them as a list. Be concise.\\n\\nThere are 12 months in a year:\\n\\n1. January\\n2. February\\n3. March\\n4. April\\n5. May\\n6. June\\n7. July\\n8. August\\n9. September']\n"]}]},{"cell_type":"markdown","source":["# If this month is March, and 3 months pass"],"metadata":{"id":"sMhVxHdxkLVy"}},{"cell_type":"code","source":["clean_text = \"Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"P-GyzEk0kLVy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879151053,"user_tz":-60,"elapsed":3897,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2b339960-b1b8-43aa-ef90-163350fdc953","id":"-xddE8H6kLVy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  June.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879151771,"user_tz":-60,"elapsed":747,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3dd3bfee-24b0-4ecf-a41a-6858a91c6392","id":"6giMxZ2VkLVy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  June.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879153336,"user_tz":-60,"elapsed":1585,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"31ecbb79-943c-403a-854e-6b5fbbee146a","id":"wpAqC206kLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  September.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879154939,"user_tz":-60,"elapsed":1615,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"944a11cf-7c82-4d6e-bbb6-d2aba6f82057","id":"kZ_csJ_7kLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  April.']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879156698,"user_tz":-60,"elapsed":1775,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"98590f87-0cd5-450f-d214-2ae0ce0d0a0e","id":"HCFEYto_kLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  December.']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717879157583,"user_tz":-60,"elapsed":1094,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"359ebec2-ce30-4b70-d1e1-aa60734a1086","id":"u1KKDsnGkLVz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. If this month is September, and 3 months pass, what is month name is it? Answer: December. If this month is March, and 3 months pass, what month name is it? Answer:  June.']\n"]}]},{"cell_type":"markdown","source":["# What is the month that is 3 months after March?"],"metadata":{"id":"g0NSuK6dHSJU"}},{"cell_type":"code","source":["clean_text = \"Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 10"],"metadata":{"id":"D9_U_CEEHSJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921827635,"user_tz":-60,"elapsed":3976,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"281267d8-7ecd-411c-cddb-0a434401b0b4","id":"HGoCez5bHSJb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  June.\\n\\nAnswer:\\nThe month']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921832086,"user_tz":-60,"elapsed":4453,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"caaa6df7-22e3-4461-96f6-ac158d96f05d","id":"0JEZjkNWHSJc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  June.\\n\\nAnswer:\\n\\nThe']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717921835828,"user_tz":-60,"elapsed":3755,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"outputId":"5374f7e8-a62f-40a5-e63c-8695b657ad10","id":"1ZHhdpu1HSJc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  April.\\n\\nSo, the pattern is']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717921840375,"user_tz":-60,"elapsed":4555,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"NxrtIT2eHSJd","outputId":"074301ec-0d42-4bb5-ec71-8726a93410f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  April.\\n\\nAnswer:\\nMarch']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717921843817,"user_tz":-60,"elapsed":3449,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"uTeL46hoHSJe","outputId":"acbf71f4-7fca-420b-d5bb-c8d51728c962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  April. What is the month that is ']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717921848528,"user_tz":-60,"elapsed":4722,"user":{"displayName":"mike lan","userId":"00221534718597437140"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"5-OG6tCWHSJe","outputId":"47227ac9-43bb-4bd6-9143-f9c46899fb37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is the month that is 3 months after January? Answer: March. What is the month that is 3 months after March? Answer:  June.\\n\\nWhat is the month that']\n"]}]}]}