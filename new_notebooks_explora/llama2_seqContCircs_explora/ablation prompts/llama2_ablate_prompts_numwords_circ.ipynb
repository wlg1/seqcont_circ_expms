{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["DcZG9rm2IAiA","Z4iJEGh6b56v","PDP2cpaiZpPX","dsdvChbcvgp5","jtaV1q3SBHow","NzaS2VB65KcX"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3fba48ab63f748f38feae6d54777a6d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd717690f14d4a00924eb4f5c03802d9","IPY_MODEL_6a599c3a04f343b8a0d96b7f96a414d7","IPY_MODEL_5967b8d8e1584f5687ac65b6b3c063dd"],"layout":"IPY_MODEL_cc106f96c3e943c6bd57cb842e260a00"}},"dd717690f14d4a00924eb4f5c03802d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5655a32eb194ca6a5d2d00c665f8616","placeholder":"​","style":"IPY_MODEL_c77451b23df64e55b904692667118800","value":"tokenizer_config.json: 100%"}},"6a599c3a04f343b8a0d96b7f96a414d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7748080f5be144aa9ba31ab3ef44376d","max":1618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2928f1c22470411ea64ec9d50119821c","value":1618}},"5967b8d8e1584f5687ac65b6b3c063dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_472e5bffb4c74a19a310b2be7b6f63fe","placeholder":"​","style":"IPY_MODEL_e55e3245a99a4c5188ed16b6ef858fc7","value":" 1.62k/1.62k [00:00&lt;00:00, 143kB/s]"}},"cc106f96c3e943c6bd57cb842e260a00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5655a32eb194ca6a5d2d00c665f8616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c77451b23df64e55b904692667118800":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7748080f5be144aa9ba31ab3ef44376d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2928f1c22470411ea64ec9d50119821c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"472e5bffb4c74a19a310b2be7b6f63fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e55e3245a99a4c5188ed16b6ef858fc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73d6292461644dcd89c374ba116d2446":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57dee3749a4d42cc8b2a86c750ff0099","IPY_MODEL_05ff68a261e84370a83f07ce7f40c782","IPY_MODEL_8dbc07337ed3456d912e710bcc507f90"],"layout":"IPY_MODEL_b4d1bb7c08c6400ea491deb20a6f76af"}},"57dee3749a4d42cc8b2a86c750ff0099":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64848306f59545b0a3f23c38559664f6","placeholder":"​","style":"IPY_MODEL_f690ada6204d4ce79e869aa5734323b6","value":"tokenizer.model: 100%"}},"05ff68a261e84370a83f07ce7f40c782":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8765591753a2427aaebbad6d1a7aae6b","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3295cecc466d4736b8d4547567264994","value":499723}},"8dbc07337ed3456d912e710bcc507f90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ee502ee17d14664a63efbd70c9a6543","placeholder":"​","style":"IPY_MODEL_868757c51ec641a3bb7cb4b1b093ad80","value":" 500k/500k [00:00&lt;00:00, 16.9MB/s]"}},"b4d1bb7c08c6400ea491deb20a6f76af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64848306f59545b0a3f23c38559664f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f690ada6204d4ce79e869aa5734323b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8765591753a2427aaebbad6d1a7aae6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3295cecc466d4736b8d4547567264994":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ee502ee17d14664a63efbd70c9a6543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"868757c51ec641a3bb7cb4b1b093ad80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6100c6a929fc4d70aecb8f648b4ebba3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6dc2fa69572e40aa97d2813612f80425","IPY_MODEL_3d8b410a12984e5e89aee53a0370b20d","IPY_MODEL_35e422292b0f485e8dfa9f5685d6f76a"],"layout":"IPY_MODEL_db6600c73ee34fc68ba4afae0b776134"}},"6dc2fa69572e40aa97d2813612f80425":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f899828c66741ae974dd44cc2911a28","placeholder":"​","style":"IPY_MODEL_c2eba1e0cf2b463081d17bd8ac399c04","value":"special_tokens_map.json: 100%"}},"3d8b410a12984e5e89aee53a0370b20d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90c08bda917f401d855550457b990e43","max":414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9c1b37aeb744f8b87930e93edc587a2","value":414}},"35e422292b0f485e8dfa9f5685d6f76a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_577e26fb1c0e44e68b048277dc29f930","placeholder":"​","style":"IPY_MODEL_1baf5b8facb84d289d97f80359601b31","value":" 414/414 [00:00&lt;00:00, 38.4kB/s]"}},"db6600c73ee34fc68ba4afae0b776134":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f899828c66741ae974dd44cc2911a28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2eba1e0cf2b463081d17bd8ac399c04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90c08bda917f401d855550457b990e43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9c1b37aeb744f8b87930e93edc587a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"577e26fb1c0e44e68b048277dc29f930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1baf5b8facb84d289d97f80359601b31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"095125dec7dd4b0ab32c1a4f8d7bb25b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09308299df754d738586bcfb86c2af93","IPY_MODEL_d498a1157f954c9fbd1bac711dfb8197","IPY_MODEL_85f6a89cec7e4d15859073a6aba59403"],"layout":"IPY_MODEL_cac5e6a1110b49c6bfcf3b8e98cfdf22"}},"09308299df754d738586bcfb86c2af93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f0ec74602c7491cbf55f8e9408396e0","placeholder":"​","style":"IPY_MODEL_283716088c194cbe9910e0b980c57583","value":"tokenizer.json: 100%"}},"d498a1157f954c9fbd1bac711dfb8197":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af7a2463b6054a81a1608ac74aa4c383","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0747bc0d60564deeb210a7e1fa7f54ca","value":1842767}},"85f6a89cec7e4d15859073a6aba59403":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1415f03f7694e70b2afa7fa4602efb5","placeholder":"​","style":"IPY_MODEL_a7e03c6163e8491fb69368e732efb1b0","value":" 1.84M/1.84M [00:00&lt;00:00, 7.57MB/s]"}},"cac5e6a1110b49c6bfcf3b8e98cfdf22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f0ec74602c7491cbf55f8e9408396e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"283716088c194cbe9910e0b980c57583":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af7a2463b6054a81a1608ac74aa4c383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0747bc0d60564deeb210a7e1fa7f54ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1415f03f7694e70b2afa7fa4602efb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7e03c6163e8491fb69368e732efb1b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48dd101f51de4d798d8adb0809cfb5bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5defad1f9bca4831a29dc117dc698712","IPY_MODEL_1af793468d0748d58020f63f1c343e8d","IPY_MODEL_78acd3df3b484af7933abbdd7f046099"],"layout":"IPY_MODEL_d84027365a8d473ca1f0fcc3744e5f25"}},"5defad1f9bca4831a29dc117dc698712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f29316928bf84d5c9df5a7f1d2f0791a","placeholder":"​","style":"IPY_MODEL_7f2c953375714c7fbb565ef2eb76aaef","value":"config.json: 100%"}},"1af793468d0748d58020f63f1c343e8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed17cc576489470494e0e12f292b0abc","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_804411d48a4548f0a7389aad334f8840","value":614}},"78acd3df3b484af7933abbdd7f046099":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f03d7234e2d04a6bb1d85340020b1e32","placeholder":"​","style":"IPY_MODEL_5ba6d5029a3b4ad49dab4835dee85009","value":" 614/614 [00:00&lt;00:00, 57.7kB/s]"}},"d84027365a8d473ca1f0fcc3744e5f25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f29316928bf84d5c9df5a7f1d2f0791a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f2c953375714c7fbb565ef2eb76aaef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed17cc576489470494e0e12f292b0abc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"804411d48a4548f0a7389aad334f8840":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f03d7234e2d04a6bb1d85340020b1e32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ba6d5029a3b4ad49dab4835dee85009":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acb52af5bab44272a3719cbc2696c9ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d73f0e036fa4590ad73cb03bed068b6","IPY_MODEL_e0873bb97ede41f2bf6c23d779a6f1b2","IPY_MODEL_cc2ad1713e4448029e5f906fbdafbe1d"],"layout":"IPY_MODEL_aaaa4125e867456bb0661c05562b02b4"}},"7d73f0e036fa4590ad73cb03bed068b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6d3ac415ba848569754a8aa9e91496e","placeholder":"​","style":"IPY_MODEL_84381b88718a43df9cea83f27e40ad3c","value":"model.safetensors.index.json: 100%"}},"e0873bb97ede41f2bf6c23d779a6f1b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20998848772b42f784ab9178aa314a70","max":26788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49311bd3e6ff41b39fa77efc5ee5fcf8","value":26788}},"cc2ad1713e4448029e5f906fbdafbe1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d52daaefdee74888a9a30b9d11e35ea9","placeholder":"​","style":"IPY_MODEL_5a66c2903bb049f9b3a9a0c08dc96205","value":" 26.8k/26.8k [00:00&lt;00:00, 2.40MB/s]"}},"aaaa4125e867456bb0661c05562b02b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6d3ac415ba848569754a8aa9e91496e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84381b88718a43df9cea83f27e40ad3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20998848772b42f784ab9178aa314a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49311bd3e6ff41b39fa77efc5ee5fcf8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d52daaefdee74888a9a30b9d11e35ea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a66c2903bb049f9b3a9a0c08dc96205":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ac4cd68e2e640fb8cf9a76d475ed3ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77ad8fedcc264ed1862c59aaf7b8caee","IPY_MODEL_f8be2bbd5782497983c17e677db06eba","IPY_MODEL_3d994e9033804a7f97877737b74956c3"],"layout":"IPY_MODEL_70e02bf2a1ee4b49972bc638715635a5"}},"77ad8fedcc264ed1862c59aaf7b8caee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cbecad63a65443b87df072eca12a97a","placeholder":"​","style":"IPY_MODEL_1a9777160bf341878432edbf46997eac","value":"Downloading shards: 100%"}},"f8be2bbd5782497983c17e677db06eba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b62907412814349881fd4d93f9318a5","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4add8b63350c471f844bfc75ecddbbee","value":2}},"3d994e9033804a7f97877737b74956c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3a202e4b8aa4add85015058b536ff6c","placeholder":"​","style":"IPY_MODEL_c665a43546444751949bda986bb119e6","value":" 2/2 [00:45&lt;00:00, 22.24s/it]"}},"70e02bf2a1ee4b49972bc638715635a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cbecad63a65443b87df072eca12a97a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a9777160bf341878432edbf46997eac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b62907412814349881fd4d93f9318a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4add8b63350c471f844bfc75ecddbbee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3a202e4b8aa4add85015058b536ff6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c665a43546444751949bda986bb119e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcfb1cb65c094c6d839fa8ac5b3c9b7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0153224a2edc46798826750e62c10cf8","IPY_MODEL_a815f41f36194ce0a5ea26bf8db8c137","IPY_MODEL_79867be3397b430f931ffc9baea308dd"],"layout":"IPY_MODEL_541faa63af374eddb3e2e12f9c756c63"}},"0153224a2edc46798826750e62c10cf8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68ea1b40abc14a88abc3f4f6a6638b42","placeholder":"​","style":"IPY_MODEL_159698dbd926453da84c3164e6170cff","value":"model-00001-of-00002.safetensors: 100%"}},"a815f41f36194ce0a5ea26bf8db8c137":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa13f2387bf546bb997af63795dcfd8a","max":9976576152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b4ca4216eee4bcfa32875ddd980d9df","value":9976576152}},"79867be3397b430f931ffc9baea308dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dd17c34b1be4e3fbd885d7dc7cd28a2","placeholder":"​","style":"IPY_MODEL_751af8c4f9074e85b46edc62b1e82520","value":" 9.98G/9.98G [00:26&lt;00:00, 432MB/s]"}},"541faa63af374eddb3e2e12f9c756c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ea1b40abc14a88abc3f4f6a6638b42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"159698dbd926453da84c3164e6170cff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa13f2387bf546bb997af63795dcfd8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b4ca4216eee4bcfa32875ddd980d9df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5dd17c34b1be4e3fbd885d7dc7cd28a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"751af8c4f9074e85b46edc62b1e82520":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1816d2c1985c466aad73d9341cf6c12f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a1353ccb04d47c787e1b6e8072f282e","IPY_MODEL_43ed06822ba843db9b1496b094e8377c","IPY_MODEL_fb216c574f38421b8f650d8a32f05d23"],"layout":"IPY_MODEL_bb2a1337c1b540b59be863412bfb3fd8"}},"5a1353ccb04d47c787e1b6e8072f282e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3217658ea8b140d2980c14b84290248f","placeholder":"​","style":"IPY_MODEL_a3df8db224ad48bfac7653545ef68450","value":"model-00002-of-00002.safetensors: 100%"}},"43ed06822ba843db9b1496b094e8377c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46cf85c05f3f4fd3a8e043be45bdeff9","max":3500296424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27304e2178594e8da944a31998750a10","value":3500296424}},"fb216c574f38421b8f650d8a32f05d23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_325c6dea08994352849c805fe254c1e1","placeholder":"​","style":"IPY_MODEL_2dd6518ba13e49e6b7b971d6842544d1","value":" 3.50G/3.50G [00:19&lt;00:00, 221MB/s]"}},"bb2a1337c1b540b59be863412bfb3fd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3217658ea8b140d2980c14b84290248f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3df8db224ad48bfac7653545ef68450":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46cf85c05f3f4fd3a8e043be45bdeff9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27304e2178594e8da944a31998750a10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"325c6dea08994352849c805fe254c1e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dd6518ba13e49e6b7b971d6842544d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e607298cc8ac44059ea6243089b2652f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a28bf9fd3f0243698422941a6fb22507","IPY_MODEL_839ebe381d9d49cb8a7e8cb565d1ec91","IPY_MODEL_97c7360af17c4846a76eda2c94ab885d"],"layout":"IPY_MODEL_ff7b737c5dfa408cb90f96f3810ad97e"}},"a28bf9fd3f0243698422941a6fb22507":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2991009432541c4b3a635c6cb8262ef","placeholder":"​","style":"IPY_MODEL_76de4309322840b1ab2df06c0bcedf10","value":"Loading checkpoint shards: 100%"}},"839ebe381d9d49cb8a7e8cb565d1ec91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5c7b3c46cc84b198be7b1c7002712a9","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99f1da609d69452a9185192cc0818ec8","value":2}},"97c7360af17c4846a76eda2c94ab885d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa5a2b5495804a9094e3833493e0cbd1","placeholder":"​","style":"IPY_MODEL_aae46fa8b0e747e1be1618a2babf31bb","value":" 2/2 [00:04&lt;00:00,  2.30s/it]"}},"ff7b737c5dfa408cb90f96f3810ad97e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2991009432541c4b3a635c6cb8262ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76de4309322840b1ab2df06c0bcedf10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5c7b3c46cc84b198be7b1c7002712a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99f1da609d69452a9185192cc0818ec8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa5a2b5495804a9094e3833493e0cbd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aae46fa8b0e747e1be1618a2babf31bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d28a2aa3b2cd4d2c9371de71269ca4bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bec7b7dc10a49dbb93f2f6934164056","IPY_MODEL_4dbe228e7d114beb9aec63bfbb7b7ee4","IPY_MODEL_27cafae2ea1f46ccbb07c050feebc7e8"],"layout":"IPY_MODEL_aaff3cb8e8924092bde2e7b76baa6a21"}},"3bec7b7dc10a49dbb93f2f6934164056":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aed01fbe7b84eda8adaa977f7f08336","placeholder":"​","style":"IPY_MODEL_1f7c78bffdb840799c84e8c073ca8889","value":"generation_config.json: 100%"}},"4dbe228e7d114beb9aec63bfbb7b7ee4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a58d9db9dac48b4a8c217be81836982","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_468bc729060444f2afe61d7ff6561277","value":188}},"27cafae2ea1f46ccbb07c050feebc7e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05ba4e2ed7704f6394bc0aafecb50c07","placeholder":"​","style":"IPY_MODEL_7b4130b586aa4a15b6e0a83232ff8655","value":" 188/188 [00:00&lt;00:00, 11.2kB/s]"}},"aaff3cb8e8924092bde2e7b76baa6a21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aed01fbe7b84eda8adaa977f7f08336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f7c78bffdb840799c84e8c073ca8889":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a58d9db9dac48b4a8c217be81836982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"468bc729060444f2afe61d7ff6561277":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05ba4e2ed7704f6394bc0aafecb50c07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b4130b586aa4a15b6e0a83232ff8655":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f5b50fdb468431b955e46decc97411d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1b80b4e4571443a83b5e1f8cb9b28ca","IPY_MODEL_7106f2311875491c87fdf3c75cbb9bc1","IPY_MODEL_8e0cfb233d6841a182fc00180bf3caf8"],"layout":"IPY_MODEL_ee89641538af4691bffc2baa1b21fd49"}},"d1b80b4e4571443a83b5e1f8cb9b28ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbb4772b737c4776ac4651eb898c487e","placeholder":"​","style":"IPY_MODEL_7c2fa41973da4221bad5332c25be1c32","value":"100%"}},"7106f2311875491c87fdf3c75cbb9bc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd39029e3dd848d6a0e94b7e98534c82","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_666f0d4f6d9e45e481326fe7e61475eb","value":1}},"8e0cfb233d6841a182fc00180bf3caf8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_731cf984860044938009b8fd7a73bcee","placeholder":"​","style":"IPY_MODEL_1d556fcfa9f24ec48fad2a1f096b10e3","value":" 1/1 [00:01&lt;00:00,  1.51s/it]"}},"ee89641538af4691bffc2baa1b21fd49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbb4772b737c4776ac4651eb898c487e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c2fa41973da4221bad5332c25be1c32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd39029e3dd848d6a0e94b7e98534c82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"666f0d4f6d9e45e481326fe7e61475eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"731cf984860044938009b8fd7a73bcee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d556fcfa9f24ec48fad2a1f096b10e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6efc1c8c4b874075b701aeed6bc0e361":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43cd947e54fa447f825ae974c1964998","IPY_MODEL_1ff65ae0b1b145ad9f66bb6dd051e51c","IPY_MODEL_7938bd11d80848c4858a5b19476c3c10"],"layout":"IPY_MODEL_43f1ec1a90a949bb821d146a01d175e3"}},"43cd947e54fa447f825ae974c1964998":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4da8b332914544879b467b2799058614","placeholder":"​","style":"IPY_MODEL_1357b597e3384bd4a10c6e4fee2a3078","value":"  0%"}},"1ff65ae0b1b145ad9f66bb6dd051e51c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad0c908ba574e148e2ebe750e38b747","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfce859eca95404e8b00555ab76986ca","value":0}},"7938bd11d80848c4858a5b19476c3c10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c58751d442e2428994b9279ee152ee26","placeholder":"​","style":"IPY_MODEL_f0e80833db804d6d805cc53aaf047163","value":" 0/1 [00:00&lt;?, ?it/s]"}},"43f1ec1a90a949bb821d146a01d175e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4da8b332914544879b467b2799058614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1357b597e3384bd4a10c6e4fee2a3078":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad0c908ba574e148e2ebe750e38b747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfce859eca95404e8b00555ab76986ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c58751d442e2428994b9279ee152ee26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0e80833db804d6d805cc53aaf047163":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70c9fd409ae943f49aec00a93f5cdeb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9803a080953488a9e776654a66b4a85","IPY_MODEL_6bde8cc5d84e49769c7fbe039aef800b","IPY_MODEL_566e5b5ea6674a0ba4ebfd2f6d121386"],"layout":"IPY_MODEL_aecdfc258a734ecd89a83bed44abe254"}},"f9803a080953488a9e776654a66b4a85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1103005d1b5148b886d5cba2d69b837c","placeholder":"​","style":"IPY_MODEL_6c653263f2684f7b8c3f39cd26d4bd5b","value":"  0%"}},"6bde8cc5d84e49769c7fbe039aef800b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_40e8b54f4e4c47829ecef1fcaacad357","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f9b1966d18c427db58ff6da6b269ea6","value":0}},"566e5b5ea6674a0ba4ebfd2f6d121386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_946f8a983755422583f750875f20ca67","placeholder":"​","style":"IPY_MODEL_30c0ea669f2943f3a24d3e6296a04ba4","value":" 0/2 [00:00&lt;?, ?it/s]"}},"aecdfc258a734ecd89a83bed44abe254":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1103005d1b5148b886d5cba2d69b837c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c653263f2684f7b8c3f39cd26d4bd5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40e8b54f4e4c47829ecef1fcaacad357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f9b1966d18c427db58ff6da6b269ea6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"946f8a983755422583f750875f20ca67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30c0ea669f2943f3a24d3e6296a04ba4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84290bf53cdd4d0495c77eeb9e53e72a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e841fc615d234e5c8ec3e181de30a535","IPY_MODEL_754fe39c484846a7ac246902f40c1330","IPY_MODEL_ad0cc70c5bd84c789f3aeb484e774b9b"],"layout":"IPY_MODEL_51aafda9f69046bab5144ee00bfecb58"}},"e841fc615d234e5c8ec3e181de30a535":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e13a79d32b340738dc1ce7df66b7e28","placeholder":"​","style":"IPY_MODEL_ae55e53fa9144bd0b9784b01506e238a","value":"100%"}},"754fe39c484846a7ac246902f40c1330":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_21dc607a0c364ddb879b84b969cca7ee","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2923ecec3528478f9ef2412b339a8a14","value":1}},"ad0cc70c5bd84c789f3aeb484e774b9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65393c3327f64a6aaab78ff9ade9938a","placeholder":"​","style":"IPY_MODEL_a7e9e7fe93054233905fba1f22332734","value":" 1/1 [00:00&lt;00:00,  5.72it/s]"}},"51aafda9f69046bab5144ee00bfecb58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e13a79d32b340738dc1ce7df66b7e28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae55e53fa9144bd0b9784b01506e238a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21dc607a0c364ddb879b84b969cca7ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2923ecec3528478f9ef2412b339a8a14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65393c3327f64a6aaab78ff9ade9938a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7e9e7fe93054233905fba1f22332734":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"code","source":["save_files = True"],"metadata":{"id":"KSKP_OsTDki6","executionInfo":{"status":"ok","timestamp":1717081000400,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0","executionInfo":{"status":"ok","timestamp":1717081080268,"user_tz":240,"elapsed":79886,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1717081083878,"user_tz":240,"elapsed":3946,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1717081086365,"user_tz":240,"elapsed":2505,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer #, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","executionInfo":{"status":"ok","timestamp":1717081086365,"user_tz":240,"elapsed":328,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy","executionInfo":{"status":"ok","timestamp":1717081086365,"user_tz":240,"elapsed":327,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717081090264,"user_tz":240,"elapsed":4225,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8541cb07-96a1-4c51-e67d-26f8e368e50d","id":"F8TXMRL3CoPd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 909, done.\u001b[K\n","remote: Counting objects: 100% (375/375), done.\u001b[K\n","remote: Compressing objects: 100% (243/243), done.\u001b[K\n","remote: Total 909 (delta 208), reused 284 (delta 121), pack-reused 534\u001b[K\n","Receiving objects: 100% (909/909), 17.08 MiB | 9.58 MiB/s, done.\n","Resolving deltas: 100% (571/571), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","# don't improt this\n","# # from dataset import Dataset\n","\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ","executionInfo":{"status":"ok","timestamp":1717081090266,"user_tz":240,"elapsed":76,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a dict whose values are tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R","executionInfo":{"status":"ok","timestamp":1717081090266,"user_tz":240,"elapsed":75,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_longer(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text\n","        # 'text': model.to_string(tokens)[0]\n","        }\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    # for i, tok in enumerate(tokens):\n","    #     prompt_dict['S'+str(i)] = model.to_string(tok)\n","\n","    # prompt_dict = {\n","    #     'corr': '4',\n","    #     'incorr': '3',\n","    #     'text': model.to_string(tokens)[0]\n","    # }\n","    # # list_tokens = tokenizer.tokenize('1 2 3 ')\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i, tok_as_str in enumerate(tokens_as_strs):\n","    #     if tok_as_str == '▁':\n","    #         prompt_dict['S'+str(i)] = ' '\n","    #     else:\n","    #         prompt_dict['S'+str(i)] = tok_as_str\n","    prompts_list.append(prompt_dict)\n","    return prompts_list"],"metadata":{"id":"VZKVG778QYyn","executionInfo":{"status":"ok","timestamp":1717081090267,"user_tz":240,"elapsed":73,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDP2cpaiZpPX"},"source":["# Load Model"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"OGCiZUPpJUsD","executionInfo":{"status":"ok","timestamp":1717081108234,"user_tz":240,"elapsed":1299,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16785,"status":"ok","timestamp":1717081125389,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"-CocJpgjsf_M","outputId":"012b1a01-dc3d-4b0b-d76a-879abcc82cb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["3fba48ab63f748f38feae6d54777a6d4","dd717690f14d4a00924eb4f5c03802d9","6a599c3a04f343b8a0d96b7f96a414d7","5967b8d8e1584f5687ac65b6b3c063dd","cc106f96c3e943c6bd57cb842e260a00","c5655a32eb194ca6a5d2d00c665f8616","c77451b23df64e55b904692667118800","7748080f5be144aa9ba31ab3ef44376d","2928f1c22470411ea64ec9d50119821c","472e5bffb4c74a19a310b2be7b6f63fe","e55e3245a99a4c5188ed16b6ef858fc7","73d6292461644dcd89c374ba116d2446","57dee3749a4d42cc8b2a86c750ff0099","05ff68a261e84370a83f07ce7f40c782","8dbc07337ed3456d912e710bcc507f90","b4d1bb7c08c6400ea491deb20a6f76af","64848306f59545b0a3f23c38559664f6","f690ada6204d4ce79e869aa5734323b6","8765591753a2427aaebbad6d1a7aae6b","3295cecc466d4736b8d4547567264994","2ee502ee17d14664a63efbd70c9a6543","868757c51ec641a3bb7cb4b1b093ad80","6100c6a929fc4d70aecb8f648b4ebba3","6dc2fa69572e40aa97d2813612f80425","3d8b410a12984e5e89aee53a0370b20d","35e422292b0f485e8dfa9f5685d6f76a","db6600c73ee34fc68ba4afae0b776134","4f899828c66741ae974dd44cc2911a28","c2eba1e0cf2b463081d17bd8ac399c04","90c08bda917f401d855550457b990e43","e9c1b37aeb744f8b87930e93edc587a2","577e26fb1c0e44e68b048277dc29f930","1baf5b8facb84d289d97f80359601b31","095125dec7dd4b0ab32c1a4f8d7bb25b","09308299df754d738586bcfb86c2af93","d498a1157f954c9fbd1bac711dfb8197","85f6a89cec7e4d15859073a6aba59403","cac5e6a1110b49c6bfcf3b8e98cfdf22","8f0ec74602c7491cbf55f8e9408396e0","283716088c194cbe9910e0b980c57583","af7a2463b6054a81a1608ac74aa4c383","0747bc0d60564deeb210a7e1fa7f54ca","e1415f03f7694e70b2afa7fa4602efb5","a7e03c6163e8491fb69368e732efb1b0","48dd101f51de4d798d8adb0809cfb5bf","5defad1f9bca4831a29dc117dc698712","1af793468d0748d58020f63f1c343e8d","78acd3df3b484af7933abbdd7f046099","d84027365a8d473ca1f0fcc3744e5f25","f29316928bf84d5c9df5a7f1d2f0791a","7f2c953375714c7fbb565ef2eb76aaef","ed17cc576489470494e0e12f292b0abc","804411d48a4548f0a7389aad334f8840","f03d7234e2d04a6bb1d85340020b1e32","5ba6d5029a3b4ad49dab4835dee85009","acb52af5bab44272a3719cbc2696c9ff","7d73f0e036fa4590ad73cb03bed068b6","e0873bb97ede41f2bf6c23d779a6f1b2","cc2ad1713e4448029e5f906fbdafbe1d","aaaa4125e867456bb0661c05562b02b4","a6d3ac415ba848569754a8aa9e91496e","84381b88718a43df9cea83f27e40ad3c","20998848772b42f784ab9178aa314a70","49311bd3e6ff41b39fa77efc5ee5fcf8","d52daaefdee74888a9a30b9d11e35ea9","5a66c2903bb049f9b3a9a0c08dc96205","1ac4cd68e2e640fb8cf9a76d475ed3ea","77ad8fedcc264ed1862c59aaf7b8caee","f8be2bbd5782497983c17e677db06eba","3d994e9033804a7f97877737b74956c3","70e02bf2a1ee4b49972bc638715635a5","7cbecad63a65443b87df072eca12a97a","1a9777160bf341878432edbf46997eac","1b62907412814349881fd4d93f9318a5","4add8b63350c471f844bfc75ecddbbee","c3a202e4b8aa4add85015058b536ff6c","c665a43546444751949bda986bb119e6","bcfb1cb65c094c6d839fa8ac5b3c9b7f","0153224a2edc46798826750e62c10cf8","a815f41f36194ce0a5ea26bf8db8c137","79867be3397b430f931ffc9baea308dd","541faa63af374eddb3e2e12f9c756c63","68ea1b40abc14a88abc3f4f6a6638b42","159698dbd926453da84c3164e6170cff","aa13f2387bf546bb997af63795dcfd8a","6b4ca4216eee4bcfa32875ddd980d9df","5dd17c34b1be4e3fbd885d7dc7cd28a2","751af8c4f9074e85b46edc62b1e82520","1816d2c1985c466aad73d9341cf6c12f","5a1353ccb04d47c787e1b6e8072f282e","43ed06822ba843db9b1496b094e8377c","fb216c574f38421b8f650d8a32f05d23","bb2a1337c1b540b59be863412bfb3fd8","3217658ea8b140d2980c14b84290248f","a3df8db224ad48bfac7653545ef68450","46cf85c05f3f4fd3a8e043be45bdeff9","27304e2178594e8da944a31998750a10","325c6dea08994352849c805fe254c1e1","2dd6518ba13e49e6b7b971d6842544d1","e607298cc8ac44059ea6243089b2652f","a28bf9fd3f0243698422941a6fb22507","839ebe381d9d49cb8a7e8cb565d1ec91","97c7360af17c4846a76eda2c94ab885d","ff7b737c5dfa408cb90f96f3810ad97e","e2991009432541c4b3a635c6cb8262ef","76de4309322840b1ab2df06c0bcedf10","a5c7b3c46cc84b198be7b1c7002712a9","99f1da609d69452a9185192cc0818ec8","aa5a2b5495804a9094e3833493e0cbd1","aae46fa8b0e747e1be1618a2babf31bb","d28a2aa3b2cd4d2c9371de71269ca4bf","3bec7b7dc10a49dbb93f2f6934164056","4dbe228e7d114beb9aec63bfbb7b7ee4","27cafae2ea1f46ccbb07c050feebc7e8","aaff3cb8e8924092bde2e7b76baa6a21","9aed01fbe7b84eda8adaa977f7f08336","1f7c78bffdb840799c84e8c073ca8889","8a58d9db9dac48b4a8c217be81836982","468bc729060444f2afe61d7ff6561277","05ba4e2ed7704f6394bc0aafecb50c07","7b4130b586aa4a15b6e0a83232ff8655"],"height":0},"executionInfo":{"elapsed":57090,"status":"ok","timestamp":1717081182465,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"xLgpia0tI6O8","outputId":"f7bcf9b1-9634-478a-d989-474a3fb82dbd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fba48ab63f748f38feae6d54777a6d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73d6292461644dcd89c374ba116d2446"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6100c6a929fc4d70aecb8f648b4ebba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"095125dec7dd4b0ab32c1a4f8d7bb25b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48dd101f51de4d798d8adb0809cfb5bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb52af5bab44272a3719cbc2696c9ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ac4cd68e2e640fb8cf9a76d475ed3ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcfb1cb65c094c6d839fa8ac5b3c9b7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1816d2c1985c466aad73d9341cf6c12f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e607298cc8ac44059ea6243089b2652f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d28a2aa3b2cd4d2c9371de71269ca4bf"}},"metadata":{}}],"source":["LLAMA_2_7B_CHAT_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n","\n","tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH)\n","# tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH, use_fast= False, add_prefix_space= False)\n","hf_model = LlamaForCausalLM.from_pretrained(LLAMA_2_7B_CHAT_PATH, low_cpu_mem_usage=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"_rtZ2e3sMY5S","executionInfo":{"status":"ok","timestamp":1717081182465,"user_tz":240,"elapsed":291,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import transformer_lens.utils as utils\n","from transformer_lens.hook_points import HookPoint\n","from transformer_lens import HookedTransformer"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31656,"status":"ok","timestamp":1717081213831,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"sUnSHvA-Myx8","outputId":"0793fe25-3c4c-47d9-a4fd-7166d23162d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n","Moving model to device:  cuda\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    LLAMA_2_7B_CHAT_PATH,\n","    hf_model = hf_model,\n","    tokenizer = tokenizer,\n","    device = \"cpu\",\n","    fold_ln = False,\n","    center_writing_weights = False,\n","    center_unembed = False,\n",")\n","\n","del hf_model\n","\n","model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["# new ablation functions"],"metadata":{"id":"dsdvChbcvgp5"}},{"cell_type":"code","source":["def get_heads_actv_mean(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Output: The mean activations of a head's output\n","    '''\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    # for layer in range(model.cfg.n_layers):\n","    #     z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","    #     for template_group in means_dataset.groups:\n","    #         z_for_this_template = z_for_this_layer[template_group]\n","    #         z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","    #         if z_means_for_this_template.shape[0] == 5:\n","    #             pdb.set_trace()\n","    #         means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means"],"metadata":{"id":"6KlWYoEy72Cf","executionInfo":{"status":"ok","timestamp":1717081976458,"user_tz":240,"elapsed":587,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# def mask_circ_heads(\n","#     means_dataset: Dataset,\n","#     model: HookedTransformer,\n","#     circuit: Dict[str, List[Tuple[int, int]]],\n","#     seq_pos_to_keep: Dict[str, str],\n","# ) -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","#     '''\n","#     Output: for each layer, a mask of circuit components that should not be ablated\n","#     '''\n","#     heads_and_posns_to_keep = {}\n","#     batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","#     for layer in range(model.cfg.n_layers):\n","\n","#         mask = t.zeros(size=(batch, seq, n_heads))\n","\n","#         for (head_type, head_list) in circuit.items():\n","#             seq_pos = seq_pos_to_keep[head_type]\n","#             # if seq_pos == 'S7':\n","#             #     pdb.set_trace()\n","#             indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","#             for (layer_idx, head_idx) in head_list:\n","#                 if layer_idx == layer:\n","#                     # if indices.item() == 7:\n","#                     #     pdb.set_trace()\n","#                     mask[:, indices, head_idx] = 1\n","#                     # mask[:, :, head_idx] = 1  # keep L.H at all pos\n","\n","#         heads_and_posns_to_keep[layer] = mask.bool()\n","#     # pdb.set_trace()\n","#     return heads_and_posns_to_keep"],"metadata":{"id":"bFDQMOt9CyVw","executionInfo":{"status":"ok","timestamp":1717081977072,"user_tz":240,"elapsed":58,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def mask_circ_heads(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Output: for each layer, a mask of circuit components that should not be ablated\n","    '''\n","    heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","    batch, seq, n_heads = len(means_dataset), len(circuit.keys()), model.cfg.n_heads\n","    print(seq)\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    # mask[:, indices, head_idx] = 1\n","                    mask[:, :, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep"],"metadata":{"id":"E1boH1469_HI","executionInfo":{"status":"ok","timestamp":1717081977072,"user_tz":240,"elapsed":58,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def hook_func_mask_head(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    # components_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    # means: Float[Tensor, \"layer batch seq head d_head\"],\n","    circuit: Dict[str, List[Tuple[int, int]]],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Use this to not mask components\n","    '''\n","    # mask_for_this_layer = components_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","    # z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    ###\n","    # heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = z.shape[0], z.shape[1], model.cfg.n_heads  # components_to_keep[0].shape[0] is batch\n","\n","    # for layer in range(model.cfg.n_layers):\n","\n","    #     mask = t.zeros(size=(batch, seq, n_heads))\n","\n","    #     for (head_type, head_list) in circuit.items():\n","    #         # seq_pos = seq_pos_to_keep[head_type]\n","    #         # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","    #         for (layer_idx, head_idx) in head_list:\n","    #             if layer_idx == layer:\n","    #                 # mask[:, indices, head_idx] = 1\n","    #                 mask[:, :, head_idx] = 1\n","\n","    #     heads_and_posns_to_keep[layer] = mask.bool()\n","    ###\n","    mask_for_this_layer = t.zeros(size=(z.shape[0], z.shape[1], z.shape[2]))\n","    for (head_type, head_list) in circuit.items():\n","        # seq_pos = seq_pos_to_keep[head_type]\n","        # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","        for (layer_idx, head_idx) in head_list:\n","            if layer_idx == hook.layer():\n","                # mask[:, indices, head_idx] = 1\n","                mask_for_this_layer[:, :, head_idx] = 1\n","\n","    mask_for_this_layer = mask_for_this_layer.bool()\n","    mask_for_this_layer = mask_for_this_layer.unsqueeze(-1).to(z.device)  # d_model is 1; then is broadcast in where\n","\n","    z = t.where(mask_for_this_layer, z, 0)\n","\n","    return z"],"metadata":{"id":"KdxeNJ5C9tHx","executionInfo":{"status":"ok","timestamp":1717081977072,"user_tz":240,"elapsed":57,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def add_ablation_hook_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Ablate the model, except as components and positions to keep\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","    means = get_heads_actv_mean(means_dataset, model)\n","    components_to_keep = mask_circ_heads(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=circuit,\n","    )\n","\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","    return model"],"metadata":{"id":"dg3XuWScAVvG","executionInfo":{"status":"ok","timestamp":1717081977072,"user_tz":240,"elapsed":57,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# from dataset import Dataset\n","from transformer_lens import HookedTransformer, utils\n","from transformer_lens.hook_points import HookPoint\n","import einops\n","from functools import partial\n","import torch as t\n","from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool\n","\n","# from head_ablation_fns import *\n","# from mlp_ablation_fns import *\n","\n","def add_ablation_hook_MLP_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    heads_lst, mlp_lst,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        CIRCUIT['S'+str(i)] = heads_lst\n","        # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","        # if i == num_pos - 1:\n","        #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        # else:\n","        SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = get_heads_actv_mean(means_dataset, model)\n","    # Convert this into a boolean map\n","    components_to_keep = mask_circ_heads(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=CIRCUIT,\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    # if all_entries_true(components_to_keep) == False:\n","    #     pdb.set_trace()\n","    ########################\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","    # # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    # num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    # for i in range(num_pos ):\n","    #     CIRCUIT['S'+str(i)] = mlp_lst\n","    #     # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","    #     # if i == num_pos - 1:\n","    #     #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","    #     # else:\n","    #     SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    # # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    # means = get_MLPs_actv_mean(means_dataset, model)\n","\n","    # # Convert this into a boolean map\n","    # components_to_keep = mask_circ_MLPs(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # # Get a hook function which will patch in the mean z values for each head, at\n","    # # all positions which aren't important for the circuit\n","    # hook_fn = partial(\n","    #     hook_func_mask_mlp_out,\n","    #     components_to_keep=components_to_keep,\n","    #     means=means\n","    # )\n","\n","    # model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"6ILjxwH9YUYP","executionInfo":{"status":"ok","timestamp":1717081977072,"user_tz":240,"elapsed":56,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def all_entries_true(tensor_dict):\n","    for key, tensor in tensor_dict.items():\n","        if not torch.all(tensor).item():\n","            return False\n","    return True"],"metadata":{"id":"u-YuOEDieLgE","executionInfo":{"status":"ok","timestamp":1717081977072,"user_tz":240,"elapsed":56,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["# ablation fns mult tok answers"],"metadata":{"id":"jtaV1q3SBHow"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    # tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","        # if next_char == '':\n","        #     next_char = ' '\n","        # clean_text = clean_text + next_char\n","        # tokens = model.to_tokens(clean_text).to(device)\n","    return corr_ans_tokLen"],"metadata":{"id":"WgbtY5fFPb71","executionInfo":{"status":"ok","timestamp":1717081961638,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    for i in range(corr_ans_tokLen):\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        print(f\"Sequence so far: {clean_text}\")\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","        # pos_dict = {}\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())"],"metadata":{"id":"lp4MyZ52cUTK","executionInfo":{"status":"ok","timestamp":1717081962873,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["# alt ablate then gen fns"],"metadata":{"id":"EqnVfw7zBpNK"}},{"cell_type":"code","source":["# Get list of arguments to pass to `generate` (specifically these are the ones relating to sampling)\n","generate_kwargs = dict(\n","    do_sample = False, # deterministic output so we can compare it to the HF model\n","    top_p = 1.0, # suppresses annoying output errors\n","    temperature = 1.0, # suppresses annoying output errors\n",")"],"metadata":{"id":"tGwlmDu4Awuf","executionInfo":{"status":"ok","timestamp":1717081397244,"user_tz":240,"elapsed":613,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def ablate_then_gen_circ(model, generate_kwargs, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    output = model.generate(clean_text, max_new_tokens= corr_ans_tokLen, **generate_kwargs)\n","    print(output)"],"metadata":{"id":"x-6OoweYA6oT","executionInfo":{"status":"ok","timestamp":1717081397721,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## test"],"metadata":{"id":"xplS-5FUDhMG"}},{"cell_type":"code","source":["prompt =  \"January February March\"\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","output = model.generate(prompt, max_new_tokens=1, **generate_kwargs)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["7f5b50fdb468431b955e46decc97411d","d1b80b4e4571443a83b5e1f8cb9b28ca","7106f2311875491c87fdf3c75cbb9bc1","8e0cfb233d6841a182fc00180bf3caf8","ee89641538af4691bffc2baa1b21fd49","cbb4772b737c4776ac4651eb898c487e","7c2fa41973da4221bad5332c25be1c32","cd39029e3dd848d6a0e94b7e98534c82","666f0d4f6d9e45e481326fe7e61475eb","731cf984860044938009b8fd7a73bcee","1d556fcfa9f24ec48fad2a1f096b10e3"]},"id":"1Uz5HZ9UA1aJ","executionInfo":{"status":"ok","timestamp":1717081415964,"user_tz":240,"elapsed":1868,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d682169d-d748-4e94-c1aa-d23789594c6d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f5b50fdb468431b955e46decc97411d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["January February March April\n"]}]},{"cell_type":"code","source":["# tokens = model.to_tokens(clean_text).to(device)\n","# prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","corr_text = \"9 6 5\"\n","corr_tokens = model.to_tokens(corr_text).to(device)\n","prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","pos_dict = {}\n","num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","for i in range(num_pos ):\n","    pos_dict['S'+str(i)] = i\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","heads_not_ablate = []\n","mlps_not_ablate = []\n","model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)"],"metadata":{"id":"1dX25KYW-wKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt =  \"January February March\"\n","output = model.generate(prompt, max_new_tokens=1, **generate_kwargs)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["6efc1c8c4b874075b701aeed6bc0e361","43cd947e54fa447f825ae974c1964998","1ff65ae0b1b145ad9f66bb6dd051e51c","7938bd11d80848c4858a5b19476c3c10","43f1ec1a90a949bb821d146a01d175e3","4da8b332914544879b467b2799058614","1357b597e3384bd4a10c6e4fee2a3078","dad0c908ba574e148e2ebe750e38b747","cfce859eca95404e8b00555ab76986ca","c58751d442e2428994b9279ee152ee26","f0e80833db804d6d805cc53aaf047163"]},"id":"VpWB6K0BDRfc","executionInfo":{"status":"error","timestamp":1717081812191,"user_tz":240,"elapsed":659,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"972a04d7-f36f-42a6-8079-9e7054807495"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6efc1c8c4b874075b701aeed6bc0e361"}},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (7) must match the size of tensor b (4) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-268cddfaf2ec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m\"January February March\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, use_past_kv_cache, prepend_bos, padding_side, return_type, verbose)\u001b[0m\n\u001b[1;32m   2102\u001b[0m                         )\n\u001b[1;32m   2103\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m                         logits = self.forward(\n\u001b[0m\u001b[1;32m   2105\u001b[0m                             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m                             \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    548\u001b[0m                     )\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    551\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1586\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_z_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, pos, head_index, d_head]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attn_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_in_4bit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mcalculate_z_scores\u001b[0;34m(self, v, pattern)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mpattern\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch head_index query_pos key_pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     ) -> Float[torch.Tensor, \"batch query_pos head_index d_head\"]:\n\u001b[0;32m--> 764\u001b[0;31m         z = self.hook_z(\n\u001b[0m\u001b[1;32m    765\u001b[0m             einsum(\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mfull_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m     86\u001b[0m             ):  # For a backwards hook, module_output is a tuple of (grad,) - I don't know why.\n\u001b[1;32m     87\u001b[0m                 \u001b[0mmodule_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         full_hook.__name__ = (\n","\u001b[0;32m/content/seqcont_circuits/src/iter_node_pruning/head_ablation_fns.py\u001b[0m in \u001b[0;36mhook_func_mask_head\u001b[0;34m(z, hook, components_to_keep, means)\u001b[0m\n\u001b[1;32m     86\u001b[0m     '''\n\u001b[1;32m     87\u001b[0m     \u001b[0mmask_for_this_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponents_to_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_for_this_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (4) at non-singleton dimension 1"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["70c9fd409ae943f49aec00a93f5cdeb3","f9803a080953488a9e776654a66b4a85","6bde8cc5d84e49769c7fbe039aef800b","566e5b5ea6674a0ba4ebfd2f6d121386","aecdfc258a734ecd89a83bed44abe254","1103005d1b5148b886d5cba2d69b837c","6c653263f2684f7b8c3f39cd26d4bd5b","40e8b54f4e4c47829ecef1fcaacad357","1f9b1966d18c427db58ff6da6b269ea6","946f8a983755422583f750875f20ca67","30c0ea669f2943f3a24d3e6296a04ba4"],"height":353},"executionInfo":{"elapsed":22,"status":"error","timestamp":1717081799684,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"4dlDnLnesbfW","outputId":"00d00e88-74c5-4431-bd03-a263d3ab98bd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70c9fd409ae943f49aec00a93f5cdeb3"}},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (7) must match the size of tensor b (4) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-1b24e5301a33>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m\"January February March\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, use_past_kv_cache, prepend_bos, padding_side, return_type, verbose)\u001b[0m\n\u001b[1;32m   2102\u001b[0m                         )\n\u001b[1;32m   2103\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m                         logits = self.forward(\n\u001b[0m\u001b[1;32m   2105\u001b[0m                             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m                             \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    548\u001b[0m                     )\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    551\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1586\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_z_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, pos, head_index, d_head]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attn_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_in_4bit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mcalculate_z_scores\u001b[0;34m(self, v, pattern)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mpattern\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch head_index query_pos key_pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     ) -> Float[torch.Tensor, \"batch query_pos head_index d_head\"]:\n\u001b[0;32m--> 764\u001b[0;31m         z = self.hook_z(\n\u001b[0m\u001b[1;32m    765\u001b[0m             einsum(\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mfull_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m     86\u001b[0m             ):  # For a backwards hook, module_output is a tuple of (grad,) - I don't know why.\n\u001b[1;32m     87\u001b[0m                 \u001b[0mmodule_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         full_hook.__name__ = (\n","\u001b[0;32m/content/seqcont_circuits/src/iter_node_pruning/head_ablation_fns.py\u001b[0m in \u001b[0;36mhook_func_mask_head\u001b[0;34m(z, hook, components_to_keep, means)\u001b[0m\n\u001b[1;32m     86\u001b[0m     '''\n\u001b[1;32m     87\u001b[0m     \u001b[0mmask_for_this_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponents_to_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_for_this_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (4) at non-singleton dimension 1"]}],"source":["prompt =  \"January February March\"\n","output = model.generate(prompt, max_new_tokens=2, **generate_kwargs)\n","print(output)"]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","corr_ans_tokLen = 1\n","# ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)\n","ablate_then_gen_circ(model, generate_kwargs, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["84290bf53cdd4d0495c77eeb9e53e72a","e841fc615d234e5c8ec3e181de30a535","754fe39c484846a7ac246902f40c1330","ad0cc70c5bd84c789f3aeb484e774b9b","51aafda9f69046bab5144ee00bfecb58","9e13a79d32b340738dc1ce7df66b7e28","ae55e53fa9144bd0b9784b01506e238a","21dc607a0c364ddb879b84b969cca7ee","2923ecec3528478f9ef2412b339a8a14","65393c3327f64a6aaab78ff9ade9938a","a7e9e7fe93054233905fba1f22332734"]},"id":"rIybRyE9lsRL","executionInfo":{"status":"ok","timestamp":1717081780937,"user_tz":240,"elapsed":3974,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b023726a-a819-479f-fd93-f062bef2a57a"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84290bf53cdd4d0495c77eeb9e53e72a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1 2 3 \n"]}]},{"cell_type":"markdown","source":["# Define circs"],"metadata":{"id":"JPKiYdKTAMni"}},{"cell_type":"code","source":["# nw_circ = [(0, 1), (0, 4), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (1, 16), (1, 24), (1, 27), (1, 28), (2, 2), (2, 5), (2, 8), (2, 24), (2, 30), (3, 7), (3, 14), (3, 19), (3, 23), (4, 3), (5, 16), (5, 25), (6, 11), (6, 14), (7, 0), (7, 30), (8, 0), (8, 2), (8, 3), (8, 4), (8, 6), (8, 21), (8, 31), (9, 1), (9, 3), (9, 7), (9, 11), (9, 29), (9, 31), (10, 13), (10, 18), (10, 23), (10, 24), (10, 25), (10, 27), (11, 18), (11, 28), (12, 18), (12, 26), (13, 11), (13, 17), (13, 18), (13, 19), (13, 20), (13, 21), (13, 23), (14, 7), (14, 14), (15, 25), (15, 28), (16, 0), (16, 12), (16, 14), (16, 15), (16, 16), (16, 19), (16, 24), (16, 29), (17, 17), (17, 23), (17, 31), (18, 31), (19, 12), (20, 17), (27, 20), (27, 25), (27, 27), (27, 31), (28, 5), (29, 5)]\n","# in order from most impt to least based on how much changes perf when ablated\n","nw_circ = [(20, 17), (5, 25), (16, 0), (29, 5), (3, 19), (6, 11), (15, 25), (8, 0), (16, 24), (8, 4), (7, 0), (6, 14), (16, 29), (5, 16), (12, 26), (4, 3), (3, 7), (7, 30), (11, 28), (28, 5), (17, 31), (13, 11), (13, 20), (12, 18), (1, 27), (10, 13), (18, 31), (8, 6), (9, 1), (0, 4), (2, 2), (9, 11), (19, 12), (1, 16), (13, 17), (9, 7), (11, 18), (2, 24), (10, 18), (9, 31), (9, 29), (2, 30), (2, 5), (1, 24), (2, 8), (15, 28), (27, 31), (16, 14), (3, 23), (3, 14), (10, 23), (27, 20), (8, 3), (14, 7), (14, 14), (16, 15), (8, 2), (17, 17), (0, 1), (10, 27), (16, 19), (0, 8), (0, 12), (1, 28), (0, 11), (17, 23), (0, 10), (0, 6), (13, 19), (8, 31), (10, 24), (16, 12), (13, 23), (13, 21), (27, 27), (9, 3), (27, 25), (16, 16), (8, 21), (0, 7), (13, 18), (10, 25)]"],"metadata":{"id":"wzTeD-OvAOwC","executionInfo":{"status":"ok","timestamp":1717082842507,"user_tz":240,"elapsed":399,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["impt_months_heads = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])"],"metadata":{"id":"a8zrblGeHiND","executionInfo":{"status":"ok","timestamp":1717082967823,"user_tz":240,"elapsed":1317,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["# test prompts"],"metadata":{"id":"SoV872mGOVhE"}},{"cell_type":"code","source":["clean_text = \"What comes after the first step in a process? Be concise.\"\n","# corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717084833660,"user_tz":240,"elapsed":851,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"J8wf9R3xOWS_","outputId":"b9bac594-babc-4e5d-ccc3-272ed3d030ad"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the first step in a process? Be concise.<0x0A>\n","16th char = '<0x0A>'\n","Sequence so far: What comes after the first step in a process? Be concise.<0x0A>The\n","17th char = 'The'\n","Sequence so far: What comes after the first step in a process? Be concise.<0x0A>Thesecond\n","18th char = 'second'\n","Sequence so far: What comes after the first step in a process? Be concise.<0x0A>Thesecondstep\n","19th char = 'step'\n","Sequence so far: What comes after the first step in a process? Be concise.<0x0A>Thesecondstep.\n","20th char = '.'\n","Sequence so far: What comes after the first step in a process? Be concise.<0x0A>Thesecondstep.</s>\n","21th char = '</s>'\n"]}]},{"cell_type":"code","source":["clean_text = \"What comes after the second item in a list? Be concise.\"\n","# corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbECvIUMO1Dq","executionInfo":{"status":"ok","timestamp":1717084852009,"user_tz":240,"elapsed":9660,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f00111eb-12e8-4b8b-dbec-a556fe2c45d5"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A>\n","16th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>\n","17th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer\n","18th char = 'Answer'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:\n","19th char = ':'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:The\n","20th char = 'The'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethird\n","21th char = 'third'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem\n","22th char = 'item'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.\n","23th char = '.'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>\n","24th char = '</s>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>\n","25th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>What\n","26th char = 'What'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatis\n","27th char = 'is'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthe\n","28th char = 'the'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethird\n","29th char = 'third'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditem\n","30th char = 'item'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditemin\n","31th char = 'in'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthe\n","32th char = 'the'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist\n","33th char = 'list'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?\n","34th char = '?'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Be\n","35th char = 'Be'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconc\n","36th char = 'conc'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise\n","37th char = 'ise'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.\n","38th char = '.'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.<0x0A>\n","39th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.<0x0A><0x0A>\n","40th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.<0x0A><0x0A>Answer\n","41th char = 'Answer'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.<0x0A><0x0A>Answer:\n","42th char = ':'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.<0x0A><0x0A>Answer:The\n","43th char = 'The'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.<0x0A><0x0A>Answer:Thethird\n","44th char = 'third'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatisthethirditeminthelist?Beconcise.<0x0A><0x0A>Answer:Thethirditem\n","45th char = 'item'\n"]}]},{"cell_type":"code","source":["clean_text = \"What comes after the second item in a list?\"\n","# corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717084694704,"user_tz":240,"elapsed":9380,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dffb550f-90f5-42dd-e211-22313e959db0","id":"wLAULhNjOWTF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list?<0x0A>\n","12th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>\n","13th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>In\n","14th char = 'In'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Ina\n","15th char = 'a'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalist\n","16th char = 'list'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistof\n","17th char = 'of'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems\n","18th char = 'items'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,\n","19th char = ','\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,what\n","20th char = 'what'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomes\n","21th char = 'comes'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesafter\n","22th char = 'after'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesafterthe\n","23th char = 'the'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesafterthesecond\n","24th char = 'second'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem\n","25th char = 'item'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?\n","26th char = '?'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A>\n","27th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>\n","28th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>For\n","29th char = 'For'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample\n","30th char = 'example'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,\n","31th char = ','\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,in\n","32th char = 'in'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthe\n","33th char = 'the'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\n","34th char = 'list'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\"\n","35th char = '\"'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\"App\n","36th char = 'App'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\"Apple\n","37th char = 'le'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\"Apple,\n","38th char = ','\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\"Apple,Ban\n","39th char = 'Ban'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\"Apple,Banana\n","40th char = 'ana'\n","Sequence so far: What comes after the second item in a list?<0x0A><0x0A>Inalistofitems,whatcomesaftertheseconditem?<0x0A><0x0A>Forexample,inthelist\"Apple,Banana,\n","41th char = ','\n"]}]},{"cell_type":"code","source":["clean_text = \"If today is the 14th of a month, what date will it be in 10 days?\"\n","# corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRVTiPWFSU9b","executionInfo":{"status":"ok","timestamp":1717085777981,"user_tz":240,"elapsed":9977,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f2401485-7b51-47ff-88c5-a96cf85e8756"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A>\n","25th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer\n","27th char = 'Answer'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:\n","28th char = ':'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:If\n","29th char = 'If'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftoday\n","30th char = 'today'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayis\n","31th char = 'is'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe\n","32th char = 'the'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe \n","33th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 1\n","34th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14\n","35th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14th\n","36th char = 'th'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thof\n","37th char = 'of'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofa\n","38th char = 'a'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth\n","39th char = 'month'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,\n","40th char = ','\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in\n","41th char = 'in'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in \n","42th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 1\n","43th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10\n","44th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10days\n","45th char = 'days'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysit\n","46th char = 'it'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwill\n","47th char = 'will'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbe\n","48th char = 'be'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe\n","49th char = 'the'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe \n","50th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 2\n","51th char = '2'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24\n","52th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24th\n","53th char = 'th'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thof\n","54th char = 'of'\n"]}]},{"cell_type":"markdown","source":["# 1 2 3 genr ablation expms"],"metadata":{"id":"H5H-d2URUSVJ"}},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"id":"rseVgwqtjnCc","executionInfo":{"status":"ok","timestamp":1717083762027,"user_tz":240,"elapsed":513,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"ljNX9lNhluyZ"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","corr_ans_tokLen = 3\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGTEU_MRECN2","executionInfo":{"status":"ok","timestamp":1717082025864,"user_tz":240,"elapsed":1317,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1d60f6ee-5223-4a9c-e5d5-77b525d537d6"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 4\n","9th char = '4'\n","Sequence so far: 1 2 3 4 \n","10th char = ' '\n"]}]},{"cell_type":"markdown","source":["## ablate circ"],"metadata":{"id":"clfcYAtXIPia"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717082052358,"user_tz":240,"elapsed":1834,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"50837617-0e96-4a22-f97d-a6128b4efbfc","id":"HYIdJj637K7f"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 1\n","9th char = '1'\n","Sequence so far: 1 2 3 1 \n","10th char = ' '\n"]}]},{"cell_type":"markdown","source":["## top nw circ heads"],"metadata":{"id":"XVqr9ezfHRAj"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:10]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TuWmMzGHSYA","executionInfo":{"status":"ok","timestamp":1717083776924,"user_tz":240,"elapsed":3053,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"867ad013-90ea-4ea7-ba90-662133c51b83"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 4\n","9th char = '4'\n","Sequence so far: 1 2 3 4 \n","10th char = ' '\n","Sequence so far: 1 2 3 4 5\n","11th char = '5'\n","Sequence so far: 1 2 3 4 5 \n","12th char = ' '\n","Sequence so far: 1 2 3 4 5 6\n","13th char = '6'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:20]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717083783385,"user_tz":240,"elapsed":2873,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4114e883-2510-42f3-db83-44228ce32d7d","id":"AM62T3HQKs4z"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 4\n","9th char = '4'\n","Sequence so far: 1 2 3 4 \n","10th char = ' '\n","Sequence so far: 1 2 3 4 1\n","11th char = '1'\n","Sequence so far: 1 2 3 4 1 \n","12th char = ' '\n","Sequence so far: 1 2 3 4 1 2\n","13th char = '2'\n"]}]},{"cell_type":"markdown","source":["## top nwcirc + impt month heads"],"metadata":{"id":"flRU1Ze8nRGB"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = nw_circ[:10]\n","head_to_remove_months = impt_months_heads[:20]\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ta_8DYXXnTTE","executionInfo":{"status":"ok","timestamp":1717082982042,"user_tz":240,"elapsed":4065,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"89798ae9-9abd-4130-f447-184a4d72bd3d"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 4\n","9th char = '4'\n","Sequence so far: 1 2 3 4 \n","10th char = ' '\n","Sequence so far: 1 2 3 4 5\n","11th char = '5'\n","Sequence so far: 1 2 3 4 5 \n","12th char = ' '\n","Sequence so far: 1 2 3 4 5 6\n","13th char = '6'\n","Sequence so far: 1 2 3 4 5 6 \n","14th char = ' '\n","Sequence so far: 1 2 3 4 5 6 7\n","15th char = '7'\n","Sequence so far: 1 2 3 4 5 6 7 \n","16th char = ' '\n","Sequence so far: 1 2 3 4 5 6 7 8\n","17th char = '8'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = nw_circ[:20]\n","head_to_remove_months = impt_months_heads[:20]\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9tBWnhDH3Ol","executionInfo":{"status":"ok","timestamp":1717083020997,"user_tz":240,"elapsed":6061,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d746a446-2181-4e9a-b844-ab0306dcc031"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 1\n","9th char = '1'\n","Sequence so far: 1 2 3 1 \n","10th char = ' '\n","Sequence so far: 1 2 3 1 2\n","11th char = '2'\n","Sequence so far: 1 2 3 1 2 \n","12th char = ' '\n","Sequence so far: 1 2 3 1 2 3\n","13th char = '3'\n","Sequence so far: 1 2 3 1 2 3 \n","14th char = ' '\n","Sequence so far: 1 2 3 1 2 3 1\n","15th char = '1'\n","Sequence so far: 1 2 3 1 2 3 1 \n","16th char = ' '\n","Sequence so far: 1 2 3 1 2 3 1 2\n","17th char = '2'\n"]}]},{"cell_type":"markdown","source":["# 2 4 6"],"metadata":{"id":"TbpxQ1mM54P_"}},{"cell_type":"code","source":["clean_text = \"2 4 6\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"id":"ADEXAK1755ah","executionInfo":{"status":"ok","timestamp":1717083868292,"user_tz":240,"elapsed":30,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":["## ablate circ"],"metadata":{"id":"ftNOVhVdIct8"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717083176261,"user_tz":240,"elapsed":707,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0cc009ba-5252-4be9-849a-a2a0de17b44e","id":"vS0nuqrJIct8"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 2\n","9th char = '2'\n","Sequence so far: 2 4 6 2 \n","10th char = ' '\n"]}]},{"cell_type":"markdown","source":["## top nw circ heads"],"metadata":{"id":"bLMWnLaPIct8"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:10]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717083873960,"user_tz":240,"elapsed":2167,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e9597eda-af92-4b5e-b900-3ef20982b18e","id":"19iyV8h2Ict9"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n","Sequence so far: 2 4 6 8 1\n","11th char = '1'\n","Sequence so far: 2 4 6 8 10\n","12th char = '0'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:15]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"311brYM2LGFm","executionInfo":{"status":"ok","timestamp":1717083876763,"user_tz":240,"elapsed":2816,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b0fcbe37-3925-402e-bd51-f1f7610cada3"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 1\n","9th char = '1'\n","Sequence so far: 2 4 6 10\n","10th char = '0'\n","Sequence so far: 2 4 6 10 \n","11th char = ' '\n","Sequence so far: 2 4 6 10 1\n","12th char = '1'\n","Sequence so far: 2 4 6 10 10\n","13th char = '0'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:20]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMBMDR3nKjJa","executionInfo":{"status":"ok","timestamp":1717083879927,"user_tz":240,"elapsed":3183,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4900dfc2-abe8-4d00-bdf7-ddd08bf5c331"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 1\n","9th char = '1'\n","Sequence so far: 2 4 6 1 \n","10th char = ' '\n","Sequence so far: 2 4 6 1 3\n","11th char = '3'\n","Sequence so far: 2 4 6 1 3 \n","12th char = ' '\n","Sequence so far: 2 4 6 1 3 1\n","13th char = '1'\n"]}]},{"cell_type":"markdown","source":["## top nwcirc + impt month heads"],"metadata":{"id":"myUPuhIuIct9"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = nw_circ[:10]\n","head_to_remove_months = impt_months_heads[:20]\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717083182241,"user_tz":240,"elapsed":3990,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"00a0164f-7e90-4b2d-cabd-2b74f0f8b34f","id":"FBtBE7mXIct9"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 4\n","9th char = '4'\n","Sequence so far: 2 4 6 4 \n","10th char = ' '\n","Sequence so far: 2 4 6 4 6\n","11th char = '6'\n","Sequence so far: 2 4 6 4 6 \n","12th char = ' '\n","Sequence so far: 2 4 6 4 6 6\n","13th char = '6'\n","Sequence so far: 2 4 6 4 6 6 \n","14th char = ' '\n","Sequence so far: 2 4 6 4 6 6 6\n","15th char = '6'\n","Sequence so far: 2 4 6 4 6 6 6 \n","16th char = ' '\n","Sequence so far: 2 4 6 4 6 6 6 6\n","17th char = '6'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = nw_circ[:20]\n","head_to_remove_months = impt_months_heads[:20]\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717083186388,"user_tz":240,"elapsed":4175,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"76ea3ade-a1d3-4d85-9b0b-0cc9bf80c7df","id":"Fvx3LLBFIct9"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 6\n","9th char = '6'\n","Sequence so far: 2 4 6 6 \n","10th char = ' '\n","Sequence so far: 2 4 6 6 6\n","11th char = '6'\n","Sequence so far: 2 4 6 6 6 \n","12th char = ' '\n","Sequence so far: 2 4 6 6 6 6\n","13th char = '6'\n","Sequence so far: 2 4 6 6 6 6 \n","14th char = ' '\n","Sequence so far: 2 4 6 6 6 6 6\n","15th char = '6'\n","Sequence so far: 2 4 6 6 6 6 6 \n","16th char = ' '\n","Sequence so far: 2 4 6 6 6 6 6 6\n","17th char = '6'\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"uCCZsKF7n6A9"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717083189083,"user_tz":240,"elapsed":2717,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b92949b3-15f5-4fca-8329-a4aaca74d87a","id":"_6SS5qR9n6A-"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n","Sequence so far: 2 4 6 8 1\n","11th char = '1'\n","Sequence so far: 2 4 6 8 10\n","12th char = '0'\n"]}]},{"cell_type":"markdown","source":["# uno dos tres"],"metadata":{"id":"hLripymZ7Abw"}},{"cell_type":"code","source":["clean_text = \"uno dos tres\"\n","corr_text = \"uno uno uno\" # dos tres cinco seis"],"metadata":{"id":"8mLfznIJ7Abx","executionInfo":{"status":"ok","timestamp":1717083992434,"user_tz":240,"elapsed":819,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"HUYu7tgJ7Abx"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716944199791,"user_tz":240,"elapsed":3128,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3d1d55c4-44a0-49f2-8ec4-9deb7e1f3f34","id":"bopREsqO7Abx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocincoseis\n","7th char = 'seis'\n","Sequence so far: uno dos trescuatrocincoseisseven\n","8th char = 'seven'\n","Sequence so far: uno dos trescuatrocincoseisseveneight\n","9th char = 'eight'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnine\n","10th char = 'nine'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineten\n","11th char = 'ten'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineteneleven\n","12th char = 'eleven'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineteneleventwelve\n","13th char = 'twelve'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineteneleventwelveth\n","14th char = 'th'\n"]}]},{"cell_type":"markdown","source":["## ablate circ"],"metadata":{"id":"ZPuf-hbiLnKX"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717084004711,"user_tz":240,"elapsed":1249,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"087a6c82-ddce-4a59-8683-fc8af9f9200a","id":"lbLKslLeLnKX"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n"]}]},{"cell_type":"markdown","source":["## top nw circ heads"],"metadata":{"id":"7SrRK-L6LnKY"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:10]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717084000078,"user_tz":240,"elapsed":2478,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7a286526-af10-4965-fcdb-15604d3fe03e","id":"JmyuhoN8LnKZ"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n"]}]},{"cell_type":"markdown","source":["## random 1"],"metadata":{"id":"UOTP8Pr40Ymp"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 1)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKeCQHHf0YHH","executionInfo":{"status":"ok","timestamp":1716943703212,"user_tz":240,"elapsed":2390,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"315fd80b-d8ad-42de-8f75-fb74b5866755"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocinco<0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 1)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bp8XZjY-1pVt","executionInfo":{"status":"ok","timestamp":1716944021522,"user_tz":240,"elapsed":2611,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e3afe18-937f-4e48-da69-1aee079b7b25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocincosix\n","7th char = 'six'\n","Sequence so far: uno dos trescuatrocincosixseven\n","8th char = 'seven'\n","Sequence so far: uno dos trescuatrocincosixseveneight\n","9th char = 'eight'\n","Sequence so far: uno dos trescuatrocincosixseveneightnine\n","10th char = 'nine'\n"]}]},{"cell_type":"markdown","source":["## random 10"],"metadata":{"id":"Ob3yJZRG1nOT"}},{"cell_type":"code","source":["# Function to randomly choose 50 pairs ensuring less than 10 overlap with heads_of_circ\n","def choose_heads_to_remove(filtered_pairs, heads_of_circ, num_pairs=50, max_overlap=10):\n","    while True:\n","        head_to_remove = random.sample(filtered_pairs, num_pairs)\n","        overlap_count = len([head for head in head_to_remove if head in heads_of_circ])\n","        if overlap_count < max_overlap:\n","            return head_to_remove"],"metadata":{"id":"t4fEsjaL3bce","executionInfo":{"status":"ok","timestamp":1717084384089,"user_tz":240,"elapsed":1866,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","heads_of_circ = nw_circ\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 10 pairs ensuring less than 10 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 10, 10)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VPLLSll3ZyA","executionInfo":{"status":"ok","timestamp":1717084453012,"user_tz":240,"elapsed":1700,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0e9a0053-185d-4317-9256-f0797cc310ff"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocinco<0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 10)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrQuYhqP0dDv","executionInfo":{"status":"ok","timestamp":1717084133195,"user_tz":240,"elapsed":2783,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ad63ac4f-ec91-43e4-cba2-31bd5fa66adb"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["head_to_remove"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umBLB-BA2wvi","executionInfo":{"status":"ok","timestamp":1717084141166,"user_tz":240,"elapsed":2941,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c034ddbe-c478-4f5a-d2b6-eab108aa1987"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(26, 2),\n"," (31, 27),\n"," (28, 7),\n"," (31, 30),\n"," (13, 7),\n"," (3, 18),\n"," (2, 6),\n"," (5, 24),\n"," (16, 20),\n"," (14, 23)]"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["top50_1234 = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","overlap = list(set(top50_1234) & set(head_to_remove))\n","overlap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOxlBwFX3BxV","executionInfo":{"status":"ok","timestamp":1717084142509,"user_tz":240,"elapsed":24,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ae3eeb09-6966-47d4-f4d2-4f16f8f70283"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(26, 2)]"]},"metadata":{},"execution_count":77}]},{"cell_type":"markdown","source":["# \"What comes after the second item in a list? Be concise.”"],"metadata":{"id":"uIkGANVZNp4_"}},{"cell_type":"code","source":["clean_text = \"What comes after the second item in a list? Be concise.\"\n","# corr_text = \"uno uno uno\" # dos tres cinco seis\n","num_toks_gen = 10"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717084928277,"user_tz":240,"elapsed":762,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"1wPK8YNfNp5G"},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"YYi6AmbZNp5H"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","num_toks_gen = 6\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717084933047,"user_tz":240,"elapsed":1644,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"365372d4-23f1-4177-aca1-3519c60046c7","id":"0pFcL9UONp5H"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A>\n","16th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>\n","17th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer\n","18th char = 'Answer'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:\n","19th char = ':'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:The\n","20th char = 'The'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethird\n","21th char = 'third'\n"]}]},{"cell_type":"markdown","source":["## ablate circ"],"metadata":{"id":"K5dKMZGANp5H"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","num_toks_gen = 30\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717084993779,"user_tz":240,"elapsed":8777,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"085129db-8026-45a7-92c1-52f3fd739e57","id":"4NE4Exs5Np5H"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A>\n","16th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>\n","17th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer\n","18th char = 'Answer'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:\n","19th char = ':'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:The\n","20th char = 'The'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenext\n","21th char = 'next'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextitem\n","22th char = 'item'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextitemin\n","23th char = 'in'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextitemina\n","24th char = 'a'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalist\n","25th char = 'list'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalistis\n","26th char = 'is'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypically\n","27th char = 'typically'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenoted\n","28th char = 'denoted'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedby\n","29th char = 'by'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbya\n","30th char = 'a'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma\n","31th char = 'comma'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\n","32th char = '('\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\n","33th char = '\",'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")\n","34th char = '\")'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followed\n","35th char = 'followed'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedby\n","36th char = 'by'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythe\n","37th char = 'the'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenext\n","38th char = 'next'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenextitem\n","39th char = 'item'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenextitemin\n","40th char = 'in'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenextiteminthe\n","41th char = 'the'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenextiteminthelist\n","42th char = 'list'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenextiteminthelist.\n","43th char = '.'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenextiteminthelist.For\n","44th char = 'For'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thenextiteminalististypicallydenotedbyacomma(\",\")followedbythenextiteminthelist.Forexample\n","45th char = 'example'\n"]}]},{"cell_type":"markdown","source":["## top nw circ heads"],"metadata":{"id":"h6rRtQSwNp5H"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:10]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 30\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085102141,"user_tz":240,"elapsed":9012,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fd78c344-3717-41d9-aaa2-297d0f1732a1","id":"dF8bETokNp5H"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A>\n","16th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>\n","17th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer\n","18th char = 'Answer'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:\n","19th char = ':'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:The\n","20th char = 'The'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethird\n","21th char = 'third'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem\n","22th char = 'item'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.\n","23th char = '.'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>\n","24th char = '</s>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>\n","25th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>What\n","26th char = 'What'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomes\n","27th char = 'comes'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafter\n","28th char = 'after'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthe\n","29th char = 'the'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethird\n","30th char = 'third'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditem\n","31th char = 'item'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditemin\n","32th char = 'in'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditemina\n","33th char = 'a'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist\n","34th char = 'list'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?\n","35th char = '?'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Be\n","36th char = 'Be'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconc\n","37th char = 'conc'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise\n","38th char = 'ise'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise.\n","39th char = '.'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise.<0x0A>\n","40th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise.<0x0A><0x0A>\n","41th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise.<0x0A><0x0A>Answer\n","42th char = 'Answer'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise.<0x0A><0x0A>Answer:\n","43th char = ':'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise.<0x0A><0x0A>Answer:The\n","44th char = 'The'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s><0x0A>Whatcomesafterthethirditeminalist?Beconcise.<0x0A><0x0A>Answer:Thefourth\n","45th char = 'fourth'\n"]}]},{"cell_type":"markdown","source":["## random 10"],"metadata":{"id":"G8L9w2A2Np5I"}},{"cell_type":"code","source":["# Function to randomly choose 50 pairs ensuring less than 10 overlap with heads_of_circ\n","def choose_heads_to_remove(filtered_pairs, heads_of_circ, num_pairs=50, max_overlap=10):\n","    while True:\n","        head_to_remove = random.sample(filtered_pairs, num_pairs)\n","        overlap_count = len([head for head in head_to_remove if head in heads_of_circ])\n","        if overlap_count < max_overlap:\n","            return head_to_remove"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717085194792,"user_tz":240,"elapsed":178,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"eMOjbBdWNp5I"},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","heads_of_circ = nw_circ\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 10 pairs ensuring less than 10 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 10, 10)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 30\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085202746,"user_tz":240,"elapsed":8131,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"79555185-0061-4913-cb18-63314565d74f","id":"2pSP-iWQNp5I"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A>\n","16th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>\n","17th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer\n","18th char = 'Answer'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:\n","19th char = ':'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:The\n","20th char = 'The'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethird\n","21th char = 'third'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem\n","22th char = 'item'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.\n","23th char = '.'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>\n","24th char = '</s>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s\n","25th char = 's'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>\n","26th char = '</s>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>s\n","27th char = 's'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales\n","28th char = 'ales'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@\n","29th char = '@'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@m\n","30th char = 'm'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mym\n","31th char = 'ym'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymed\n","32th char = 'ed'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedical\n","33th char = 'ical'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalb\n","34th char = 'b'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling\n","35th char = 'illing'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.\n","36th char = '.'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com\n","37th char = 'com'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>\n","38th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>My\n","39th char = 'My'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>MyMedical\n","40th char = 'Medical'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>MyMedicalBill\n","41th char = 'Bill'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>MyMedicalBilling\n","42th char = 'ing'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>MyMedicalBilling<0x0A>\n","43th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>MyMedicalBilling<0x0A>Med\n","44th char = 'Med'\n","Sequence so far: What comes after the second item in a list? Be concise.<0x0A><0x0A>Answer:Thethirditem.</s>s</s>sales@mymedicalbilling.com<0x0A>MyMedicalBilling<0x0A>Medical\n","45th char = 'ical'\n"]}]},{"cell_type":"markdown","source":["# \"What comes after the second item in a list? The next item in a list is the”"],"metadata":{"id":"jAnn3KWKQQfL"}},{"cell_type":"code","source":["clean_text = \"What comes after the second item in a list? The next item in a list is the\"\n","# corr_text = \"uno uno uno\" # dos tres cinco seis\n","num_toks_gen = 10"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717085263265,"user_tz":240,"elapsed":221,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"TahZyaimQQfR"},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"wRuAnX2GQQfR"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","num_toks_gen = 6\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085268132,"user_tz":240,"elapsed":208,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2f6afc54-62ef-4928-ab7d-19ae8eba454f","id":"41x-WZgFQQfR"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethird\n","20th char = 'third'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem\n","21th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.\n","22th char = '.'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A>\n","23th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>\n","24th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>What\n","25th char = 'What'\n"]}]},{"cell_type":"markdown","source":["## ablate circ"],"metadata":{"id":"Ur5_QGnzQQfS"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","num_toks_gen = 30\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085279321,"user_tz":240,"elapsed":11393,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dcf35389-2b85-4a1e-d8fc-10944604b9bf","id":"O1n1xD53QQfS"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirst\n","20th char = 'first'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstitem\n","21th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstitemin\n","22th char = 'in'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthe\n","23th char = 'the'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist\n","24th char = 'list'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.\n","25th char = '.'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>\n","27th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So\n","28th char = 'So'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,\n","29th char = ','\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,the\n","30th char = 'the'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theanswer\n","31th char = 'answer'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris\n","32th char = 'is'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:\n","33th char = ':'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A>\n","34th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>\n","35th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>The\n","36th char = 'The'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirst\n","37th char = 'first'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstitem\n","38th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstitemin\n","39th char = 'in'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthe\n","40th char = 'the'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist\n","41th char = 'list'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.\n","42th char = '.'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.</s>\n","43th char = '</s>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.</s><0x0A>\n","44th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.</s><0x0A>import\n","45th char = 'import'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.</s><0x0A>importnumpy\n","46th char = 'numpy'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.</s><0x0A>importnumpyas\n","47th char = 'as'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.</s><0x0A>importnumpyasnp\n","48th char = 'np'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thefirstiteminthelist.<0x0A><0x0A>So,theansweris:<0x0A><0x0A>Thefirstiteminthelist.</s><0x0A>importnumpyasnp<0x0A>\n","49th char = '<0x0A>'\n"]}]},{"cell_type":"markdown","source":["## top nw circ heads"],"metadata":{"id":"N03Dzq4FQQfS"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:10]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 30\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085286971,"user_tz":240,"elapsed":9203,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6197cd09-2e76-4dd1-90a4-12762a94a0d9","id":"uo4gucfpQQfS"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethird\n","20th char = 'third'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem\n","21th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.\n","22th char = '.'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A>\n","23th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>\n","24th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>What\n","25th char = 'What'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomes\n","26th char = 'comes'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafter\n","27th char = 'after'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthe\n","28th char = 'the'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethird\n","29th char = 'third'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditem\n","30th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditemin\n","31th char = 'in'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditemina\n","32th char = 'a'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist\n","33th char = 'list'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?\n","34th char = '?'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?The\n","35th char = 'The'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenext\n","36th char = 'next'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextitem\n","37th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextitemin\n","38th char = 'in'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextitemina\n","39th char = 'a'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalist\n","40th char = 'list'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalistis\n","41th char = 'is'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhe\n","42th char = 'the'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourth\n","43th char = 'fourth'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem\n","44th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.\n","45th char = '.'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A>\n","46th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A><0x0A>\n","47th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A><0x0A>What\n","48th char = 'What'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A><0x0A>Whatcomes\n","49th char = 'comes'\n"]}]},{"cell_type":"markdown","source":["## random 10"],"metadata":{"id":"pd4GAIYlQQfS"}},{"cell_type":"code","source":["# Function to randomly choose 50 pairs ensuring less than 10 overlap with heads_of_circ\n","def choose_heads_to_remove(filtered_pairs, heads_of_circ, num_pairs=50, max_overlap=10):\n","    while True:\n","        head_to_remove = random.sample(filtered_pairs, num_pairs)\n","        overlap_count = len([head for head in head_to_remove if head in heads_of_circ])\n","        if overlap_count < max_overlap:\n","            return head_to_remove"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717085286971,"user_tz":240,"elapsed":50,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"IkH7jj-oQQfS"},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","heads_of_circ = nw_circ\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 10 pairs ensuring less than 10 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 10, 10)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 30\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085293997,"user_tz":240,"elapsed":7075,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ddc5befa-ffa1-4103-ee1b-1cbee7dc13ee","id":"BfY82BxwQQfS"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethird\n","20th char = 'third'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem\n","21th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.\n","22th char = '.'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A>\n","23th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>\n","24th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>What\n","25th char = 'What'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomes\n","26th char = 'comes'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafter\n","27th char = 'after'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthe\n","28th char = 'the'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethird\n","29th char = 'third'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditem\n","30th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditemin\n","31th char = 'in'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditemina\n","32th char = 'a'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist\n","33th char = 'list'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?\n","34th char = '?'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?The\n","35th char = 'The'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenext\n","36th char = 'next'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextitem\n","37th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextitemin\n","38th char = 'in'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextitemina\n","39th char = 'a'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalist\n","40th char = 'list'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalistis\n","41th char = 'is'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhe\n","42th char = 'the'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourth\n","43th char = 'fourth'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem\n","44th char = 'item'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.\n","45th char = '.'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A>\n","46th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A><0x0A>\n","47th char = '<0x0A>'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A><0x0A>What\n","48th char = 'What'\n","Sequence so far: What comes after the second item in a list? The next item in a list is thethirditem.<0x0A><0x0A>Whatcomesafterthethirditeminalist?Thenextiteminalististhefourthitem.<0x0A><0x0A>Whatcomes\n","49th char = 'comes'\n"]}]},{"cell_type":"markdown","source":["# \"If today is the 14th of a month, what date will it be in 10 days?”"],"metadata":{"id":"dsMwdQXwSm95"}},{"cell_type":"code","source":["clean_text = \"If today is the 14th of a month, what date will it be in 10 days?\"\n","# corr_text = \"uno uno uno\" # dos tres cinco seis\n","num_toks_gen = 10"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717085862484,"user_tz":240,"elapsed":1135,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"jhWaI8wXSm-E"},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"C1aGMdWYSm-E"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","num_toks_gen = 6\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085864387,"user_tz":240,"elapsed":1917,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e6248b1c-41c5-47eb-ee8e-4d1797fa734f","id":"CL6RXdPSSm-E"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A>\n","25th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer\n","27th char = 'Answer'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:\n","28th char = ':'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:If\n","29th char = 'If'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftoday\n","30th char = 'today'\n"]}]},{"cell_type":"markdown","source":["## ablate circ"],"metadata":{"id":"V3cjjEbuSm-F"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","num_toks_gen = 30\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085872539,"user_tz":240,"elapsed":8166,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b9bfb8f5-a783-4801-8274-bb656bc4f9a0","id":"yDaWJCS0Sm-F"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s>\n","25th char = '</s>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ\n","27th char = 'Љ'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�\n","28th char = '�'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A>\n","29th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>\n","30th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>The\n","31th char = 'The'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theanswer\n","32th char = 'answer'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris\n","33th char = 'is'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris \n","34th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 0\n","35th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04\n","36th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-\n","37th char = '-'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-0\n","38th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04\n","39th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-\n","40th char = '-'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2\n","41th char = '2'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-20\n","42th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-201\n","43th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012\n","44th char = '2'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.\n","45th char = '.'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A>\n","46th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>\n","47th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>Note\n","48th char = 'Note'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>Note:\n","49th char = ':'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>Note:The\n","50th char = 'The'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>Note:Thedate\n","51th char = 'date'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>Note:Thedateformat\n","52th char = 'format'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>Note:Thedateformatis\n","53th char = 'is'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?</s><0x0A>Љ�<0x0A><0x0A>Theansweris 04-04-2012.<0x0A><0x0A>Note:Thedateformatisin\n","54th char = 'in'\n"]}]},{"cell_type":"markdown","source":["## top nw circ heads"],"metadata":{"id":"rLGFugs9Sm-F"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ[:10]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 30\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085882531,"user_tz":240,"elapsed":10194,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c0dd0322-7ff3-4789-ad63-6353d19dc18e","id":"on0sN-8sSm-F"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A>\n","25th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer\n","27th char = 'Answer'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:\n","28th char = ':'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:If\n","29th char = 'If'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftoday\n","30th char = 'today'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayis\n","31th char = 'is'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe\n","32th char = 'the'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe \n","33th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 1\n","34th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14\n","35th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14th\n","36th char = 'th'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thof\n","37th char = 'of'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofa\n","38th char = 'a'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth\n","39th char = 'month'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,\n","40th char = ','\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in\n","41th char = 'in'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in \n","42th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 1\n","43th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10\n","44th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10days\n","45th char = 'days'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysit\n","46th char = 'it'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwill\n","47th char = 'will'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbe\n","48th char = 'be'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe\n","49th char = 'the'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe \n","50th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 2\n","51th char = '2'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24\n","52th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24th\n","53th char = 'th'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thof\n","54th char = 'of'\n"]}]},{"cell_type":"markdown","source":["## random 10"],"metadata":{"id":"FsVEQ9HPSm-G"}},{"cell_type":"code","source":["# Function to randomly choose 50 pairs ensuring less than 10 overlap with heads_of_circ\n","def choose_heads_to_remove(filtered_pairs, heads_of_circ, num_pairs=50, max_overlap=10):\n","    while True:\n","        head_to_remove = random.sample(filtered_pairs, num_pairs)\n","        overlap_count = len([head for head in head_to_remove if head in heads_of_circ])\n","        if overlap_count < max_overlap:\n","            return head_to_remove"],"metadata":{"executionInfo":{"status":"ok","timestamp":1717085882531,"user_tz":240,"elapsed":89,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"S8KYb2BBSm-G"},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","heads_of_circ = nw_circ\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 10 pairs ensuring less than 10 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 10, 10)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","num_toks_gen = 50\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717085928994,"user_tz":240,"elapsed":15440,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fbf93174-6775-4d91-fa71-13681b1d0e93","id":"bAklqwEjSm-G"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A>\n","25th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer\n","27th char = 'Answer'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:\n","28th char = ':'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:If\n","29th char = 'If'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftoday\n","30th char = 'today'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayis\n","31th char = 'is'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe\n","32th char = 'the'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe \n","33th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 1\n","34th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14\n","35th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14th\n","36th char = 'th'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thof\n","37th char = 'of'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofa\n","38th char = 'a'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth\n","39th char = 'month'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,\n","40th char = ','\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in\n","41th char = 'in'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in \n","42th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 1\n","43th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10\n","44th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10days\n","45th char = 'days'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysit\n","46th char = 'it'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwill\n","47th char = 'will'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbe\n","48th char = 'be'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe\n","49th char = 'the'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe \n","50th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 2\n","51th char = '2'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24\n","52th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24th\n","53th char = 'th'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thof\n","54th char = 'of'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthe\n","55th char = 'the'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth\n","56th char = 'month'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.\n","57th char = '.'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>\n","58th char = '</s>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>0\n","59th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04\n","60th char = '4'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-\n","61th char = '-'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-2\n","62th char = '2'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20\n","63th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 \n","64th char = ' '\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 1\n","65th char = '1'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16\n","66th char = '6'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:\n","67th char = ':'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:0\n","68th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:00\n","69th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:00:\n","70th char = ':'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:00:0\n","71th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:00:00\n","72th char = '0'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:00:00<0x0A>\n","73th char = '<0x0A>'\n","Sequence so far: If today is the 14th of a month, what date will it be in 10 days?<0x0A><0x0A>Answer:Iftodayisthe 14thofamonth,in 10daysitwillbethe 24thofthemonth.</s>04-20 16:00:00<0x0A><0x0A>\n","74th char = '<0x0A>'\n"]}]}]}