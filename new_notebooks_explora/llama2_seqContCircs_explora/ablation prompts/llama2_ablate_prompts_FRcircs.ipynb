{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["9R_g1Ghv7cGE","PDP2cpaiZpPX","dsdvChbcvgp5","jtaV1q3SBHow","OBo0IKv80oM7","85Iqlq_c_lQv","0Fllcm_N50Zu","16CQTjZ77wci","JsT_qlx49FQT"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fac32e3c54e545738aee1b1b3e902c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b681c63db32417a9c085f0f1da9027f","IPY_MODEL_c5d28daaa7db448d88bdcc96f4bf11cf","IPY_MODEL_041a23ed8c114559a065a146b01efa09"],"layout":"IPY_MODEL_78d100df23da44e1a44fa7def793c75f"}},"7b681c63db32417a9c085f0f1da9027f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f99b14837ac14bf2827568ea870830de","placeholder":"​","style":"IPY_MODEL_ed088fccba8346a78628fa4d71ec5063","value":"tokenizer_config.json: 100%"}},"c5d28daaa7db448d88bdcc96f4bf11cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6c3969ac71948a6809d7e3e782179c0","max":1618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4805215b73ba44a29e956be5bb7bbadb","value":1618}},"041a23ed8c114559a065a146b01efa09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d335747fc181480d8067ddcde2c742c0","placeholder":"​","style":"IPY_MODEL_570f99751125422daa1236fd8c2da00f","value":" 1.62k/1.62k [00:00&lt;00:00, 138kB/s]"}},"78d100df23da44e1a44fa7def793c75f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f99b14837ac14bf2827568ea870830de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed088fccba8346a78628fa4d71ec5063":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6c3969ac71948a6809d7e3e782179c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4805215b73ba44a29e956be5bb7bbadb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d335747fc181480d8067ddcde2c742c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"570f99751125422daa1236fd8c2da00f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b606d7fba9ea4a609792a153d68b6d44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf16bcabe98045cbb403c09e913dfbb6","IPY_MODEL_7c595cf8fdad44b69f2bf37ad968abe7","IPY_MODEL_fca4d617cac14a5795acddee3be1cda6"],"layout":"IPY_MODEL_efed169e19c5471e95fc27bb7cbbab02"}},"cf16bcabe98045cbb403c09e913dfbb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0eb8694b3dd40c69fd40c1f49d61770","placeholder":"​","style":"IPY_MODEL_5185c5b6031c4959b1d1bf7d7fb23544","value":"tokenizer.model: 100%"}},"7c595cf8fdad44b69f2bf37ad968abe7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_01032838237d48adaac7c8f55d73d9f6","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dea2b05381194d9fa42961d55cd5add1","value":499723}},"fca4d617cac14a5795acddee3be1cda6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_399617b82eed4a5a91f96bafa06cc2bd","placeholder":"​","style":"IPY_MODEL_b3a53a4cfbab442596788f392b7e8ca1","value":" 500k/500k [00:00&lt;00:00, 24.8MB/s]"}},"efed169e19c5471e95fc27bb7cbbab02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0eb8694b3dd40c69fd40c1f49d61770":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5185c5b6031c4959b1d1bf7d7fb23544":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01032838237d48adaac7c8f55d73d9f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dea2b05381194d9fa42961d55cd5add1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"399617b82eed4a5a91f96bafa06cc2bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3a53a4cfbab442596788f392b7e8ca1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0aa532b5263f4be081bfc8abc7650c6d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d3c1ec376ec4ebb935075e7435e440d","IPY_MODEL_243561540d90416a89bfca1d5f79e295","IPY_MODEL_eeaa861c31ac4eae87b271bdd112d558"],"layout":"IPY_MODEL_a8f7f6b0d4934594969175b11dba1bee"}},"0d3c1ec376ec4ebb935075e7435e440d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fd55a43f36940efa72579fd20b53925","placeholder":"​","style":"IPY_MODEL_96aaa7f46a254a4abd64542b87f83217","value":"special_tokens_map.json: 100%"}},"243561540d90416a89bfca1d5f79e295":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49fe8db828404d9a98171dd404ab74d3","max":414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52d7cbae085c47178683d3c0cbd9dd69","value":414}},"eeaa861c31ac4eae87b271bdd112d558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8360f3969174c7b8043ff6f0f426018","placeholder":"​","style":"IPY_MODEL_4e22b169d4904c03b321923f36b3e821","value":" 414/414 [00:00&lt;00:00, 30.4kB/s]"}},"a8f7f6b0d4934594969175b11dba1bee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fd55a43f36940efa72579fd20b53925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96aaa7f46a254a4abd64542b87f83217":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49fe8db828404d9a98171dd404ab74d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52d7cbae085c47178683d3c0cbd9dd69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8360f3969174c7b8043ff6f0f426018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e22b169d4904c03b321923f36b3e821":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7fc84c9a41e4393acd299c9bcb9f67a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35f82f1c3bf54c5dbab136b165abeb7c","IPY_MODEL_f90acae3d93e47dab956e425650f0b23","IPY_MODEL_d419f747562c466cb494538a3baa41dd"],"layout":"IPY_MODEL_4095471ca24345ae928ccf351f7481c3"}},"35f82f1c3bf54c5dbab136b165abeb7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7396c4150e146228cc9ab407c27d9bf","placeholder":"​","style":"IPY_MODEL_5281cd8fda264af6a0ac6d8ef868b635","value":"tokenizer.json: 100%"}},"f90acae3d93e47dab956e425650f0b23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51c75cceb1eb434ebb3f2c740e249199","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd9cff14e9e34a7e89d9698d9e0ed92e","value":1842767}},"d419f747562c466cb494538a3baa41dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f518052438431caba7834f35efd65e","placeholder":"​","style":"IPY_MODEL_1db95a40b8e849f7b00eb8e814eac4f9","value":" 1.84M/1.84M [00:00&lt;00:00, 39.2MB/s]"}},"4095471ca24345ae928ccf351f7481c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7396c4150e146228cc9ab407c27d9bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5281cd8fda264af6a0ac6d8ef868b635":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51c75cceb1eb434ebb3f2c740e249199":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd9cff14e9e34a7e89d9698d9e0ed92e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5f518052438431caba7834f35efd65e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1db95a40b8e849f7b00eb8e814eac4f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2f6fcbf9c5c488bb855d48c48026f70":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab8562915694463790ab4040b330b2ba","IPY_MODEL_9221edcdfd684066b78968ac58883034","IPY_MODEL_db28777161c647aea652a8af64d8efad"],"layout":"IPY_MODEL_6fd83798f59241b5b904c971d896d5b6"}},"ab8562915694463790ab4040b330b2ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30973238325648989f33355e49ca88ee","placeholder":"​","style":"IPY_MODEL_9e6caddb0122446eaa1709bb4e62ba32","value":"config.json: 100%"}},"9221edcdfd684066b78968ac58883034":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41784a1c4ac14910b3bca62d1e522dc3","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f83f9673c854a549f8de792f1f2953b","value":614}},"db28777161c647aea652a8af64d8efad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afba5e24cd314a80b3c4128aee3bad2e","placeholder":"​","style":"IPY_MODEL_b9c632229df94e65bce25f5dd5b6d6b3","value":" 614/614 [00:00&lt;00:00, 44.4kB/s]"}},"6fd83798f59241b5b904c971d896d5b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30973238325648989f33355e49ca88ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e6caddb0122446eaa1709bb4e62ba32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41784a1c4ac14910b3bca62d1e522dc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f83f9673c854a549f8de792f1f2953b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afba5e24cd314a80b3c4128aee3bad2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c632229df94e65bce25f5dd5b6d6b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4997de68859424eadc8bfcc1735148a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38f75f6a862b46f39c3dadcda66cb169","IPY_MODEL_305d258bbfd540369fa96151577b551f","IPY_MODEL_bafb5ed19d3749959406960c186113ac"],"layout":"IPY_MODEL_58cf3126dcd9495eaa658e27872c3482"}},"38f75f6a862b46f39c3dadcda66cb169":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_755a916aadb84db4937cac0045c478fb","placeholder":"​","style":"IPY_MODEL_99c0d4bc0e094424824f90b2f35e8af6","value":"model.safetensors.index.json: 100%"}},"305d258bbfd540369fa96151577b551f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75e6ee9faf614222a2c09518929fe1d7","max":26788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7faa4a00c7ee48339c48a8c2ded265c4","value":26788}},"bafb5ed19d3749959406960c186113ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_688f37879ff9433db1f4010ceb89562e","placeholder":"​","style":"IPY_MODEL_2171f341ffb746fdaf0f43071c59457f","value":" 26.8k/26.8k [00:00&lt;00:00, 2.18MB/s]"}},"58cf3126dcd9495eaa658e27872c3482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"755a916aadb84db4937cac0045c478fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99c0d4bc0e094424824f90b2f35e8af6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75e6ee9faf614222a2c09518929fe1d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7faa4a00c7ee48339c48a8c2ded265c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"688f37879ff9433db1f4010ceb89562e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2171f341ffb746fdaf0f43071c59457f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14e30836a06e414fb450f7baf2e8ea32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb14ce24f4df490a9fe22cb0ae36ff02","IPY_MODEL_8bb561d3de034baebf29eb0bf9c371e1","IPY_MODEL_17f8404c1cef40b69ca77191ad029a4d"],"layout":"IPY_MODEL_f52a76ecafa34b0dbaf61052b25dea3e"}},"eb14ce24f4df490a9fe22cb0ae36ff02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_231f0ca7c36743a289542e236b3a3adb","placeholder":"​","style":"IPY_MODEL_2effd117ed9e43caa11cb9f4897423d0","value":"Downloading shards: 100%"}},"8bb561d3de034baebf29eb0bf9c371e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2e846ba2d4b4b2fa76ae926e3692108","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c41ba22ad31c42d88b8ca5afac56514a","value":2}},"17f8404c1cef40b69ca77191ad029a4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fa6898ef2674794a60bc38e9db1d384","placeholder":"​","style":"IPY_MODEL_758a4505c2f148569d92b5b19c67e969","value":" 2/2 [00:48&lt;00:00, 23.20s/it]"}},"f52a76ecafa34b0dbaf61052b25dea3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"231f0ca7c36743a289542e236b3a3adb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2effd117ed9e43caa11cb9f4897423d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2e846ba2d4b4b2fa76ae926e3692108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41ba22ad31c42d88b8ca5afac56514a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fa6898ef2674794a60bc38e9db1d384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"758a4505c2f148569d92b5b19c67e969":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"039483d399b94c029eeb1f7d257ff67c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23a3308993854489b33a14698a5fc9ad","IPY_MODEL_f16787ac263e40678b8f0f5abd8ecba1","IPY_MODEL_3af81ab714c145569117b4841ceb6ae9"],"layout":"IPY_MODEL_3230dc696f01427abe6390339f184ecf"}},"23a3308993854489b33a14698a5fc9ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22ab5036c8cf48ad98b8fc1649944a9b","placeholder":"​","style":"IPY_MODEL_6e418c3c5f714de0a4f94e166258eed0","value":"model-00001-of-00002.safetensors: 100%"}},"f16787ac263e40678b8f0f5abd8ecba1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ae7193765e14f079f91f2f14485ab93","max":9976576152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53822c74fcc140eda96479c1588cdb2e","value":9976576152}},"3af81ab714c145569117b4841ceb6ae9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8fdbc0316ab4eac8c5c5167c42647db","placeholder":"​","style":"IPY_MODEL_27147450d0b342a7b8839afce33e3e36","value":" 9.98G/9.98G [00:31&lt;00:00, 206MB/s]"}},"3230dc696f01427abe6390339f184ecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22ab5036c8cf48ad98b8fc1649944a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e418c3c5f714de0a4f94e166258eed0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ae7193765e14f079f91f2f14485ab93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53822c74fcc140eda96479c1588cdb2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8fdbc0316ab4eac8c5c5167c42647db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27147450d0b342a7b8839afce33e3e36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"581b0dd3266a4540ad2b2aad99acdbb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10c06f9291cd44508ec30742529300fd","IPY_MODEL_878b4177cfc14ea09e0e50dfe20cd987","IPY_MODEL_74fe28872cc1412b9b1e95071baf5063"],"layout":"IPY_MODEL_d67bc8f91ac5404c99bfaeb594916154"}},"10c06f9291cd44508ec30742529300fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55d5161d92924554a00b3ea4a2515718","placeholder":"​","style":"IPY_MODEL_5902bb96d7d34c599a1c4c5ef0e0c61f","value":"model-00002-of-00002.safetensors: 100%"}},"878b4177cfc14ea09e0e50dfe20cd987":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_daecf46d2319482496ca40446962c0aa","max":3500296424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3b6326d046649358133535c05fa4916","value":3500296424}},"74fe28872cc1412b9b1e95071baf5063":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7851040ebb20482cb3b401244adc36d1","placeholder":"​","style":"IPY_MODEL_391bea5ae6454942be7671879084d11f","value":" 3.50G/3.50G [00:17&lt;00:00, 123MB/s]"}},"d67bc8f91ac5404c99bfaeb594916154":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d5161d92924554a00b3ea4a2515718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5902bb96d7d34c599a1c4c5ef0e0c61f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daecf46d2319482496ca40446962c0aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3b6326d046649358133535c05fa4916":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7851040ebb20482cb3b401244adc36d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"391bea5ae6454942be7671879084d11f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7be510cb533b4a30b41120e3098d7416":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0a8c430dbda4f2385c86d03a6bbc1fd","IPY_MODEL_c0dc26347c124258b5af531c962c9993","IPY_MODEL_48425bd52c094907a0bcb92a58f803d4"],"layout":"IPY_MODEL_2de2ea03411e4b2285f9d7c168329f23"}},"b0a8c430dbda4f2385c86d03a6bbc1fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73b2fa81e6b44c07bc0361f2f4c4ff11","placeholder":"​","style":"IPY_MODEL_f705e8155bb34dacb1ffc57667a157e5","value":"Loading checkpoint shards: 100%"}},"c0dc26347c124258b5af531c962c9993":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65546d13510c439e83f9e4167c7a2f6f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfa3bea317574fc9b32aa4e1596ad1d5","value":2}},"48425bd52c094907a0bcb92a58f803d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d03a6f7e514e4c0a801acaadedd97a3d","placeholder":"​","style":"IPY_MODEL_fee68e6ce9944f739484dc31e312dc01","value":" 2/2 [00:04&lt;00:00,  1.85s/it]"}},"2de2ea03411e4b2285f9d7c168329f23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73b2fa81e6b44c07bc0361f2f4c4ff11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f705e8155bb34dacb1ffc57667a157e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65546d13510c439e83f9e4167c7a2f6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfa3bea317574fc9b32aa4e1596ad1d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d03a6f7e514e4c0a801acaadedd97a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fee68e6ce9944f739484dc31e312dc01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc3e5ba6a14e4a6da18c54705a419be4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1c1f2f338a342f195ad798d0cfff1ed","IPY_MODEL_becbaf802d09420991fcf9aa09e34425","IPY_MODEL_39ea5aec5cb54355bd7aae6448c51f74"],"layout":"IPY_MODEL_d7167d2dcd44490a907a7b888e9a2d2e"}},"a1c1f2f338a342f195ad798d0cfff1ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3097d4aa4ba4c93a5a781939c8e0699","placeholder":"​","style":"IPY_MODEL_1b0096b16d1448d1bdc89c4a14ac87a2","value":"generation_config.json: 100%"}},"becbaf802d09420991fcf9aa09e34425":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d4d0f1f58c241cda12c6f104674e0f8","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_719d86ae87d44954a39082326b4d0bea","value":188}},"39ea5aec5cb54355bd7aae6448c51f74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29cc6eedccfe4051a7e486c75b6b7ec9","placeholder":"​","style":"IPY_MODEL_44a4bfd48eee45f18478afb7d16461b9","value":" 188/188 [00:00&lt;00:00, 16.9kB/s]"}},"d7167d2dcd44490a907a7b888e9a2d2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3097d4aa4ba4c93a5a781939c8e0699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b0096b16d1448d1bdc89c4a14ac87a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d4d0f1f58c241cda12c6f104674e0f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"719d86ae87d44954a39082326b4d0bea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29cc6eedccfe4051a7e486c75b6b7ec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44a4bfd48eee45f18478afb7d16461b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"code","source":["save_files = True"],"metadata":{"id":"KSKP_OsTDki6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6b1n2tvIAiD"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuhzYxbsIAiE"},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer #, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFMTUcQiIAiF"},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718113420754,"user_tz":-60,"elapsed":2813,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"139fcfa0-5e7b-4251-d139-f974fd34d3a7","id":"F8TXMRL3CoPd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 967, done.\u001b[K\n","remote: Counting objects: 100% (433/433), done.\u001b[K\n","remote: Compressing objects: 100% (262/262), done.\u001b[K\n","remote: Total 967 (delta 254), reused 335 (delta 160), pack-reused 534\u001b[K\n","Receiving objects: 100% (967/967), 17.66 MiB | 14.17 MiB/s, done.\n","Resolving deltas: 100% (617/617), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","# don't improt this\n","# # from dataset import Dataset\n","\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["import random\n"],"metadata":{"id":"jsJmCq-C2Zu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a dict whose values are tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_longer(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text\n","        # 'text': model.to_string(tokens)[0]\n","        }\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    # for i, tok in enumerate(tokens):\n","    #     prompt_dict['S'+str(i)] = model.to_string(tok)\n","\n","    # prompt_dict = {\n","    #     'corr': '4',\n","    #     'incorr': '3',\n","    #     'text': model.to_string(tokens)[0]\n","    # }\n","    # # list_tokens = tokenizer.tokenize('1 2 3 ')\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i, tok_as_str in enumerate(tokens_as_strs):\n","    #     if tok_as_str == '▁':\n","    #         prompt_dict['S'+str(i)] = ' '\n","    #     else:\n","    #         prompt_dict['S'+str(i)] = tok_as_str\n","    prompts_list.append(prompt_dict)\n","    return prompts_list"],"metadata":{"id":"VZKVG778QYyn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDP2cpaiZpPX"},"source":["# Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGCiZUPpJUsD"},"outputs":[],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CocJpgjsf_M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718113451580,"user_tz":-60,"elapsed":13168,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ec81d885-b2e2-44e9-ea7b-a2cb2de3fa57"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLgpia0tI6O8","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["fac32e3c54e545738aee1b1b3e902c2d","7b681c63db32417a9c085f0f1da9027f","c5d28daaa7db448d88bdcc96f4bf11cf","041a23ed8c114559a065a146b01efa09","78d100df23da44e1a44fa7def793c75f","f99b14837ac14bf2827568ea870830de","ed088fccba8346a78628fa4d71ec5063","d6c3969ac71948a6809d7e3e782179c0","4805215b73ba44a29e956be5bb7bbadb","d335747fc181480d8067ddcde2c742c0","570f99751125422daa1236fd8c2da00f","b606d7fba9ea4a609792a153d68b6d44","cf16bcabe98045cbb403c09e913dfbb6","7c595cf8fdad44b69f2bf37ad968abe7","fca4d617cac14a5795acddee3be1cda6","efed169e19c5471e95fc27bb7cbbab02","c0eb8694b3dd40c69fd40c1f49d61770","5185c5b6031c4959b1d1bf7d7fb23544","01032838237d48adaac7c8f55d73d9f6","dea2b05381194d9fa42961d55cd5add1","399617b82eed4a5a91f96bafa06cc2bd","b3a53a4cfbab442596788f392b7e8ca1","0aa532b5263f4be081bfc8abc7650c6d","0d3c1ec376ec4ebb935075e7435e440d","243561540d90416a89bfca1d5f79e295","eeaa861c31ac4eae87b271bdd112d558","a8f7f6b0d4934594969175b11dba1bee","2fd55a43f36940efa72579fd20b53925","96aaa7f46a254a4abd64542b87f83217","49fe8db828404d9a98171dd404ab74d3","52d7cbae085c47178683d3c0cbd9dd69","b8360f3969174c7b8043ff6f0f426018","4e22b169d4904c03b321923f36b3e821","b7fc84c9a41e4393acd299c9bcb9f67a","35f82f1c3bf54c5dbab136b165abeb7c","f90acae3d93e47dab956e425650f0b23","d419f747562c466cb494538a3baa41dd","4095471ca24345ae928ccf351f7481c3","b7396c4150e146228cc9ab407c27d9bf","5281cd8fda264af6a0ac6d8ef868b635","51c75cceb1eb434ebb3f2c740e249199","dd9cff14e9e34a7e89d9698d9e0ed92e","d5f518052438431caba7834f35efd65e","1db95a40b8e849f7b00eb8e814eac4f9","c2f6fcbf9c5c488bb855d48c48026f70","ab8562915694463790ab4040b330b2ba","9221edcdfd684066b78968ac58883034","db28777161c647aea652a8af64d8efad","6fd83798f59241b5b904c971d896d5b6","30973238325648989f33355e49ca88ee","9e6caddb0122446eaa1709bb4e62ba32","41784a1c4ac14910b3bca62d1e522dc3","9f83f9673c854a549f8de792f1f2953b","afba5e24cd314a80b3c4128aee3bad2e","b9c632229df94e65bce25f5dd5b6d6b3","a4997de68859424eadc8bfcc1735148a","38f75f6a862b46f39c3dadcda66cb169","305d258bbfd540369fa96151577b551f","bafb5ed19d3749959406960c186113ac","58cf3126dcd9495eaa658e27872c3482","755a916aadb84db4937cac0045c478fb","99c0d4bc0e094424824f90b2f35e8af6","75e6ee9faf614222a2c09518929fe1d7","7faa4a00c7ee48339c48a8c2ded265c4","688f37879ff9433db1f4010ceb89562e","2171f341ffb746fdaf0f43071c59457f","14e30836a06e414fb450f7baf2e8ea32","eb14ce24f4df490a9fe22cb0ae36ff02","8bb561d3de034baebf29eb0bf9c371e1","17f8404c1cef40b69ca77191ad029a4d","f52a76ecafa34b0dbaf61052b25dea3e","231f0ca7c36743a289542e236b3a3adb","2effd117ed9e43caa11cb9f4897423d0","f2e846ba2d4b4b2fa76ae926e3692108","c41ba22ad31c42d88b8ca5afac56514a","4fa6898ef2674794a60bc38e9db1d384","758a4505c2f148569d92b5b19c67e969","039483d399b94c029eeb1f7d257ff67c","23a3308993854489b33a14698a5fc9ad","f16787ac263e40678b8f0f5abd8ecba1","3af81ab714c145569117b4841ceb6ae9","3230dc696f01427abe6390339f184ecf","22ab5036c8cf48ad98b8fc1649944a9b","6e418c3c5f714de0a4f94e166258eed0","3ae7193765e14f079f91f2f14485ab93","53822c74fcc140eda96479c1588cdb2e","f8fdbc0316ab4eac8c5c5167c42647db","27147450d0b342a7b8839afce33e3e36","581b0dd3266a4540ad2b2aad99acdbb7","10c06f9291cd44508ec30742529300fd","878b4177cfc14ea09e0e50dfe20cd987","74fe28872cc1412b9b1e95071baf5063","d67bc8f91ac5404c99bfaeb594916154","55d5161d92924554a00b3ea4a2515718","5902bb96d7d34c599a1c4c5ef0e0c61f","daecf46d2319482496ca40446962c0aa","e3b6326d046649358133535c05fa4916","7851040ebb20482cb3b401244adc36d1","391bea5ae6454942be7671879084d11f","7be510cb533b4a30b41120e3098d7416","b0a8c430dbda4f2385c86d03a6bbc1fd","c0dc26347c124258b5af531c962c9993","48425bd52c094907a0bcb92a58f803d4","2de2ea03411e4b2285f9d7c168329f23","73b2fa81e6b44c07bc0361f2f4c4ff11","f705e8155bb34dacb1ffc57667a157e5","65546d13510c439e83f9e4167c7a2f6f","dfa3bea317574fc9b32aa4e1596ad1d5","d03a6f7e514e4c0a801acaadedd97a3d","fee68e6ce9944f739484dc31e312dc01","fc3e5ba6a14e4a6da18c54705a419be4","a1c1f2f338a342f195ad798d0cfff1ed","becbaf802d09420991fcf9aa09e34425","39ea5aec5cb54355bd7aae6448c51f74","d7167d2dcd44490a907a7b888e9a2d2e","f3097d4aa4ba4c93a5a781939c8e0699","1b0096b16d1448d1bdc89c4a14ac87a2","1d4d0f1f58c241cda12c6f104674e0f8","719d86ae87d44954a39082326b4d0bea","29cc6eedccfe4051a7e486c75b6b7ec9","44a4bfd48eee45f18478afb7d16461b9"]},"executionInfo":{"status":"ok","timestamp":1718113511268,"user_tz":-60,"elapsed":59697,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"aee1d766-fe81-4002-8613-316e483b180c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fac32e3c54e545738aee1b1b3e902c2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b606d7fba9ea4a609792a153d68b6d44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aa532b5263f4be081bfc8abc7650c6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7fc84c9a41e4393acd299c9bcb9f67a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2f6fcbf9c5c488bb855d48c48026f70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4997de68859424eadc8bfcc1735148a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14e30836a06e414fb450f7baf2e8ea32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"039483d399b94c029eeb1f7d257ff67c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581b0dd3266a4540ad2b2aad99acdbb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be510cb533b4a30b41120e3098d7416"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc3e5ba6a14e4a6da18c54705a419be4"}},"metadata":{}}],"source":["LLAMA_2_7B_CHAT_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n","\n","tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH)\n","# tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH, use_fast= False, add_prefix_space= False)\n","hf_model = LlamaForCausalLM.from_pretrained(LLAMA_2_7B_CHAT_PATH, low_cpu_mem_usage=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rtZ2e3sMY5S"},"outputs":[],"source":["import transformer_lens.utils as utils\n","from transformer_lens.hook_points import HookPoint\n","from transformer_lens import HookedTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUnSHvA-Myx8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718113542428,"user_tz":-60,"elapsed":31176,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"799e6db7-04f8-41c7-e23d-151e63ea874e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n","Moving model to device:  cuda\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    LLAMA_2_7B_CHAT_PATH,\n","    hf_model = hf_model,\n","    tokenizer = tokenizer,\n","    device = \"cpu\",\n","    fold_ln = False,\n","    center_writing_weights = False,\n","    center_unembed = False,\n",")\n","\n","del hf_model\n","\n","model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["# new ablation functions"],"metadata":{"id":"dsdvChbcvgp5"}},{"cell_type":"code","source":["def get_heads_actv_mean(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Output: The mean activations of a head's output\n","    '''\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    # for layer in range(model.cfg.n_layers):\n","    #     z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","    #     for template_group in means_dataset.groups:\n","    #         z_for_this_template = z_for_this_layer[template_group]\n","    #         z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","    #         if z_means_for_this_template.shape[0] == 5:\n","    #             pdb.set_trace()\n","    #         means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means"],"metadata":{"id":"6KlWYoEy72Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def mask_circ_heads(\n","#     means_dataset: Dataset,\n","#     model: HookedTransformer,\n","#     circuit: Dict[str, List[Tuple[int, int]]],\n","#     seq_pos_to_keep: Dict[str, str],\n","# ) -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","#     '''\n","#     Output: for each layer, a mask of circuit components that should not be ablated\n","#     '''\n","#     heads_and_posns_to_keep = {}\n","#     batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","#     for layer in range(model.cfg.n_layers):\n","\n","#         mask = t.zeros(size=(batch, seq, n_heads))\n","\n","#         for (head_type, head_list) in circuit.items():\n","#             seq_pos = seq_pos_to_keep[head_type]\n","#             # if seq_pos == 'S7':\n","#             #     pdb.set_trace()\n","#             indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","#             for (layer_idx, head_idx) in head_list:\n","#                 if layer_idx == layer:\n","#                     # if indices.item() == 7:\n","#                     #     pdb.set_trace()\n","#                     mask[:, indices, head_idx] = 1\n","#                     # mask[:, :, head_idx] = 1  # keep L.H at all pos\n","\n","#         heads_and_posns_to_keep[layer] = mask.bool()\n","#     # pdb.set_trace()\n","#     return heads_and_posns_to_keep"],"metadata":{"id":"bFDQMOt9CyVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mask_circ_heads(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Output: for each layer, a mask of circuit components that should not be ablated\n","    '''\n","    heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","    batch, seq, n_heads = len(means_dataset), len(circuit.keys()), model.cfg.n_heads\n","    # print(seq)\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    # mask[:, indices, head_idx] = 1\n","                    mask[:, :, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep"],"metadata":{"id":"E1boH1469_HI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def hook_func_mask_head(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    # components_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    # means: Float[Tensor, \"layer batch seq head d_head\"],\n","    circuit: Dict[str, List[Tuple[int, int]]],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Use this to not mask components\n","    '''\n","    # mask_for_this_layer = components_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","    # z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    ###\n","    # heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = z.shape[0], z.shape[1], model.cfg.n_heads  # components_to_keep[0].shape[0] is batch\n","\n","    # for layer in range(model.cfg.n_layers):\n","\n","    #     mask = t.zeros(size=(batch, seq, n_heads))\n","\n","    #     for (head_type, head_list) in circuit.items():\n","    #         # seq_pos = seq_pos_to_keep[head_type]\n","    #         # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","    #         for (layer_idx, head_idx) in head_list:\n","    #             if layer_idx == layer:\n","    #                 # mask[:, indices, head_idx] = 1\n","    #                 mask[:, :, head_idx] = 1\n","\n","    #     heads_and_posns_to_keep[layer] = mask.bool()\n","    ###\n","    mask_for_this_layer = t.zeros(size=(z.shape[0], z.shape[1], z.shape[2]))\n","    for (head_type, head_list) in circuit.items():\n","        # seq_pos = seq_pos_to_keep[head_type]\n","        # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","        for (layer_idx, head_idx) in head_list:\n","            if layer_idx == hook.layer():\n","                # mask[:, indices, head_idx] = 1\n","                mask_for_this_layer[:, :, head_idx] = 1\n","\n","    mask_for_this_layer = mask_for_this_layer.bool()\n","    mask_for_this_layer = mask_for_this_layer.unsqueeze(-1).to(z.device)  # d_model is 1; then is broadcast in where\n","\n","    z = t.where(mask_for_this_layer, z, 0)\n","\n","    return z"],"metadata":{"id":"KdxeNJ5C9tHx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_ablation_hook_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Ablate the model, except as components and positions to keep\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","    means = get_heads_actv_mean(means_dataset, model)\n","    components_to_keep = mask_circ_heads(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=circuit,\n","    )\n","\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","    return model"],"metadata":{"id":"dg3XuWScAVvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from dataset import Dataset\n","from transformer_lens import HookedTransformer, utils\n","from transformer_lens.hook_points import HookPoint\n","import einops\n","from functools import partial\n","import torch as t\n","from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool\n","\n","# from head_ablation_fns import *\n","# from mlp_ablation_fns import *\n","\n","def add_ablation_hook_MLP_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    heads_lst, mlp_lst,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        CIRCUIT['S'+str(i)] = heads_lst\n","        # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","        # if i == num_pos - 1:\n","        #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        # else:\n","        SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = get_heads_actv_mean(means_dataset, model)\n","    # Convert this into a boolean map\n","    components_to_keep = mask_circ_heads(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=CIRCUIT,\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    # if all_entries_true(components_to_keep) == False:\n","    #     pdb.set_trace()\n","    ########################\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","    # # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    # num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    # for i in range(num_pos ):\n","    #     CIRCUIT['S'+str(i)] = mlp_lst\n","    #     # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","    #     # if i == num_pos - 1:\n","    #     #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","    #     # else:\n","    #     SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    # # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    # means = get_MLPs_actv_mean(means_dataset, model)\n","\n","    # # Convert this into a boolean map\n","    # components_to_keep = mask_circ_MLPs(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # # Get a hook function which will patch in the mean z values for each head, at\n","    # # all positions which aren't important for the circuit\n","    # hook_fn = partial(\n","    #     hook_func_mask_mlp_out,\n","    #     components_to_keep=components_to_keep,\n","    #     means=means\n","    # )\n","\n","    # model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"6ILjxwH9YUYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def all_entries_true(tensor_dict):\n","    for key, tensor in tensor_dict.items():\n","        if not torch.all(tensor).item():\n","            return False\n","    return True"],"metadata":{"id":"u-YuOEDieLgE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ablation fns mult tok answers"],"metadata":{"id":"jtaV1q3SBHow"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    # tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","        # if next_char == '':\n","        #     next_char = ' '\n","        # clean_text = clean_text + next_char\n","        # tokens = model.to_tokens(clean_text).to(device)\n","    return corr_ans_tokLen"],"metadata":{"id":"WgbtY5fFPb71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    for i in range(corr_ans_tokLen):\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        if i == corr_ans_tokLen - 1:\n","            print(model.to_string(tokens))\n","            # print(f\"Sequence so far: {clean_text}\")\n","            # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","        # pos_dict = {}\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())"],"metadata":{"id":"lp4MyZ52cUTK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to randomly choose 50 pairs ensuring less than 10 overlap with heads_of_circ\n","def choose_heads_to_remove(filtered_pairs, heads_of_circ, num_pairs=50, max_overlap=10):\n","    while True:\n","        head_to_remove = random.sample(filtered_pairs, num_pairs)\n","        overlap_count = len([head for head in head_to_remove if head in heads_of_circ])\n","        if overlap_count < max_overlap:\n","            return head_to_remove"],"metadata":{"id":"S8KYb2BBSm-G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define circs"],"metadata":{"id":"JPKiYdKTAMni"}},{"cell_type":"code","source":["# from Llama2_numerals_1to10.ipynb\n","nums_1to9 = [(0, 2), (0, 5), (0, 6), (0, 15), (1, 15), (1, 28), (2, 13), (2, 24), (3, 24), (4, 3), (4, 16), (5, 11), (5, 13), (5, 15), (5, 16), (5, 23), (5, 25), (5, 27), (6, 11), (6, 14), (6, 20), (6, 23), (6, 24), (6, 26), (6, 28), (6, 30), (6, 31), (7, 0), (7, 13), (7, 21), (7, 30), (8, 0), (8, 2), (8, 12), (8, 15), (8, 26), (8, 27), (8, 30), (8, 31), (9, 15), (9, 16), (9, 23), (9, 26), (9, 27), (9, 29), (9, 31), (10, 1), (10, 13), (10, 18), (10, 23), (10, 29), (11, 7), (11, 8), (11, 9), (11, 17), (11, 18), (11, 25), (11, 28), (12, 18), (12, 19), (12, 23), (12, 27), (13, 6), (13, 11), (13, 20), (14, 18), (14, 19), (14, 20), (14, 21), (16, 0), (18, 19), (18, 21), (18, 25), (18, 26), (18, 31), (19, 28), (20, 17), (21, 0), (21, 2), (22, 18), (22, 20), (22, 25), (23, 27), (26, 2)]\n","len(nums_1to9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YId1M9rIroEe","executionInfo":{"status":"ok","timestamp":1718113542429,"user_tz":-60,"elapsed":495,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2ff15e16-af5d-468e-dbeb-cd3bdbcdd399"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["84"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# nw_circ = [(0, 1), (0, 4), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (1, 16), (1, 24), (1, 27), (1, 28), (2, 2), (2, 5), (2, 8), (2, 24), (2, 30), (3, 7), (3, 14), (3, 19), (3, 23), (4, 3), (5, 16), (5, 25), (6, 11), (6, 14), (7, 0), (7, 30), (8, 0), (8, 2), (8, 3), (8, 4), (8, 6), (8, 21), (8, 31), (9, 1), (9, 3), (9, 7), (9, 11), (9, 29), (9, 31), (10, 13), (10, 18), (10, 23), (10, 24), (10, 25), (10, 27), (11, 18), (11, 28), (12, 18), (12, 26), (13, 11), (13, 17), (13, 18), (13, 19), (13, 20), (13, 21), (13, 23), (14, 7), (14, 14), (15, 25), (15, 28), (16, 0), (16, 12), (16, 14), (16, 15), (16, 16), (16, 19), (16, 24), (16, 29), (17, 17), (17, 23), (17, 31), (18, 31), (19, 12), (20, 17), (27, 20), (27, 25), (27, 27), (27, 31), (28, 5), (29, 5)]\n","# in order from most impt to least based on how much changes perf when ablated\n","nw_circ = [(20, 17), (5, 25), (16, 0), (29, 5), (3, 19), (6, 11), (15, 25), (8, 0), (16, 24), (8, 4), (7, 0), (6, 14), (16, 29), (5, 16), (12, 26), (4, 3), (3, 7), (7, 30), (11, 28), (28, 5), (17, 31), (13, 11), (13, 20), (12, 18), (1, 27), (10, 13), (18, 31), (8, 6), (9, 1), (0, 4), (2, 2), (9, 11), (19, 12), (1, 16), (13, 17), (9, 7), (11, 18), (2, 24), (10, 18), (9, 31), (9, 29), (2, 30), (2, 5), (1, 24), (2, 8), (15, 28), (27, 31), (16, 14), (3, 23), (3, 14), (10, 23), (27, 20), (8, 3), (14, 7), (14, 14), (16, 15), (8, 2), (17, 17), (0, 1), (10, 27), (16, 19), (0, 8), (0, 12), (1, 28), (0, 11), (17, 23), (0, 10), (0, 6), (13, 19), (8, 31), (10, 24), (16, 12), (13, 23), (13, 21), (27, 27), (9, 3), (27, 25), (16, 16), (8, 21), (0, 7), (13, 18), (10, 25)]\n","len(nw_circ)"],"metadata":{"id":"wzTeD-OvAOwC","executionInfo":{"status":"ok","timestamp":1718113542429,"user_tz":-60,"elapsed":487,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4588aac-b634-44b2-a5d1-90bab827d422"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["82"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# impt_months_heads = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","months_circ = [(20, 17), (6, 11), (16, 0), (5, 15), (17, 11), (23, 16), (5, 25), (7, 0), (26, 14), (6, 14), (12, 22), (8, 4), (12, 15), (16, 29), (15, 25), (5, 16), (18, 31), (14, 7), (11, 18), (4, 12), (3, 19), (12, 2), (11, 28), (4, 3), (18, 9), (8, 14), (12, 3), (11, 2), (10, 13), (4, 16), (1, 22), (11, 16), (3, 15), (13, 31), (2, 4), (2, 16), (8, 13), (0, 13), (8, 15), (12, 28), (1, 5), (0, 4), (0, 25), (3, 24), (13, 11), (1, 24), (8, 16), (13, 8), (3, 26), (0, 6), (3, 23), (1, 3), (14, 3), (8, 19), (8, 12), (14, 2), (8, 5), (1, 28), (8, 20), (2, 30), (8, 6), (10, 1), (13, 20), (19, 27)]\n","len(months_circ)"],"metadata":{"id":"a8zrblGeHiND","executionInfo":{"status":"ok","timestamp":1718113542429,"user_tz":-60,"elapsed":479,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f6d38db-8766-43c3-e2a8-3169bbffb1d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["intersect_all = list(set(nums_1to9) & set(nw_circ) & set(months_circ))\n","len(intersect_all)"],"metadata":{"id":"e2XFugMsd3BY","executionInfo":{"status":"ok","timestamp":1718113542429,"user_tz":-60,"elapsed":477,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"92529d02-8362-4730-8b04-9cfe9fb9fd73"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["union_all = list(set(nums_1to9) | set(nw_circ) | set(months_circ))\n","len(union_all)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2CL3XqQ4E7R","executionInfo":{"status":"ok","timestamp":1718113542429,"user_tz":-60,"elapsed":469,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9a257b71-7e52-429f-b443-3fbba36e52a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["172"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["# test prompts"],"metadata":{"id":"oOoMYJ14bZcb"}},{"cell_type":"code","source":["instruction = \"\"\n","# clean_text =  \"un, deux, trois, quatre, cinq, six, sept, huit, neuf, dix\"\n","clean_text =  \"Continue to count in French: un deux trois quatre cinq\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKHD7iN1CnWd","executionInfo":{"status":"ok","timestamp":1718111065336,"user_tz":-60,"elapsed":1766,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6bfc8a0d-46fc-4823-b735-0c19bf2ed276"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Continue to count in French: un deux trois quatre cinq six seven']\n"]}]},{"cell_type":"code","source":["instruction = \"\"\n","# clean_text =  \"un, deux, trois, quatre, cinq, six, sept, huit, neuf, dix\"\n","clean_text =  \"un, deux, trois\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i_7IEX1KZ_Du","executionInfo":{"status":"ok","timestamp":1718111182057,"user_tz":-60,"elapsed":1034,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"10c53d56-34c8-4c41-cb87-9beec9e99a02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, four']\n"]}]},{"cell_type":"code","source":["instruction = \"\"\n","# clean_text =  \"un, deux, trois, quatre, cinq, six, sept, huit, neuf, dix\"\n","clean_text =  \"un, deux, trois, quatre\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTEo6XnExrSn","executionInfo":{"status":"ok","timestamp":1718117390971,"user_tz":-60,"elapsed":1992,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"af230306-548c-4aad-946b-e46b9479d2fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, cinq']\n"]}]},{"cell_type":"code","source":["instruction = \"\"\n","clean_text =  \"uno dos tres\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5_r6HOqaDUh","executionInfo":{"status":"ok","timestamp":1718111218432,"user_tz":-60,"elapsed":1524,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d1d722e6-94cb-48d8-bb94-f59c9ff555f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres cuatro cinco']\n"]}]},{"cell_type":"code","source":["instruction = \"\"\n","clean_text =  \"dos cuatro seis\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ie-MD89LaXO9","executionInfo":{"status":"ok","timestamp":1718117021081,"user_tz":-60,"elapsed":1368,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ade0cd7b-da39-4968-c017-7403144e0441"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> dos cuatro seis\\n\\n']\n"]}]},{"cell_type":"code","source":["instruction = \"Continue counting: \"\n","clean_text =  \"uno dos tres cuatro cinco seis siete ocho nueve diez\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117258888,"user_tz":-60,"elapsed":2364,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d2d432e7-c3a6-450d-de6b-fc0aa7a23685","id":"1Ntmea6SwQLM"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Continue counting: uno dos tres cuatro cinco seis siete ocho nueve diez...\\n\\n¿']\n"]}]},{"cell_type":"code","source":["instruction = \"Continue counting in Spanish: \"\n","clean_text =  \"uno dos tres cuatro cinco seis\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1A8MN1rgw3ie","executionInfo":{"status":"ok","timestamp":1718117292261,"user_tz":-60,"elapsed":1780,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"569d7a52-3a39-40b8-d497-f7e492921228"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Continue counting in Spanish: uno dos tres cuatro cinco seis (one']\n"]}]},{"cell_type":"code","source":["instruction = \"\"\n","clean_text =  \"cuatro cinco seis \"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxODmBhyxZfv","executionInfo":{"status":"ok","timestamp":1718117330515,"user_tz":-60,"elapsed":1822,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ec733d7b-1d1e-4cf6-e87f-f7e7dc926329"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> cuatro cinco seis 78']\n"]}]},{"cell_type":"code","source":["words = ['enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre']"],"metadata":{"id":"-ovndDQxddnR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["instruction = \"\"\n","clean_text =  \"enero, febrero, marzo, abril\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjlWNSz3aMf0","executionInfo":{"status":"ok","timestamp":1718111260020,"user_tz":-60,"elapsed":1405,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f530a35e-c8f1-473d-e41f-33ba2358ea09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> enero, febrero, marzo, abril, mayo']\n"]}]},{"cell_type":"code","source":["instruction = \"\"\n","clean_text = \"What are the months in a year in Spanish? Give all of them as a list. Be concise.\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-u0a4YBRbeWj","executionInfo":{"status":"ok","timestamp":1718111700779,"user_tz":-60,"elapsed":27270,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"47c9debf-edf3-41ba-f0ca-4e11df5365c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish? Give all of them as a list. Be concise.\\n\\nThe months in a year in Spanish are:\\n\\n1. Enero (January)\\n2. Febrero (February)\\n3. Marzo (March)\\n4. Abril (April)\\n5. Mayo (May)\\n6. Junio (June)\\n7. Julio (July)\\n8. Agosto (August)\\n9. Septiembre (September)\\n10. Octubre']\n"]}]},{"cell_type":"code","source":["instruction = \"\"\n","clean_text = \"What are the months in a year in Spanish?\"\n","clean_text = instruction + clean_text\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTzvmCNWcAZv","executionInfo":{"status":"ok","timestamp":1718111745666,"user_tz":-60,"elapsed":27675,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"999bc2bc-0489-4fe6-a045-71d44e413b2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish?\\n\\nIn Spanish, the months of the year are:\\n\\n1. Enero (January)\\n2. Febrero (February)\\n3. Marzo (March)\\n4. Abril (April)\\n5. Mayo (May)\\n6. Junio (June)\\n7. Julio (July)\\n8. Agosto (August)\\n9. Septiembre (September)\\n10. Oct']\n"]}]},{"cell_type":"code","source":["instruction = \"Be concise. \"\n","clean_text = \"What is uno plus cuatro?\"\n","clean_text = instruction + clean_text + \" Answer: \"\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57VOr2D_eL02","executionInfo":{"status":"ok","timestamp":1718112328300,"user_tz":-60,"elapsed":4791,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9fd1976e-d717-42eb-bb24-935a2870f9c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"<s> Be concise. What is uno plus cuatro? Answer: 5.</s>sorry, I don't understand what you are\"]\n"]}]},{"cell_type":"code","source":["instruction = \"Be concise. Answer in Spanish. \"\n","clean_text = \"What is uno plus cuatro?\"\n","clean_text = instruction + clean_text + \" Answer: \"\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dQPlWeAeb-p","executionInfo":{"status":"ok","timestamp":1718112352336,"user_tz":-60,"elapsed":2065,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"323a3c38-222b-4052-ba75-ed1c8953f747"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. Answer in Spanish. What is uno plus cuatro? Answer: 5.</s>s']\n"]}]},{"cell_type":"code","source":["instruction = \"Be concise. Answer in Spanish. What is uno plus uno? Answer: dos. \"\n","clean_text = \"What is uno plus cuatro?\"\n","clean_text = instruction + clean_text + \" Answer: \"\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bkPvFGbehdg","executionInfo":{"status":"ok","timestamp":1718112375875,"user_tz":-60,"elapsed":2183,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"53cca51c-9b55-4a28-ef4c-dc845975b12d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. Answer in Spanish. What is uno plus uno? Answer: dos. What is uno plus cuatro? Answer: 5. What is']\n"]}]},{"cell_type":"code","source":["instruction = \"Be concise. \"\n","clean_text = \"What is cinco minus dos?\"\n","clean_text = instruction + clean_text + \" Answer: \"\n","corr_text = \"uno uno uno\" # dos tres cinco seis\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116051371,"user_tz":-60,"elapsed":2205,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c2e74ca6-c590-4ded-8bd1-d74cf20e3f17","id":"RQbPMkIQseVU"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 3']\n"]}]},{"cell_type":"markdown","source":["# uno dos tres"],"metadata":{"id":"H5H-d2URUSVJ"}},{"cell_type":"code","source":["clean_text = \"uno dos tres\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"rseVgwqtjnCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = [(20, 17)]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xO3PYjdFkvrI","executionInfo":{"status":"ok","timestamp":1718114934468,"user_tz":-60,"elapsed":3102,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"03bd0bc0-03bc-459d-eba8-5d66f6b868ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres\\n\\n\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = [(16, 0)]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g6T2ETxWkdLC","executionInfo":{"status":"ok","timestamp":1718113924261,"user_tz":-60,"elapsed":3144,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ce627f1f-fe44-40ca-99ed-c05acfd69171"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres\\n\\n\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = [(5, 25)]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pKLVxnqkpdK","executionInfo":{"status":"ok","timestamp":1718113974576,"user_tz":-60,"elapsed":3299,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"64b9b271-7161-4335-d36d-d54787fcd5e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres cuatro cinco\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"id":"sBN3wGX2ys8z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718111475267,"user_tz":-60,"elapsed":1120,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9aa36b87-5b76-4806-83a6-05d61817f187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOa1QlFgd790","executionInfo":{"status":"ok","timestamp":1718112215210,"user_tz":-60,"elapsed":1473,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"82eaff10-8a71-4b88-d9ba-a3682bf16766"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres uno\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 1, 1)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvnqEcaNkM8K","executionInfo":{"status":"ok","timestamp":1718113897796,"user_tz":-60,"elapsed":2703,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"eaafdd78-37bb-45ad-dab8-db64d6e14f25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres cuatro cinco']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 1, 1)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3g0pimpooeq-","executionInfo":{"status":"ok","timestamp":1718114975849,"user_tz":-60,"elapsed":1179,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2f0a42eb-2a3d-4ec5-fcde-a427eb34d799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> uno dos tres cuatro cinco']\n"]}]},{"cell_type":"markdown","source":["# seis siete ocho"],"metadata":{"id":"ktZnU5n4uy4_"}},{"cell_type":"code","source":["clean_text = \"seis siete ocho\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"YOMK8x4auy4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = [(20, 17)]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116650800,"user_tz":-60,"elapsed":2811,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5a535df4-69e9-4c79-9cd4-8c70b62d5313","id":"Lt30ndf-uy5A"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> seis siete ocho nueve diez']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = [(16, 0)]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116653339,"user_tz":-60,"elapsed":2549,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d96ac17f-e017-42b4-8d05-0a461932283f","id":"ABoKpa1Huy5A"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> seis siete ocho nueve diez']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = [(5, 25)]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116655758,"user_tz":-60,"elapsed":2435,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8f26c016-7b62-455c-bf22-4f81116dbfa9","id":"53uR5JC2uy5A"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> seis siete ocho nueve diez']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116658911,"user_tz":-60,"elapsed":3166,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"be379cbf-23df-4769-882e-f950c53c1040","id":"mDNjQ4cQuy5A"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> seis siete ocho\\n\\n\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116659988,"user_tz":-60,"elapsed":1090,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8bb99208-88f3-4451-eebc-509c9705d888","id":"CHQ4VqDYuy5B"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> seis siete ocho nueve']\n"]}]},{"cell_type":"markdown","source":["# ocho neuve diez"],"metadata":{"id":"bbNUFkV0z8sP"}},{"cell_type":"code","source":["clean_text = \"dos cuatro siete\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 3"],"metadata":{"id":"9MYk0cE7z8sP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDO2i8Omz8sQ","executionInfo":{"status":"ok","timestamp":1718112118503,"user_tz":-60,"elapsed":1633,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"272c0efa-e703-4866-fcb0-47051db3de14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> dos cuatro siete y medio']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112120049,"user_tz":-60,"elapsed":1562,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"70a26261-e35f-429a-98e7-aee42d198088","id":"fpkxwipRz8sQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> dos cuatro siete\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112121738,"user_tz":-60,"elapsed":1705,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"950dff20-ba91-405e-a1ed-762ade61991e","id":"u6TWCITWz8sQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> dos cuatro siete.\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112123468,"user_tz":-60,"elapsed":1746,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8e51abdb-2184-4cbb-c110-495a6a969c4b","id":"zuwO75Qwz8sQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> dos cuatro siete.\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112143832,"user_tz":-60,"elapsed":1987,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c86d0599-778e-4f06-921d-9eb49a7e79df","id":"mBsYkDYwdrpX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> dos cuatro siete ocho']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJhy3Ds6dunJ","executionInfo":{"status":"ok","timestamp":1718112155979,"user_tz":-60,"elapsed":1751,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"15577525-b676-4102-8783-f6516ef45eb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> dos cuatro siete ocho']\n"]}]},{"cell_type":"markdown","source":["# What are the months in a year in Spanish?"],"metadata":{"id":"85Iqlq_c_lQv"}},{"cell_type":"code","source":["clean_text = \"What are the months in a year in Spanish?\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 50"],"metadata":{"id":"UEg9BhbH_lQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3mwqDRI_skN","executionInfo":{"status":"ok","timestamp":1718111853825,"user_tz":-60,"elapsed":18334,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ad7eb51b-e62a-4448-ff6e-1b8b9dc512e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish?\\n\\nIn Spanish, the months of the year are:\\n\\n1. Enero (January)\\n2. Febrero (February)\\n3. Marzo (March)\\n4. Abril (A']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718111872790,"user_tz":-60,"elapsed":18971,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e187830b-fad1-4221-d24a-62f992f7cf18","id":"uk4dPlDW_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish?\\n\\nIn Spanish, the months of the year are:\\n\\n1. Enero (January)\\n2. Febrero (February)\\n3. Marzo (March)\\n4. Abril (A']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718111890244,"user_tz":-60,"elapsed":17469,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5b996573-7c10-449b-eb1e-337043fd7ae8","id":"D5ZSEzzN_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish?\\n\\n\\nThe months in a year in Spanish are \"meses\" (months).\\n\\nFor example:\\n\\n* ¿Cuál es el mes más largo del año? (What is the longest month of the year?)']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718111909234,"user_tz":-60,"elapsed":19026,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9b5e8c52-b406-4bba-ef58-85aff8b967be","id":"1YOcHosP_lQ6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish?\\n\\n\\nAnswer:\\nThe months in a year in Spanish are:\\n\\n1. Enero (January)\\n2. Febrero (February)\\n3. Marzo (March)\\n\\nNote:']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718111925544,"user_tz":-60,"elapsed":16366,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2cf9f462-d270-4586-ae10-6f0348487ee7","id":"Zi_AzXVV_lQ7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish?\\n\\n\\n\\n\\n\\n* Months in a year in Spanish\\n\\n\\n\\n* Months in a year in Spanish\\n\\n\\n\\n* Months in a year in Spanish\\n\\n\\n\\n* Months in a year in']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718111942987,"user_tz":-60,"elapsed":17469,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"123a421c-3063-4615-aadf-be9dded94ced","id":"68BLgm07_lQ7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> What are the months in a year in Spanish?\\n\\nIn Spanish, the months of the year are:\\n\\n1. Enero (January)\\n2. Febrero (February)\\n3. Marzo (March)\\n4. Abril (A']\n"]}]},{"cell_type":"markdown","source":["# Be concise. List the months in Spanish. Answer:"],"metadata":{"id":"JxSMHleSo_vt"}},{"cell_type":"code","source":["clean_text = \"Be concise. List the months in Spanish. Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 50"],"metadata":{"id":"9ofyYJtNo_v6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115199916,"user_tz":-60,"elapsed":18833,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"416002d3-a38c-4aa9-fdf7-e9dbb56d030a","id":"nKDCfFZEo_v6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. List the months in Spanish. Answer: 1. Enero (January) 2. Febrero (February) 3. Marzo (March) 4. Abril (April) 5. Mayo (May) 6. Jun']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115217643,"user_tz":-60,"elapsed":17772,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0a29b64d-f4cb-46fc-d799-1f5717b6ec61","id":"tZ1T04rqo_v7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. List the months in Spanish. Answer: 1. Enero (January) 2. Febrero (February) 3. Marzo (March) 4. Abril (April) 5. Mayo (May) 6. Jun']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115234933,"user_tz":-60,"elapsed":17316,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"46a5447d-c888-4103-da3b-4e0d0d1a5c9f","id":"qxzYW6smo_v7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. List the months in Spanish. Answer: \\n\\n* Enero (January)\\n* Febrero (February)\\n* Marzo (March)\\n* Abril (April)\\n* Mayo (May)\\n* Junio (June']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115252680,"user_tz":-60,"elapsed":17774,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"049d2cdc-e94e-49f7-d78a-ba0084989741","id":"pGWqVhLNo_v7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. List the months in Spanish. Answer: 1. January (Enero) 2. February (Febrero) 3. March (Marzo) 4. April (Abril) 2. May (Mai) 3. Mexico (México']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115270073,"user_tz":-60,"elapsed":17386,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"23ee0e06-925c-4711-b81e-f59844ade7c1","id":"BiJArqBFo_v8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. List the months in Spanish. Answer: 1. January (diciembre) 2. February (febrero) 3. March (marzo) 3. May (mayo) 3. July (julio) 3. September (sept']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115287256,"user_tz":-60,"elapsed":17328,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d311f080-6f1d-44c3-9ef2-5dbb8681abac","id":"4RkgUnn0o_v8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. List the months in Spanish. Answer: 1. January (Enero) 2. February (Febrero) 3. March (Marzo) 4. April (Abril) 5. May (Mayo) 6. June (Junio']\n"]}]},{"cell_type":"markdown","source":["# \"enero, febrero, marzo, abril\""],"metadata":{"id":"AKsb1-u3qWlu"}},{"cell_type":"code","source":["clean_text = \"enero, febrero, marzo, abril\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 10"],"metadata":{"id":"sgsbsViTqWlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115542902,"user_tz":-60,"elapsed":4550,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9ce7e505-a890-44de-9940-f102a7b28af2","id":"21mdWAC0qWlv"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> enero, febrero, marzo, abril, mayo, junio, julio, agosto,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115546795,"user_tz":-60,"elapsed":4427,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f2837528-5ee1-4ca2-a2fc-d6a60f3e0d37","id":"P4uD-kfMqWlw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> enero, febrero, marzo, abril, mayo, septiembre, noviembre, diciembre,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115550649,"user_tz":-60,"elapsed":4376,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b61d8185-7e6d-42aa-96ae-a6b9eaa62395","id":"2kfuY53DqWlw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> enero, febrero, marzo, abril, mayo, mayo, mayo, mayo,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115554500,"user_tz":-60,"elapsed":3924,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8067c989-2244-457e-d063-9dba03a57f07","id":"_RJ-XipiqWlw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> enero, febrero, marzo, abril, mayo, 19, 2']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115558514,"user_tz":-60,"elapsed":4060,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c789040b-648f-49c6-d843-8da8dff75b3e","id":"1gG9geOhqWlx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> enero, febrero, marzo, abril, mayo, mayo, y septiembre.\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718115563088,"user_tz":-60,"elapsed":4625,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"21843d45-dfa8-473f-e2e0-8f24fb01ae54","id":"ipYzIZRLqWlx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> enero, febrero, marzo, abril, mayo, junio, julio, agosto,']\n"]}]},{"cell_type":"markdown","source":["# What is uno plus cuatro?"],"metadata":{"id":"WYrLYJAQe7ll"}},{"cell_type":"code","source":["clean_text = \"Be concise. What is uno plus cuatro? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 5"],"metadata":{"id":"aL6HOJYHe7ly"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112589270,"user_tz":-60,"elapsed":2782,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ef00bdab-625d-4d93-c1e8-7104df4261fd","id":"ZFtEh57oe7ly"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is uno plus cuatro? Answer: 5.</s>s']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112591490,"user_tz":-60,"elapsed":2231,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2cabce04-9168-4c45-9767-29b0daa7a554","id":"q2eS_s2pe7lz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is uno plus cuatro? Answer: 4.</s>s']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112593989,"user_tz":-60,"elapsed":2598,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e620c8f-d94d-43c3-a34f-0a352bf3a9cc","id":"3vAaj1Uye7lz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is uno plus cuatro? Answer: 4.\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112596762,"user_tz":-60,"elapsed":2813,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2d41e6fd-54a7-4d99-a862-1f9e0f66306a","id":"0OVzJhpae7lz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is uno plus cuatro? Answer: 4.\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718112599544,"user_tz":-60,"elapsed":2944,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"18b8af3a-ad1e-4db1-a543-eb0bcfdccb5e","id":"a8EM5qgZe7lz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is uno plus cuatro? Answer: 4.\\n\\n']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuNfmrqLfdqN","executionInfo":{"status":"ok","timestamp":1718116554875,"user_tz":-60,"elapsed":3214,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4e50e6bd-84ee-42d9-fa6f-7f9ff70c7230"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is uno plus cuatro? Answer: 4.\\n\\n']\n"]}]},{"cell_type":"markdown","source":["# What is cinco minus dos?"],"metadata":{"id":"7kKFPVCXs0Yk"}},{"cell_type":"code","source":["clean_text = \"Be concise. What is cinco minus dos? Answer: \"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 2"],"metadata":{"id":"GDs7XRHts0Yk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116131468,"user_tz":-60,"elapsed":1110,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e106bdcf-6ee9-477e-ce56-645de417145c","id":"8rbREHb5s0Yl"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 3']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116133676,"user_tz":-60,"elapsed":2223,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b6ce8e68-e0f6-4698-f0db-a552786ca184","id":"e1cr5gYLs0Yl"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 3']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116134336,"user_tz":-60,"elapsed":673,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f4e734ea-dd34-42a1-8064-60368b12ac5b","id":"59040U8ts0Yl"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 5']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116135576,"user_tz":-60,"elapsed":1255,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e7d76df1-cd26-4cd6-f14e-a77660d86cbd","id":"7fPF_1lMs0Yl"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 3']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116137218,"user_tz":-60,"elapsed":1831,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e7f1869c-2573-4466-8e0a-c0a4440028e5","id":"RJ_Tzr-9s0Yl"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 5']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116483667,"user_tz":-60,"elapsed":1498,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c525cb0d-f2a0-4a18-b445-d6df7d0f1cea","id":"-1V8qGsSs0Ym"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 3']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718116514261,"user_tz":-60,"elapsed":1541,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9b251614-b716-4cb3-b79c-0a344f38dee4","id":"qIhYuX72s0Ym"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> Be concise. What is cinco minus dos? Answer: 4']\n"]}]},{"cell_type":"markdown","source":["# un, deux, trois, quatre"],"metadata":{"id":"KtkJCO-Tx3AV"}},{"cell_type":"code","source":["clean_text = \"un, deux, trois, quatre\"\n","corr_text = \"5 3 9\"\n","num_toks_gen = 4"],"metadata":{"id":"w7QoGUjAx3AV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117485106,"user_tz":-60,"elapsed":1837,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"903b64a7-ffc6-40fd-be80-4e99a3ca3cf4","id":"A5yQ1OkNx3AW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, cinq,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = intersect_all\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117487177,"user_tz":-60,"elapsed":2084,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b998fa42-6a6c-42d5-8fba-986f758cce26","id":"wx5W0qOXx3AW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, cinq,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nums_1to9\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117488773,"user_tz":-60,"elapsed":1612,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2233a1d3-e92a-4e06-efd8-5e41b65eed5f","id":"Zq8c1CjVx3AW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, cinq,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = nw_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117490998,"user_tz":-60,"elapsed":2237,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"877672b2-30fd-47a6-e400-c029cc986ab0","id":"-Go1jUKvx3AW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, six,']\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = months_circ\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117493009,"user_tz":-60,"elapsed":2037,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6230ca60-0196-4c91-9d03-6edad169dc4f","id":"UEqXvorjx3AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, six,']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117495355,"user_tz":-60,"elapsed":2366,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1d26fd45-0842-4eba-ca19-1b9acf2b6655","id":"NBG3l6Y0x3AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, five,']\n"]}]},{"cell_type":"code","source":["heads_of_circ = union_all\n","\n","all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","# Filter out heads_of_circ from all_possible_pairs\n","filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_of_circ]\n","\n","# Randomly choose 100 pairs ensuring less than 50 overlaps with heads_of_circ\n","head_to_remove = choose_heads_to_remove(filtered_pairs, heads_of_circ, 100, 50)\n","\n","heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, num_toks_gen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718117499311,"user_tz":-60,"elapsed":4031,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b83ebf9e-1ac3-4a7c-d468-36a0d9ad444f","id":"vFkjW3gix3AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['<s> un, deux, trois, quatre, cinq,']\n"]}]}]}