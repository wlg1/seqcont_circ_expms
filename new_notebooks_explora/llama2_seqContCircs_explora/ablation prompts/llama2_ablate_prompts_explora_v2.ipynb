{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["DcZG9rm2IAiA","Z4iJEGh6b56v","PDP2cpaiZpPX","TbpxQ1mM54P_","gkDcCaovxJbb","sEj6tfZMxo7o"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c93968b5ce16445ba72e96add1c4b5a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_959d9503d90f4067a126e614ce93e767","IPY_MODEL_0cd68b11a7b043b1a7d5bf997a128a59","IPY_MODEL_50d7d07d9c7740318a0c5beb9fdf73a7"],"layout":"IPY_MODEL_21f5b1ded59e40c0b06b48e6ec2e0b03"}},"959d9503d90f4067a126e614ce93e767":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bae4338f69c45f99ccb2634f1fc5a24","placeholder":"​","style":"IPY_MODEL_35a1d5174a504ccf88d5e00059f8d95f","value":"tokenizer_config.json: 100%"}},"0cd68b11a7b043b1a7d5bf997a128a59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8df5b78df2f44860baa627c8ea9886de","max":1618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2ee0893dd9f4c02b34d1c3addb9de9b","value":1618}},"50d7d07d9c7740318a0c5beb9fdf73a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_920c9ab2fa4c4fbfa5ea6c56e1a8bd6c","placeholder":"​","style":"IPY_MODEL_9541b1edc6934e158d7a37c17d034b3a","value":" 1.62k/1.62k [00:00&lt;00:00, 139kB/s]"}},"21f5b1ded59e40c0b06b48e6ec2e0b03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bae4338f69c45f99ccb2634f1fc5a24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35a1d5174a504ccf88d5e00059f8d95f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8df5b78df2f44860baa627c8ea9886de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2ee0893dd9f4c02b34d1c3addb9de9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"920c9ab2fa4c4fbfa5ea6c56e1a8bd6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9541b1edc6934e158d7a37c17d034b3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"374f9bd0f01d4a6ba64128f6ccdbf6fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23199af7a2eb42c9b894a6f945f48380","IPY_MODEL_118959f698694ed386355af7f05ee893","IPY_MODEL_2f528f55a5724c7099b9c98bdf73eca2"],"layout":"IPY_MODEL_de1f874e373a4dab98316f885075a96e"}},"23199af7a2eb42c9b894a6f945f48380":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae52e94d87e645b588a640ef058497a3","placeholder":"​","style":"IPY_MODEL_641504db5741474a8e4fcf4a912d99aa","value":"tokenizer.model: 100%"}},"118959f698694ed386355af7f05ee893":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2a6158f689a4a2a88605a02807d0252","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dbaf21af746443d3bd2cb1271b05e045","value":499723}},"2f528f55a5724c7099b9c98bdf73eca2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d6af86e80e44044b483cafa9df69907","placeholder":"​","style":"IPY_MODEL_84e3df7c8e944b33bbc13f482a8ecec4","value":" 500k/500k [00:00&lt;00:00, 22.8MB/s]"}},"de1f874e373a4dab98316f885075a96e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae52e94d87e645b588a640ef058497a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"641504db5741474a8e4fcf4a912d99aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2a6158f689a4a2a88605a02807d0252":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbaf21af746443d3bd2cb1271b05e045":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d6af86e80e44044b483cafa9df69907":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84e3df7c8e944b33bbc13f482a8ecec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c3bcd2ff119469eaf91f1d610f1f321":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d99c5ed7aa244ddb7d49f0f2d282a2c","IPY_MODEL_77cb403bf3fb4950926da2e52becf40d","IPY_MODEL_c1776ad89f2f4675860ff39bf9db4134"],"layout":"IPY_MODEL_e61f1dc517954acca0a28732603785c2"}},"5d99c5ed7aa244ddb7d49f0f2d282a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d02159dbbb414f63bf9d029aed48d67c","placeholder":"​","style":"IPY_MODEL_cd8fbc712c89494786a5fed08deb411a","value":"special_tokens_map.json: 100%"}},"77cb403bf3fb4950926da2e52becf40d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f942f6875ab4aad94b7ee0b897a7bae","max":414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f08e1c9e2b34065975061448604383d","value":414}},"c1776ad89f2f4675860ff39bf9db4134":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ecb600f1bc5420d8f4ce6f4e2eb2074","placeholder":"​","style":"IPY_MODEL_48d59a4c84e64c3bb8ed0e82834e6471","value":" 414/414 [00:00&lt;00:00, 37.7kB/s]"}},"e61f1dc517954acca0a28732603785c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d02159dbbb414f63bf9d029aed48d67c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd8fbc712c89494786a5fed08deb411a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f942f6875ab4aad94b7ee0b897a7bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f08e1c9e2b34065975061448604383d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ecb600f1bc5420d8f4ce6f4e2eb2074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48d59a4c84e64c3bb8ed0e82834e6471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d43943044a1949a3aadfbd45fb4c871c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b6216e4dd6e4a09b4d070c9d656a2ed","IPY_MODEL_bb34db9ab0904562b4de75a4fce7accc","IPY_MODEL_9d6e2d826c2548a3a7bf108cf0641a35"],"layout":"IPY_MODEL_d1b4505dbec94156b65956d476196101"}},"5b6216e4dd6e4a09b4d070c9d656a2ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b159c386f6d4b7b834ef467ce9cf819","placeholder":"​","style":"IPY_MODEL_3c10c26fefdc4e9f9604963c4e891128","value":"tokenizer.json: 100%"}},"bb34db9ab0904562b4de75a4fce7accc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfd8bf86da484ea3902c93e6799b6e88","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4869ece04b241c2bd8d48991b9e8369","value":1842767}},"9d6e2d826c2548a3a7bf108cf0641a35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cbf55c94c9c4e989f98250842e56f78","placeholder":"​","style":"IPY_MODEL_50f80daacee040d49012813f21cc167a","value":" 1.84M/1.84M [00:00&lt;00:00, 7.57MB/s]"}},"d1b4505dbec94156b65956d476196101":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b159c386f6d4b7b834ef467ce9cf819":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c10c26fefdc4e9f9604963c4e891128":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd8bf86da484ea3902c93e6799b6e88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4869ece04b241c2bd8d48991b9e8369":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cbf55c94c9c4e989f98250842e56f78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50f80daacee040d49012813f21cc167a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba6cbcafbe2d4c4d9133b544d1043178":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6caa608d807e4b04aa0e79cd789c2803","IPY_MODEL_7d13ebcc3b394419918b7b050a13baa0","IPY_MODEL_9f7da7f11d1242429e2b8b1c67e4b554"],"layout":"IPY_MODEL_7df1f23ea9094d1188b014aa123e2456"}},"6caa608d807e4b04aa0e79cd789c2803":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c6d0e1de20c46ae96fa42adffb7ad81","placeholder":"​","style":"IPY_MODEL_51fa090dc17c45d0b9b13e58ef122d79","value":"config.json: 100%"}},"7d13ebcc3b394419918b7b050a13baa0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf17c8967725445dbac890a81018e3ec","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b9688953de34e03ace0933611bfdcb6","value":614}},"9f7da7f11d1242429e2b8b1c67e4b554":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b89d3fbd6ef4e80a9bf4f5541079278","placeholder":"​","style":"IPY_MODEL_9ea04b0d5dc845ff981e677d23aab03a","value":" 614/614 [00:00&lt;00:00, 57.5kB/s]"}},"7df1f23ea9094d1188b014aa123e2456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c6d0e1de20c46ae96fa42adffb7ad81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51fa090dc17c45d0b9b13e58ef122d79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf17c8967725445dbac890a81018e3ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b9688953de34e03ace0933611bfdcb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b89d3fbd6ef4e80a9bf4f5541079278":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ea04b0d5dc845ff981e677d23aab03a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d96e145e9244adc9ab3c18441b6420b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed52dd32ff664c9ebd8e78219622c97f","IPY_MODEL_4adeb2b2536c47cda2b99d84b1133606","IPY_MODEL_46148a8bace34feebe94b46b81b068d9"],"layout":"IPY_MODEL_e1d3c4ec149e47c09190914d9ed3ecbf"}},"ed52dd32ff664c9ebd8e78219622c97f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea65afad65fb4eee894b3075c48bc950","placeholder":"​","style":"IPY_MODEL_d0200813b3a244a6a65414ed3d33122b","value":"model.safetensors.index.json: 100%"}},"4adeb2b2536c47cda2b99d84b1133606":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8632386f523047e89ef041796de391c2","max":26788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c02d5731f644076aec4874f2c2a5dd6","value":26788}},"46148a8bace34feebe94b46b81b068d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c88e0d06c3d499ab6f17d051aee8a96","placeholder":"​","style":"IPY_MODEL_bee78c14b5d74925af6e796319db0b5a","value":" 26.8k/26.8k [00:00&lt;00:00, 2.10MB/s]"}},"e1d3c4ec149e47c09190914d9ed3ecbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea65afad65fb4eee894b3075c48bc950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0200813b3a244a6a65414ed3d33122b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8632386f523047e89ef041796de391c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c02d5731f644076aec4874f2c2a5dd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c88e0d06c3d499ab6f17d051aee8a96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee78c14b5d74925af6e796319db0b5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b86c14205fce4c6fb41b6336a67dcab6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6850667b3164b49931145ffca2f2201","IPY_MODEL_2f87b355e7dc4044a03fea038851ed96","IPY_MODEL_5a12c9d4d7384586adbd341cb32e814a"],"layout":"IPY_MODEL_d9438c47da574f1d82e9244cc1bf47bf"}},"c6850667b3164b49931145ffca2f2201":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_994caa767895435dab51e1010c31aa4c","placeholder":"​","style":"IPY_MODEL_b41dbb4fa7e04a32875be506c993755b","value":"Downloading shards: 100%"}},"2f87b355e7dc4044a03fea038851ed96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e1bd65bcb9642cb903090da433a0a75","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b90b24aca20a4fd384ea9a0baedb938f","value":2}},"5a12c9d4d7384586adbd341cb32e814a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc5097931e6d427e90728d0d504cf699","placeholder":"​","style":"IPY_MODEL_e3a16c39f19341bab7f451ab5d7a8b06","value":" 2/2 [00:35&lt;00:00, 15.95s/it]"}},"d9438c47da574f1d82e9244cc1bf47bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"994caa767895435dab51e1010c31aa4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b41dbb4fa7e04a32875be506c993755b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e1bd65bcb9642cb903090da433a0a75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b90b24aca20a4fd384ea9a0baedb938f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc5097931e6d427e90728d0d504cf699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3a16c39f19341bab7f451ab5d7a8b06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c8b63e1e8dc4582bb7908c9e14dac83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efa3bfcc5114404cad498cd1a8cb9b75","IPY_MODEL_cf06f3f7d11a4fd08e1441928d869bb6","IPY_MODEL_0af47586ba964983a73221b7ad843f57"],"layout":"IPY_MODEL_e137d348426c4bf49093d23ccffd0339"}},"efa3bfcc5114404cad498cd1a8cb9b75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b2403f68e29478cb3ca302e168e7440","placeholder":"​","style":"IPY_MODEL_0952a92807b04be4ba6b3f462c73e179","value":"model-00001-of-00002.safetensors: 100%"}},"cf06f3f7d11a4fd08e1441928d869bb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a863af2e2a4c45ae866b8dbc4d1dda19","max":9976576152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5cd9187136ce459682c4f55b7cd44793","value":9976576152}},"0af47586ba964983a73221b7ad843f57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67c720857b7f43118040375c27b63375","placeholder":"​","style":"IPY_MODEL_b7ef79d3647a48508d6987fbace5b5b2","value":" 9.98G/9.98G [00:26&lt;00:00, 363MB/s]"}},"e137d348426c4bf49093d23ccffd0339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b2403f68e29478cb3ca302e168e7440":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0952a92807b04be4ba6b3f462c73e179":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a863af2e2a4c45ae866b8dbc4d1dda19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cd9187136ce459682c4f55b7cd44793":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67c720857b7f43118040375c27b63375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7ef79d3647a48508d6987fbace5b5b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c5a870ab79044469e66f63ffcc706f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ad7f5e439b24bc9a57869b6a3ba0cfc","IPY_MODEL_b1e4bea028954c57ac324f307f3f06cf","IPY_MODEL_d62d55a1972c4a87ac87d53c86bec411"],"layout":"IPY_MODEL_2bde9d400eff4a5e92c468f816c42551"}},"3ad7f5e439b24bc9a57869b6a3ba0cfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34b9465015b84157bf699227f0b2cb8f","placeholder":"​","style":"IPY_MODEL_e1fa060e5ab14249b8c236966c0271fe","value":"model-00002-of-00002.safetensors: 100%"}},"b1e4bea028954c57ac324f307f3f06cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4663d312e0544bfbaa61bc18b13fd35f","max":3500296424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a80b88cb7eb4628b5886d50397e4291","value":3500296424}},"d62d55a1972c4a87ac87d53c86bec411":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68102d9c1d5648d1b1eb29610e679f11","placeholder":"​","style":"IPY_MODEL_5af4d04c26324fcea7ea203c6ed9bf7e","value":" 3.50G/3.50G [00:08&lt;00:00, 490MB/s]"}},"2bde9d400eff4a5e92c468f816c42551":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34b9465015b84157bf699227f0b2cb8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1fa060e5ab14249b8c236966c0271fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4663d312e0544bfbaa61bc18b13fd35f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a80b88cb7eb4628b5886d50397e4291":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68102d9c1d5648d1b1eb29610e679f11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af4d04c26324fcea7ea203c6ed9bf7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"303e3f8f23b243d99e0a053660c8bb0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_437621bdde044243bfcbabb954347b0f","IPY_MODEL_e565e92cb45e466f8add8e84f6b736e5","IPY_MODEL_3be8b65654df4a8fbc6bf047f72d5d1e"],"layout":"IPY_MODEL_f3bb22d4b1af4402b775af1cc448f6db"}},"437621bdde044243bfcbabb954347b0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73baa99447d14a5fac76cff029897c65","placeholder":"​","style":"IPY_MODEL_58fef4cf3dad4a2a9198a8bf09f7ec47","value":"Loading checkpoint shards: 100%"}},"e565e92cb45e466f8add8e84f6b736e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2010397cf56349aca695dbda1e234429","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fac1f4c303840f68758c1bdb6d471c9","value":2}},"3be8b65654df4a8fbc6bf047f72d5d1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efaea2963bb24abab31b822daf5d2d9b","placeholder":"​","style":"IPY_MODEL_54bbe5b7b8a04328a5263455b8585e06","value":" 2/2 [00:04&lt;00:00,  1.95s/it]"}},"f3bb22d4b1af4402b775af1cc448f6db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73baa99447d14a5fac76cff029897c65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58fef4cf3dad4a2a9198a8bf09f7ec47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2010397cf56349aca695dbda1e234429":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fac1f4c303840f68758c1bdb6d471c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"efaea2963bb24abab31b822daf5d2d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54bbe5b7b8a04328a5263455b8585e06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e737b413feb4fb98d819dd2a225793f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a19cb10e8a26470db5a4dd11985f52e1","IPY_MODEL_40eee73319734c408579e312638535fb","IPY_MODEL_89b4b0c2afc344e8b7fe60fd6eeed28e"],"layout":"IPY_MODEL_45dffd7a919f495e8abc2f636f1fa882"}},"a19cb10e8a26470db5a4dd11985f52e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3cc93bdc76f45f59ea7d666abeeb309","placeholder":"​","style":"IPY_MODEL_2b1a9c3230bf4c518d83284c1381a993","value":"generation_config.json: 100%"}},"40eee73319734c408579e312638535fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0343791029b14b0aa68edc7af2a55b8e","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9da5e71319334e6493f5b243ae72c717","value":188}},"89b4b0c2afc344e8b7fe60fd6eeed28e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_240e7d8fe4544bffba053f7390e1df3b","placeholder":"​","style":"IPY_MODEL_52cbfb7aee1742c8a2caa3c6c6154fd5","value":" 188/188 [00:00&lt;00:00, 15.2kB/s]"}},"45dffd7a919f495e8abc2f636f1fa882":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3cc93bdc76f45f59ea7d666abeeb309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b1a9c3230bf4c518d83284c1381a993":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0343791029b14b0aa68edc7af2a55b8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9da5e71319334e6493f5b243ae72c717":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"240e7d8fe4544bffba053f7390e1df3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52cbfb7aee1742c8a2caa3c6c6154fd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"code","source":["save_files = True"],"metadata":{"id":"KSKP_OsTDki6","executionInfo":{"status":"ok","timestamp":1716932747865,"user_tz":240,"elapsed":53,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0","executionInfo":{"status":"ok","timestamp":1716932821956,"user_tz":240,"elapsed":74142,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1716932825952,"user_tz":240,"elapsed":4043,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1716932828561,"user_tz":240,"elapsed":2624,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer #, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","executionInfo":{"status":"ok","timestamp":1716932828561,"user_tz":240,"elapsed":33,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy","executionInfo":{"status":"ok","timestamp":1716932828562,"user_tz":240,"elapsed":33,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716932831231,"user_tz":240,"elapsed":2702,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b67c53b6-c618-44be-999b-19110200a0cf","id":"F8TXMRL3CoPd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 875, done.\u001b[K\n","remote: Counting objects: 100% (341/341), done.\u001b[K\n","remote: Compressing objects: 100% (223/223), done.\u001b[K\n","remote: Total 875 (delta 187), reused 257 (delta 107), pack-reused 534\u001b[K\n","Receiving objects: 100% (875/875), 16.78 MiB | 14.70 MiB/s, done.\n","Resolving deltas: 100% (550/550), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","# don't improt this\n","# # from dataset import Dataset\n","\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ","executionInfo":{"status":"ok","timestamp":1716932831231,"user_tz":240,"elapsed":56,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a dict whose values are tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R","executionInfo":{"status":"ok","timestamp":1716932831232,"user_tz":240,"elapsed":56,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_longer(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text\n","        # 'text': model.to_string(tokens)[0]\n","        }\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    # for i, tok in enumerate(tokens):\n","    #     prompt_dict['S'+str(i)] = model.to_string(tok)\n","\n","    # prompt_dict = {\n","    #     'corr': '4',\n","    #     'incorr': '3',\n","    #     'text': model.to_string(tokens)[0]\n","    # }\n","    # # list_tokens = tokenizer.tokenize('1 2 3 ')\n","    # tokens_as_strs = model.to_string(tokens)[0].split()\n","    # for i, tok_as_str in enumerate(tokens_as_strs):\n","    #     if tok_as_str == '▁':\n","    #         prompt_dict['S'+str(i)] = ' '\n","    #     else:\n","    #         prompt_dict['S'+str(i)] = tok_as_str\n","    prompts_list.append(prompt_dict)\n","    return prompts_list"],"metadata":{"id":"VZKVG778QYyn","executionInfo":{"status":"ok","timestamp":1716932831232,"user_tz":240,"elapsed":55,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDP2cpaiZpPX"},"source":["# Load Model"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"OGCiZUPpJUsD","executionInfo":{"status":"ok","timestamp":1716932900776,"user_tz":240,"elapsed":365,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10319,"status":"ok","timestamp":1716932911664,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"-CocJpgjsf_M","outputId":"52e6e125-ee54-4bcf-be75-6bf5646250a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493,"referenced_widgets":["c93968b5ce16445ba72e96add1c4b5a2","959d9503d90f4067a126e614ce93e767","0cd68b11a7b043b1a7d5bf997a128a59","50d7d07d9c7740318a0c5beb9fdf73a7","21f5b1ded59e40c0b06b48e6ec2e0b03","5bae4338f69c45f99ccb2634f1fc5a24","35a1d5174a504ccf88d5e00059f8d95f","8df5b78df2f44860baa627c8ea9886de","e2ee0893dd9f4c02b34d1c3addb9de9b","920c9ab2fa4c4fbfa5ea6c56e1a8bd6c","9541b1edc6934e158d7a37c17d034b3a","374f9bd0f01d4a6ba64128f6ccdbf6fd","23199af7a2eb42c9b894a6f945f48380","118959f698694ed386355af7f05ee893","2f528f55a5724c7099b9c98bdf73eca2","de1f874e373a4dab98316f885075a96e","ae52e94d87e645b588a640ef058497a3","641504db5741474a8e4fcf4a912d99aa","a2a6158f689a4a2a88605a02807d0252","dbaf21af746443d3bd2cb1271b05e045","0d6af86e80e44044b483cafa9df69907","84e3df7c8e944b33bbc13f482a8ecec4","4c3bcd2ff119469eaf91f1d610f1f321","5d99c5ed7aa244ddb7d49f0f2d282a2c","77cb403bf3fb4950926da2e52becf40d","c1776ad89f2f4675860ff39bf9db4134","e61f1dc517954acca0a28732603785c2","d02159dbbb414f63bf9d029aed48d67c","cd8fbc712c89494786a5fed08deb411a","3f942f6875ab4aad94b7ee0b897a7bae","8f08e1c9e2b34065975061448604383d","5ecb600f1bc5420d8f4ce6f4e2eb2074","48d59a4c84e64c3bb8ed0e82834e6471","d43943044a1949a3aadfbd45fb4c871c","5b6216e4dd6e4a09b4d070c9d656a2ed","bb34db9ab0904562b4de75a4fce7accc","9d6e2d826c2548a3a7bf108cf0641a35","d1b4505dbec94156b65956d476196101","3b159c386f6d4b7b834ef467ce9cf819","3c10c26fefdc4e9f9604963c4e891128","bfd8bf86da484ea3902c93e6799b6e88","f4869ece04b241c2bd8d48991b9e8369","6cbf55c94c9c4e989f98250842e56f78","50f80daacee040d49012813f21cc167a","ba6cbcafbe2d4c4d9133b544d1043178","6caa608d807e4b04aa0e79cd789c2803","7d13ebcc3b394419918b7b050a13baa0","9f7da7f11d1242429e2b8b1c67e4b554","7df1f23ea9094d1188b014aa123e2456","3c6d0e1de20c46ae96fa42adffb7ad81","51fa090dc17c45d0b9b13e58ef122d79","cf17c8967725445dbac890a81018e3ec","5b9688953de34e03ace0933611bfdcb6","7b89d3fbd6ef4e80a9bf4f5541079278","9ea04b0d5dc845ff981e677d23aab03a","2d96e145e9244adc9ab3c18441b6420b","ed52dd32ff664c9ebd8e78219622c97f","4adeb2b2536c47cda2b99d84b1133606","46148a8bace34feebe94b46b81b068d9","e1d3c4ec149e47c09190914d9ed3ecbf","ea65afad65fb4eee894b3075c48bc950","d0200813b3a244a6a65414ed3d33122b","8632386f523047e89ef041796de391c2","7c02d5731f644076aec4874f2c2a5dd6","5c88e0d06c3d499ab6f17d051aee8a96","bee78c14b5d74925af6e796319db0b5a","b86c14205fce4c6fb41b6336a67dcab6","c6850667b3164b49931145ffca2f2201","2f87b355e7dc4044a03fea038851ed96","5a12c9d4d7384586adbd341cb32e814a","d9438c47da574f1d82e9244cc1bf47bf","994caa767895435dab51e1010c31aa4c","b41dbb4fa7e04a32875be506c993755b","8e1bd65bcb9642cb903090da433a0a75","b90b24aca20a4fd384ea9a0baedb938f","dc5097931e6d427e90728d0d504cf699","e3a16c39f19341bab7f451ab5d7a8b06","5c8b63e1e8dc4582bb7908c9e14dac83","efa3bfcc5114404cad498cd1a8cb9b75","cf06f3f7d11a4fd08e1441928d869bb6","0af47586ba964983a73221b7ad843f57","e137d348426c4bf49093d23ccffd0339","0b2403f68e29478cb3ca302e168e7440","0952a92807b04be4ba6b3f462c73e179","a863af2e2a4c45ae866b8dbc4d1dda19","5cd9187136ce459682c4f55b7cd44793","67c720857b7f43118040375c27b63375","b7ef79d3647a48508d6987fbace5b5b2","8c5a870ab79044469e66f63ffcc706f8","3ad7f5e439b24bc9a57869b6a3ba0cfc","b1e4bea028954c57ac324f307f3f06cf","d62d55a1972c4a87ac87d53c86bec411","2bde9d400eff4a5e92c468f816c42551","34b9465015b84157bf699227f0b2cb8f","e1fa060e5ab14249b8c236966c0271fe","4663d312e0544bfbaa61bc18b13fd35f","3a80b88cb7eb4628b5886d50397e4291","68102d9c1d5648d1b1eb29610e679f11","5af4d04c26324fcea7ea203c6ed9bf7e","303e3f8f23b243d99e0a053660c8bb0b","437621bdde044243bfcbabb954347b0f","e565e92cb45e466f8add8e84f6b736e5","3be8b65654df4a8fbc6bf047f72d5d1e","f3bb22d4b1af4402b775af1cc448f6db","73baa99447d14a5fac76cff029897c65","58fef4cf3dad4a2a9198a8bf09f7ec47","2010397cf56349aca695dbda1e234429","8fac1f4c303840f68758c1bdb6d471c9","efaea2963bb24abab31b822daf5d2d9b","54bbe5b7b8a04328a5263455b8585e06","7e737b413feb4fb98d819dd2a225793f","a19cb10e8a26470db5a4dd11985f52e1","40eee73319734c408579e312638535fb","89b4b0c2afc344e8b7fe60fd6eeed28e","45dffd7a919f495e8abc2f636f1fa882","d3cc93bdc76f45f59ea7d666abeeb309","2b1a9c3230bf4c518d83284c1381a993","0343791029b14b0aa68edc7af2a55b8e","9da5e71319334e6493f5b243ae72c717","240e7d8fe4544bffba053f7390e1df3b","52cbfb7aee1742c8a2caa3c6c6154fd5"]},"executionInfo":{"elapsed":45390,"status":"ok","timestamp":1716932957036,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"xLgpia0tI6O8","outputId":"525da641-da0e-4857-8c41-e8e2ea900fb6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c93968b5ce16445ba72e96add1c4b5a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374f9bd0f01d4a6ba64128f6ccdbf6fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c3bcd2ff119469eaf91f1d610f1f321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d43943044a1949a3aadfbd45fb4c871c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6cbcafbe2d4c4d9133b544d1043178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d96e145e9244adc9ab3c18441b6420b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b86c14205fce4c6fb41b6336a67dcab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c8b63e1e8dc4582bb7908c9e14dac83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c5a870ab79044469e66f63ffcc706f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"303e3f8f23b243d99e0a053660c8bb0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e737b413feb4fb98d819dd2a225793f"}},"metadata":{}}],"source":["LLAMA_2_7B_CHAT_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n","\n","tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH)\n","# tokenizer = LlamaTokenizer.from_pretrained(LLAMA_2_7B_CHAT_PATH, use_fast= False, add_prefix_space= False)\n","hf_model = LlamaForCausalLM.from_pretrained(LLAMA_2_7B_CHAT_PATH, low_cpu_mem_usage=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"_rtZ2e3sMY5S","executionInfo":{"status":"ok","timestamp":1716932957037,"user_tz":240,"elapsed":76,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import transformer_lens.utils as utils\n","from transformer_lens.hook_points import HookPoint\n","from transformer_lens import HookedTransformer"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30124,"status":"ok","timestamp":1716932987088,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"sUnSHvA-Myx8","outputId":"4c4f8b87-c458-47c8-b588-722172f5e8d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n","Moving model to device:  cuda\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    LLAMA_2_7B_CHAT_PATH,\n","    hf_model = hf_model,\n","    tokenizer = tokenizer,\n","    device = \"cpu\",\n","    fold_ln = False,\n","    center_writing_weights = False,\n","    center_unembed = False,\n",")\n","\n","del hf_model\n","\n","model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["# new functions"],"metadata":{"id":"dsdvChbcvgp5"}},{"cell_type":"code","source":["# class Dataset:\n","#     def __init__(self, prompts, pos_dict, tokenizer, tokens):  # , S1_is_first=False\n","#         self.prompts = prompts\n","#         self.tokenizer = tokenizer\n","#         self.N = len(prompts)\n","#         self.max_len = max(\n","#             [\n","#                 len(self.tokenizer(prompt[\"text\"]).input_ids)\n","#                 for prompt in self.prompts\n","#             ]\n","#         )\n","#         all_ids = [0 for prompt in self.prompts] # only 1 template\n","#         all_ids_ar = np.array(all_ids)\n","#         self.groups = []\n","#         for id in list(set(all_ids)):\n","#             self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","#         texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","#         # self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","#         #     torch.int\n","#         # )\n","#         self.toks = tokens\n","#         self.corr_tokenIDs = [\n","#             # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","#             self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","#         ]\n","#         self.incorr_tokenIDs = [\n","#             # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","#             self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","#         ]\n","\n","#         # word_idx: for every prompt, find the token index of each target token and \"end\"\n","#         # word_idx is a dict whose values are tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","#         self.word_idx = {}\n","#         # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","#         for targ in [key for key in pos_dict]:\n","#             targ_lst = []\n","#             for prompt in self.prompts:\n","#                 input_text = prompt[\"text\"]\n","#                 # tokens = self.tokenizer.tokenize(input_text)\n","#                 # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","#                 #     target_token = prompt[targ]\n","#                 # else:\n","#                 #     target_token = \"Ġ\" + prompt[targ]\n","#                 # target_index = tokens.index(target_token)\n","#                 target_index = pos_dict[targ]\n","#                 targ_lst.append(target_index)\n","#             self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","#         # targ_lst = []\n","#         # for prompt in self.prompts:\n","#         #     input_text = prompt[\"text\"]\n","#         #     tokens = self.tokenizer.tokenize(input_text)\n","#         #     end_token_index = len(tokens) - 1\n","#         #     targ_lst.append(end_token_index)\n","#         # self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","#     def __len__(self):\n","#         return self.N"],"metadata":{"id":"PfyVT_0Vvhjm","executionInfo":{"status":"ok","timestamp":1716933828136,"user_tz":240,"elapsed":655,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def get_heads_actv_mean(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Output: The mean activations of a head's output\n","    '''\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    # for layer in range(model.cfg.n_layers):\n","    #     z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","    #     for template_group in means_dataset.groups:\n","    #         z_for_this_template = z_for_this_layer[template_group]\n","    #         z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","    #         if z_means_for_this_template.shape[0] == 5:\n","    #             pdb.set_trace()\n","    #         means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means"],"metadata":{"id":"6KlWYoEy72Cf","executionInfo":{"status":"ok","timestamp":1716933829015,"user_tz":240,"elapsed":92,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# def mask_circ_heads(\n","#     means_dataset: Dataset,\n","#     model: HookedTransformer,\n","#     circuit: Dict[str, List[Tuple[int, int]]],\n","#     seq_pos_to_keep: Dict[str, str],\n","# ) -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","#     '''\n","#     Output: for each layer, a mask of circuit components that should not be ablated\n","#     '''\n","#     heads_and_posns_to_keep = {}\n","#     batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","#     for layer in range(model.cfg.n_layers):\n","\n","#         mask = t.zeros(size=(batch, seq, n_heads))\n","\n","#         for (head_type, head_list) in circuit.items():\n","#             seq_pos = seq_pos_to_keep[head_type]\n","#             # if seq_pos == 'S7':\n","#             #     pdb.set_trace()\n","#             indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","#             for (layer_idx, head_idx) in head_list:\n","#                 if layer_idx == layer:\n","#                     # if indices.item() == 7:\n","#                     #     pdb.set_trace()\n","#                     mask[:, indices, head_idx] = 1\n","#                     # mask[:, :, head_idx] = 1  # keep L.H at all pos\n","\n","#         heads_and_posns_to_keep[layer] = mask.bool()\n","#     # pdb.set_trace()\n","#     return heads_and_posns_to_keep"],"metadata":{"id":"bFDQMOt9CyVw","executionInfo":{"status":"ok","timestamp":1716933829015,"user_tz":240,"elapsed":91,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def mask_circ_heads(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Output: for each layer, a mask of circuit components that should not be ablated\n","    '''\n","    heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","    batch, seq, n_heads = len(means_dataset), len(circuit.keys()), model.cfg.n_heads\n","    print(seq)\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    # mask[:, indices, head_idx] = 1\n","                    mask[:, :, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep"],"metadata":{"id":"E1boH1469_HI","executionInfo":{"status":"ok","timestamp":1716933829015,"user_tz":240,"elapsed":91,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def hook_func_mask_head(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    # components_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    # means: Float[Tensor, \"layer batch seq head d_head\"],\n","    circuit: Dict[str, List[Tuple[int, int]]],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Use this to not mask components\n","    '''\n","    # mask_for_this_layer = components_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","    # z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    ###\n","    # heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = z.shape[0], z.shape[1], model.cfg.n_heads  # components_to_keep[0].shape[0] is batch\n","\n","    # for layer in range(model.cfg.n_layers):\n","\n","    #     mask = t.zeros(size=(batch, seq, n_heads))\n","\n","    #     for (head_type, head_list) in circuit.items():\n","    #         # seq_pos = seq_pos_to_keep[head_type]\n","    #         # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","    #         for (layer_idx, head_idx) in head_list:\n","    #             if layer_idx == layer:\n","    #                 # mask[:, indices, head_idx] = 1\n","    #                 mask[:, :, head_idx] = 1\n","\n","    #     heads_and_posns_to_keep[layer] = mask.bool()\n","    ###\n","    mask_for_this_layer = t.zeros(size=(z.shape[0], z.shape[1], z.shape[2]))\n","    for (head_type, head_list) in circuit.items():\n","        # seq_pos = seq_pos_to_keep[head_type]\n","        # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","        for (layer_idx, head_idx) in head_list:\n","            if layer_idx == hook.layer():\n","                # mask[:, indices, head_idx] = 1\n","                mask_for_this_layer[:, :, head_idx] = 1\n","\n","    mask_for_this_layer = mask_for_this_layer.bool()\n","    mask_for_this_layer = mask_for_this_layer.unsqueeze(-1).to(z.device)  # d_model is 1; then is broadcast in where\n","\n","    z = t.where(mask_for_this_layer, z, 0)\n","\n","    return z"],"metadata":{"id":"KdxeNJ5C9tHx","executionInfo":{"status":"ok","timestamp":1716933829016,"user_tz":240,"elapsed":91,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def add_ablation_hook_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Ablate the model, except as components and positions to keep\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","    means = get_heads_actv_mean(means_dataset, model)\n","    components_to_keep = mask_circ_heads(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=circuit,\n","    )\n","\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","    return model"],"metadata":{"id":"dg3XuWScAVvG","executionInfo":{"status":"ok","timestamp":1716933829016,"user_tz":240,"elapsed":91,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# from dataset import Dataset\n","from transformer_lens import HookedTransformer, utils\n","from transformer_lens.hook_points import HookPoint\n","import einops\n","from functools import partial\n","import torch as t\n","from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool\n","\n","# from head_ablation_fns import *\n","# from mlp_ablation_fns import *\n","\n","def add_ablation_hook_MLP_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    heads_lst, mlp_lst,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        CIRCUIT['S'+str(i)] = heads_lst\n","        # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","        # if i == num_pos - 1:\n","        #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        # else:\n","        SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = get_heads_actv_mean(means_dataset, model)\n","    # Convert this into a boolean map\n","    components_to_keep = mask_circ_heads(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=CIRCUIT,\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    # if all_entries_true(components_to_keep) == False:\n","    #     pdb.set_trace()\n","    ########################\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","    # # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    # num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    # for i in range(num_pos ):\n","    #     CIRCUIT['S'+str(i)] = mlp_lst\n","    #     # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","    #     # if i == num_pos - 1:\n","    #     #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","    #     # else:\n","    #     SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    # # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    # means = get_MLPs_actv_mean(means_dataset, model)\n","\n","    # # Convert this into a boolean map\n","    # components_to_keep = mask_circ_MLPs(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # # Get a hook function which will patch in the mean z values for each head, at\n","    # # all positions which aren't important for the circuit\n","    # hook_fn = partial(\n","    #     hook_func_mask_mlp_out,\n","    #     components_to_keep=components_to_keep,\n","    #     means=means\n","    # )\n","\n","    # model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"6ILjxwH9YUYP","executionInfo":{"status":"ok","timestamp":1716933829016,"user_tz":240,"elapsed":91,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def all_entries_true(tensor_dict):\n","    for key, tensor in tensor_dict.items():\n","        if not torch.all(tensor).item():\n","            return False\n","    return True"],"metadata":{"id":"u-YuOEDieLgE","executionInfo":{"status":"ok","timestamp":1716933829016,"user_tz":240,"elapsed":90,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["# ablation fns mult tok answers"],"metadata":{"id":"jtaV1q3SBHow"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    # tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","        # if next_char == '':\n","        #     next_char = ' '\n","        # clean_text = clean_text + next_char\n","        # tokens = model.to_tokens(clean_text).to(device)\n","    return corr_ans_tokLen"],"metadata":{"id":"WgbtY5fFPb71","executionInfo":{"status":"ok","timestamp":1716933829990,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_ans = ' 5'\n","corr_ans_tokLen = clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7ScEnVdeJwD","executionInfo":{"status":"ok","timestamp":1716933831967,"user_tz":240,"elapsed":1997,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e8d95534-f7a7-4e1b-cc73-a6fb3d1fc2b7"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> 1 2 3'\n","logit diff of new char: tensor([16.3678], device='cuda:0')\n","8th char = ''\n","Sequence so far: '<s> 1 2 3 '\n","logit diff of new char: tensor([19.4441], device='cuda:0')\n","9th char = '4'\n","Sequence so far: '<s> 1 2 3 4'\n","logit diff of new char: tensor([20.5775], device='cuda:0')\n","10th char = ''\n","Sequence so far: '<s> 1 2 3 4 '\n","logit diff of new char: tensor([19.2083], device='cuda:0')\n","11th char = '5'\n","Sequence so far: '<s> 1 2 3 4 5'\n","logit diff of new char: tensor([18.8848], device='cuda:0')\n","12th char = ''\n"]}]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    # for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    # for i in range(num_pos + 1):\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, tokens)\n","    # pdb.set_trace()\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    # tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    for i in range(corr_ans_tokLen):\n","    # for i in range(5):\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        # tokens = model.to_tokens(clean_text).to(device)\n","        # tokens = tokens[:, 1:]\n","        print(f\"Sequence so far: {clean_text}\")\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        # clean_text = model.to_string(tokens)[0]\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","        # print(clean_text)\n","        # print(tokens.shape)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # # corr_tokens = model.to_tokens(corr_text).to(device)\n","\n","        # # corr_text = model.to_string(corr_tokens)[0]\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","        # print(corr_text)\n","        # # print(corr_tokens.shape)\n","\n","        # pos_dict = {}\n","        # # for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","        # # for i in range(corr_tokens.shape[1]):\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # # for i in range(num_pos + 1):\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        # print('\\n')\n","        # print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())"],"metadata":{"id":"lp4MyZ52cUTK","executionInfo":{"status":"ok","timestamp":1716933831969,"user_tz":240,"elapsed":64,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["# test clean prompts"],"metadata":{"id":"NzaS2VB65KcX"}},{"cell_type":"code","source":["# clean_text = \"1\"\n","# tokens = model.to_tokens(clean_text).to(device)\n","# tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","# # tokens = model.tokenizer(clean_text)['input_ids']\n","# logits = model(tokens)\n","# next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","# next_char = model.to_string(next_token)\n","\n","clean_text = \"1\"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911283517,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9de5654b-6e25-481b-a727-1852765b0e24","id":"QskNkr65Bqhy"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> 1'\n","logit diff of new char: tensor([12.9576], device='cuda:0')\n","4th char = '.'\n","Sequence so far: '<s> 1.'\n","logit diff of new char: tensor([5.0549], device='cuda:0')\n","5th char = ''\n","Sequence so far: '<s> 1. '\n","logit diff of new char: tensor([8.5630], device='cuda:0')\n","6th char = 'Introduction'\n","Sequence so far: '<s> 1.  Introduction'\n","logit diff of new char: tensor([19.3782], device='cuda:0')\n","7th char = '<0x0A>'\n","Sequence so far: '<s> 1.  Introduction\\n'\n","logit diff of new char: tensor([12.2388], device='cuda:0')\n","8th char = '<0x0A>'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["clean_text = \"two\"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uU9Gdw8ZB1yi","executionInfo":{"status":"ok","timestamp":1716911285001,"user_tz":240,"elapsed":1509,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"06b7d4f3-ab63-4d7c-af35-a5cc01dd0efe"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> two'\n","logit diff of new char: tensor([5.4994], device='cuda:0')\n","3th char = '-'\n","Sequence so far: '<s> two-'\n","logit diff of new char: tensor([10.8123], device='cuda:0')\n","4th char = 'time'\n","Sequence so far: '<s> two-time'\n","logit diff of new char: tensor([10.4234], device='cuda:0')\n","5th char = 'Pul'\n","Sequence so far: '<s> two-time Pul'\n","logit diff of new char: tensor([24.6146], device='cuda:0')\n","6th char = 'itzer'\n","Sequence so far: '<s> two-time Pulitzer'\n","logit diff of new char: tensor([22.3427], device='cuda:0')\n","7th char = 'Prize'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["clean_text = \"March\"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_E-r4CmDQKj","executionInfo":{"status":"ok","timestamp":1716911285001,"user_tz":240,"elapsed":18,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a6eadbe-35e0-4d1a-e328-3787a241459c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> March'\n","logit diff of new char: tensor([17.5723], device='cuda:0')\n","3th char = ''\n","Sequence so far: '<s> March '\n","logit diff of new char: tensor([19.5974], device='cuda:0')\n","4th char = '2'\n","Sequence so far: '<s> March 2'\n","logit diff of new char: tensor([18.3477], device='cuda:0')\n","5th char = '0'\n","Sequence so far: '<s> March 20'\n","logit diff of new char: tensor([20.1788], device='cuda:0')\n","6th char = '1'\n","Sequence so far: '<s> March 201'\n","logit diff of new char: tensor([19.7587], device='cuda:0')\n","7th char = '7'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["clean_text = \"Bob is first. David is\"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97-q7H6FDYcy","executionInfo":{"status":"ok","timestamp":1716911286233,"user_tz":240,"elapsed":1247,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6b9cdea3-c266-4ac6-da2e-cbfc15f8b592"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> Bob is first. David is'\n","logit diff of new char: tensor([13.4227], device='cuda:0')\n","8th char = 'second'\n","Sequence so far: '<s> Bob is first. David is second'\n","logit diff of new char: tensor([20.7910], device='cuda:0')\n","9th char = '.'\n","Sequence so far: '<s> Bob is first. David is second.'\n","logit diff of new char: tensor([12.5447], device='cuda:0')\n","10th char = '<0x0A>'\n","Sequence so far: '<s> Bob is first. David is second.\\n'\n","logit diff of new char: tensor([11.2046], device='cuda:0')\n","11th char = '<0x0A>'\n","Sequence so far: '<s> Bob is first. David is second.\\n\\n'\n","logit diff of new char: tensor([11.9983], device='cuda:0')\n","12th char = 'Bob'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["clean_text = \"Two days after Monday is\"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911286770,"user_tz":240,"elapsed":555,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"40a7e3aa-a5b7-46df-d564-9cacc6eef3fc","id":"4XlBEm6s5NVK"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> Two days after Monday is'\n","logit diff of new char: tensor([17.0134], device='cuda:0')\n","7th char = 'T'\n","Sequence so far: '<s> Two days after Monday is T'\n","logit diff of new char: tensor([22.0867], device='cuda:0')\n","8th char = 'ues'\n","Sequence so far: '<s> Two days after Monday is Tues'\n","logit diff of new char: tensor([27.3643], device='cuda:0')\n","9th char = 'day'\n","Sequence so far: '<s> Two days after Monday is Tuesday'\n","logit diff of new char: tensor([18.9252], device='cuda:0')\n","10th char = '.'\n","Sequence so far: '<s> Two days after Monday is Tuesday.'\n","logit diff of new char: tensor([10.3426], device='cuda:0')\n","11th char = '<0x0A>'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["clean_text = \"uno dos tres\"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911287934,"user_tz":240,"elapsed":1180,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b86e2854-3693-4224-b741-57f486f4f9f9","id":"m2SEHJ0K9HCm"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> uno dos tres'\n","logit diff of new char: tensor([7.8090], device='cuda:0')\n","5th char = 'cuatro'\n","Sequence so far: '<s> uno dos tres cuatro'\n","logit diff of new char: tensor([9.7915], device='cuda:0')\n","6th char = 'cinco'\n","Sequence so far: '<s> uno dos tres cuatro cinco'\n","logit diff of new char: tensor([9.3842], device='cuda:0')\n","7th char = 'seis'\n","Sequence so far: '<s> uno dos tres cuatro cinco seis'\n","logit diff of new char: tensor([12.1068], device='cuda:0')\n","8th char = 'seven'\n","Sequence so far: '<s> uno dos tres cuatro cinco seis seven'\n","logit diff of new char: tensor([16.4966], device='cuda:0')\n","9th char = 'eight'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["clean_text = \"one two three\"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"id":"lZF_IjOw9KcI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911288698,"user_tz":240,"elapsed":857,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d7888a72-3420-4468-af4e-70fcbdd23905"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> one two three'\n","logit diff of new char: tensor([10.4469], device='cuda:0')\n","5th char = 'four'\n","Sequence so far: '<s> one two three four'\n","logit diff of new char: tensor([16.2546], device='cuda:0')\n","6th char = 'five'\n","Sequence so far: '<s> one two three four five'\n","logit diff of new char: tensor([15.9061], device='cuda:0')\n","7th char = 'six'\n","Sequence so far: '<s> one two three four five six'\n","logit diff of new char: tensor([18.5995], device='cuda:0')\n","8th char = 'seven'\n","Sequence so far: '<s> one two three four five six seven'\n","logit diff of new char: tensor([18.7767], device='cuda:0')\n","9th char = 'eight'\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["clean_text = \"2 4 6 \"\n","corr_ans_tokLen = 3\n","clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvQKFsInijSr","executionInfo":{"status":"ok","timestamp":1716911288699,"user_tz":240,"elapsed":30,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"97e8a2fb-ba44-4bf8-8503-e4b0e4328e57"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '<s> 2 4 6 '\n","logit diff of new char: tensor([19.3199], device='cuda:0')\n","9th char = '8'\n","Sequence so far: '<s> 2 4 6 8'\n","logit diff of new char: tensor([9.7377], device='cuda:0')\n","10th char = ''\n","Sequence so far: '<s> 2 4 6 8 '\n","logit diff of new char: tensor([16.1787], device='cuda:0')\n","11th char = '1'\n","Sequence so far: '<s> 2 4 6 8 1'\n","logit diff of new char: tensor([22.3343], device='cuda:0')\n","12th char = '0'\n","Sequence so far: '<s> 2 4 6 8 10'\n","logit diff of new char: tensor([7.2428], device='cuda:0')\n","13th char = ''\n"]},{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["# 1 2 3 genr ablation expms"],"metadata":{"id":"H5H-d2URUSVJ"}},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"id":"rseVgwqtjnCc","executionInfo":{"status":"ok","timestamp":1716940295106,"user_tz":240,"elapsed":404,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"ljNX9lNhluyZ"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIybRyE9lsRL","executionInfo":{"status":"ok","timestamp":1716911878064,"user_tz":240,"elapsed":1808,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4414fbfc-6075-4b31-a492-c931578730ea"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","9th char = ' '\n","Sequence so far: 1 2 3 4\n","10th char = '4'\n","Sequence so far: 1 2 3 4 \n","11th char = ' '\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"KV7Dknbr66qv"}},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\"\n","heads_not_ablate = []  # ablate all heads but not MLPs\n","mlps_not_ablate = []  # ablate all MLPs\n","corr_ans_tokLen = 2\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmBaWRhCctue","executionInfo":{"status":"ok","timestamp":1716911883121,"user_tz":240,"elapsed":1610,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"90530d51-a47b-4c01-dc75-84b210256aa1"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 39\n","9th char = '9'\n","Sequence so far: 1 2 399\n","10th char = '9'\n"]}]},{"cell_type":"markdown","source":["ablate just head 20.7"],"metadata":{"id":"cvDoLG2YR73k"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate.remove((20, 7))\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFezBzOtje6o","executionInfo":{"status":"ok","timestamp":1716911893660,"user_tz":240,"elapsed":2111,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e101a6b5-db20-4d35-d9da-6a0827d5b037"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","9th char = ' '\n","Sequence so far: 1 2 3 4\n","10th char = '4'\n","Sequence so far: 1 2 3 4 \n","11th char = ' '\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 7), (1, 11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911900195,"user_tz":240,"elapsed":1662,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"05269f4a-70be-4092-c639-6219393580e0","id":"HYIdJj637K7f"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","9th char = ' '\n","Sequence so far: 1 2 3 4\n","10th char = '4'\n","Sequence so far: 1 2 3 4 \n","11th char = ' '\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 7), (1, 11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32) if layer != 1]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCzNXhYb7ZZ0","executionInfo":{"status":"ok","timestamp":1716911901324,"user_tz":240,"elapsed":1150,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5f4be4b6-e792-43b3-fa14-9c1e93bd49b3"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","9th char = ' '\n","Sequence so far: 1 2 3 4\n","10th char = '4'\n","Sequence so far: 1 2 3 4 \n","11th char = ' '\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 7), (1, 11), (16,0)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32) if layer != 1]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZRogWK27ih7","executionInfo":{"status":"ok","timestamp":1716911910513,"user_tz":240,"elapsed":2259,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"18814420-1b2a-4480-a274-d2a78932a060"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","9th char = ' '\n","Sequence so far: 1 2 3 4\n","10th char = '4'\n","Sequence so far: 1 2 3 4 \n","11th char = ' '\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 7), (1, 11), (16,0)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32) if layer <10]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnVpxOu17vjj","executionInfo":{"status":"ok","timestamp":1716911914452,"user_tz":240,"elapsed":2705,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"383220cc-7849-4c2c-b071-c5e0118220b2"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","9th char = ' '\n","Sequence so far: 1 2 3 4\n","10th char = '4'\n","Sequence so far: 1 2 3 4 \n","11th char = ' '\n"]}]},{"cell_type":"code","source":["heads_not_ablate = []\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpNVPp-A70uP","executionInfo":{"status":"ok","timestamp":1716911919222,"user_tz":240,"elapsed":1480,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5b3360a9-4827-45a0-e4a2-967c65fdcbf1"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 39\n","9th char = '9'\n","Sequence so far: 1 2 399\n","10th char = '9'\n","Sequence so far: 1 2 3999\n","11th char = '9'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 7), (1, 11), (16,0), (0, 30), (0, 9), (15,25)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJwhb2IX79yK","executionInfo":{"status":"ok","timestamp":1716911925547,"user_tz":240,"elapsed":2567,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"aef52d93-bfa3-48c9-8354-0c08732d8fbb"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","9th char = ' '\n","Sequence so far: 1 2 3 4\n","10th char = '4'\n","Sequence so far: 1 2 3 4 \n","11th char = ' '\n"]}]},{"cell_type":"markdown","source":["## top 20"],"metadata":{"id":"flRU1Ze8nRGB"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove_months = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","head_to_remove_num = head_to_remove_num[:20]\n","head_to_remove_months = head_to_remove_months[:20]\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ta_8DYXXnTTE","executionInfo":{"status":"ok","timestamp":1716940347157,"user_tz":240,"elapsed":4830,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"56d63890-d81a-4139-aff7-05bce5d6aca5"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 4\n","9th char = '4'\n","Sequence so far: 1 2 3 4 \n","10th char = ' '\n","Sequence so far: 1 2 3 4 5\n","11th char = '5'\n","Sequence so far: 1 2 3 4 5 \n","12th char = ' '\n","Sequence so far: 1 2 3 4 5 6\n","13th char = '6'\n","Sequence so far: 1 2 3 4 5 6 \n","14th char = ' '\n","Sequence so far: 1 2 3 4 5 6 7\n","15th char = '7'\n","Sequence so far: 1 2 3 4 5 6 7 \n","16th char = ' '\n","Sequence so far: 1 2 3 4 5 6 7 8\n","17th char = '8'\n"]}]},{"cell_type":"markdown","source":["## top 50"],"metadata":{"id":"GoLUBKhhf2Tq"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASqTTnAmnVYa","executionInfo":{"status":"ok","timestamp":1716940299261,"user_tz":240,"elapsed":2171,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c1ca95f2-5949-44f0-f77a-ccab23d363a1"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 1 2 3 \n","8th char = ' '\n","Sequence so far: 1 2 3 4\n","9th char = '4'\n","Sequence so far: 1 2 3 4 \n","10th char = ' '\n"]}]},{"cell_type":"markdown","source":["# 2 4 6"],"metadata":{"id":"TbpxQ1mM54P_"}},{"cell_type":"code","source":["clean_text = \"2 4 6\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"id":"ADEXAK1755ah","executionInfo":{"status":"ok","timestamp":1716942705204,"user_tz":240,"elapsed":627,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"_WKAVpct55ai"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911931826,"user_tz":240,"elapsed":515,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0c53ca51-732a-4e71-ed5b-0bea62a970dd","id":"mocInxG955ai"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","9th char = ' '\n","Sequence so far: 2 4 6 8\n","10th char = '8'\n","Sequence so far: 2 4 6 8 \n","11th char = ' '\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(0, 13)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-5BUOwP5-0J","executionInfo":{"status":"ok","timestamp":1716911933893,"user_tz":240,"elapsed":2086,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dd5baf28-efe6-4a13-fb84-ff0f2771812c"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","9th char = ' '\n","Sequence so far: 2 4 6 8\n","10th char = '8'\n","Sequence so far: 2 4 6 88\n","11th char = '8'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(0, 1)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWSllbb16dOG","executionInfo":{"status":"ok","timestamp":1716911934956,"user_tz":240,"elapsed":1206,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d50e348d-c2b0-49cd-fded-159086f1901b"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","9th char = ' '\n","Sequence so far: 2 4 6 8\n","10th char = '8'\n","Sequence so far: 2 4 6 8 \n","11th char = ' '\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(1, 14)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911937170,"user_tz":240,"elapsed":2228,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e01db7e8-9db9-4e10-a278-bc4d42189220","id":"S5yrJ9Nv64uS"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","9th char = ' '\n","Sequence so far: 2 4 6 8\n","10th char = '8'\n","Sequence so far: 2 4 6 8 \n","11th char = ' '\n"]}]},{"cell_type":"markdown","source":["## top 50"],"metadata":{"id":"73_npozFny-o"}},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716940401194,"user_tz":240,"elapsed":1945,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0cc29224-567c-48c4-a588-adee503d7494","id":"Ayr-swo5ny-o"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 7\n","9th char = '7'\n","Sequence so far: 2 4 6 7 \n","10th char = ' '\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:20]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAdzTa7tsAgq","executionInfo":{"status":"ok","timestamp":1716941501543,"user_tz":240,"elapsed":2266,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"74c32d90-8b9d-4cad-a48c-a89ee4287558"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:30]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSvwrM7usEAV","executionInfo":{"status":"ok","timestamp":1716941510443,"user_tz":240,"elapsed":2536,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"470fc38e-b223-4a55-ae61-2cd52cdba65e"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1n5R-kshsF47","executionInfo":{"status":"ok","timestamp":1716941520969,"user_tz":240,"elapsed":2276,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d6c45613-8cf9-42fd-c162-9d819894bb7c"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 7\n","9th char = '7'\n","Sequence so far: 2 4 6 7 \n","10th char = ' '\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[30:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cW7d9zo5sJTJ","executionInfo":{"status":"ok","timestamp":1716941534807,"user_tz":240,"elapsed":2149,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3029e0c5-9f81-4551-a177-7ef2a61a9089"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"uCCZsKF7n6A9"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716940433002,"user_tz":240,"elapsed":2925,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"96cb9831-64ad-4ee0-ce67-0a1e4d10d747","id":"_6SS5qR9n6A-"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n","Sequence so far: 2 4 6 8 1\n","11th char = '1'\n","Sequence so far: 2 4 6 8 10\n","12th char = '0'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdLJlagar8O0","executionInfo":{"status":"ok","timestamp":1716941477723,"user_tz":240,"elapsed":3059,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"75508817-b036-41c3-87c0-dd2333aef02a"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n","Sequence so far: 2 4 6 8 1\n","11th char = '1'\n","Sequence so far: 2 4 6 8 10\n","12th char = '0'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"she2tB_Xr94I","executionInfo":{"status":"ok","timestamp":1716941484181,"user_tz":240,"elapsed":2832,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0c86ae0d-de86-42eb-bd1a-7112e02d3cc1"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n","Sequence so far: 2 4 6 8 1\n","11th char = '1'\n","Sequence so far: 2 4 6 8 10\n","12th char = '0'\n"]}]},{"cell_type":"markdown","source":["## top 40 from 2 4 6 circ"],"metadata":{"id":"3WK3q4K5wSRL"}},{"cell_type":"code","source":["# from 2 4 6\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","# head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = ([(0, 13), (1, 8), (0, 15), (0, 14), (4, 3), (16, 0), (15, 25), (5, 25), (5, 26), (7, 30), (1, 11), (8, 0), (22, 25), (6, 11), (5, 29), (2, 2), (6, 26), (6, 24), (5, 15), (20, 17), (6, 5), (5, 17), (2, 30), (7, 9), (4, 0), (13, 6), (5, 11), (0, 21), (0, 7), (29, 1), (0, 1), (29, 5), (8, 4), (5, 16), (31, 4), (18, 19), (28, 16), (18, 9), (0, 4), (4, 16)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXMgp035wVjQ","executionInfo":{"status":"ok","timestamp":1716942742097,"user_tz":240,"elapsed":3495,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1f7f1b1d-7113-4f61-efbf-521dc93a02d4"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 2 4 6 \n","8th char = ' '\n","Sequence so far: 2 4 6 8\n","9th char = '8'\n","Sequence so far: 2 4 6 8 \n","10th char = ' '\n","Sequence so far: 2 4 6 8 1\n","11th char = '1'\n","Sequence so far: 2 4 6 8 10\n","12th char = '0'\n","Sequence so far: 2 4 6 8 10 \n","13th char = ' '\n","Sequence so far: 2 4 6 8 10 1\n","14th char = '1'\n"]}]},{"cell_type":"markdown","source":["# 10 12 14"],"metadata":{"id":"iyxXpGnQsUl7"}},{"cell_type":"code","source":["clean_text = \"10 12 14\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1716942773316,"user_tz":240,"elapsed":536,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"9ojlJXS9sX90"},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"4Nwuu0z0sX96"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716941596231,"user_tz":240,"elapsed":2258,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cf4ff5e1-91d3-445a-cf2a-87cdc9ee0c04","id":"nnR0di5zsX97"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 10 12 14 \n","11th char = ' '\n","Sequence so far: 10 12 14 1\n","12th char = '1'\n","Sequence so far: 10 12 14 16\n","13th char = '6'\n"]}]},{"cell_type":"markdown","source":["## top 50"],"metadata":{"id":"k0CrJG3Ysd27"}},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716941614689,"user_tz":240,"elapsed":2415,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"409837ed-1aec-4050-e777-85da48f26ff6","id":"pmypMSCPsd3Q"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 10 12 14 \n","11th char = ' '\n","Sequence so far: 10 12 14 1\n","12th char = '1'\n","Sequence so far: 10 12 14 10\n","13th char = '0'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phkp0j5dtJ9l","executionInfo":{"status":"ok","timestamp":1716941796625,"user_tz":240,"elapsed":2319,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5f345ae0-cca0-4179-9a30-9640a8945382"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 10 12 14 \n","11th char = ' '\n","Sequence so far: 10 12 14 1\n","12th char = '1'\n","Sequence so far: 10 12 14 15\n","13th char = '5'\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"SUOpDz-CsguL"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716941626868,"user_tz":240,"elapsed":2600,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"953179bf-85bb-4de3-d7d6-f46b402af71e","id":"-aUwfb8zsguU"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 10 12 14 \n","11th char = ' '\n","Sequence so far: 10 12 14 1\n","12th char = '1'\n","Sequence so far: 10 12 14 16\n","13th char = '6'\n","Sequence so far: 10 12 14 16 \n","14th char = ' '\n","Sequence so far: 10 12 14 16 1\n","15th char = '1'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4eWFdy4tDo7","executionInfo":{"status":"ok","timestamp":1716941769952,"user_tz":240,"elapsed":2755,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"094e8a76-2803-4af9-c1d6-2c8f66509db7"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 10 12 14 \n","11th char = ' '\n","Sequence so far: 10 12 14 1\n","12th char = '1'\n","Sequence so far: 10 12 14 16\n","13th char = '6'\n","Sequence so far: 10 12 14 16 \n","14th char = ' '\n","Sequence so far: 10 12 14 16 1\n","15th char = '1'\n"]}]},{"cell_type":"markdown","source":["## top 40 from 2 4 6 circ"],"metadata":{"id":"vtiJLz1mw45f"}},{"cell_type":"code","source":["# from 2 4 6\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","# head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = ([(0, 13), (1, 8), (0, 15), (0, 14), (4, 3), (16, 0), (15, 25), (5, 25), (5, 26), (7, 30), (1, 11), (8, 0), (22, 25), (6, 11), (5, 29), (2, 2), (6, 26), (6, 24), (5, 15), (20, 17), (6, 5), (5, 17), (2, 30), (7, 9), (4, 0), (13, 6), (5, 11), (0, 21), (0, 7), (29, 1), (0, 1), (29, 5), (8, 4), (5, 16), (31, 4), (18, 19), (28, 16), (18, 9), (0, 4), (4, 16)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942778125,"user_tz":240,"elapsed":3155,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ae2471ca-88fc-4392-88f6-c5df2a5f07a2","id":"igib0tMZw45g"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 10 12 14 \n","11th char = ' '\n","Sequence so far: 10 12 14 1\n","12th char = '1'\n","Sequence so far: 10 12 14 16\n","13th char = '6'\n","Sequence so far: 10 12 14 16 \n","14th char = ' '\n","Sequence so far: 10 12 14 16 1\n","15th char = '1'\n","Sequence so far: 10 12 14 16 18\n","16th char = '8'\n","Sequence so far: 10 12 14 16 18 \n","17th char = ' '\n"]}]},{"cell_type":"markdown","source":["# 21 23 25"],"metadata":{"id":"lUHX_9FeuLGi"}},{"cell_type":"code","source":["clean_text = \"21 23 25\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1716942075994,"user_tz":240,"elapsed":604,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"ogJxT5-8uLGj"},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"h-vGYcs_uLGj"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942078234,"user_tz":240,"elapsed":1653,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8b8c15be-6bad-4a89-b113-2e703fe110d8","id":"GZfLDcDcuLGj"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 21 23 25 \n","11th char = ' '\n","Sequence so far: 21 23 25 2\n","12th char = '2'\n","Sequence so far: 21 23 25 27\n","13th char = '7'\n"]}]},{"cell_type":"markdown","source":["## top 50"],"metadata":{"id":"v5DcEePkuLGj"}},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942079544,"user_tz":240,"elapsed":1325,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0b9cb15e-1c4b-44ea-ec8c-aa526966b048","id":"3nJ9HiShuLGk"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 21 23 25 \n","11th char = ' '\n","Sequence so far: 21 23 25 2\n","12th char = '2'\n","Sequence so far: 21 23 25 20\n","13th char = '0'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942081300,"user_tz":240,"elapsed":1776,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b507cd19-b2ef-4689-b0ce-ab121915f543","id":"gvL2v86yuLGk"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 21 23 25 \n","11th char = ' '\n","Sequence so far: 21 23 25 2\n","12th char = '2'\n","Sequence so far: 21 23 25 22\n","13th char = '2'\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"pAAPOqASuLGk"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942144211,"user_tz":240,"elapsed":4655,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5395f9eb-13fa-4b19-c2ef-169943451009","id":"uemHL8P9uLGk"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 21 23 25 \n","11th char = ' '\n","Sequence so far: 21 23 25 2\n","12th char = '2'\n","Sequence so far: 21 23 25 27\n","13th char = '7'\n","Sequence so far: 21 23 25 27 \n","14th char = ' '\n","Sequence so far: 21 23 25 27 3\n","15th char = '3'\n","Sequence so far: 21 23 25 27 31\n","16th char = '1'\n","Sequence so far: 21 23 25 27 31 \n","17th char = ' '\n","Sequence so far: 21 23 25 27 31 3\n","18th char = '3'\n","Sequence so far: 21 23 25 27 31 33\n","19th char = '3'\n","Sequence so far: 21 23 25 27 31 33 \n","20th char = ' '\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942236275,"user_tz":240,"elapsed":4772,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"73c71c23-5eaa-4a09-a967-a6c63312f7c7","id":"6pWvVoUCuLGk"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 21 23 25 \n","11th char = ' '\n","Sequence so far: 21 23 25 2\n","12th char = '2'\n","Sequence so far: 21 23 25 27\n","13th char = '7'\n","Sequence so far: 21 23 25 27 \n","14th char = ' '\n","Sequence so far: 21 23 25 27 2\n","15th char = '2'\n","Sequence so far: 21 23 25 27 29\n","16th char = '9'\n","Sequence so far: 21 23 25 27 29 \n","17th char = ' '\n","Sequence so far: 21 23 25 27 29 3\n","18th char = '3'\n","Sequence so far: 21 23 25 27 29 31\n","19th char = '1'\n","Sequence so far: 21 23 25 27 29 31 \n","20th char = ' '\n"]}]},{"cell_type":"markdown","source":["## top 40 from 2 4 6 circ"],"metadata":{"id":"qG5PP4gEwm4F"}},{"cell_type":"code","source":["# from 2 4 6\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","# head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = ([(0, 13), (1, 8), (0, 15), (0, 14), (4, 3), (16, 0), (15, 25), (5, 25), (5, 26), (7, 30), (1, 11), (8, 0), (22, 25), (6, 11), (5, 29), (2, 2), (6, 26), (6, 24), (5, 15), (20, 17), (6, 5), (5, 17), (2, 30), (7, 9), (4, 0), (13, 6), (5, 11), (0, 21), (0, 7), (29, 1), (0, 1), (29, 5), (8, 4), (5, 16), (31, 4), (18, 19), (28, 16), (18, 9), (0, 4), (4, 16)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942660992,"user_tz":240,"elapsed":2687,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"18cb906d-5116-4014-8cfa-285d34cafb34","id":"xBZOCHNfwm4L"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 21 23 25 \n","11th char = ' '\n","Sequence so far: 21 23 25 2\n","12th char = '2'\n","Sequence so far: 21 23 25 25\n","13th char = '5'\n"]}]},{"cell_type":"markdown","source":["# 3 6 9"],"metadata":{"id":"gkDcCaovxJbb"}},{"cell_type":"code","source":["clean_text = \"3 6 9\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1716942854415,"user_tz":240,"elapsed":646,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"Q7kzfEKxxJbb"},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"9xAnkIs9xJbb"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942856431,"user_tz":240,"elapsed":1406,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"628bf4e5-d603-4e1c-a985-dc98b49f7ea4","id":"1UAA-dJ8xJbb"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 12\n","10th char = '2'\n"]}]},{"cell_type":"markdown","source":["## top 50"],"metadata":{"id":"6LrZeIaLxJbc"}},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942863703,"user_tz":240,"elapsed":2074,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"328eb288-eab1-40a3-e6d6-0c7866feda57","id":"4wQy_YZ3xJbc"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 10\n","10th char = '0'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:20]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942865129,"user_tz":240,"elapsed":1462,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"88424a70-a659-4051-cddb-7f57ec371d60","id":"sNYNl-9TxJbc"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 10\n","10th char = '0'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:30]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942867128,"user_tz":240,"elapsed":2021,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fabc8db6-1722-4871-a778-22c96c632d1c","id":"TlaI4LMhxJbc"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 10\n","10th char = '0'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942868923,"user_tz":240,"elapsed":1818,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1f26b83c-61d1-4f78-d6cf-f36b359b9df1","id":"joKNETWjxJbc"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 10\n","10th char = '0'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[30:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942870637,"user_tz":240,"elapsed":1736,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"86f21f79-4427-449d-c036-64b93cb06cc5","id":"_NZnUQIlxJbd"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 12\n","10th char = '2'\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"QVthTBArxJbd"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942874943,"user_tz":240,"elapsed":4325,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5c917d02-afb7-43fd-8535-946865c9deac","id":"reZTHiDNxJbd"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 12\n","10th char = '2'\n","Sequence so far: 3 6 9 12 \n","11th char = ' '\n","Sequence so far: 3 6 9 12 1\n","12th char = '1'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942875326,"user_tz":240,"elapsed":423,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e82b521e-64aa-4379-bbe5-262f5fcb36f6","id":"NEUsJhHBxJbd"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 12\n","10th char = '2'\n","Sequence so far: 3 6 9 12 \n","11th char = ' '\n","Sequence so far: 3 6 9 12 1\n","12th char = '1'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942878358,"user_tz":240,"elapsed":3077,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"07b2b0ee-5af4-448f-f05d-e62592463f0b","id":"Kcy6TNojxJbd"},"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 12\n","10th char = '2'\n","Sequence so far: 3 6 9 12 \n","11th char = ' '\n","Sequence so far: 3 6 9 12 1\n","12th char = '1'\n"]}]},{"cell_type":"markdown","source":["## top 40 from 2 4 6 circ"],"metadata":{"id":"MEMWtjsdxJbd"}},{"cell_type":"code","source":["# from 2 4 6\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","# head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = ([(0, 13), (1, 8), (0, 15), (0, 14), (4, 3), (16, 0), (15, 25), (5, 25), (5, 26), (7, 30), (1, 11), (8, 0), (22, 25), (6, 11), (5, 29), (2, 2), (6, 26), (6, 24), (5, 15), (20, 17), (6, 5), (5, 17), (2, 30), (7, 9), (4, 0), (13, 6), (5, 11), (0, 21), (0, 7), (29, 1), (0, 1), (29, 5), (8, 4), (5, 16), (31, 4), (18, 19), (28, 16), (18, 9), (0, 4), (4, 16)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716942881845,"user_tz":240,"elapsed":3559,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"25bf4d03-01a5-4a7e-d618-5ab8a928dcf7","id":"6SmOx0w5xJbd"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 3 6 9 \n","8th char = ' '\n","Sequence so far: 3 6 9 1\n","9th char = '1'\n","Sequence so far: 3 6 9 10\n","10th char = '0'\n","Sequence so far: 3 6 9 10 \n","11th char = ' '\n","Sequence so far: 3 6 9 10 1\n","12th char = '1'\n","Sequence so far: 3 6 9 10 10\n","13th char = '0'\n","Sequence so far: 3 6 9 10 10 \n","14th char = ' '\n"]}]},{"cell_type":"markdown","source":["# 100 200 300"],"metadata":{"id":"sEj6tfZMxo7o"}},{"cell_type":"code","source":["clean_text = \"100 200 300\"\n","corr_text = \"5 3 9\"\n","# corr_text = \"1 2 3\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1716943034367,"user_tz":240,"elapsed":984,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"MqR89QLIxo7u"},"execution_count":132,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"LWyhW7uexo7u"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943037904,"user_tz":240,"elapsed":628,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0ef7d6d5-dec7-496b-8e9a-320cb50a1a87","id":"wegBtrdJxo7u"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"markdown","source":["## top 50"],"metadata":{"id":"dDt18FyUxo7u"}},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943041319,"user_tz":240,"elapsed":3437,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"08e6c9b7-9dbc-4f64-eca0-da8c59071349","id":"glvZiGzgxo7u"},"execution_count":134,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 3\n","15th char = '3'\n","Sequence so far: 100 200 300 30\n","16th char = '0'\n","Sequence so far: 100 200 300 300\n","17th char = '0'\n","Sequence so far: 100 200 300 300 \n","18th char = ' '\n","Sequence so far: 100 200 300 300 3\n","19th char = '3'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:20]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943043948,"user_tz":240,"elapsed":2692,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b81e1d0e-bfd2-44d5-f53d-d537d00b8ae0","id":"zXEl6l8Oxo7v"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:30]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943049024,"user_tz":240,"elapsed":5138,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1479e7cb-f720-4d3e-935f-07361e7184d3","id":"t6atXu35xo7v"},"execution_count":136,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943051989,"user_tz":240,"elapsed":3058,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7a4421d6-44c2-4b6c-dd31-2a128577acc6","id":"srOiFprSxo7v"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[30:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943056144,"user_tz":240,"elapsed":4237,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0c067000-2b0b-4cb9-ebc7-b43fdf030623","id":"-G7rXjfJxo7v"},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"-meaTWOUxo7v"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943056509,"user_tz":240,"elapsed":384,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"60ee0c7f-f004-4e3b-b0bf-099ef8e60ab7","id":"zdyMbo6Cxo7v"},"execution_count":139,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943057285,"user_tz":240,"elapsed":794,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bb8286e3-3cc9-456e-b252-6bc2cbfc45f6","id":"ZNLZxJaaxo7v"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943060487,"user_tz":240,"elapsed":3215,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c8819ab8-f010-47c0-8dc5-66b2f1f5b286","id":"CnAawpn3xo7v"},"execution_count":141,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n"]}]},{"cell_type":"markdown","source":["## top 40 from 2 4 6 circ"],"metadata":{"id":"-t2mF5W2xo7v"}},{"cell_type":"code","source":["# from 2 4 6\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","# head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = ([(0, 13), (1, 8), (0, 15), (0, 14), (4, 3), (16, 0), (15, 25), (5, 25), (5, 26), (7, 30), (1, 11), (8, 0), (22, 25), (6, 11), (5, 29), (2, 2), (6, 26), (6, 24), (5, 15), (20, 17), (6, 5), (5, 17), (2, 30), (7, 9), (4, 0), (13, 6), (5, 11), (0, 21), (0, 7), (29, 1), (0, 1), (29, 5), (8, 4), (5, 16), (31, 4), (18, 19), (28, 16), (18, 9), (0, 4), (4, 16)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943063247,"user_tz":240,"elapsed":2791,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c25407af-22d5-4350-8522-1a29c480d442","id":"LCJbR8Gwxo7w"},"execution_count":142,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Sequence so far: 100 200 300 \n","14th char = ' '\n","Sequence so far: 100 200 300 4\n","15th char = '4'\n","Sequence so far: 100 200 300 40\n","16th char = '0'\n","Sequence so far: 100 200 300 400\n","17th char = '0'\n","Sequence so far: 100 200 300 400 \n","18th char = ' '\n","Sequence so far: 100 200 300 400 5\n","19th char = '5'\n","Sequence so far: 100 200 300 400 50\n","20th char = '0'\n"]}]},{"cell_type":"markdown","source":["# uno dos tres"],"metadata":{"id":"hLripymZ7Abw"}},{"cell_type":"code","source":["clean_text = \"uno dos tres\"\n","corr_text = \"uno uno uno\" # dos tres cinco seis"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716943579163,"user_tz":240,"elapsed":511,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"8mLfznIJ7Abx"},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"HUYu7tgJ7Abx"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716944199791,"user_tz":240,"elapsed":3128,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3d1d55c4-44a0-49f2-8ec4-9deb7e1f3f34","id":"bopREsqO7Abx"},"execution_count":164,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocincoseis\n","7th char = 'seis'\n","Sequence so far: uno dos trescuatrocincoseisseven\n","8th char = 'seven'\n","Sequence so far: uno dos trescuatrocincoseisseveneight\n","9th char = 'eight'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnine\n","10th char = 'nine'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineten\n","11th char = 'ten'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineteneleven\n","12th char = 'eleven'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineteneleventwelve\n","13th char = 'twelve'\n","Sequence so far: uno dos trescuatrocincoseisseveneightnineteneleventwelveth\n","14th char = 'th'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(0, 13)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943582854,"user_tz":240,"elapsed":1958,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cdf73f9c-c1c4-43b4-869d-f771d78728bb","id":"M6K8w_CcB5oV"},"execution_count":145,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocincoseis\n","7th char = 'seis'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcdKKFZ9B9N0","executionInfo":{"status":"ok","timestamp":1716943583964,"user_tz":240,"elapsed":1132,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b1cbacf3-8d77-4d72-9257-5092ee66b77a"},"execution_count":146,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n"]}]},{"cell_type":"markdown","source":["## top 50"],"metadata":{"id":"WbO4I7b8zw0-"}},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943586055,"user_tz":240,"elapsed":2119,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b9201ed1-f2b0-4e02-9b36-20a4d60a37b2","id":"Bgkm93vnzw0-"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>o\n","7th char = 'o'\n","Sequence so far: uno dos tres<0x0A><0x0A>otres\n","8th char = 'tres'\n","Sequence so far: uno dos tres<0x0A><0x0A>otresuno\n","9th char = 'uno'\n","Sequence so far: uno dos tres<0x0A><0x0A>otresuno<0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:20]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943588216,"user_tz":240,"elapsed":2190,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f74e0a8a-de8b-45bf-b4cf-4cfc5c039634","id":"Hoqd-7eTzw0_"},"execution_count":148,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:30]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943591143,"user_tz":240,"elapsed":2999,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b459c3ac-2d3f-40a1-d893-7fe50abcf8a9","id":"PNgR4A76zw0_"},"execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>uno\n","10th char = 'uno'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943592380,"user_tz":240,"elapsed":1295,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b412567d-2011-4c9d-f319-4cb22ac272e1","id":"aSaUdEcRzw0_"},"execution_count":150,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>o\n","7th char = 'o'\n","Sequence so far: uno dos tres<0x0A><0x0A>ocho\n","8th char = 'cho'\n","Sequence so far: uno dos tres<0x0A><0x0A>ochodos\n","9th char = 'dos'\n","Sequence so far: uno dos tres<0x0A><0x0A>ochodosdos\n","10th char = 'dos'\n"]}]},{"cell_type":"code","source":["# from 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = head_to_remove[30:40]\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943594728,"user_tz":240,"elapsed":2379,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"66aff1a6-305c-42ce-b515-f565ae02fafc","id":"A2PelNmdzw0_"},"execution_count":151,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrofive\n","6th char = 'five'\n","Sequence so far: uno dos trescuatrofivesix\n","7th char = 'six'\n","Sequence so far: uno dos trescuatrofivesixseven\n","8th char = 'seven'\n","Sequence so far: uno dos trescuatrofivesixseveneight\n","9th char = 'eight'\n","Sequence so far: uno dos trescuatrofivesixseveneightnine\n","10th char = 'nine'\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"lbUeHL4Kzw0_"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943598942,"user_tz":240,"elapsed":4237,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"df0b765a-b7b7-4d87-9153-7e68837ab435","id":"-wGOp4p0zw0_"},"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres\"\n","5th char = '\"'\n","Sequence so far: uno dos tres\"<0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres\"<0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres\"<0x0A><0x0A>Answer\n","8th char = 'Answer'\n","Sequence so far: uno dos tres\"<0x0A><0x0A>Answer:\n","9th char = ':'\n","Sequence so far: uno dos tres\"<0x0A><0x0A>Answer:<0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943599658,"user_tz":240,"elapsed":761,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ea5f5580-a52d-462a-ff76-73d1ad964984","id":"YjKikSPvzw0_"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 50)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943601376,"user_tz":240,"elapsed":1827,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e8e91375-cbc5-4241-b464-39c2a4fcd277","id":"dlrZvyqDzw0_"},"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"markdown","source":["## random 1"],"metadata":{"id":"UOTP8Pr40Ymp"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 1)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKeCQHHf0YHH","executionInfo":{"status":"ok","timestamp":1716943703212,"user_tz":240,"elapsed":2390,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"315fd80b-d8ad-42de-8f75-fb74b5866755"},"execution_count":156,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocinco<0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 1)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bp8XZjY-1pVt","executionInfo":{"status":"ok","timestamp":1716944021522,"user_tz":240,"elapsed":2611,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e3afe18-937f-4e48-da69-1aee079b7b25"},"execution_count":159,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocincosix\n","7th char = 'six'\n","Sequence so far: uno dos trescuatrocincosixseven\n","8th char = 'seven'\n","Sequence so far: uno dos trescuatrocincosixseveneight\n","9th char = 'eight'\n","Sequence so far: uno dos trescuatrocincosixseveneightnine\n","10th char = 'nine'\n"]}]},{"cell_type":"markdown","source":["## random 10"],"metadata":{"id":"Ob3yJZRG1nOT"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 10)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrQuYhqP0dDv","executionInfo":{"status":"ok","timestamp":1716943712554,"user_tz":240,"elapsed":2575,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cd32ab56-563b-4b43-be14-9f74090c7571"},"execution_count":157,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocincosix\n","7th char = 'six'\n","Sequence so far: uno dos trescuatrocincosixseven\n","8th char = 'seven'\n","Sequence so far: uno dos trescuatrocincosixseveneight\n","9th char = 'eight'\n","Sequence so far: uno dos trescuatrocincosixseveneightnine\n","10th char = 'nine'\n"]}]},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 10)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrPuVmTt2qfJ","executionInfo":{"status":"ok","timestamp":1716944291552,"user_tz":240,"elapsed":3275,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a2c36891-64cc-40b5-e4e1-78d2a651c2d1"},"execution_count":165,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres<0x0A>\n","5th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A>\n","6th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos tres<0x0A><0x0A><0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["head_to_remove"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umBLB-BA2wvi","executionInfo":{"status":"ok","timestamp":1716944321249,"user_tz":240,"elapsed":428,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ef20e29f-5cbc-4fea-f7cd-58243aa6c9e7"},"execution_count":167,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(17, 27),\n"," (16, 15),\n"," (4, 16),\n"," (16, 25),\n"," (0, 23),\n"," (18, 10),\n"," (27, 3),\n"," (9, 6),\n"," (9, 7),\n"," (14, 8)]"]},"metadata":{},"execution_count":167}]},{"cell_type":"code","source":["top50_1234 = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","overlap = list(set(top50_1234) & set(head_to_remove))\n","overlap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOxlBwFX3BxV","executionInfo":{"status":"ok","timestamp":1716944409778,"user_tz":240,"elapsed":400,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d79c8e7d-ccfd-4fa6-b11d-8e5f578b9248"},"execution_count":168,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(14, 8)]"]},"metadata":{},"execution_count":168}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(14, 8)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 6)"],"metadata":{"id":"O0WDrYto3UG8","executionInfo":{"status":"ok","timestamp":1716944471287,"user_tz":240,"elapsed":2266,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"92752b9d-ff35-40d8-9d1c-9f1ecaa8cdfe","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos trescuatro\n","5th char = 'cuatro'\n","Sequence so far: uno dos trescuatrocinco\n","6th char = 'cinco'\n","Sequence so far: uno dos trescuatrocinco<0x0A>\n","7th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A>\n","8th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A>\n","9th char = '<0x0A>'\n","Sequence so far: uno dos trescuatrocinco<0x0A><0x0A><0x0A><0x0A>\n","10th char = '<0x0A>'\n"]}]},{"cell_type":"markdown","source":["## top 40 from 2 4 6 circ"],"metadata":{"id":"IN4h4MLTzw0_"}},{"cell_type":"code","source":["# from 2 4 6\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","# head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove = ([(0, 13), (1, 8), (0, 15), (0, 14), (4, 3), (16, 0), (15, 25), (5, 25), (5, 26), (7, 30), (1, 11), (8, 0), (22, 25), (6, 11), (5, 29), (2, 2), (6, 26), (6, 24), (5, 15), (20, 17), (6, 5), (5, 17), (2, 30), (7, 9), (4, 0), (13, 6), (5, 11), (0, 21), (0, 7), (29, 1), (0, 1), (29, 5), (8, 4), (5, 16), (31, 4), (18, 19), (28, 16), (18, 9), (0, 4), (4, 16)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716943610730,"user_tz":240,"elapsed":9418,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d923b24b-2cfe-4d80-8a9b-b874f718f872","id":"Rru0atXozw0_"},"execution_count":155,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: uno dos tres,\n","5th char = ','\n","Sequence so far: uno dos tres,and\n","6th char = 'and'\n","Sequence so far: uno dos tres,andthe\n","7th char = 'the'\n","Sequence so far: uno dos tres,andtheother\n","8th char = 'other'\n","Sequence so far: uno dos tres,andtheothertwo\n","9th char = 'two'\n","Sequence so far: uno dos tres,andtheothertwoare\n","10th char = 'are'\n","Sequence so far: uno dos tres,andtheothertwoaretwo\n","11th char = 'two'\n"]}]},{"cell_type":"markdown","source":["# \"What comes after Monday is Tuesday, and two days after is\""],"metadata":{"id":"xVQNcXCdIabN"}},{"cell_type":"code","source":["clean_text = \"What comes after Monday is Tuesday, and two days after is\"\n","corr_text = \"What comes after X is Y, and two days after is\""],"metadata":{"id":"syZM-USVlI20","executionInfo":{"status":"ok","timestamp":1716911941266,"user_tz":240,"elapsed":114,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"xPy2WPWexTOY"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911943344,"user_tz":240,"elapsed":2191,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b2513bb2-f715-41e4-9ea4-2dde2ad1a4fc","id":"ivjnpe5HxTOZ"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["13\n","Sequence so far: What comes after Monday is Tuesday, and two days after isTh\n","17th char = 'Th'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThurs\n","18th char = 'urs'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThursday\n","19th char = 'day'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(0, 13)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911946270,"user_tz":240,"elapsed":3040,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3a7b63ac-17f1-4ae3-c6c5-0af5af662a83","id":"YgZT25FYxTOZ"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["13\n","Sequence so far: What comes after Monday is Tuesday, and two days after isTh\n","17th char = 'Th'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThurs\n","18th char = 'urs'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThursday\n","19th char = 'day'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716911949549,"user_tz":240,"elapsed":3308,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e4d5c7f8-931e-4a8b-e745-fba9572af3f7","id":"oaGMHFqIxTOZ"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["13\n","Sequence so far: What comes after Monday is Tuesday, and two days after isTh\n","17th char = 'Th'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThurs\n","18th char = 'urs'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThursday\n","19th char = 'day'\n"]}]},{"cell_type":"markdown","source":["Obtain heads from top 20 of https://colab.research.google.com/drive/1p_x98vp4OMx46rphUdIk64E7P94cQmg9#scrollTo=susSZdqpqVzd&line=1&uniqifier=1"],"metadata":{"id":"3uTwg7foyvX9"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25),\n","    (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15),\n","    (26, 2), (10, 25), (2, 2), (23, 2)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ft-W3LYsx6GP","executionInfo":{"status":"ok","timestamp":1716911951752,"user_tz":240,"elapsed":2229,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"28f11be9-bf35-40c4-f78a-78063c47410b"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["13\n","Sequence so far: What comes after Monday is Tuesday, and two days after isTh\n","17th char = 'Th'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThurs\n","18th char = 'urs'\n","Sequence so far: What comes after Monday is Tuesday, and two days after isThursday\n","19th char = 'day'\n"]}]},{"cell_type":"markdown","source":["# What are the months in a year?"],"metadata":{"id":"CFwRmFnHOqx5"}},{"cell_type":"code","source":["clean_text = \"What are the months in a year?\"\n","corr_text = \"What are the X in a year?\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1716937297819,"user_tz":240,"elapsed":583,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"_pkqmZvhOv26"},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"aj6-OLHXOv26"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716933889921,"user_tz":240,"elapsed":13452,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"112a454a-28f6-42cb-a059-1337efca2645","id":"nHTQQa0BOv27"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>There\n","12th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare \n","14th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 1\n","15th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12\n","16th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12months\n","17th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsin\n","18th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsina\n","19th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear\n","20th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.\n","21th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.The\n","22th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonths\n","23th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare\n","24th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:\n","25th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>\n","27th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1\n","28th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.\n","29th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January\n","30th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>\n","31th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2\n","32th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.\n","33th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February\n","34th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","35th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","36th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","37th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","38th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","39th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(23, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716933903219,"user_tz":240,"elapsed":13309,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ea08000a-fb83-4f55-ba23-454b4af3e6e5","id":"eQZBtOH1Ov27"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>There\n","12th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare \n","14th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 1\n","15th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12\n","16th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12months\n","17th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsin\n","18th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsina\n","19th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear\n","20th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.\n","21th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.The\n","22th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonths\n","23th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare\n","24th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:\n","25th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>\n","27th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1\n","28th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.\n","29th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January\n","30th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>\n","31th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2\n","32th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.\n","33th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February\n","34th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","35th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","36th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","37th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","38th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","39th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = []\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LGM0PXPPG2r","executionInfo":{"status":"ok","timestamp":1716933949982,"user_tz":240,"elapsed":5106,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"aa6de253-4b40-4fd4-fe10-4f7648f4158e"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?That\n","10th char = 'That'\n","Sequence so far: What are the months in a year?That,\n","11th char = ','\n","Sequence so far: What are the months in a year?That,g\n","12th char = 'g'\n","Sequence so far: What are the months in a year?That,g.,\n","13th char = '.,'\n","Sequence so far: What are the months in a year?That,g.,a\n","14th char = 'a'\n","Sequence so far: What are the months in a year?That,g.,aand\n","15th char = 'and'\n","Sequence so far: What are the months in a year?That,g.,aand \n","16th char = ' '\n","Sequence so far: What are the months in a year?That,g.,aand 1\n","17th char = '1'\n","Sequence so far: What are the months in a year?That,g.,aand 1(\n","18th char = '('\n","Sequence so far: What are the months in a year?That,g.,aand 1(As\n","19th char = 'As'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.\n","20th char = '.'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>\n","21th char = '<0x0A>'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al\n","22th char = 'al'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/\n","23th char = '/'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s\n","24th char = 's'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2\n","25th char = '2'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se\n","26th char = 'se'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*\n","27th char = '*'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:\n","28th char = ':'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re\n","29th char = 're'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1\n","30th char = '1'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(\n","31th char = '('\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As\n","32th char = 'As'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As.\n","33th char = '.'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As.<0x0A>\n","34th char = '<0x0A>'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As.<0x0A>al\n","35th char = 'al'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As.<0x0A>al/\n","36th char = '/'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As.<0x0A>al/s\n","37th char = 's'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As.<0x0A>al/s2\n","38th char = '2'\n","Sequence so far: What are the months in a year?That,g.,aand 1(As.<0x0A>al/s2se*:re1(As.<0x0A>al/s2se\n","39th char = 'se'\n"]}]},{"cell_type":"code","source":["# top 7 heads from seqcont months\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gf3j2thXPUO_","executionInfo":{"status":"ok","timestamp":1716934034771,"user_tz":240,"elapsed":13689,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6c9394b5-13b1-4f94-8392-72e8bcb16667"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>There\n","12th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare \n","14th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 1\n","15th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12\n","16th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12months\n","17th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsin\n","18th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsina\n","19th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear\n","20th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.\n","21th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.The\n","22th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonths\n","23th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare\n","24th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:\n","25th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>\n","27th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1\n","28th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.\n","29th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January\n","30th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>\n","31th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2\n","32th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.\n","33th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February\n","34th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","35th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","36th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","37th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","38th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","39th char = '<0x0A>'\n"]}]},{"cell_type":"markdown","source":["## top 50 from seqcont circs"],"metadata":{"id":"vs0p2EmafUzl"}},{"cell_type":"code","source":["# top 50 heads from seqcont months\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1REcENdZQLEx","executionInfo":{"status":"ok","timestamp":1716937335351,"user_tz":240,"elapsed":17304,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d6edf0af-d20f-4e4b-bbcd-8b277e35b617"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>There\n","12th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare \n","14th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 1\n","15th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12\n","16th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12months\n","17th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsin\n","18th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsina\n","19th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear\n","20th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.\n","21th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Here\n","22th char = 'Here'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Hereare\n","23th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethe\n","24th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenames\n","25th char = 'names'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesof\n","26th char = 'of'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthe\n","27th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonths\n","28th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsin\n","29th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder\n","30th char = 'order'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:\n","31th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A>\n","32th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>\n","33th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1\n","34th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.\n","35th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January\n","36th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>\n","37th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2\n","38th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.\n","39th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February\n","40th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","41th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","42th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","43th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","44th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","45th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4\n","46th char = '4'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.\n","47th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April\n","48th char = 'April'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>\n","49th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["# top 50 heads from seqcont 1234\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jayHObPqcer_","executionInfo":{"status":"ok","timestamp":1716937469059,"user_tz":240,"elapsed":17511,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6b9e2523-8133-49ce-e6d0-3f9fe25bc78d"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>There\n","12th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare \n","14th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 1\n","15th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12\n","16th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124\n","17th char = '4'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124months\n","18th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsin\n","19th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsina\n","20th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear\n","21th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.\n","22th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A>\n","23th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>\n","24th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1\n","25th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.\n","26th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January\n","27th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>\n","28th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2\n","29th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.\n","30th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February\n","31th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","32th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","33th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","34th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","35th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","36th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4\n","37th char = '4'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.\n","38th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April\n","39th char = 'April'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>\n","40th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5\n","41th char = '5'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.\n","42th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May\n","43th char = 'May'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>\n","44th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>5\n","45th char = '5'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>5.\n","46th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>5.May\n","47th char = 'May'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>5.May<0x0A>\n","48th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 124monthsinayear.<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>5.May<0x0A>6\n","49th char = '6'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove_months = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3X1UXmTvcyv5","executionInfo":{"status":"ok","timestamp":1716938118992,"user_tz":240,"elapsed":25335,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"25424570-c0ef-41eb-8aef-ddc4e1649e16"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>\n","12th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>What\n","13th char = 'What'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatare\n","14th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethe\n","15th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonths\n","16th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsin\n","17th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsina\n","18th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear\n","19th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?\n","20th char = '?'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A>\n","21th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>\n","22th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>\n","23th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>The\n","24th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonths\n","25th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsin\n","26th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsina\n","27th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayear\n","28th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare\n","29th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:\n","30th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A>\n","31th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>\n","32th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1\n","33th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.\n","34th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January\n","35th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>\n","36th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.\n","37th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January\n","38th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January \n","39th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 1\n","40th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 15\n","41th char = '5'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153\n","42th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days\n","43th char = 'days'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>\n","44th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.\n","45th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January\n","46th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January \n","47th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 3\n","48th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31\n","49th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>\n","50th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.\n","51th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January\n","52th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January \n","53th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 3\n","54th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31\n","55th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>\n","56th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.\n","57th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January\n","58th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January \n","59th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 3\n","60th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31\n","61th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>\n","62th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>.\n","63th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>.January\n","64th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>.January \n","65th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>.January 3\n","66th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>.January 3<0x0A>\n","67th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>.January 3<0x0A>.\n","68th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>.January 153days<0x0A>.January 31<0x0A>.January 31<0x0A>.January 31<0x0A>.January 3<0x0A>.January\n","69th char = 'January'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove_months = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","head_to_remove_num = head_to_remove_num[:10]\n","head_to_remove_months = head_to_remove_months[:10]\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKZSTbOrfdPl","executionInfo":{"status":"ok","timestamp":1716938256847,"user_tz":240,"elapsed":13434,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1b1f66fc-0479-40f6-88dd-5f0efb8234a7"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>What\n","12th char = 'What'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethe\n","14th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonths\n","15th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsin\n","16th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsina\n","17th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear\n","18th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?\n","19th char = '?'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A>\n","20th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>\n","21th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>The\n","22th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonths\n","23th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsin\n","24th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsina\n","25th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayear\n","26th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare\n","27th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:\n","28th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A>\n","29th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>\n","30th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1\n","31th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.\n","32th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January\n","33th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>\n","34th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2\n","35th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.\n","36th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.February\n","37th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","38th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","39th char = '3'\n"]}]},{"cell_type":"markdown","source":["## top 20"],"metadata":{"id":"qyq2ytYonNqw"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove_num = ([(20, 17), (1, 11), (0, 30), (0, 9), (5, 26), (16, 0), (13, 6), (15, 25), (5, 15), (6, 11), (5, 25), (5, 17), (1, 28), (29, 5), (4, 3), (15, 15), (26, 2), (10, 25), (2, 2), (23, 2), (30, 13), (25, 23), (6, 24), (11, 28), (10, 1), (7, 0), (18, 19), (0, 26), (9, 26), (18, 9), (19, 28), (10, 5), (2, 24), (15, 26), (31, 4), (1, 16), (11, 27), (31, 11), (16, 14), (23, 17), (23, 27), (14, 8), (1, 22), (23, 6), (7, 30), (19, 30), (3, 6), (19, 12), (20, 25), (17, 17)])\n","head_to_remove_months = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","head_to_remove_num = head_to_remove_num[:20]\n","head_to_remove_months = head_to_remove_months[:20]\n","head_to_remove = head_to_remove_num + head_to_remove_months\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3EfIN_7f9LI","executionInfo":{"status":"ok","timestamp":1716938891764,"user_tz":240,"elapsed":22617,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fa653b6e-c565-4283-acee-5a10291d2f3e"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>What\n","12th char = 'What'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethe\n","14th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonths\n","15th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsin\n","16th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsina\n","17th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear\n","18th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?\n","19th char = '?'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A>\n","20th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>\n","21th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>The\n","22th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonths\n","23th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsin\n","24th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsina\n","25th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayear\n","26th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare\n","27th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:\n","28th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A>\n","29th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>\n","30th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1\n","31th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.\n","32th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January\n","33th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>\n","34th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2\n","35th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.\n","36th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January\n","37th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>\n","38th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2\n","39th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.\n","40th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January\n","41th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A>\n","42th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>\n","43th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>What\n","44th char = 'What'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatare\n","45th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethe\n","46th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonths\n","47th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsin\n","48th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsina\n","49th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear\n","50th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?\n","51th char = '?'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A>\n","52th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>\n","53th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>The\n","54th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonths\n","55th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsin\n","56th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsina\n","57th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayear\n","58th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare:<0x0A><0x0A>1.January<0x0A>2.January<0x0A>2.January<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>Themonthsinayearare\n","59th char = 'are'\n"]}]},{"cell_type":"markdown","source":["## random"],"metadata":{"id":"_516xSlZfQ4S"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 40)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q56KzwkQijJb","executionInfo":{"status":"ok","timestamp":1716939034074,"user_tz":240,"elapsed":17967,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"764f3e3c-aa67-44e2-a463-8b5145f4ff11"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A>There\n","11th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A>Thereare\n","12th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A>Thereare \n","13th char = ' '\n","Sequence so far: What are the months in a year?<0x0A>Thereare 1\n","14th char = '1'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12\n","15th char = '2'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12months\n","16th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsin\n","17th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsina\n","18th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear\n","19th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.\n","20th char = '.'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Here\n","21th char = 'Here'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Hereare\n","22th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethe\n","23th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenames\n","24th char = 'names'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesof\n","25th char = 'of'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthe\n","26th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonths\n","27th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsin\n","28th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder\n","29th char = 'order'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:\n","30th char = ':'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A>\n","31th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>\n","32th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1\n","33th char = '1'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.\n","34th char = '.'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January\n","35th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>\n","36th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2\n","37th char = '2'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.\n","38th char = '.'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February\n","39th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","40th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","41th char = '3'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","42th char = '.'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","43th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","44th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4\n","45th char = '4'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.\n","46th char = '.'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April\n","47th char = 'April'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>\n","48th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A>Thereare 12monthsinayear.Herearethenamesofthemonthsinorder:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5\n","49th char = '5'\n"]}]},{"cell_type":"code","source":["all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","head_to_remove = random.sample(all_possible_pairs, 40)\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-L76q9fYm2Tt","executionInfo":{"status":"ok","timestamp":1716940167555,"user_tz":240,"elapsed":16383,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a5afe42a-1e19-4664-ee02-1ef7956d9e90"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>There\n","12th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare \n","14th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 1\n","15th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12\n","16th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12months\n","17th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsin\n","18th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsina\n","19th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear\n","20th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.\n","21th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.The\n","22th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonths\n","23th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare\n","24th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:\n","25th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A>\n","26th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>\n","27th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1\n","28th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.\n","29th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January\n","30th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>\n","31th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2\n","32th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.\n","33th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February\n","34th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","35th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","36th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","37th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","38th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","39th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4\n","40th char = '4'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.\n","41th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April\n","42th char = 'April'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>\n","43th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5\n","44th char = '5'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.\n","45th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May\n","46th char = 'May'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>\n","47th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>6\n","48th char = '6'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.Themonthsare:<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>5.May<0x0A>6.\n","49th char = '.'\n"]}]},{"cell_type":"markdown","source":["### 100 rand"],"metadata":{"id":"t6HyyOuRm3lf"}},{"cell_type":"code","source":["import random\n","\n","# Generate all possible pairs (i, j) where i and j range from 0 to 31 inclusive\n","all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","\n","# Randomly choose 100 pairs from the list\n","head_to_remove = random.sample(all_possible_pairs, 100)\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKA4U4dbdGs8","executionInfo":{"status":"ok","timestamp":1716937913467,"user_tz":240,"elapsed":17636,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"174206d5-656d-410b-8637-a5336d3b4874"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer\n","12th char = 'Answer'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:\n","13th char = ':'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:The\n","14th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:Themonths\n","15th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:Themonthsin\n","16th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:Themonthsina\n","17th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:Themonthsinayear\n","18th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:Themonthsinayearare\n","19th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary\n","20th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,\n","21th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February\n","22th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,\n","23th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March\n","24th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,\n","25th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April\n","26th char = 'April'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,\n","27th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May\n","28th char = 'May'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,\n","29th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June\n","30th char = 'June'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,\n","31th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July\n","32th char = 'July'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,\n","33th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August\n","34th char = 'August'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,\n","35th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September\n","36th char = 'September'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,\n","37th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October\n","38th char = 'October'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,\n","39th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November\n","40th char = 'November'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,\n","41th char = ','\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,and\n","42th char = 'and'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,andDecember\n","43th char = 'December'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,andDecember.\n","44th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,andDecember.</s>\n","45th char = '</s>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,andDecember.</s><s>\n","46th char = '<s>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,andDecember.</s><s>The\n","47th char = 'The'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,andDecember.</s><s>The \n","48th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Answer:ThemonthsinayearareJanuary,February,March,April,May,June,July,August,September,October,November,andDecember.</s><s>The 1\n","49th char = '1'\n"]}]},{"cell_type":"code","source":["all_possible_pairs = [(i, j) for i in range(32) for j in range(32)]\n","head_to_remove = random.sample(all_possible_pairs, 100)\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8LdqF_me49I","executionInfo":{"status":"ok","timestamp":1716938075158,"user_tz":240,"elapsed":16597,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cddf65cf-97f4-44da-bb3c-601d9234cfbd"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n","Sequence so far: What are the months in a year?<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>There\n","12th char = 'There'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare\n","13th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare \n","14th char = ' '\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 1\n","15th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12\n","16th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12months\n","17th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsin\n","18th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsina\n","19th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear\n","20th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.\n","21th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A>\n","22th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>\n","23th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>What\n","24th char = 'What'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatare\n","25th char = 'are'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethe\n","26th char = 'the'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonths\n","27th char = 'months'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsin\n","28th char = 'in'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsina\n","29th char = 'a'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear\n","30th char = 'year'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?\n","31th char = '?'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A>\n","32th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>\n","33th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1\n","34th char = '1'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.\n","35th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January\n","36th char = 'January'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>\n","37th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2\n","38th char = '2'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.\n","39th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February\n","40th char = 'February'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>\n","41th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3\n","42th char = '3'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.\n","43th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March\n","44th char = 'March'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>\n","45th char = '<0x0A>'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4\n","46th char = '4'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.\n","47th char = '.'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April\n","48th char = 'April'\n","Sequence so far: What are the months in a year?<0x0A><0x0A>Thereare 12monthsinayear.<0x0A><0x0A>Whatarethemonthsinayear?<0x0A><0x0A>1.January<0x0A>2.February<0x0A>3.March<0x0A>4.April<0x0A>\n","49th char = '<0x0A>'\n"]}]},{"cell_type":"code","source":["len(heads_not_ablate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_eVfEeooeqW5","executionInfo":{"status":"ok","timestamp":1716938044178,"user_tz":240,"elapsed":626,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"27caab80-4f3b-4016-b561-fa576b280f06"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["924"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["# jan feb mar"],"metadata":{"id":"c5dRizjEa5hW"}},{"cell_type":"code","source":["clean_text = \"January February March\"\n","corr_text = \"July April September\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1716937070008,"user_tz":240,"elapsed":537,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"bbGIcb1Sa_Op"},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"Wz2Kt4B6a_Oq"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","mlps_not_ablate = [layer for layer in range(32)]\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716937071907,"user_tz":240,"elapsed":1503,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"337152ac-d748-4095-b631-4c037f051253","id":"g-dhVRCRa_Oq"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: January February MarchApril\n","5th char = 'April'\n","Sequence so far: January February MarchAprilMay\n","6th char = 'May'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(23, 17)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716937072659,"user_tz":240,"elapsed":765,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e65461fa-8386-483f-d622-1dee3556f258","id":"uSzHG8J3a_Oq"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: January February MarchApril\n","5th char = 'April'\n","Sequence so far: January February MarchAprilMay\n","6th char = 'May'\n"]}]},{"cell_type":"code","source":["# top 7 heads from seqcont months\n","\n","heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bP9WG2ttbkBb","executionInfo":{"status":"ok","timestamp":1716937189281,"user_tz":240,"elapsed":1355,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"999c8aae-cda3-4441-cdc5-1ec7137db305"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: January February MarchApril\n","5th char = 'April'\n","Sequence so far: January February MarchAprilMay\n","6th char = 'May'\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","head_to_remove = ([(23, 17), (17, 11), (16, 0), (26, 14), (18, 9), (5, 25), (22, 20), (6, 24), (26, 9), (12, 18), (13, 20), (19, 12), (27, 29), (13, 14), (16, 14), (12, 26), (19, 30), (16, 18), (31, 27), (26, 28), (16, 1), (18, 1), (19, 28), (18, 31), (29, 4), (17, 0), (14, 1), (17, 12), (12, 15), (28, 16), (10, 1), (16, 19), (9, 27), (30, 1), (19, 27), (0, 3), (15, 11), (21, 3), (11, 19), (12, 0), (23, 11), (8, 14), (16, 8), (22, 13), (13, 3), (4, 19), (14, 15), (12, 20), (19, 16), (18, 5)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(32)] #  if layer <10\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716937118135,"user_tz":240,"elapsed":8701,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5bf48166-55eb-4d8b-fde2-1f2b6fbafcc6","id":"gVrIpULobSmd"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Sequence so far: January February March \n","5th char = ' '\n","Sequence so far: January February March 2\n","6th char = '2'\n","Sequence so far: January February March 20\n","7th char = '0'\n","Sequence so far: January February March 202\n","8th char = '2'\n","Sequence so far: January February March 2023\n","9th char = '3'\n","Sequence so far: January February March 2023<0x0A>\n","10th char = '<0x0A>'\n","Sequence so far: January February March 2023<0x0A><0x0A>\n","11th char = '<0x0A>'\n","Sequence so far: January February March 2023<0x0A><0x0A>J\n","12th char = 'J'\n","Sequence so far: January February March 2023<0x0A><0x0A>Janu\n","13th char = 'anu'\n","Sequence so far: January February March 2023<0x0A><0x0A>January\n","14th char = 'ary'\n","Sequence so far: January February March 2023<0x0A><0x0A>January \n","15th char = ' '\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2\n","16th char = '2'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 20\n","17th char = '0'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 202\n","18th char = '2'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023\n","19th char = '3'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A>\n","20th char = '<0x0A>'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>\n","21th char = '<0x0A>'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>*\n","22th char = '*'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* \n","23th char = ' '\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1\n","24th char = '1'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January\n","25th char = 'January'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:\n","26th char = ':'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:New\n","27th char = 'New'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:NewYear\n","28th char = 'Year'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:NewYear'\n","29th char = \"'\"\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:NewYear's\n","30th char = 's'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:NewYear'sDay\n","31th char = 'Day'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:NewYear'sDay(\n","32th char = '('\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:NewYear'sDay(public\n","33th char = 'public'\n","Sequence so far: January February March 2023<0x0A><0x0A>January 2023<0x0A><0x0A>* 1January:NewYear'sDay(publichol\n","34th char = 'hol'\n"]}]}]}