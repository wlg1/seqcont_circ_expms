{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["wxS8oMwNS4dM","ekeOLatgdxhi"],"authorship_tag":"ABX9TyOuyDgdEngQF0xg7viW4mPo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"74c51e3119204e2e80ebdb5c88715853":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9afde1e17a344c8b2a8a211448a6ecf","IPY_MODEL_895899b18d3b4f6192d0fac1fd82fd65","IPY_MODEL_13b063418bf2474cb88e0d09ed0456f5"],"layout":"IPY_MODEL_0223bbde37dd48aa90c1faa099215542"}},"c9afde1e17a344c8b2a8a211448a6ecf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53ba0db561354a3ab10c922568a8529f","placeholder":"​","style":"IPY_MODEL_1c6255efa12841bcacb525612a0d9c26","value":"Downloading (…)lve/main/config.json: 100%"}},"895899b18d3b4f6192d0fac1fd82fd65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6edb5d87b9aa426ebfe30c7a54e4ab1d","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5296778c1c1f4d6d9bef9b75d37bdfff","value":665}},"13b063418bf2474cb88e0d09ed0456f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_080443dd33a649c68d80ad134b970264","placeholder":"​","style":"IPY_MODEL_0f16a95e3b424d42a6a6f433bb06cdf5","value":" 665/665 [00:00&lt;00:00, 34.7kB/s]"}},"0223bbde37dd48aa90c1faa099215542":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53ba0db561354a3ab10c922568a8529f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6255efa12841bcacb525612a0d9c26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6edb5d87b9aa426ebfe30c7a54e4ab1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5296778c1c1f4d6d9bef9b75d37bdfff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"080443dd33a649c68d80ad134b970264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f16a95e3b424d42a6a6f433bb06cdf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f3e825bd8724b879339d7d6df6c926e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a95b7c6a8a7c43c28afc35b8f6b7c154","IPY_MODEL_40a8ea9b3acc41a598f3cd84a6770456","IPY_MODEL_7cef1499ebd14cfe8c44e779cbd9a427"],"layout":"IPY_MODEL_8a5018872f364999a24f4ab748dc290e"}},"a95b7c6a8a7c43c28afc35b8f6b7c154":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b71e77d55d4fca8bcfda8775bc715d","placeholder":"​","style":"IPY_MODEL_4b46e42909ab49bf8b6c6fbe5540b583","value":"Downloading model.safetensors: 100%"}},"40a8ea9b3acc41a598f3cd84a6770456":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c729acad4309428bbec5fa0bbbb36946","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb910283232d4de0acd31911c2fd192a","value":548105171}},"7cef1499ebd14cfe8c44e779cbd9a427":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb2a261ba470480995f14ad99ce3d90a","placeholder":"​","style":"IPY_MODEL_0b59c6e98b094d838f4c4aa52adaa55d","value":" 548M/548M [00:06&lt;00:00, 75.8MB/s]"}},"8a5018872f364999a24f4ab748dc290e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b71e77d55d4fca8bcfda8775bc715d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b46e42909ab49bf8b6c6fbe5540b583":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c729acad4309428bbec5fa0bbbb36946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb910283232d4de0acd31911c2fd192a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb2a261ba470480995f14ad99ce3d90a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b59c6e98b094d838f4c4aa52adaa55d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1f8bb0e06dd4941a3e1eeb6b02681b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8abfdbb7f624b26aca7cba2c6ba1fa8","IPY_MODEL_52b7288f79324d7abdfff32568fcae9b","IPY_MODEL_9513f5e73d7143f0b3b7e7b28a856dca"],"layout":"IPY_MODEL_74aa4d15a4ba47489376174b25ef26c4"}},"f8abfdbb7f624b26aca7cba2c6ba1fa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_716698e034644f5ea7257c6fd17c7c4e","placeholder":"​","style":"IPY_MODEL_72122d012666460e9d032350eb135886","value":"Downloading (…)neration_config.json: 100%"}},"52b7288f79324d7abdfff32568fcae9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76368bc883284f6b894ce8f782c88158","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fda83c098fb04e25b286c2d2ce37aa2a","value":124}},"9513f5e73d7143f0b3b7e7b28a856dca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b783864eab14032af4abf631eb04b87","placeholder":"​","style":"IPY_MODEL_0232da1454f243dda5693ee40b039b5e","value":" 124/124 [00:00&lt;00:00, 3.64kB/s]"}},"74aa4d15a4ba47489376174b25ef26c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"716698e034644f5ea7257c6fd17c7c4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72122d012666460e9d032350eb135886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76368bc883284f6b894ce8f782c88158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fda83c098fb04e25b286c2d2ce37aa2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b783864eab14032af4abf631eb04b87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0232da1454f243dda5693ee40b039b5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f284e8f1c3f49ea9673e63a7edfc984":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6f8685a07ad46299a5662ac9ffec443","IPY_MODEL_c5da805efb034da7b3adb558b69b0a9c","IPY_MODEL_2785ed0ebe794d4e921f4d85efc3a626"],"layout":"IPY_MODEL_d89f23de6617406299f96ff4528c19d1"}},"b6f8685a07ad46299a5662ac9ffec443":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44adc2216e6e4cf4945329a49781b9a1","placeholder":"​","style":"IPY_MODEL_11410d53fffd4c199fb81ce2f10eb607","value":"Downloading (…)olve/main/vocab.json: 100%"}},"c5da805efb034da7b3adb558b69b0a9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68efae3a96ac46278c1e4b223791acd5","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13e96ca251b641b88d67cf626230f4ca","value":1042301}},"2785ed0ebe794d4e921f4d85efc3a626":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_105a31c2ffa14401a9e9b67948b2fc25","placeholder":"​","style":"IPY_MODEL_c166d36d37ee46509a8e25cecd4e8fab","value":" 1.04M/1.04M [00:00&lt;00:00, 2.27MB/s]"}},"d89f23de6617406299f96ff4528c19d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44adc2216e6e4cf4945329a49781b9a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11410d53fffd4c199fb81ce2f10eb607":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68efae3a96ac46278c1e4b223791acd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13e96ca251b641b88d67cf626230f4ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"105a31c2ffa14401a9e9b67948b2fc25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c166d36d37ee46509a8e25cecd4e8fab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8be3492158d472fae34cc3157fbee06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc2d5879940c4a97a0d3a45a90981689","IPY_MODEL_5e0a30ed15714e3794e3d0a27d1e2f2f","IPY_MODEL_426faaf664644f7c95d75e9302289df3"],"layout":"IPY_MODEL_d4930f805efd40188d7241a9430fc7fd"}},"cc2d5879940c4a97a0d3a45a90981689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5333bca3c7d4f6bb1c0ec9f06fda0ff","placeholder":"​","style":"IPY_MODEL_0c1139ddb0c043d4b16e5ede67a618af","value":"Downloading (…)olve/main/merges.txt: 100%"}},"5e0a30ed15714e3794e3d0a27d1e2f2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1675bd780c714e2bb2539a276ff6fb39","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c22b23c0faa740029b86ddd15e1df138","value":456318}},"426faaf664644f7c95d75e9302289df3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f26ad87f499b4f87ad6a7318a57f2b14","placeholder":"​","style":"IPY_MODEL_b282ab6a73794b7bab36a235d00866fe","value":" 456k/456k [00:00&lt;00:00, 3.04MB/s]"}},"d4930f805efd40188d7241a9430fc7fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5333bca3c7d4f6bb1c0ec9f06fda0ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c1139ddb0c043d4b16e5ede67a618af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1675bd780c714e2bb2539a276ff6fb39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c22b23c0faa740029b86ddd15e1df138":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f26ad87f499b4f87ad6a7318a57f2b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b282ab6a73794b7bab36a235d00866fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66f068b1592c421d8374c2ec045ab2d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fee39313f5964e56b7317306e3c306d4","IPY_MODEL_6827ad088a404c7581e5cfc41e368b97","IPY_MODEL_05b41665a37046daa67f74bd2b630989"],"layout":"IPY_MODEL_24f736b8cafb4896a6556aed92b22a3d"}},"fee39313f5964e56b7317306e3c306d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71904b35ad6941ae815478fa88690907","placeholder":"​","style":"IPY_MODEL_17f3fe2689584b6f8cd3baa7b8dc9a11","value":"Downloading (…)/main/tokenizer.json: 100%"}},"6827ad088a404c7581e5cfc41e368b97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_807fc93585704d748f10e4c4dff05137","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d09a14078604364800c35019a879277","value":1355256}},"05b41665a37046daa67f74bd2b630989":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_422f8f569ca64a31a53241c592f1aed3","placeholder":"​","style":"IPY_MODEL_ad0ddff61c5f48cb94d41e4e870b8921","value":" 1.36M/1.36M [00:00&lt;00:00, 3.50MB/s]"}},"24f736b8cafb4896a6556aed92b22a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71904b35ad6941ae815478fa88690907":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17f3fe2689584b6f8cd3baa7b8dc9a11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"807fc93585704d748f10e4c4dff05137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d09a14078604364800c35019a879277":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"422f8f569ca64a31a53241c592f1aed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad0ddff61c5f48cb94d41e4e870b8921":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"wxS8oMwNS4dM"},"source":["# Initial Setup Code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143538,"status":"ok","timestamp":1696549858668,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"eIThWRFlvryT","outputId":"613f294b-8e47-4f0a-fa71-9b0da4092ff1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n","\n","  \n","  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n","  install Node.js is deprecated now and will eventually be made inactive.\n","\n","  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n","  instructions to migrate your repo.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n","  information about which versions of Node.js and which Linux distributions\n","  are supported and how to install it.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","\n","                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n","Continuing in 60 seconds (press Ctrl-C to abort) ...\n","\n","\n","## Installing the NodeSource Node.js 16.x repo...\n","\n","\n","## Populating apt-get cache...\n","\n","+ apt-get update\n","Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Get:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [44.5 kB]\n","Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,002 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,081 kB]\n","Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,226 kB]\n","Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,342 kB]\n","Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,266 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,252 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [28.1 kB]\n","Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:19 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,197 kB]\n","Get:20 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,128 kB]\n","Fetched 10.9 MB in 4s (2,603 kB/s)\n","Reading package lists... Done\n","\n","## Confirming \"jammy\" is supported...\n","\n","+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n","\n","## Adding the NodeSource signing key to your keyring...\n","\n","+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n","\n","## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n","\n","+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n","+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n","\n","## Running `apt-get update` for you...\n","\n","+ apt-get update\n","Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Get:9 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [776 B]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 5,359 B in 2s (3,141 B/s)\n","Reading package lists... Done\n","\n","## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n","## You may also need development tools to build native addons:\n","     sudo apt-get install gcc g++ make\n","## To install the Yarn package manager, run:\n","     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n","     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n","     sudo apt-get update && sudo apt-get install yarn\n","\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  nodejs\n","0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n","Need to get 27.2 MB of archives.\n","After this operation, 128 MB of additional disk space will be used.\n","Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.2-deb-1nodesource1 [27.2 MB]\n","Fetched 27.2 MB in 1s (50.2 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package nodejs.\n","(Reading database ... 120879 files and directories currently installed.)\n","Preparing to unpack .../nodejs_16.20.2-deb-1nodesource1_amd64.deb ...\n","Unpacking nodejs (16.20.2-deb-1nodesource1) ...\n","Setting up nodejs (16.20.2-deb-1nodesource1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Collecting transformers\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0\n","Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.4.1\n","Cloning into 'svd_directions'...\n","remote: Enumerating objects: 69, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 69 (delta 3), reused 0 (delta 0), pack-reused 60\u001b[K\n","Receiving objects: 100% (69/69), 8.26 MiB | 15.61 MiB/s, done.\n","Resolving deltas: 100% (33/33), done.\n","/content/svd_directions\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.34.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.14.5)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.12.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.14.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.8.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.43.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.16.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2023.7.22)\n","Cloning into 'PySvelte'...\n","remote: Enumerating objects: 148, done.\u001b[K\n","remote: Counting objects: 100% (22/22), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 148 (delta 15), reused 13 (delta 13), pack-reused 126\u001b[K\n","Receiving objects: 100% (148/148), 1.85 MiB | 12.41 MiB/s, done.\n","Resolving deltas: 100% (72/72), done.\n","Obtaining file:///content/svd_directions/PySvelte\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pysvelte==1.0.1) (2.0.1+cu118)\n","Collecting einops (from pysvelte==1.0.1)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pysvelte==1.0.1) (1.23.5)\n","Collecting typeguard (from pysvelte==1.0.1)\n","  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pysvelte==1.0.1) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pysvelte==1.0.1) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pysvelte==1.0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pysvelte==1.0.1) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pysvelte==1.0.1) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pysvelte==1.0.1) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pysvelte==1.0.1) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pysvelte==1.0.1) (17.0.2)\n","Collecting typing-extensions (from torch->pysvelte==1.0.1)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pysvelte==1.0.1) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pysvelte==1.0.1) (1.3.0)\n","Installing collected packages: typing-extensions, einops, typeguard, pysvelte\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Running setup.py develop for pysvelte\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed einops-0.7.0 pysvelte-1.0.1 typeguard-4.1.5 typing-extensions-4.8.0\n"]}],"source":["# get everything set up\n","# more rapidly install node\n","!curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","# install other dependencies\n","!pip install transformers\n","!pip install datasets\n","# install repo with the data\n","!git clone https://github.com/BerenMillidge/svd_directions\n","%cd svd_directions\n","\n","!bash setup.sh\n","\n","import torch\n","from collections import Counter\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc\n","from copy import deepcopy\n","from tqdm.auto import tqdm, trange\n","import re\n","from collections import defaultdict\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","# utils\n","import json\n","from torch import nn\n","import torch.nn.functional as F\n","from datasets import load_dataset\n","from copy import deepcopy\n","from torch.nn import functional as F\n","from tabulate import tabulate\n","from tqdm import tqdm, trange\n","import functools\n","import math\n","\n","# this resets up the site so you don't have to restart the runtime to use pysvelte\n","import site\n","site.main()\n","# import pysvelte\n","\n","\n","# sns.set_palette('colorblind')\n","# cmap = sns.color_palette('colorblind')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-Fci9FTwq9b"},"outputs":[],"source":["def keep_k(x, k=100, absolute=True, dim=-1):\n","    shape = x.shape\n","    x_ = x\n","    if absolute:\n","        x_ = abs(x)\n","    values, indices = torch.topk(x_, k=k, dim=dim)\n","    res = torch.zeros_like(x)\n","    res.scatter_(dim, indices, x.gather(dim, indices))\n","    return res\n","\n","def get_max_token_length(tokens):\n","  maxlen = 0\n","  for t in tokens:\n","    l = len(t)\n","    if l > maxlen:\n","      maxlen = l\n","  return maxlen\n","\n","def pad_with_space(t, maxlen):\n","  spaces_to_add = maxlen - len(t)\n","  for i in range(spaces_to_add):\n","    t += \" \"\n","  return t\n","\n","def convert_to_tokens(indices, tokenizer, extended, extra_values_pos, strip=True, pad_to_maxlen=False):\n","    if extended:\n","        res = [tokenizer.convert_ids_to_tokens([idx])[0] if idx < len(tokenizer) else\n","               (f\"[pos{idx-len(tokenizer)}]\" if idx < extra_values_pos else f\"[val{idx-extra_values_pos}]\")\n","               for idx in indices]\n","    else:\n","        res = tokenizer.convert_ids_to_tokens(indices)\n","    if strip:\n","        res = list(map(lambda x: x[1:] if x[0] == 'Ġ' else \"#\" + x, res))\n","    if pad_to_maxlen:\n","      maxlen = get_max_token_length(res)\n","      res = list(map(lambda t: pad_with_space(t, maxlen), res))\n","    return res\n","\n","\n","def top_tokens(v_tok, k=100, tokenizer=None, only_english=False, only_ascii=True, with_values=False,\n","               exclude_brackets=False, extended=True, extra_values=None, pad_to_maxlen=False):\n","    if tokenizer is None:\n","        tokenizer = my_tokenizer\n","    v_tok = deepcopy(v_tok)\n","    ignored_indices = []\n","    if only_ascii:\n","        ignored_indices = [key for val, key in tokenizer.vocab.items() if not val.strip('Ġ').isascii()]\n","    if only_english:\n","        ignored_indices =[key for val, key in tokenizer.vocab.items() if not (val.strip('Ġ').isascii() and val.strip('Ġ[]').isalnum())]\n","    if exclude_brackets:\n","        ignored_indices = set(ignored_indices).intersection(\n","            {key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.isalnum())})\n","        ignored_indices = list(ignored_indices)\n","    v_tok[ignored_indices] = -np.inf\n","    extra_values_pos = len(v_tok)\n","    if extra_values is not None:\n","        v_tok = torch.cat([v_tok, extra_values])\n","    values, indices = torch.topk(v_tok, k=k)\n","    res = convert_to_tokens(indices, tokenizer, extended=extended, extra_values_pos=extra_values_pos,pad_to_maxlen = pad_to_maxlen)\n","    if with_values:\n","        res = list(zip(res, values.cpu().numpy()))\n","    return res\n","\n","\n","def top_matrix_tokens(mat, k=100, tokenizer=None, rel_thresh=None, thresh=None,\n","                      sample_entries=10000, alphabetical=True, only_english=False,\n","                      exclude_brackets=False, with_values=True, extended=True):\n","    if tokenizer is None:\n","        tokenizer = my_tokenizer\n","    mat = deepcopy(mat)\n","    ignored_indices = []\n","    if only_english:\n","        ignored_indices = [key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.strip('[]').isalnum())]\n","    if exclude_brackets:\n","        ignored_indices = set(ignored_indices).intersection(\n","            {key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.isalnum())})\n","        ignored_indices = list(ignored_indices)\n","    mat[ignored_indices, :] = -np.inf\n","    mat[:, ignored_indices] = -np.inf\n","    cond = torch.ones_like(mat).bool()\n","    if rel_thresh:\n","        cond &= (mat > torch.max(mat) * rel_thresh)\n","    if thresh:\n","        cond &= (mat > thresh)\n","    entries = torch.nonzero(cond)\n","    if sample_entries:\n","        entries = entries[np.random.randint(len(torch.nonzero(cond)), size=sample_entries)]\n","    res_indices = sorted(entries,\n","                         key=lambda x: x[0] if alphabetical else -mat[x[0], x[1]])\n","    res = [*map(partial(convert_to_tokens, extended=extended, tokenizer=tokenizer), res_indices)]\n","\n","    if with_values:\n","        res_ = []\n","        for (x1, x2), (i1, i2) in zip(res, res_indices):\n","            res_.append((x1, x2, mat[i1][i2].item()))\n","        res = res_\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpD59bpfxndh"},"outputs":[],"source":["def rgetattr(obj, attr, *args):\n","    def _getattr(obj, attr):\n","        return getattr(obj, attr, *args)\n","    return functools.reduce(_getattr, [obj] + attr.split('.'))\n","\n","def rsetattr(obj, attr, val):\n","    pre, _, post = attr.rpartition('.')\n","    return setattr(rgetattr(obj, pre) if pre else obj, post, val)\n","\n","def get_model_tokenizer_embedding(model_name=\"gpt2\"):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  if device == 'cpu':\n","    print(\"WARNING: you should probably restart on a GPU runtime\")\n","\n","  model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n","  tokenizer = AutoTokenizer.from_pretrained(model_name)\n","  emb = model.get_output_embeddings().weight.data.T.detach()\n","  return model, tokenizer, emb, device\n","\n","\n","def get_model_info(model):\n","  num_layers = model.config.n_layer\n","  num_heads = model.config.n_head\n","  hidden_dim = model.config.n_embd\n","  head_size = hidden_dim // num_heads\n","  return num_layers, num_heads, hidden_dim, head_size\n","\n","def get_mlp_weights(model,num_layers, hidden_dim):\n","  Ks = []\n","  Vs = []\n","  for j in range(num_layers):\n","    K = model.get_parameter(f\"transformer.h.{j}.mlp.c_fc.weight\").T.detach()\n","    # fuse the layernorm\n","    ln_2_weight = model.get_parameter(f\"transformer.h.{j}.ln_2.weight\").detach()\n","    K = torch.einsum(\"oi,i -> oi\", K, ln_2_weight)\n","\n","    V = model.get_parameter(f\"transformer.h.{j}.mlp.c_proj.weight\")\n","    Ks.append(K)\n","    Vs.append(V)\n","\n","  Ks =  torch.cat(Ks)\n","  Vs = torch.cat(Vs)\n","  K_heads = Ks.reshape(num_layers, -1, hidden_dim)\n","  V_heads = Vs.reshape(num_layers, -1, hidden_dim)\n","  return K_heads, V_heads\n","\n","def get_attention_heads(model, num_layers, hidden_dim, num_heads, head_size):\n","  qkvs = []\n","  for j in range(num_layers):\n","    qkv = model.get_parameter(f\"transformer.h.{j}.attn.c_attn.weight\").detach().T\n","    ln_weight_1 = model.get_parameter(f\"transformer.h.{j}.ln_1.weight\").detach()\n","\n","    qkv = qkv - torch.mean(qkv, dim=0)\n","    qkv = torch.einsum(\"oi,i -> oi\", qkv, ln_weight_1)\n","    qkvs.append(qkv.T)\n","\n","  W_Q, W_K, W_V = torch.cat(qkvs).chunk(3, dim=-1)\n","  W_O = torch.cat([model.get_parameter(f\"transformer.h.{j}.attn.c_proj.weight\") for j in range(num_layers)]).detach()\n","  W_V_heads = W_V.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n","  W_O_heads = W_O.reshape(num_layers, num_heads, head_size, hidden_dim)\n","  W_Q_heads = W_Q.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n","  W_K_heads = W_K.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n","  return W_Q_heads, W_K_heads, W_V_heads, W_O_heads\n","\n","def top_singular_vectors(mat, emb, all_tokens, k = 20, N_singular_vectors = 10, with_negative = False,use_visualization=True, filter=\"topk\"):\n","  U,S,V = torch.linalg.svd(mat)\n","  Vs = []\n","  for i in range(N_singular_vectors):\n","      acts = V[i,:].float() @ emb\n","      Vs.append(acts)\n","  if use_visualization:\n","    Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","    pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","  else:\n","    Vs = [top_tokens(Vs[i].float().cpu(), k = k, pad_to_maxlen=True) for i in range(len(Vs))]\n","    print(tabulate([*zip(*Vs)]))\n","  if with_negative:\n","    Vs = []\n","    for i in range(N_singular_vectors):\n","      acts = -V[i,:].float() @ emb\n","      Vs.append(acts)\n","    if use_visualization:\n","      Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","      pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","    else:\n","      Vs = [top_tokens(Vs[i].float().cpu(), k = k, pad_to_maxlen=True) for i in range(len(Vs))]\n","      print(tabulate([*zip(*Vs)]))\n","\n","def plot_MLP_singular_vectors(K,layer_idx, max_rank=None):\n","  W_matrix = K[layer_idx, :,:]\n","  U,S,V = torch.linalg.svd(W_matrix,full_matrices=False)\n","  if not max_rank:\n","    max_rank = len(S)\n","  if max_rank > len(S):\n","    max_rank = len(S) -1\n","  plt.plot(S[0:max_rank].detach().cpu().numpy())\n","  plt.yscale('log')\n","  plt.ylabel(\"Singular value\")\n","  plt.xlabel(\"Rank\")\n","  plt.title(\"Distribution of the singular vectors\")\n","  plt.show()\n","\n","def cosine_sim(x,y):\n","    return torch.dot(x,y) / (torch.norm(x) * torch.norm(y))\n","\n","\n","def normalize_and_entropy(V, eps=1e-6):\n","    absV = torch.abs(V)\n","    normV = absV / torch.sum(absV)\n","    entropy = torch.sum(normV * torch.log(normV + eps)).item()\n","    return -entropy\n"]},{"cell_type":"markdown","source":["## load model and get weights"],"metadata":{"id":"0rl4Hr0u8Ai1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBppCQTf57ne","executionInfo":{"status":"ok","timestamp":1696549885612,"user_tz":240,"elapsed":26956,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5446120b-c365-4ec4-bc8a-3f9b771b1bfa","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["74c51e3119204e2e80ebdb5c88715853","c9afde1e17a344c8b2a8a211448a6ecf","895899b18d3b4f6192d0fac1fd82fd65","13b063418bf2474cb88e0d09ed0456f5","0223bbde37dd48aa90c1faa099215542","53ba0db561354a3ab10c922568a8529f","1c6255efa12841bcacb525612a0d9c26","6edb5d87b9aa426ebfe30c7a54e4ab1d","5296778c1c1f4d6d9bef9b75d37bdfff","080443dd33a649c68d80ad134b970264","0f16a95e3b424d42a6a6f433bb06cdf5","0f3e825bd8724b879339d7d6df6c926e","a95b7c6a8a7c43c28afc35b8f6b7c154","40a8ea9b3acc41a598f3cd84a6770456","7cef1499ebd14cfe8c44e779cbd9a427","8a5018872f364999a24f4ab748dc290e","43b71e77d55d4fca8bcfda8775bc715d","4b46e42909ab49bf8b6c6fbe5540b583","c729acad4309428bbec5fa0bbbb36946","fb910283232d4de0acd31911c2fd192a","fb2a261ba470480995f14ad99ce3d90a","0b59c6e98b094d838f4c4aa52adaa55d","c1f8bb0e06dd4941a3e1eeb6b02681b9","f8abfdbb7f624b26aca7cba2c6ba1fa8","52b7288f79324d7abdfff32568fcae9b","9513f5e73d7143f0b3b7e7b28a856dca","74aa4d15a4ba47489376174b25ef26c4","716698e034644f5ea7257c6fd17c7c4e","72122d012666460e9d032350eb135886","76368bc883284f6b894ce8f782c88158","fda83c098fb04e25b286c2d2ce37aa2a","7b783864eab14032af4abf631eb04b87","0232da1454f243dda5693ee40b039b5e","0f284e8f1c3f49ea9673e63a7edfc984","b6f8685a07ad46299a5662ac9ffec443","c5da805efb034da7b3adb558b69b0a9c","2785ed0ebe794d4e921f4d85efc3a626","d89f23de6617406299f96ff4528c19d1","44adc2216e6e4cf4945329a49781b9a1","11410d53fffd4c199fb81ce2f10eb607","68efae3a96ac46278c1e4b223791acd5","13e96ca251b641b88d67cf626230f4ca","105a31c2ffa14401a9e9b67948b2fc25","c166d36d37ee46509a8e25cecd4e8fab","a8be3492158d472fae34cc3157fbee06","cc2d5879940c4a97a0d3a45a90981689","5e0a30ed15714e3794e3d0a27d1e2f2f","426faaf664644f7c95d75e9302289df3","d4930f805efd40188d7241a9430fc7fd","c5333bca3c7d4f6bb1c0ec9f06fda0ff","0c1139ddb0c043d4b16e5ede67a618af","1675bd780c714e2bb2539a276ff6fb39","c22b23c0faa740029b86ddd15e1df138","f26ad87f499b4f87ad6a7318a57f2b14","b282ab6a73794b7bab36a235d00866fe","66f068b1592c421d8374c2ec045ab2d5","fee39313f5964e56b7317306e3c306d4","6827ad088a404c7581e5cfc41e368b97","05b41665a37046daa67f74bd2b630989","24f736b8cafb4896a6556aed92b22a3d","71904b35ad6941ae815478fa88690907","17f3fe2689584b6f8cd3baa7b8dc9a11","807fc93585704d748f10e4c4dff05137","3d09a14078604364800c35019a879277","422f8f569ca64a31a53241c592f1aed3","ad0ddff61c5f48cb94d41e4e870b8921"]}},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: you should probably restart on a GPU runtime\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74c51e3119204e2e80ebdb5c88715853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f3e825bd8724b879339d7d6df6c926e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1f8bb0e06dd4941a3e1eeb6b02681b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f284e8f1c3f49ea9673e63a7edfc984"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8be3492158d472fae34cc3157fbee06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66f068b1592c421d8374c2ec045ab2d5"}},"metadata":{}}],"source":["# Load up the model and get all the key weight matrices.\n","model, tokenizer, emb, device = get_model_tokenizer_embedding()\n","my_tokenizer = tokenizer\n","num_layers, num_heads, hidden_dim, head_size = get_model_info(model)\n","all_tokens = [tokenizer.decode([i]) for i in range(tokenizer.vocab_size)]\n","\n","K,V = get_mlp_weights(model, num_layers = num_layers, hidden_dim = hidden_dim)\n","W_Q_heads, W_K_heads, W_V_heads, W_O_heads = get_attention_heads(model, num_layers=num_layers, hidden_dim=hidden_dim, num_heads=num_heads, head_size = head_size)"]},{"cell_type":"markdown","metadata":{"id":"ekeOLatgdxhi"},"source":["# Visualizing the SVD directions"]},{"cell_type":"code","source":["def OV_top_singular_vectors(W_V_heads, W_O_heads, emb, layer_idx, head_idx, all_tokens, k=20, N_singular_vectors=10, use_visualization=True, with_negative=False, filter=\"topk\", return_OV=False):\n","  W_V_tmp, W_O_tmp = W_V_heads[layer_idx, head_idx, :], W_O_heads[layer_idx, head_idx]\n","  OV = W_V_tmp @ W_O_tmp\n","  U,S,V = torch.linalg.svd(OV)\n","  Vs = []\n","  for i in range(N_singular_vectors):\n","      acts = V[i,:].float() @ emb\n","      Vs.append(acts)\n","  if use_visualization:\n","    Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","    pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","  else:\n","    Vs = [top_tokens(Vs[i].float().cpu(), k = k, pad_to_maxlen=True) for i in range(len(Vs))]\n","    print(tabulate([*zip(*Vs)]))\n","  if with_negative:\n","    Vs = []\n","    for i in range(N_singular_vectors):\n","      acts = -V[i,:].float() @ emb\n","      Vs.append(acts)\n","    if use_visualization:\n","      Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","      pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","    else:\n","      Vs = [top_tokens(Vs[i].float().cpu(), k = k, pad_to_maxlen=True) for i in range(len(Vs))]\n","      print(tabulate([*zip(*Vs)]))\n","  if return_OV:\n","    return OV"],"metadata":{"id":"s7ELf7dCPavW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OV_top_singular_vectors(W_V_heads, W_O_heads, emb, layer_idx=9, head_idx=1,k=20, N_singular_vectors=15, all_tokens = all_tokens, use_visualization=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khu3x3FIPe6g","executionInfo":{"status":"ok","timestamp":1696549918744,"user_tz":240,"elapsed":4234,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"901fddce-2516-4f71-f686-8c8ac1a8bb56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----  ------------  -------------  ---------  --------  ---------  ----------  ------------------  ----------  ----------  --------  ----------  ----------  --------  ----------\n","#,    MUST          #rule          #That      #RAW      52         #different  #hett               1953        #iless      #razil    #ahan       #erate      promul    ways\n","the   indefinitely  #Enlarge       That       #rency    Misc       #ukong      #zeb                1954        #ellig      #uese     Included    thous       #orum     #olean\n","#-    Cannot        #sen           #that      #ucha     #ettle     #Different  whilst              1955        #atively    #748      Still       1000        #adesh    Julius\n","and   #must         #efe           #ardy      cue       #wrong     RU          #440                chosen      #HER        Braun     Ogre        101         #dos      #merce\n","#.    #ife          #rules         #Those     #rises    okay       #KNOWN      #ischer             #iol        intellig    #oqu      ones        contrace    Dawn      #rette\n","in    Nass          #otta          that       #roma     #chuk      1850        #gow                #lem        endlessly   #825      included    #thro       #encia    #16\n","a     entirety      gotta          #ardi      #dot      SAR        #ignment    Europa              whichever   Would       #pell     includes    #Loading    #ilogy    #sylv\n","\"     cannot        #toggle        #ISIS      #netflix  #ordan     Wooden      #NZ                 1956        #elligent   #latable  still       100         #041      microscope\n","(     #obs          everybody      #MORE      #bett     hey        182         #ozo                formerly    comprehens  Kara      71          999         #oria     never\n","to    #ofi          really         deserving  COMPLE    lockout    #igmat      #netflix            insofar     Jas         #enough   #including  #utral      #certain  #ado\n","of    #kefeller     differentiate  #teenth    96        #lamm      1800        #40                 yourselves  #iable      #paralle  #chens      ultrasound  UL        #skirts\n","that  #Beginning    maybe          Those      #uyomi    Scandinav  Origin      guiActiveUnfocused  #former     Gael        #people   #tained     #100        66        may\n","I     #attribute    #eneg          #rahim     Canter    Mayo       Different   Tradable            particular  eleg        #tes      including   #1000       #yrinth   #oland\n","for   #ANGE         #164           #ricular   #omore    OK         #icultural  #\"]=>               #utions     kindly      #796      #olla       cous        defin     #iqueness\n","#:    ONLY          #1996          #kay       #rod      #NI        520         #TE                 #Kind       cog         #ools     #hern       #ect        #phis     #olin\n","on    Retrieved     #inelli        THAT       #ortium   #762       #ulla       #java               1952        1300        #irl      hasn        trickle     certain   Never\n","The   incorrectly   Kou            thats      97        hands      #ussen      #atche              Kung        Gentleman   #782      majority    #ugen       47        #nas\n","is    Gained        #really        #cause     #rences   #oche      VIDE        #DEV                herself     Jenkins     #728      #ahime      #ograp      #aah      #TON\n","with  very          #igmatic       #ichick    #airo     correctly  goodbye     ECO                 #LB         #chie       #756      variety     #ysc        #haw      #lov\n","#'s   VERY          */             #bre       #rin      62         Schro       #stead              craw        FAQ         average   #zos        #essen      #481      Mysterious\n","----  ------------  -------------  ---------  --------  ---------  ----------  ------------------  ----------  ----------  --------  ----------  ----------  --------  ----------\n"]}]},{"cell_type":"markdown","metadata":{"id":"ELdYODbHfBUd"},"source":["The way to read these tables is that the columns each represent a singular vector, ordered from that of the highest singular vector down to the lowest. The rows are the top-k token activations when the singular vector dimension is projected to token space, ordered by their value from top (greatest) to bottom (lowest). The colors represent the strength of the embedding.\n"]},{"cell_type":"code","source":["def extract_tokens_from_Vs(W_V_heads, W_O_heads, emb, layer_idx, head_idx, all_tokens, k=20, N_singular_vectors=10):\n","    \"\"\"\n","    Modified function to extract tokens from Vs without visualization or printing.\n","    \"\"\"\n","    W_V_tmp, W_O_tmp = W_V_heads[layer_idx, head_idx, :], W_O_heads[layer_idx, head_idx]\n","    OV = W_V_tmp @ W_O_tmp\n","    U, S, V = torch.linalg.svd(OV)\n","    Vs_tokens = []\n","    for i in range(N_singular_vectors):\n","        acts = V[i,:].float() @ emb\n","        # Use the top_tokens function to get the top k tokens for each singular vector\n","        Vs_tokens.extend(top_tokens(acts.float().cpu(), k=k))\n","    return Vs_tokens\n","\n","def percentage_of_numbers(tokens):\n","    \"\"\"\n","    Computes the percentage of tokens that are numbers.\n","    \"\"\"\n","    # Count how many tokens are numbers\n","    num_count = sum([token.isnumeric() for token in tokens])\n","\n","    # Compute the percentage\n","    percentage = (num_count / len(tokens)) * 100 if tokens else 0\n","\n","    return percentage\n","\n","# def compute_percentage_of_numbers_in_Vs(W_V_heads, W_O_heads, emb, layer_idx, head_idx, all_tokens, k=20, N_singular_vectors=10):\n","#     \"\"\"\n","#     Combined function to compute and print the percentage of tokens in Vs that are numbers, and print the numbers.\n","#     \"\"\"\n","#     # Extract the tokens from Vs\n","#     tokens_from_Vs = extract_tokens_from_Vs(W_V_heads, W_O_heads, emb, layer_idx, head_idx, all_tokens, k, N_singular_vectors)\n","\n","#     # Extract and print the numbers from the tokens\n","#     numbers = [token for token in tokens_from_Vs if token.isnumeric()]\n","#     print(\"Numbers found in tokens:\", numbers)\n","\n","#     # Compute the percentage of tokens that are numbers\n","#     percentage = percentage_of_numbers(tokens_from_Vs)\n","\n","#     print(f\"Percentage of tokens that are numbers: {percentage:.2f}%\")\n","#     return percentage\n","\n","def OV_top_singular_vectors_combined(W_V_heads, W_O_heads, emb, layer_idx, head_idx, all_tokens,\n","                                     k=20, N_singular_vectors=10, use_visualization=True, with_negative=False, filter=\"topk\", return_OV=False):\n","    \"\"\"\n","    Combined function that integrates compute_percentage_of_numbers_in_Vs into OV_top_singular_vectors.\n","    \"\"\"\n","    # Original OV_top_singular_vectors functionality\n","    W_V_tmp, W_O_tmp = W_V_heads[layer_idx, head_idx, :], W_O_heads[layer_idx, head_idx]\n","    OV = W_V_tmp @ W_O_tmp\n","    U,S,V = torch.linalg.svd(OV)\n","    Vs = []\n","\n","    for i in range(N_singular_vectors):\n","        acts = V[i,:].float() @ emb\n","        Vs.append(acts)\n","\n","    if use_visualization:\n","        # This part assumes that there's a visualization function in the original notebook\n","        # that can display the top tokens for each singular vector\n","        Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","        # Visualization function assumed from the original notebook\n","        # pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","    else:\n","        Vs_tokens = [top_tokens(Vs[i].float().cpu(), k=k) for i in range(len(Vs))]\n","        print(tabulate([*zip(*Vs_tokens)]))\n","\n","    if with_negative:\n","        Vs = []\n","        for i in range(N_singular_vectors):\n","            acts = -V[i,:].float() @ emb\n","            Vs.append(acts)\n","\n","        if use_visualization:\n","            # Visualization function assumed from the original notebook\n","            Vs = torch.stack(Vs, dim=1).unsqueeze(1) # n_tokens, n_layers (1), n_directions\n","            # pysvelte.TopKTable(tokens=all_tokens, activations=Vs, obj_type=\"SVD direction\", k=k, filter=filter).show()\n","        else:\n","            Vs_tokens = [top_tokens(Vs[i].float().cpu(), k=k) for i in range(len(Vs))]\n","            print(tabulate([*zip(*Vs_tokens)]))\n","\n","    # New functionality to compute and print the percentage of tokens that are numbers\n","    all_Vs_tokens = [top_tokens(Vs[i].float().cpu(), k=k) for i in range(len(Vs))]\n","    all_Vs_tokens_flat = [token for sublist in all_Vs_tokens for token in sublist]\n","\n","    # Extract and print the numbers from the tokens\n","    numbers = [token for token in all_Vs_tokens_flat if token.isnumeric()]\n","    print(\"\\nNumbers found in tokens:\", numbers)\n","\n","    # Compute the percentage of tokens that are numbers\n","    percentage = percentage_of_numbers(all_Vs_tokens_flat)\n","    print(f\"Percentage of tokens that are numbers: {percentage:.2f}%\")\n","\n","    if return_OV:\n","        return OV"],"metadata":{"id":"_xPl5UKE6Dhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OV_top_singular_vectors_combined(W_V_heads, W_O_heads, emb, layer_idx=9, head_idx=1, k=20, N_singular_vectors=15, all_tokens = all_tokens, use_visualization=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6F1cITA_Jvpj","executionInfo":{"status":"ok","timestamp":1696548490781,"user_tz":240,"elapsed":2944,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d74665c5-09a0-472a-ecd5-5e1341f9dcba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----  ------------  -------------  ---------  --------  ---------  ----------  ------------------  ----------  ----------  --------  ----------  ----------  --------  ----------\n","#,    MUST          #rule          #That      #RAW      52         #different  #hett               1953        #iless      #razil    #ahan       #erate      promul    #rier\n","the   indefinitely  #Enlarge       That       #rency    Misc       #ukong      #zeb                1954        #ellig      #uese     Included    thous       #orum     #gart\n","#-    Cannot        #sen           #that      #ucha     #ettle     #Different  whilst              1955        #atively    #748      Still       1000        #adesh    #Anyway\n","and   #must         #efe           #ardy      cue       #wrong     RU          #440                chosen      #HER        Braun     Ogre        101         #dos      #usterity\n","#.    #ife          #rules         #Those     #rises    okay       #KNOWN      #ischer             #iol        intellig    #oqu      ones        contrace    Dawn      Anyway\n","in    Nass          #otta          that       #roma     #chuk      1850        #gow                #lem        endlessly   #825      included    #thro       #encia    #urer\n","a     entirety      gotta          #ardi      #dot      SAR        #ignment    Europa              whichever   Would       #pell     includes    #Loading    #ilogy    #gre\n","\"     cannot        #toggle        #ISIS      #netflix  #ordan     Wooden      #NZ                 1956        #elligent   #latable  still       100         #041      avail\n","(     #obs          everybody      #MORE      #bett     hey        182         #ozo                formerly    comprehens  Kara      71          999         #oria     #adra\n","to    #ofi          really         deserving  COMPLE    lockout    #igmat      #netflix            insofar     Jas         #enough   #including  #utral      #certain  #igger\n","of    #kefeller     differentiate  #teenth    96        #lamm      1800        #40                 yourselves  #iable      #paralle  #chens      ultrasound  UL        Leban\n","that  #Beginning    maybe          Those      #uyomi    Scandinav  Origin      guiActiveUnfocused  #former     Gael        #people   #tained     #100        66        #ctor\n","I     #attribute    #eneg          #rahim     Canter    Mayo       Different   Tradable            particular  eleg        #tes      including   #1000       #yrinth   Marketable\n","for   #ANGE         #164           #ricular   #omore    OK         #icultural  #\"]=>               #utions     kindly      #796      #olla       cous        defin     #icago\n","#:    ONLY          #1996          #kay       #rod      #NI        520         #TE                 #Kind       cog         #ools     #hern       #ect        #phis     #Well\n","on    Retrieved     #inelli        THAT       #ortium   #762       #ulla       #java               1952        1300        #irl      hasn        trickle     certain   #esc\n","The   incorrectly   Kou            thats      97        hands      #ussen      #atche              Kung        Gentleman   #782      majority    #ugen       47        sucker\n","is    Gained        #really        #cause     #rences   #oche      VIDE        #DEV                herself     Jenkins     #728      #ahime      #ograp      #aah      #uted\n","with  very          #igmatic       #ichick    #airo     correctly  goodbye     ECO                 #LB         #chie       #756      variety     #ysc        #haw      #ERG\n","#'s   VERY          */             #bre       #rin      62         Schro       #stead              craw        FAQ         average   #zos        #essen      #481      nicer\n","----  ------------  -------------  ---------  --------  ---------  ----------  ------------------  ----------  ----------  --------  ----------  ----------  --------  ----------\n","\n","Numbers found in tokens: ['96', '97', '52', '62', '1850', '182', '1800', '520', '1953', '1954', '1955', '1956', '1952', '1300', '71', '1000', '101', '100', '999', '66', '47']\n","Percentage of tokens that are numbers: 7.00%\n"]}]},{"cell_type":"code","source":["def compute_percentage_dict(W_V_heads, W_O_heads, emb, all_tokens, k=20, N_singular_vectors=15, print_numbers=False):\n","    \"\"\"\n","    Computes a dictionary with the percentage of tokens in Vs that are numbers for each layer-head combination.\n","    \"\"\"\n","    percentage_dict = {}\n","\n","    # Loop through layers and heads\n","    for layer_idx in range(12):\n","        for head_idx in range(12):\n","            # Extract the tokens from Vs\n","            tokens_from_Vs = extract_tokens_from_Vs(W_V_heads, W_O_heads, emb, layer_idx, head_idx, all_tokens, k, N_singular_vectors)\n","\n","            # Optionally print the numbers\n","            if print_numbers:\n","                numbers = [token for token in tokens_from_Vs if token.isnumeric()]\n","                if numbers:\n","                    print(f\"Numbers for layer {layer_idx}, head {head_idx}:\", numbers)\n","\n","            # Compute the percentage of tokens that are numbers\n","            percentage = percentage_of_numbers(tokens_from_Vs)\n","\n","            # Save the percentage in the dictionary\n","            percentage_dict[(layer_idx, head_idx)] = percentage\n","\n","    return percentage_dict"],"metadata":{"id":"tlV7-o7GERk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["percentages = compute_percentage_dict(W_V_heads, W_O_heads, emb, all_tokens, k=20, N_singular_vectors=15, print_numbers=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUovtCNoEaOD","executionInfo":{"status":"ok","timestamp":1696548920364,"user_tz":240,"elapsed":301321,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ee0b21dc-6976-426c-ecd3-b796853fe0ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Numbers for layer 0, head 6: ['1945']\n","Numbers for layer 0, head 9: ['2']\n","Numbers for layer 1, head 2: ['0004']\n","Numbers for layer 1, head 5: ['2021']\n","Numbers for layer 1, head 7: ['2']\n","Numbers for layer 1, head 11: ['3']\n","Numbers for layer 3, head 3: ['978']\n","Numbers for layer 3, head 4: ['1080']\n","Numbers for layer 4, head 2: ['2']\n","Numbers for layer 4, head 7: ['255']\n","Numbers for layer 4, head 8: ['2018', '2017', '2019', '2016']\n","Numbers for layer 4, head 9: ['2020']\n","Numbers for layer 4, head 10: ['3', '2', '4', '1']\n","Numbers for layer 5, head 8: ['295']\n","Numbers for layer 5, head 10: ['1']\n","Numbers for layer 6, head 2: ['2017']\n","Numbers for layer 6, head 9: ['12']\n","Numbers for layer 6, head 10: ['2']\n","Numbers for layer 7, head 5: ['1915', '1917', '2020']\n","Numbers for layer 7, head 6: ['2019', '2018']\n","Numbers for layer 7, head 10: ['1978']\n","Numbers for layer 9, head 1: ['96', '97', '52', '62', '1850', '182', '1800', '520', '1953', '1954', '1955', '1956', '1952', '1300', '71', '1000', '101', '100', '999', '66', '47']\n","Numbers for layer 9, head 4: ['0004', '1863']\n","Numbers for layer 9, head 7: ['4090', '5', '1']\n","Numbers for layer 9, head 9: ['159', '73', '293']\n","Numbers for layer 10, head 2: ['13', '14', '15', '10', '08', '17', '11', '16', '09', '12', '26', '27', '1840', '978', '980', '999', '970', '737', '3000', '09', '9', '211', '170', '172', '178', '190', '185', '187', '177', '209', '210', '203', '175', '204', '179', '171', '186', '1880', '1300', '1500', '37', '1500', '2500', '800', '700', '2', '3000', '900', '750', '1', '1400', '0000', '1600', '1700', '1300', '2100', '850', '2400']\n","Numbers for layer 10, head 3: ['2012', '1907', '1900', '2016', '2001', '1996', '1998', '2015', '1997', '2002', '2004', '2006', '2007', '2005', '2014', '2003', '2021', '1995', '1999', '2013']\n","Numbers for layer 10, head 7: ['75', '1947', '1987', '1985']\n","Numbers for layer 11, head 4: ['1', '2', '9', '3', '5', '0', '7', '8', '1', '2', '5', '4', '6', '3', '0']\n"]}]},{"cell_type":"code","source":["sorted_percentages_by_value_actual = sorted(percentages.items(), key=lambda item: item[1], reverse=True)\n","sorted_percentages_by_value_actual[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKzaWjC5FYuW","executionInfo":{"status":"ok","timestamp":1696548920366,"user_tz":240,"elapsed":82,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"eb285736-3be1-45bf-a699-59175e5ee3a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[((10, 2), 19.333333333333332),\n"," ((9, 1), 7.000000000000001),\n"," ((10, 3), 6.666666666666667),\n"," ((11, 4), 5.0),\n"," ((4, 8), 1.3333333333333335),\n"," ((4, 10), 1.3333333333333335),\n"," ((10, 7), 1.3333333333333335),\n"," ((7, 5), 1.0),\n"," ((9, 7), 1.0),\n"," ((9, 9), 1.0)]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"FANOHRMNff6_"},"source":["We also see an interesting pattern, which is common, whereby the head as a whole seems to handle a broad concept and each singular vector specializes into a separate semantic aspect of this broader concept.\n","\n","It is very common that the first singular vector does not encode anything meaningful and simply encodes a component in the direction of the most frequent words, as in this example."]}]}