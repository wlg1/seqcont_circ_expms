{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b13177b7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/nb_templates/circuit_expms_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will save files to your local machine if `save_files` is set to True."
      ],
      "metadata": {
        "id": "6iIlUWijq7eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change Inputs Here"
      ],
      "metadata": {
        "id": "vKYgaZ9JjihZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"months\"  # choose: numerals, numwords, months\n",
        "prompt_types = ['done', 'lost', 'names']\n",
        "num_samps_per_ptype = 512 #768 512\n",
        "\n",
        "model_name = \"gpt2-small\"\n",
        "\n",
        "# Without MLP 11\n",
        "heads_not_ablate = [(0, 1), (0, 5), (4, 4), (6, 1), (6, 6), (6, 10), (7, 6), (7, 9), (7, 10), (7, 11), (8, 8), (9, 1), (10, 7)]\n",
        "mlps_not_ablate = [0, 1, 2, 3, 4, 6, 7, 8, 9, 10]\n",
        "\n",
        "# With MLP 11\n",
        "# heads_not_ablate = [(0, 1), (4, 4), (4, 10), (6, 1), (6, 6), (6, 10), (7, 2), (7, 10), (7, 11), (8, 8), (9, 1)]\n",
        "# mlps_not_ablate = [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11] # incl 5 makes it 66.1155%\n",
        "\n",
        "threshold = 0.8\n",
        "save_files = True\n",
        "load_graph_files = False\n",
        "run_on_other_tasks = True"
      ],
      "metadata": {
        "id": "KSKP_OsTDki6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcZG9rm2IAiA"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install git+https://github.com/neelnanda-io/TransformerLens.git"
      ],
      "metadata": {
        "id": "F1wsEy0MqHU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6b1n2tvIAiD"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "from torch import Tensor\n",
        "from jaxtyping import Float\n",
        "from typing import List, Optional, Callable, Tuple\n",
        "from functools import partial\n",
        "\n",
        "import pickle\n",
        "from google.colab import files\n",
        "\n",
        "from graphviz import Digraph, Source\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuhzYxbsIAiE"
      },
      "outputs": [],
      "source": [
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, ActivationCache\n",
        "\n",
        "t.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "OLkInsdjyHMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLwDyosvIAiJ"
      },
      "outputs": [],
      "source": [
        "model = HookedTransformer.from_pretrained(\n",
        "    model_name,\n",
        "    center_unembed=True,\n",
        "    center_writing_weights=True,\n",
        "    fold_ln=True,\n",
        "    refactor_factored_attn_matrices=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import functions from repo"
      ],
      "metadata": {
        "id": "Z4iJEGh6b56v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/apartresearch/seqcont_circuits.git"
      ],
      "metadata": {
        "id": "F8TXMRL3CoPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/seqcont_circuits/src/iter_node_pruning\n",
        "\n",
        "from dataset import Dataset\n",
        "from metrics import *\n",
        "from head_ablation_fns import *\n",
        "from mlp_ablation_fns import *\n",
        "from node_ablation_fns import *\n",
        "from loop_node_ablation_fns import *"
      ],
      "metadata": {
        "id": "22TI4zjMDMfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/seqcont_circuits/src/iter_edge_pruning\n",
        "\n",
        "from edge_pruning_fns import *\n",
        "from viz_circuits import *"
      ],
      "metadata": {
        "id": "ujEhuZBNhhFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets"
      ],
      "metadata": {
        "id": "6Fuq8XW770vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_list = []\n",
        "\n",
        "for i in prompt_types:\n",
        "    file_name = f'/content/seqcont_circuits/data/{task}/{task}_prompts_{i}.pkl'\n",
        "    with open(file_name, 'rb') as file:\n",
        "        filelist = pickle.load(file)\n",
        "\n",
        "    print(filelist[0]['text'])\n",
        "    prompts_list += filelist [:num_samps_per_ptype]\n",
        "\n",
        "len(prompts_list)"
      ],
      "metadata": {
        "id": "CIe5yXuDhgEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_dict = {}\n",
        "for i in range(len(model.tokenizer.tokenize(prompts_list[0]['text']))):\n",
        "    pos_dict['S'+str(i)] = i"
      ],
      "metadata": {
        "id": "kS_Tlrb_70vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1 = Dataset(prompts_list, pos_dict, model.tokenizer)"
      ],
      "metadata": {
        "id": "u0NPSKcZ1iDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = f'/content/seqcont_circuits/data/{task}/randDS_{task}.pkl'\n",
        "with open(file_name, 'rb') as file:\n",
        "    prompts_list_2 = pickle.load(file)"
      ],
      "metadata": {
        "id": "-GJ_ZC48FB1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)"
      ],
      "metadata": {
        "id": "msu6D4p_feW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "BHHvz84w70vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_hooks(including_permanent=True)\n",
        "logits_original = model(dataset_1.toks)\n",
        "orig_score = get_logit_diff(logits_original, dataset_1)\n",
        "\n",
        "# model.reset_hooks(including_permanent=True)\n",
        "# logits_corrup = model(dataset_2.toks)\n",
        "# corrup_score = get_logit_diff(abc_logits_original, dataset_2)"
      ],
      "metadata": {
        "id": "OI3FcmpMaNxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logit_diff_perc(\n",
        "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
        "    clean_logit_diff: float = orig_score,\n",
        "    dataset_1: Dataset = dataset_1,\n",
        ") -> float:\n",
        "    patched_logit_diff = get_logit_diff(logits, dataset_1)\n",
        "    return (patched_logit_diff / clean_logit_diff)"
      ],
      "metadata": {
        "id": "5GGyaa_u7jGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del(logits_original)\n",
        "# del(logits_corrup)\n",
        "t.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "A-TjmW5PUwGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Iter Edge Pruning"
      ],
      "metadata": {
        "id": "c54cqFf2lT2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get circuit"
      ],
      "metadata": {
        "id": "no8gv3Hgka8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the node ablated circuit without edges ablated."
      ],
      "metadata": {
        "id": "tmFnku5GOeVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "abl_model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n",
        "\n",
        "new_logits = model(dataset_1.toks)\n",
        "new_score = get_logit_diff(new_logits, dataset_1)\n",
        "circ_score = (100 * new_score / orig_score).item()\n",
        "print(f\"(cand circuit / full) %: {circ_score:.4f}\")\n",
        "del(new_logits)"
      ],
      "metadata": {
        "id": "vLVucYAnkdKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## head to head"
      ],
      "metadata": {
        "id": "HLA7GH89vZY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_to_HH = {} # qkv to dict\n",
        "\n",
        "for head_type in [\"q\", \"k\", \"v\"]:\n",
        "    head_to_head_results = {}\n",
        "    for head in heads_not_ablate:\n",
        "        print(head_type, head)\n",
        "        model.reset_hooks()\n",
        "        model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n",
        "\n",
        "        result = circ_path_patch_head_to_heads(\n",
        "            circuit = heads_not_ablate,\n",
        "            receiver_heads = [head],\n",
        "            receiver_input = head_type,\n",
        "            model = model,\n",
        "            patching_metric = logit_diff_perc,\n",
        "            new_dataset = dataset_2,\n",
        "            orig_dataset = dataset_1\n",
        "        )\n",
        "        head_to_head_results[head] = result\n",
        "    qkv_to_HH[head_type] = head_to_head_results"
      ],
      "metadata": {
        "id": "LfncU3j7vWWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_to_head_adjList = {}\n",
        "for head_type in [\"q\", \"k\", \"v\"]:\n",
        "    for head in heads_not_ablate:\n",
        "        result = qkv_to_HH[head_type][head]\n",
        "        filtered_indices = (result < threshold) & (result != 0.0)\n",
        "        rows, cols = filtered_indices.nonzero(as_tuple=True)\n",
        "        sender_nodes = list(zip(rows.tolist(), cols.tolist()))\n",
        "        head_with_type = head + (head_type,)\n",
        "        head_to_head_adjList[head_with_type] = sender_nodes"
      ],
      "metadata": {
        "id": "VE2IpLNpHgeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mlp to mlp"
      ],
      "metadata": {
        "id": "ccROLT75vT7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_to_mlp_results = {}\n",
        "\n",
        "for layer in reversed(mlps_not_ablate):\n",
        "    print(layer)\n",
        "    model.reset_hooks()\n",
        "    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n",
        "    result = circ_path_patch_MLPs_to_MLPs(\n",
        "        mlp_circuit = mlps_not_ablate,\n",
        "        receiver_layers = [layer],\n",
        "        model = model,\n",
        "        patching_metric = logit_diff_perc,\n",
        "        new_dataset = dataset_2,\n",
        "        orig_dataset = dataset_1\n",
        "    )\n",
        "    mlp_to_mlp_results[layer] = result"
      ],
      "metadata": {
        "id": "nD4bTlmHlVks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_to_mlp_adjList = {}\n",
        "for mlp in mlps_not_ablate:\n",
        "    result = mlp_to_mlp_results[mlp]\n",
        "    filtered_indices = (result < threshold) & (result != 0.0)\n",
        "    filtered_indices = filtered_indices.nonzero(as_tuple=True)[0]\n",
        "    mlp_to_mlp_adjList[mlp] = filtered_indices.tolist()"
      ],
      "metadata": {
        "id": "NN0Vd9eIrpL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## head to mlp"
      ],
      "metadata": {
        "id": "qStvFtFrBHTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head_to_mlp_results = {}\n",
        "\n",
        "for layer in reversed(mlps_not_ablate):\n",
        "    print(layer)\n",
        "    model.reset_hooks()\n",
        "    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n",
        "    result = circ_path_patch_head_to_mlp(\n",
        "        circuit = heads_not_ablate,\n",
        "        receiver_layers = [layer],\n",
        "        model = model,\n",
        "        patching_metric = logit_diff_perc,\n",
        "        new_dataset = dataset_2,\n",
        "        orig_dataset = dataset_1\n",
        "    )\n",
        "    head_to_mlp_results[layer] = result"
      ],
      "metadata": {
        "id": "RkeGOxibBMIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_to_mlp_adjList = {}\n",
        "for layer in mlps_not_ablate:\n",
        "    result = head_to_mlp_results[layer]\n",
        "    filtered_indices = (result < threshold) & (result != 0.0)\n",
        "    rows, cols = filtered_indices.nonzero(as_tuple=True)\n",
        "    sender_nodes = list(zip(rows.tolist(), cols.tolist()))\n",
        "    head_to_mlp_adjList[layer] = sender_nodes"
      ],
      "metadata": {
        "id": "9sSF5sgSCQfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mlp to head"
      ],
      "metadata": {
        "id": "y1DQqZXrEi4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_mlp_to_HH = {} # qkv to dict\n",
        "\n",
        "for head_type in [\"q\", \"k\", \"v\"]:\n",
        "    mlp_to_head_results = {}\n",
        "    for head in heads_not_ablate:\n",
        "        print(head_type, head)\n",
        "        model.reset_hooks()\n",
        "        model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n",
        "\n",
        "        result = circ_path_patch_mlp_to_head(\n",
        "            mlp_circuit = mlps_not_ablate,\n",
        "            receiver_heads = [head],\n",
        "            receiver_input = head_type,\n",
        "            model = model,\n",
        "            patching_metric = logit_diff_perc,\n",
        "            new_dataset = dataset_2,\n",
        "            orig_dataset = dataset_1\n",
        "        )\n",
        "        mlp_to_head_results[head] = result\n",
        "    qkv_mlp_to_HH[head_type] = mlp_to_head_results"
      ],
      "metadata": {
        "id": "4GdPAN1wEuhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_to_head_adjList = {}\n",
        "for head_type in [\"q\", \"k\", \"v\"]:\n",
        "    for head in heads_not_ablate:\n",
        "        result = qkv_mlp_to_HH[head_type][head]\n",
        "        filtered_indices = (result < threshold) & (result != 0.0)\n",
        "        filtered_indices = filtered_indices.nonzero(as_tuple=True)[0]\n",
        "        head_with_type = head + (head_type,)\n",
        "        mlp_to_head_adjList[head_with_type] = filtered_indices.tolist()"
      ],
      "metadata": {
        "id": "OKDLGm2KPlJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save graph files to free up memory"
      ],
      "metadata": {
        "id": "u1VIlinotlLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if save_files:\n",
        "    with open(task + \"_head_to_head_results.pkl\", \"wb\") as file:\n",
        "        pickle.dump(head_to_head_results, file)\n",
        "    files.download(task + \"_head_to_head_results.pkl\")\n",
        "\n",
        "    with open(task + \"_mlp_to_mlp_results.pkl\", \"wb\") as file:\n",
        "        pickle.dump(mlp_to_mlp_results, file)\n",
        "    files.download(task + \"_mlp_to_mlp_results.pkl\")\n",
        "\n",
        "    with open(task + \"_head_to_mlp_results.pkl\", \"wb\") as file:\n",
        "        pickle.dump(head_to_mlp_results, file)\n",
        "    files.download(task + \"_head_to_mlp_results.pkl\")\n",
        "\n",
        "    with open(task + \"_mlp_to_head_results.pkl\", \"wb\") as file:\n",
        "        pickle.dump(mlp_to_head_results, file)\n",
        "    files.download(task + \"_mlp_to_head_results.pkl\")\n",
        "\n",
        "del(head_to_head_results)\n",
        "del(mlp_to_mlp_results)\n",
        "del(head_to_mlp_results)\n",
        "del(mlp_to_head_results)"
      ],
      "metadata": {
        "id": "U8Fosqu6rt3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Iter Edge Pruning- resid post"
      ],
      "metadata": {
        "id": "xyMeogkrRdVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## head to resid"
      ],
      "metadata": {
        "id": "ZT1l8tATRna6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_hooks()\n",
        "model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n",
        "\n",
        "path_patch_head_to_final_resid_post = get_path_patch_head_to_final_resid_post(heads_not_ablate, model, logit_diff_perc,\n",
        "                                                                new_dataset = dataset_2, orig_dataset = dataset_1)"
      ],
      "metadata": {
        "id": "4m3Qf4FHTzwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heads_to_resid = {}\n",
        "result = path_patch_head_to_final_resid_post\n",
        "filtered_indices = (result < threshold) & (result != 0.0)\n",
        "rows, cols = filtered_indices.nonzero(as_tuple=True)\n",
        "heads_to_resid['resid'] = list(zip(rows.tolist(), cols.tolist()))"
      ],
      "metadata": {
        "id": "81vDVv78Re-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mlp to resid"
      ],
      "metadata": {
        "id": "gdBVxmksWbO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_hooks()\n",
        "model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n",
        "\n",
        "path_patch_mlp_to_final_resid_post = get_path_patch_mlp_to_final_resid_post(mlps_not_ablate, model, logit_diff_perc,\n",
        "                                                                new_dataset = dataset_2, orig_dataset = dataset_1)"
      ],
      "metadata": {
        "id": "oSbfi1kPZqI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlps_to_resid = {}\n",
        "result = path_patch_mlp_to_final_resid_post\n",
        "filtered_indices = (result < threshold) & (result != 0.0)\n",
        "filtered_indices = filtered_indices.nonzero(as_tuple=True)[0]\n",
        "mlps_to_resid['resid'] = filtered_indices.tolist()"
      ],
      "metadata": {
        "id": "idRsYRx2ZqI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter out nodes with no ingoing edges"
      ],
      "metadata": {
        "id": "o8sGuo1wb10E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head_to_head_adjList = {node: neighbors for node, neighbors in head_to_head_adjList.items() if neighbors}"
      ],
      "metadata": {
        "id": "L5BLSrZAb5sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_to_head_adjList = {node: neighbors for node, neighbors in mlp_to_head_adjList.items() if neighbors}"
      ],
      "metadata": {
        "id": "fXuZqTiFcL0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save rest of graph files"
      ],
      "metadata": {
        "id": "Scg7MWoGmkFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if save_files:\n",
        "    # graphs\n",
        "    with open(task + \"_head_to_head_adjList.pkl\", \"wb\") as file:\n",
        "        pickle.dump(head_to_head_adjList, file)\n",
        "    files.download(task + \"_head_to_head_adjList.pkl\")\n",
        "\n",
        "    with open(task + \"_mlp_to_mlp_adjList.pkl\", \"wb\") as file:\n",
        "        pickle.dump(mlp_to_mlp_adjList, file)\n",
        "    files.download(task + \"_mlp_to_mlp_adjList.pkl\")\n",
        "\n",
        "    with open(task + \"_head_to_mlp_adjList.pkl\", \"wb\") as file:\n",
        "        pickle.dump(head_to_mlp_adjList, file)\n",
        "    files.download(task + \"_head_to_mlp_adjList.pkl\")\n",
        "\n",
        "    with open(task + \"_mlp_to_head_adjList.pkl\", \"wb\") as file:\n",
        "        pickle.dump(mlp_to_head_adjList, file)\n",
        "    files.download(task + \"_mlp_to_head_adjList.pkl\")\n",
        "\n",
        "    with open(task + \"_heads_to_resid.pkl\", \"wb\") as file:\n",
        "        pickle.dump(heads_to_resid, file)\n",
        "    files.download(task + \"_heads_to_resid.pkl\")\n",
        "\n",
        "    with open(task + \"_mlps_to_resid.pkl\", \"wb\") as file:\n",
        "        pickle.dump(mlps_to_resid, file)\n",
        "    files.download(task + \"_mlps_to_resid.pkl\")\n",
        "\n",
        "    # score results\n",
        "    with open(task + \"_heads_to_resid_results.pkl\", \"wb\") as file:\n",
        "        pickle.dump(path_patch_head_to_final_resid_post, file)\n",
        "    files.download(task + \"_heads_to_resid_results.pkl\")\n",
        "\n",
        "    with open(task + \"_mlps_to_resid_results.pkl\", \"wb\") as file:\n",
        "        pickle.dump(path_patch_mlp_to_final_resid_post, file)\n",
        "    files.download(task + \"_mlps_to_resid_results.pkl\")"
      ],
      "metadata": {
        "id": "NIJrXZOupjVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Circuit graph plot"
      ],
      "metadata": {
        "id": "qNC5dz11VcRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load data"
      ],
      "metadata": {
        "id": "noqfBOdpiVGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if load_graph_files:\n",
        "    with open(task + \"_head_to_head_adjList.pkl\", \"rb\") as file:\n",
        "        head_to_head_adjList = pickle.load(file)\n",
        "\n",
        "    with open(task + \"_mlp_to_mlp_adjList.pkl\", \"rb\") as file:\n",
        "        mlp_to_mlp_adjList = pickle.load(file)\n",
        "\n",
        "    with open(task + \"_head_to_mlp_adjList.pkl\", \"rb\") as file:\n",
        "        head_to_mlp_adjList = pickle.load(file)\n",
        "\n",
        "    with open(task + \"_mlp_to_head_adjList.pkl\", \"rb\") as file:\n",
        "        mlp_to_head_adjList = pickle.load(file)\n",
        "\n",
        "    with open(task + \"_heads_to_resid.pkl\", \"rb\") as file:\n",
        "        heads_to_resid = pickle.load(file)\n",
        "\n",
        "    with open(task + \"_mlps_to_resid.pkl\", \"rb\") as file:\n",
        "        mlps_to_resid = pickle.load(file)"
      ],
      "metadata": {
        "id": "0jQ5s9Ji5OB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot qkv"
      ],
      "metadata": {
        "id": "ST-TgrqgVgqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph_adjacency_qkv(head_to_head_adjList, mlp_to_mlp_adjList, head_to_mlp_adjList,\n",
        "                         mlp_to_head_adjList, heads_to_resid, mlps_to_resid, filename=\"qkv\")"
      ],
      "metadata": {
        "id": "aS-TFDTOVgqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot no qkv fn"
      ],
      "metadata": {
        "id": "5zQfhV5QVgqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph_adjacency(head_to_head_adjList, mlp_to_mlp_adjList, head_to_mlp_adjList,\n",
        "                         mlp_to_head_adjList, heads_to_resid, mlps_to_resid, filename=\"no qkv\")"
      ],
      "metadata": {
        "id": "jlB5soNZVgqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}