{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","collapsed_sections":["DcZG9rm2IAiA","b3Chees1fkO1","VDfzJNjP66tK"],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyPWF0Uv6v5U1PQCAPWove4l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# run this to add files without wiating for setup. after adding, run all\n","1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2itLOY5xX24","executionInfo":{"status":"ok","timestamp":1702715462124,"user_tz":300,"elapsed":427,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7fe0956a-843f-4805-e513-8fef2654ddc4"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1c2be4b-2331-44df-c60f-1ecea5f19d20","executionInfo":{"status":"ok","timestamp":1702715478071,"user_tz":300,"elapsed":15510,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-4fj4sugf\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-4fj4sugf\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit ce82675a8e89b6d5e6229a89620c843c794f3b04\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.25.0)\n","Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.14.1)\n","Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.15.0)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.7.0)\n","Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.0.3)\n","Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.2.25)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.26.2)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.7.0)\n","Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.2)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.35.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.16.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.4.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.7)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.9.1)\n","Requirement already satisfied: typeguard<3,>=2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (2.13.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (12.1.105)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (12.3.101)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.15.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.40)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.39.1)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.11)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.1)\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1702715478071,"user_tz":300,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# # Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","# import plotly.io as pio\n","\n","# if IN_COLAB or not DEBUG_MODE:\n","#     # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","#     pio.renderers.default = \"colab\"\n","# else:\n","#     pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":33,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1702715478071,"user_tz":300,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1702715478071,"user_tz":300,"elapsed":13,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"cFMTUcQiIAiF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702715478071,"user_tz":300,"elapsed":13,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"adc11ca0-440e-4db6-fa01-775125268403"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7e84f8519030>"]},"metadata":{},"execution_count":35}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"KFs9BrbzIAiH","executionInfo":{"status":"ok","timestamp":1702715478072,"user_tz":300,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# def imshow(tensor, renderer=None, **kwargs):\n","#     px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","# def line(tensor, renderer=None, **kwargs):\n","#     px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","# def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","#     x = utils.to_numpy(x)\n","#     y = utils.to_numpy(y)\n","#     px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"code","execution_count":37,"metadata":{"id":"xLwDyosvIAiJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702715484413,"user_tz":300,"elapsed":6352,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"418e379c-f245-474c-bb52-8d1b7a4578fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"id":"Fdh5--MfYw7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":14000,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1764042a-9d4c-4c25-bcd6-d3df14bb441b"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9262, done.\u001b[K\n","remote: Counting objects: 100% (1976/1976), done.\u001b[K\n","remote: Compressing objects: 100% (344/344), done.\u001b[K\n","remote: Total 9262 (delta 1727), reused 1732 (delta 1628), pack-reused 7286\u001b[K\n","Receiving objects: 100% (9262/9262), 156.79 MiB | 16.03 MiB/s, done.\n","Resolving deltas: 100% (5620/5620), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"id":"iZ4C_bsXZFfj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ffab8808-eb60-40ab-dc0c-464caa1531d8"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"6Fuq8XW770vX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': str(i),\n","            'S2': str(i+1),\n","            'S3': str(i+2),\n","            'S4': str(i+3),\n","            'corr': str(i+4),\n","            'incorr': str(i+3),\n","            'text': f\"{i} {i+1} {i+2} {i+3}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 9)"],"metadata":{"id":"u0NPSKcZ1iDe","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# pos_dict = {\n","#     'S1': 4,\n","#     'S2': 10,\n","#     'S3': 16,\n","#     'S4': 22,\n","# }\n","\n","pos_dict = {}\n","for i in range(len(model.tokenizer.tokenize(prompts_list[0]['text']))):\n","    pos_dict['S'+str(i)] = i\n","\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"kS_Tlrb_70vg","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(prompt_list):\n","    outlist = []\n","    for prompt_dict in prompts_list:\n","        r1 = random.randint(1, 12)\n","        r2 = random.randint(1, 12)\n","        while True:\n","            r3 = random.randint(1, 12)\n","            r4 = random.randint(1, 12)\n","            if r4 - 1 != r3:\n","                break\n","        new_text = prompt_dict['text'].replace(prompt_dict['S1'], str(r1)).replace(prompt_dict['S2'], str(r2)).replace(prompt_dict['S3'], str(r3)).replace(prompt_dict['S4'], str(r4))\n","        new_prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': prompt_dict['corr'],\n","            'incorr': prompt_dict['incorr'],\n","            'text': new_text\n","        }\n","        outlist.append(new_prompt_dict)\n","    return outlist\n","prompts_list_2 = generate_prompts_list_corr(prompts_list)"],"metadata":{"id":"YqAdblFt1_tx","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["prompts_list_2[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ry2G9aV9EnEn","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0f225ec1-1651-443f-f93a-a9a9bd5b410b"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': '9',\n","  'S2': '5',\n","  'S3': '1',\n","  'S4': '9',\n","  'corr': '5',\n","  'incorr': '4',\n","  'text': '9 5 1 9'},\n"," {'S1': '12',\n","  'S2': '7',\n","  'S3': '7',\n","  'S4': '11',\n","  'corr': '6',\n","  'incorr': '5',\n","  'text': '12 7 7 11'},\n"," {'S1': '8',\n","  'S2': '6',\n","  'S3': '2',\n","  'S4': '6',\n","  'corr': '7',\n","  'incorr': '6',\n","  'text': '8 6 2 6'},\n"," {'S1': '4',\n","  'S2': '12',\n","  'S3': '10',\n","  'S4': '2',\n","  'corr': '8',\n","  'incorr': '7',\n","  'text': '4 12 10 2'},\n"," {'S1': '12',\n","  'S2': '8',\n","  'S3': '5',\n","  'S4': '9',\n","  'corr': '9',\n","  'incorr': '8',\n","  'text': '12 9 5 9'},\n"," {'S1': '3',\n","  'S2': '1',\n","  'S3': '6',\n","  'S4': '4',\n","  'corr': '10',\n","  'incorr': '9',\n","  'text': '3 1 6 4'},\n"," {'S1': '4',\n","  'S2': '11',\n","  'S3': '5',\n","  'S4': '8',\n","  'corr': '11',\n","  'incorr': '10',\n","  'text': '4 11 5 8'},\n"," {'S1': '2',\n","  'S2': '3',\n","  'S3': '1',\n","  'S4': '6',\n","  'corr': '12',\n","  'incorr': '11',\n","  'text': '2 3 1 6'}]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# import pickle\n","# from google.colab import files\n","\n","# with open('randDS_numerals.pkl', 'wb') as file:\n","#     pickle.dump(prompts_list_2, file)\n","# files.download('randDS_numerals.pkl')"],"metadata":{"id":"SeiO3sgDxC9q","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["len(prompts_list_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6sRiXpRY9hL","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a3d83234-0e0d-404e-c414-c8f643ad8b52"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"msu6D4p_feW5","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["# get orig score"],"metadata":{"id":"BHHvz84w70vh"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    corr_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.corr_tokenIDs]\n","    incorr_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.incorr_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = corr_logits - incorr_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"AFYffMoP70vh","executionInfo":{"status":"ok","timestamp":1702715498395,"user_tz":300,"elapsed":2,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","# ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","ioi_logits_original = model(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"id":"OI3FcmpMaNxB","executionInfo":{"status":"ok","timestamp":1702715498772,"user_tz":300,"elapsed":379,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["import gc\n","\n","# del(ioi_cache)\n","del(ioi_logits_original)\n","\n","torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1702715498772,"user_tz":300,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"A-TjmW5PUwGC","outputId":"c6a004b0-0ae5-4a43-cd5d-058aeb82a777"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["orig_score"],"metadata":{"id":"XfjQPngxBYBM","executionInfo":{"status":"ok","timestamp":1702715498772,"user_tz":300,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a8529e7-ca24-4441-e821-59394812224f"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(5.1792, device='cuda:0')"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"b3Chees1fkO1"}},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, orig_score, print_output=True):\n","    # CIRCUIT = {\n","    #     \"number mover\": lst,\n","    #     \"number mover 4\": lst,\n","    #     \"number mover 3\": lst,\n","    #     \"number mover 2\": lst,\n","    #     \"number mover 1\": lst,\n","    # }\n","\n","    # SEQ_POS_TO_KEEP = {\n","    #     \"number mover\": \"end\",\n","    #     \"number mover 4\": \"S4\",\n","    #     \"number mover 3\": \"S3\",\n","    #     \"number mover 2\": \"S2\",\n","    #     \"number mover 1\": \"S1\",\n","    # }\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","        CIRCUIT['S'+str(i)] = lst\n","        if i == len(model.tokenizer.tokenize(prompts_list_2[0]['text'])) - 1:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        else:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    # ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    # orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    # del(ioi_logits_minimal)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"QLK5m1Ps70vh","executionInfo":{"status":"ok","timestamp":1702715498772,"user_tz":300,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["# rmv most impt heads from full"],"metadata":{"id":"w82u8B4EZdWi"}},{"cell_type":"code","source":["circ = [(layer, head) for layer in range(12) for head in range(12)]\n","to_loop = [(layer, head) for layer in range(12) for head in range(12)]\n","# to_loop = [(7, 11), (4, 4), (1, 5), (10, 7), (8, 8), (8, 6), (9, 1), (6, 6), (8, 1), (6, 10)]\n","\n","lh_scores = {}\n","# for lh in circ:\n","for lh in to_loop:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"85e2cb6d-172b-487e-a2eb-bdbcaa6b24f6","id":"msckx6kcZgAd","executionInfo":{"status":"ok","timestamp":1702715874618,"user_tz":300,"elapsed":375849,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 0)\n","Average logit difference (circuit / full) %: 99.9047\n","removed: (0, 1)\n","Average logit difference (circuit / full) %: 77.7997\n","removed: (0, 2)\n","Average logit difference (circuit / full) %: 97.8450\n","removed: (0, 3)\n","Average logit difference (circuit / full) %: 97.9966\n","removed: (0, 4)\n","Average logit difference (circuit / full) %: 99.5758\n","removed: (0, 5)\n","Average logit difference (circuit / full) %: 96.9887\n","removed: (0, 6)\n","Average logit difference (circuit / full) %: 99.9610\n","removed: (0, 7)\n","Average logit difference (circuit / full) %: 97.7459\n","removed: (0, 8)\n","Average logit difference (circuit / full) %: 99.7245\n","removed: (0, 9)\n","Average logit difference (circuit / full) %: 95.8878\n","removed: (0, 10)\n","Average logit difference (circuit / full) %: 101.5281\n","removed: (0, 11)\n","Average logit difference (circuit / full) %: 99.9279\n","removed: (1, 0)\n","Average logit difference (circuit / full) %: 95.7013\n","removed: (1, 1)\n","Average logit difference (circuit / full) %: 99.9656\n","removed: (1, 2)\n","Average logit difference (circuit / full) %: 99.2656\n","removed: (1, 3)\n","Average logit difference (circuit / full) %: 100.6868\n","removed: (1, 4)\n","Average logit difference (circuit / full) %: 100.4460\n","removed: (1, 5)\n","Average logit difference (circuit / full) %: 74.3134\n","removed: (1, 6)\n","Average logit difference (circuit / full) %: 98.8596\n","removed: (1, 7)\n","Average logit difference (circuit / full) %: 99.1904\n","removed: (1, 8)\n","Average logit difference (circuit / full) %: 99.7922\n","removed: (1, 9)\n","Average logit difference (circuit / full) %: 99.6469\n","removed: (1, 10)\n","Average logit difference (circuit / full) %: 100.0002\n","removed: (1, 11)\n","Average logit difference (circuit / full) %: 99.4430\n","removed: (2, 0)\n","Average logit difference (circuit / full) %: 99.4623\n","removed: (2, 1)\n","Average logit difference (circuit / full) %: 99.6943\n","removed: (2, 2)\n","Average logit difference (circuit / full) %: 97.5360\n","removed: (2, 3)\n","Average logit difference (circuit / full) %: 100.2614\n","removed: (2, 4)\n","Average logit difference (circuit / full) %: 100.7029\n","removed: (2, 5)\n","Average logit difference (circuit / full) %: 100.1211\n","removed: (2, 6)\n","Average logit difference (circuit / full) %: 99.3967\n","removed: (2, 7)\n","Average logit difference (circuit / full) %: 98.0168\n","removed: (2, 8)\n","Average logit difference (circuit / full) %: 99.2658\n","removed: (2, 9)\n","Average logit difference (circuit / full) %: 98.9491\n","removed: (2, 10)\n","Average logit difference (circuit / full) %: 98.1944\n","removed: (2, 11)\n","Average logit difference (circuit / full) %: 100.2763\n","removed: (3, 0)\n","Average logit difference (circuit / full) %: 99.8672\n","removed: (3, 1)\n","Average logit difference (circuit / full) %: 100.1581\n","removed: (3, 2)\n","Average logit difference (circuit / full) %: 96.1599\n","removed: (3, 3)\n","Average logit difference (circuit / full) %: 96.9060\n","removed: (3, 4)\n","Average logit difference (circuit / full) %: 100.9615\n","removed: (3, 5)\n","Average logit difference (circuit / full) %: 99.1177\n","removed: (3, 6)\n","Average logit difference (circuit / full) %: 98.2813\n","removed: (3, 7)\n","Average logit difference (circuit / full) %: 96.4671\n","removed: (3, 8)\n","Average logit difference (circuit / full) %: 98.1487\n","removed: (3, 9)\n","Average logit difference (circuit / full) %: 99.5742\n","removed: (3, 10)\n","Average logit difference (circuit / full) %: 103.7278\n","removed: (3, 11)\n","Average logit difference (circuit / full) %: 98.8099\n","removed: (4, 0)\n","Average logit difference (circuit / full) %: 99.8739\n","removed: (4, 1)\n","Average logit difference (circuit / full) %: 100.0075\n","removed: (4, 2)\n","Average logit difference (circuit / full) %: 99.6062\n","removed: (4, 3)\n","Average logit difference (circuit / full) %: 100.1882\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 29.6778\n","removed: (4, 5)\n","Average logit difference (circuit / full) %: 100.0702\n","removed: (4, 6)\n","Average logit difference (circuit / full) %: 99.6317\n","removed: (4, 7)\n","Average logit difference (circuit / full) %: 101.4648\n","removed: (4, 8)\n","Average logit difference (circuit / full) %: 95.1107\n","removed: (4, 9)\n","Average logit difference (circuit / full) %: 99.2574\n","removed: (4, 10)\n","Average logit difference (circuit / full) %: 97.0087\n","removed: (4, 11)\n","Average logit difference (circuit / full) %: 95.7399\n","removed: (5, 0)\n","Average logit difference (circuit / full) %: 100.8566\n","removed: (5, 1)\n","Average logit difference (circuit / full) %: 99.6923\n","removed: (5, 2)\n","Average logit difference (circuit / full) %: 99.5734\n","removed: (5, 3)\n","Average logit difference (circuit / full) %: 98.4163\n","removed: (5, 4)\n","Average logit difference (circuit / full) %: 94.7002\n","removed: (5, 5)\n","Average logit difference (circuit / full) %: 96.7597\n","removed: (5, 6)\n","Average logit difference (circuit / full) %: 97.7134\n","removed: (5, 7)\n","Average logit difference (circuit / full) %: 100.1052\n","removed: (5, 8)\n","Average logit difference (circuit / full) %: 76.2529\n","removed: (5, 9)\n","Average logit difference (circuit / full) %: 99.3285\n","removed: (5, 10)\n","Average logit difference (circuit / full) %: 98.6930\n","removed: (5, 11)\n","Average logit difference (circuit / full) %: 99.4340\n","removed: (6, 0)\n","Average logit difference (circuit / full) %: 100.4930\n","removed: (6, 1)\n","Average logit difference (circuit / full) %: 89.5359\n","removed: (6, 2)\n","Average logit difference (circuit / full) %: 100.4387\n","removed: (6, 3)\n","Average logit difference (circuit / full) %: 97.2243\n","removed: (6, 4)\n","Average logit difference (circuit / full) %: 97.0814\n","removed: (6, 5)\n","Average logit difference (circuit / full) %: 99.4416\n","removed: (6, 6)\n","Average logit difference (circuit / full) %: 96.4170\n","removed: (6, 7)\n","Average logit difference (circuit / full) %: 98.5920\n","removed: (6, 8)\n","Average logit difference (circuit / full) %: 100.3258\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 103.5349\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 89.6090\n","removed: (6, 11)\n","Average logit difference (circuit / full) %: 99.0645\n","removed: (7, 0)\n","Average logit difference (circuit / full) %: 97.5276\n","removed: (7, 1)\n","Average logit difference (circuit / full) %: 99.8047\n","removed: (7, 2)\n","Average logit difference (circuit / full) %: 99.6525\n","removed: (7, 3)\n","Average logit difference (circuit / full) %: 102.0521\n","removed: (7, 4)\n","Average logit difference (circuit / full) %: 99.3873\n","removed: (7, 5)\n","Average logit difference (circuit / full) %: 96.5387\n","removed: (7, 6)\n","Average logit difference (circuit / full) %: 97.4562\n","removed: (7, 7)\n","Average logit difference (circuit / full) %: 99.5265\n","removed: (7, 8)\n","Average logit difference (circuit / full) %: 98.6713\n","removed: (7, 9)\n","Average logit difference (circuit / full) %: 99.0380\n","removed: (7, 10)\n","Average logit difference (circuit / full) %: 99.7022\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 79.1738\n","removed: (8, 0)\n","Average logit difference (circuit / full) %: 95.4440\n","removed: (8, 1)\n","Average logit difference (circuit / full) %: 98.6625\n","removed: (8, 2)\n","Average logit difference (circuit / full) %: 100.5680\n","removed: (8, 3)\n","Average logit difference (circuit / full) %: 100.2588\n","removed: (8, 4)\n","Average logit difference (circuit / full) %: 99.9319\n","removed: (8, 5)\n","Average logit difference (circuit / full) %: 98.0301\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 89.6323\n","removed: (8, 7)\n","Average logit difference (circuit / full) %: 98.9478\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 90.5548\n","removed: (8, 9)\n","Average logit difference (circuit / full) %: 100.1830\n","removed: (8, 10)\n","Average logit difference (circuit / full) %: 101.4236\n","removed: (8, 11)\n","Average logit difference (circuit / full) %: 103.3851\n","removed: (9, 0)\n","Average logit difference (circuit / full) %: 99.9620\n","removed: (9, 1)\n","Average logit difference (circuit / full) %: 83.3996\n","removed: (9, 2)\n","Average logit difference (circuit / full) %: 100.0556\n","removed: (9, 3)\n","Average logit difference (circuit / full) %: 100.3102\n","removed: (9, 4)\n","Average logit difference (circuit / full) %: 99.0112\n","removed: (9, 5)\n","Average logit difference (circuit / full) %: 95.8931\n","removed: (9, 6)\n","Average logit difference (circuit / full) %: 99.9109\n","removed: (9, 7)\n","Average logit difference (circuit / full) %: 98.9160\n","removed: (9, 8)\n","Average logit difference (circuit / full) %: 100.0963\n","removed: (9, 9)\n","Average logit difference (circuit / full) %: 101.4186\n","removed: (9, 10)\n","Average logit difference (circuit / full) %: 99.7155\n","removed: (9, 11)\n","Average logit difference (circuit / full) %: 99.1716\n","removed: (10, 0)\n","Average logit difference (circuit / full) %: 99.9925\n","removed: (10, 1)\n","Average logit difference (circuit / full) %: 99.4922\n","removed: (10, 2)\n","Average logit difference (circuit / full) %: 102.9925\n","removed: (10, 3)\n","Average logit difference (circuit / full) %: 99.9462\n","removed: (10, 4)\n","Average logit difference (circuit / full) %: 100.1337\n","removed: (10, 5)\n","Average logit difference (circuit / full) %: 100.4571\n","removed: (10, 6)\n","Average logit difference (circuit / full) %: 99.9902\n","removed: (10, 7)\n","Average logit difference (circuit / full) %: 88.7333\n","removed: (10, 8)\n","Average logit difference (circuit / full) %: 100.0854\n","removed: (10, 9)\n","Average logit difference (circuit / full) %: 100.1080\n","removed: (10, 10)\n","Average logit difference (circuit / full) %: 100.1526\n","removed: (10, 11)\n","Average logit difference (circuit / full) %: 99.8807\n","removed: (11, 0)\n","Average logit difference (circuit / full) %: 98.8178\n","removed: (11, 1)\n","Average logit difference (circuit / full) %: 99.9614\n","removed: (11, 2)\n","Average logit difference (circuit / full) %: 100.1868\n","removed: (11, 3)\n","Average logit difference (circuit / full) %: 100.4337\n","removed: (11, 4)\n","Average logit difference (circuit / full) %: 100.7522\n","removed: (11, 5)\n","Average logit difference (circuit / full) %: 100.0548\n","removed: (11, 6)\n","Average logit difference (circuit / full) %: 100.1143\n","removed: (11, 7)\n","Average logit difference (circuit / full) %: 99.7876\n","removed: (11, 8)\n","Average logit difference (circuit / full) %: 99.0810\n","removed: (11, 9)\n","Average logit difference (circuit / full) %: 99.7751\n","removed: (11, 10)\n","Average logit difference (circuit / full) %: 98.7539\n","removed: (11, 11)\n","Average logit difference (circuit / full) %: 101.9397\n"]}]},{"cell_type":"code","source":["# Sort the dictionary by values in descending order\n","sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: -item[1], reverse=True))\n","\n","# Select the top 10 items\n","top_10_lh_scores = dict(list(sorted_lh_scores.items())[:10])\n","top_10_lh_scores"],"metadata":{"executionInfo":{"status":"ok","timestamp":1702715874619,"user_tz":300,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"LTNyxnWMZgAd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d1e0a84-35fe-4148-e452-b072919ddc2b"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 29.677785873413086,\n"," (1, 5): 74.3133544921875,\n"," (5, 8): 76.25294494628906,\n"," (0, 1): 77.79967498779297,\n"," (7, 11): 79.17378234863281,\n"," (9, 1): 83.39955139160156,\n"," (10, 7): 88.7332992553711,\n"," (6, 1): 89.53585052490234,\n"," (6, 10): 89.60902404785156,\n"," (8, 6): 89.63231658935547}"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# for lh, score in sorted_lh_scores.items():\n","#     print(lh, -round(100-score, 2))\n","\n","# Sort the dictionary by values in descending order\n","sorted_lh_scores = sorted(lh_scores.items(), key=lambda item: -item[1], reverse=True)\n","\n","# Iterate over the top 10 items and print them\n","for lh, score in sorted_lh_scores[:10]:\n","    modified_score = -round(100 - score, 2)\n","    print(lh, modified_score)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1702715874619,"user_tz":300,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"D3E9dzLOZgAe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1557542-8566-428d-af5f-6fc69a1d3a22"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4) -70.32\n","(1, 5) -25.69\n","(5, 8) -23.75\n","(0, 1) -22.2\n","(7, 11) -20.83\n","(9, 1) -16.6\n","(10, 7) -11.27\n","(6, 1) -10.46\n","(6, 10) -10.39\n","(8, 6) -10.37\n"]}]},{"cell_type":"code","source":["score = lh_scores[(0,1)]\n","modified_score = -round(100 - score, 2)\n","print( modified_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Io_R_slyyac2","executionInfo":{"status":"ok","timestamp":1702715874619,"user_tz":300,"elapsed":27,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2ee710fa-03fa-4173-9d3e-47f119d3b909"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["-22.2\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","import matplotlib.pyplot as plt\n","\n","lh_scores_drop = {key: min(0, val-100) for key, val in lh_scores.items()}\n","\n","# Extracting only the values (scores) from the dictionary\n","scores = list(lh_scores_drop.values())\n","\n","# Creating a histogram for the scores\n","plt.hist(scores, bins=10, edgecolor='black')  # Adjust the number of bins as needed\n","\n","# Creating a histogram for the scores\n","n, bins, patches = plt.hist(scores, bins=10, edgecolor='black')  # Adjust the number of bins as needed\n","\n","# Annotating the histogram with the number of values in each bin\n","for i in range(len(n)):\n","    plt.text(bins[i]+5, n[i], str(int(n[i])), va='bottom', ha='center')\n","\n","# Setting x-axis ticks at intervals of 10 from 0 to 100\n","plt.xticks(range(-100, 0, 10))\n","\n","# Adding labels and title for clarity\n","plt.xlabel('Percentage Drop from Full Performance')\n","plt.ylabel('Number of Attention Heads')\n","# plt.title('Distribution of Attention Head Performance Drop Percentages')\n","\n","# Displaying the plot\n","# plt.show()\n","\n","# Save the figure\n","pdf_filename = 'lh_scores_distribution.pdf'\n","plt.savefig(pdf_filename)\n","\n","# Download the file in Colab\n","files.download(pdf_filename)"],"metadata":{"id":"yVAAmsZikKQV","executionInfo":{"status":"ok","timestamp":1702715875101,"user_tz":300,"elapsed":505,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","height":466},"outputId":"ec67a419-d62a-4b82-aaa5-80ef156a56fd"},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_969b029e-c4bf-4cf4-b4a8-9bab37c41263\", \"lh_scores_distribution.pdf\", 14719)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import statistics\n","\n","# Assuming lh_scores_drop is already defined\n","# For example, lh_scores_drop = {key: max(0, 100 - val) for key, val in lh_scores.items()}\n","\n","# Extracting the values from the dictionary\n","scores = list(lh_scores_drop.values())\n","\n","# Calculating the mean\n","mean_score = statistics.mean(scores)\n","\n","print(\"Mean of the scores:\", mean_score)\n"],"metadata":{"id":"A6E_Lbomm1js","executionInfo":{"status":"ok","timestamp":1702715875102,"user_tz":300,"elapsed":82,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab32df9a-d466-4adc-a6af-21fd1019e49d"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean of the scores: -2.4674116373062134\n"]}]},{"cell_type":"code","source":["# def get_probability_ranking(value, distribution):\n","#     # Convert distribution to a probability distribution (if not already)\n","#     total = sum(distribution)\n","#     prob_distribution = [x / total for x in distribution]\n","\n","#     # Sort the probability distribution\n","#     sorted_distribution = sorted(prob_distribution)\n","\n","#     # Calculate the cumulative probability up to the given value\n","#     cumulative_prob = sum(prob for prob in sorted_distribution if prob <= value)\n","\n","#     return cumulative_prob\n","\n","# # Example usage\n","# distribution = lh_scores_drop.values()\n","# value = -0.69  # Value to get the probability ranking for\n","# ranking = get_probability_ranking(value, distribution)\n","# print(f\"Probability Ranking of {value} in the distribution: {ranking}\")\n"],"metadata":{"id":"74LSPw6fg4ru","executionInfo":{"status":"ok","timestamp":1702715875103,"user_tz":300,"elapsed":77,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","# Saving the dictionary to a file using pickle\n","with open('numerals_lh_scores.pkl', 'wb') as file:\n","    pickle.dump(lh_scores, file)\n","\n","from google.colab import files\n","\n","# Download the file to your local machine\n","files.download('numerals_lh_scores.pkl')"],"metadata":{"id":"HhKz7gEBcEqa","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1702715875104,"user_tz":300,"elapsed":76,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2664f688-a688-4be0-89ab-051d1daa5925"},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f555b8cc-6e72-442a-8984-fc1a72c5e83e\", \"numerals_lh_scores.pkl\", 2176)"]},"metadata":{}}]},{"cell_type":"markdown","source":["# MLP ablation fns"],"metadata":{"id":"G9FQY3H3zkFV"}},{"cell_type":"code","source":["from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool\n","import torch as t\n","\n","def logits_to_ave_logit_diff(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    corr_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.corr_tokenIDs]\n","    incorr_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.incorr_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = corr_logits - incorr_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"ZOTRN8KnheFO","executionInfo":{"status":"ok","timestamp":1702715875104,"user_tz":300,"elapsed":65,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["def compute_means_by_template_MLP(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Returns the mean of each head's output over the means dataset. This mean is\n","    computed separately for each group of prompts with the same template (these\n","    are given by means_dataset.groups).\n","    '''\n","    # Cache the outputs of every head\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"mlp_out\"),\n","    )\n","    # Create tensor to store means\n","    n_layers, d_model = model.cfg.n_layers, model.cfg.d_model\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, d_model), device=model.cfg.device)\n","\n","    # Get set of different templates for this data\n","    for layer in range(n_layers):\n","        mlp_output_for_this_layer: Float[Tensor, \"batch seq d_model\"] = means_cache[utils.get_act_name(\"mlp_out\", layer)]\n","        for template_group in means_dataset.groups:  # here, we only have one group\n","            mlp_output_for_this_template = mlp_output_for_this_layer[template_group]\n","            # aggregate all batches\n","            mlp_output_means_for_this_template = einops.reduce(mlp_output_for_this_template, \"batch seq d_model -> seq d_model\", \"mean\")\n","            means[layer, template_group] = mlp_output_means_for_this_template\n","            # at layer, each batch ind is tempalte group (a tensor of size seq d_model)\n","            # is assigned the SAME mean, \"mlp_output_means_for_this_template\"\n","\n","    del(means_cache)\n","\n","    return means"],"metadata":{"id":"McmRZoY7Wudl","executionInfo":{"status":"ok","timestamp":1702715875105,"user_tz":300,"elapsed":61,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["def get_mlp_outputs_and_posns_to_keep(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[int]],  # Adjusted to hold list of layers instead of (layer, head) tuples\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq\"]]:  # Adjusted the return type to \"batch seq\"\n","    '''\n","    Returns a dictionary mapping layers to a boolean mask giving the indices of the\n","    MLP output which *shouldn't* be mean-ablated.\n","\n","    The output of this function will be used for the hook function that does ablation.\n","    '''\n","    mlp_outputs_and_posns_to_keep = {}\n","    batch, seq = len(means_dataset), means_dataset.max_len\n","\n","    for layer in range(model.cfg.n_layers):\n","        mask = t.zeros(size=(batch, seq))\n","\n","        for (mlp_type, layer_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[mlp_type]\n","            indices = means_dataset.word_idx[seq_pos]\n","            if layer in layer_list:  # Check if the current layer is in the layer list for this mlp_type\n","                mask[:, indices] = 1\n","\n","        mlp_outputs_and_posns_to_keep[layer] = mask.bool()\n","\n","    return mlp_outputs_and_posns_to_keep"],"metadata":{"id":"MH4KI_wCu7M-","executionInfo":{"status":"ok","timestamp":1702715875105,"user_tz":300,"elapsed":58,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["def hook_fn_mask_mlp_out(\n","    mlp_out: Float[Tensor, \"batch seq d_mlp\"],\n","    hook: HookPoint,\n","    mlp_outputs_and_posns_to_keep: Dict[int, Bool[Tensor, \"batch seq\"]],\n","    means: Float[Tensor, \"layer batch seq d_mlp\"],\n",") -> Float[Tensor, \"batch seq d_mlp\"]:\n","    '''\n","    Hook function which masks the MLP output of a transformer layer.\n","\n","    mlp_outputs_and_posns_to_keep\n","        Dict created with the get_mlp_outputs_and_posns_to_keep function. This tells\n","        us where to mask.\n","\n","    means\n","        Tensor of mean MLP output values of the means_dataset over each group of prompts\n","        with the same template. This tells us what values to mask with.\n","    '''\n","    # Get the mask for this layer, adapted for MLP output structure\n","    mask_for_this_layer = mlp_outputs_and_posns_to_keep[hook.layer()].unsqueeze(-1).to(mlp_out.device)\n","\n","    # Set MLP output values to the mean where necessary\n","    mlp_out = t.where(mask_for_this_layer, mlp_out, means[hook.layer()])\n","\n","    return mlp_out"],"metadata":{"id":"fXWq7V0Mv0F4","executionInfo":{"status":"ok","timestamp":1702715875105,"user_tz":300,"elapsed":51,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["CIRCUIT = {}\n","SEQ_POS_TO_KEEP = {}\n","def add_mean_ablation_hook_MLP(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]] = CIRCUIT,\n","    seq_pos_to_keep: Dict[str, str] = SEQ_POS_TO_KEEP,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Adds a permanent hook to the model, which ablates according to the circuit and\n","    seq_pos_to_keep dictionaries.\n","\n","    In other words, when the model is run on ioi_dataset, every head's output will\n","    be replaced with the mean over means_dataset for sequences with the same template,\n","    except for a subset of heads and sequence positions as specified by the circuit\n","    and seq_pos_to_keep dicts.\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = compute_means_by_template_MLP(means_dataset, model)\n","\n","    # Convert this into a boolean map\n","    mlp_outputs_and_posns_to_keep = get_mlp_outputs_and_posns_to_keep(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_fn_mask_mlp_out,\n","        mlp_outputs_and_posns_to_keep=mlp_outputs_and_posns_to_keep,\n","        means=means\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"sJlawX18v-yD","executionInfo":{"status":"ok","timestamp":1702715875105,"user_tz":300,"elapsed":49,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst_MLP(lst, model, orig_score, print_output=True):\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","        CIRCUIT['S'+str(i)] = lst\n","        if i == len(model.tokenizer.tokenize(prompts_list_2[0]['text'])) - 1:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        else:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    # ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = add_mean_ablation_hook_MLP(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    new_logits = model(dataset.toks)\n","\n","    # orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","    del(new_logits)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"Ko6itvH15NtO","executionInfo":{"status":"ok","timestamp":1702715875106,"user_tz":300,"elapsed":48,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":["# loop thru MLPs from full"],"metadata":{"id":"zkx8xD8dwWOL"}},{"cell_type":"code","source":["for i in range(12):\n","    lst = [layer for layer in range(12) if layer != i]\n","    perc_of_orig = mean_ablate_by_lst_MLP(lst, model, orig_score, print_output=False).item()\n","    print(i, perc_of_orig)"],"metadata":{"id":"I9SR5ETh6BWw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702715881151,"user_tz":300,"elapsed":6092,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"55eaa75c-cb6a-4470-84a1-2fa98161c500"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["0 8.65108585357666\n","1 40.84244155883789\n","2 65.73948669433594\n","3 68.71742248535156\n","4 52.02574157714844\n","5 66.89879608154297\n","6 58.48796081542969\n","7 74.70417785644531\n","8 90.1178207397461\n","9 15.870546340942383\n","10 66.43033599853516\n","11 80.11389923095703\n"]}]},{"cell_type":"markdown","source":["# MLP and Head together fns"],"metadata":{"id":"DlpH0Wib-v1j"}},{"cell_type":"markdown","source":["## head fns"],"metadata":{"id":"Zv5yGHXhpAK_"}},{"cell_type":"code","source":["def get_heads_and_posns_to_keep(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Returns a dictionary mapping layers to a boolean mask giving the indices of the\n","    z output which *shouldn't* be mean-ablated.\n","\n","    The output of this function will be used for the hook function that does ablation.\n","    '''\n","    heads_and_posns_to_keep = {}\n","    batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    mask[:, indices, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep\n","\n","def hook_fn_mask_z(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    heads_and_posns_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    means: Float[Tensor, \"layer batch seq head d_head\"],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Hook function which masks the z output of a transformer head.\n","\n","    heads_and_posns_to_keep\n","        Dict created with the get_heads_and_posns_to_keep function. This tells\n","        us where to mask.\n","\n","    means\n","        Tensor of mean z values of the means_dataset over each group of prompts\n","        with the same template. This tells us what values to mask with.\n","    '''\n","    # Get the mask for this layer, and add d_head=1 dimension so it broadcasts correctly\n","    mask_for_this_layer = heads_and_posns_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","\n","    # Set z values to the mean\n","    z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    return z\n","\n","def compute_means_by_template(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Returns the mean of each head's output over the means dataset. This mean is\n","    computed separately for each group of prompts with the same template (these\n","    are given by means_dataset.groups).\n","    '''\n","    # Cache the outputs of every head\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    # Create tensor to store means\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    # Get set of different templates for this data\n","    for layer in range(model.cfg.n_layers):\n","        z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","        for template_group in means_dataset.groups:\n","            z_for_this_template = z_for_this_layer[template_group]\n","            z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","            means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means\n","\n","def add_mean_ablation_hook(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]] = CIRCUIT,\n","    seq_pos_to_keep: Dict[str, str] = SEQ_POS_TO_KEEP,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Adds a permanent hook to the model, which ablates according to the circuit and\n","    seq_pos_to_keep dictionaries.\n","\n","    In other words, when the model is run on ioi_dataset, every head's output will\n","    be replaced with the mean over means_dataset for sequences with the same template,\n","    except for a subset of heads and sequence positions as specified by the circuit\n","    and seq_pos_to_keep dicts.\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = compute_means_by_template(means_dataset, model)\n","\n","    # Convert this into a boolean map\n","    heads_and_posns_to_keep = get_heads_and_posns_to_keep(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_fn_mask_z,\n","        heads_and_posns_to_keep=heads_and_posns_to_keep,\n","        means=means\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    return model"],"metadata":{"id":"cE7xLtws_Pnt","executionInfo":{"status":"ok","timestamp":1702715881151,"user_tz":300,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["## both"],"metadata":{"id":"4zlcncHKo2h6"}},{"cell_type":"code","source":["def add_mean_ablation_hook_MLP_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    heads_lst, mlp_lst,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","        CIRCUIT['S'+str(i)] = heads_lst\n","        if i == len(model.tokenizer.tokenize(prompts_list_2[0]['text'])) - 1:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        else:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = compute_means_by_template(means_dataset, model)\n","\n","    # Convert this into a boolean map\n","    heads_and_posns_to_keep = get_heads_and_posns_to_keep(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_fn_mask_z,\n","        heads_and_posns_to_keep=heads_and_posns_to_keep,\n","        means=means\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    ########################\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","        CIRCUIT['S'+str(i)] = mlp_lst\n","        if i == len(model.tokenizer.tokenize(prompts_list_2[0]['text'])) - 1:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        else:\n","            SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = compute_means_by_template_MLP(means_dataset, model)\n","\n","    # Convert this into a boolean map\n","    mlp_outputs_and_posns_to_keep = get_mlp_outputs_and_posns_to_keep(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_fn_mask_mlp_out,\n","        mlp_outputs_and_posns_to_keep=mlp_outputs_and_posns_to_keep,\n","        means=means\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"mnGaDWe__CyA","executionInfo":{"status":"ok","timestamp":1702715881151,"user_tz":300,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":["## loop iters"],"metadata":{"id":"049GQVcZoyrI"}},{"cell_type":"code","source":["def find_circuit_forw(heads_not_ablate=None, mlps_not_ablate=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    # we don't ablate the curr circuits\n","    if heads_not_ablate == []: # Start with full circuit\n","        heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]\n","    if mlps_not_ablate == []:\n","        mlps_not_ablate = [layer for layer in range(12)]\n","\n","    comp_scores = {}\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            print(layer, head)\n","            if (layer, head) not in heads_not_ablate:\n","                continue\n","\n","            copy_heads_not_ablate = heads_not_ablate.copy()\n","            copy_heads_not_ablate.remove((layer, head))\n","\n","            model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","            ablated_model = add_mean_ablation_hook_MLP_head(model, dataset_2, copy_heads_not_ablate, mlps_not_ablate)\n","\n","            new_logits = ablated_model(dataset.toks)\n","            new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","            new_perc = 100 * new_score / orig_score\n","            comp_scores[layer] = new_perc\n","            print(f\"(cand circuit / full) %: {new_perc:.4f}\")\n","            if (100 - new_perc) < threshold:\n","                heads_not_ablate.remove((layer, head))\n","                print(\"Removed:\", (layer, head))\n","            del(new_logits)\n","\n","        print(layer)\n","        if layer in mlps_not_ablate:\n","            copy_mlps_not_ablate = mlps_not_ablate.copy()\n","            copy_mlps_not_ablate.remove(layer)\n","\n","            model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","            ablated_model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, copy_mlps_not_ablate)\n","\n","            new_logits = ablated_model(dataset.toks)\n","            new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","            new_perc = 100 * new_score / orig_score\n","            comp_scores[(layer, head)] = new_perc\n","            print(f\"(cand circuit / full) %: {new_perc:.4f}\")\n","            if (100 - new_perc) < threshold:\n","                mlps_not_ablate.remove(layer)\n","                print(\"Removed: MLP \", layer)\n","            del(new_logits)\n","\n","    return heads_not_ablate, mlps_not_ablate, new_perc, comp_scores"],"metadata":{"id":"Tx5xoj2HtT4C","executionInfo":{"status":"ok","timestamp":1702715881151,"user_tz":300,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(heads_not_ablate=None, mlps_not_ablate=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    # we don't ablate the curr circuits\n","    if heads_not_ablate == []: # Start with full circuit\n","        heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]\n","    if mlps_not_ablate == []:\n","        mlps_not_ablate = [layer for layer in range(12)]\n","\n","    comp_scores = {}\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        print(layer)\n","        if layer in mlps_not_ablate:\n","            copy_mlps_not_ablate = mlps_not_ablate.copy()\n","            copy_mlps_not_ablate.remove(layer)\n","\n","            model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","            ablated_model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, copy_mlps_not_ablate)\n","\n","            new_logits = ablated_model(dataset.toks)\n","            new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","            new_perc = 100 * new_score / orig_score\n","            comp_scores[layer] = new_perc\n","            print(f\"(cand circuit / full) %: {new_perc:.4f}\")\n","            if (100 - new_perc) < threshold:\n","                mlps_not_ablate.remove(layer)\n","                print(\"Removed: MLP \", layer)\n","            del(new_logits)\n","\n","        for head in range(12):\n","            print(layer, head)\n","            if (layer, head) not in heads_not_ablate:\n","                continue\n","\n","            copy_heads_not_ablate = heads_not_ablate.copy()\n","            copy_heads_not_ablate.remove((layer, head))\n","\n","            model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","            ablated_model = add_mean_ablation_hook_MLP_head(model, dataset_2, copy_heads_not_ablate, mlps_not_ablate)\n","\n","            new_logits = ablated_model(dataset.toks)\n","            new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","            new_perc = 100 * new_score / orig_score\n","            comp_scores[(layer, head)] = new_perc\n","            print(f\"(cand circuit / full) %: {new_perc:.4f}\")\n","            if (100 - new_perc) < threshold:\n","                heads_not_ablate.remove((layer, head))\n","                print(\"Removed:\", (layer, head))\n","            del(new_logits)\n","\n","    return heads_not_ablate, mlps_not_ablate, new_score, comp_scores"],"metadata":{"id":"hJYEoSI3ox5l","executionInfo":{"status":"ok","timestamp":1702715881563,"user_tz":300,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["# run MLP and Head together"],"metadata":{"id":"VDfzJNjP66tK"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]\n","mlps_not_ablate = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","\n","ablated_model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","new_logits = ablated_model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")"],"metadata":{"id":"pfjSc0rEALmb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702715884501,"user_tz":300,"elapsed":2940,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b88d220e-c754-4dbd-987d-7bca2998dd14"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 100.0000\n"]}]},{"cell_type":"code","source":["del(new_logits)"],"metadata":{"id":"kPHjfqyKpXGd","executionInfo":{"status":"ok","timestamp":1702715884501,"user_tz":300,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["# get rid of last layer\n","\n","heads_not_ablate = [(layer, head) for layer in range(11) for head in range(12)]\n","mlps_not_ablate = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","\n","ablated_model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","new_logits = ablated_model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")"],"metadata":{"id":"RHbM_oeSAsbO","executionInfo":{"status":"ok","timestamp":1702715887500,"user_tz":300,"elapsed":3001,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9471c84c-12ff-4ed2-bc85-217ec8038a78"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 79.5333\n"]}]},{"cell_type":"markdown","source":["# iter backw fwd, threshold 20"],"metadata":{"id":"0NYZB-G19liQ"}},{"cell_type":"code","source":["threshold = 20\n","curr_circ_heads = []\n","curr_circ_mlps = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","all_comp_scores = []\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circ_heads = curr_circ_heads.copy() # save old before finding new one\n","    old_circ_mlps = curr_circ_mlps.copy()\n","    curr_circ_heads, curr_circ_mlps, new_score, comp_scores = find_circuit_backw(curr_circ_heads, curr_circ_mlps, orig_score, threshold)\n","    if old_circ_heads == curr_circ_heads and old_circ_mlps == curr_circ_mlps:\n","        break\n","    all_comp_scores.append(comp_scores)\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circ_heads = curr_circ_heads.copy()\n","    old_circ_mlps = curr_circ_mlps.copy()\n","    curr_circ_heads, curr_circ_mlps, new_score, comp_scores = find_circuit_forw(curr_circ_heads, curr_circ_mlps, orig_score, threshold)\n","    if old_circ_heads == curr_circ_heads and old_circ_mlps == curr_circ_mlps:\n","        break\n","    all_comp_scores.append(comp_scores)\n","    iter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUqLZl-QsahY","outputId":"55293719-9251-4b97-937a-e25f2831b6a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","11\n","(cand circuit / full) %: 80.1139\n","Removed: MLP  11\n","11 0\n","(cand circuit / full) %: 79.1838\n","11 1\n","(cand circuit / full) %: 80.0625\n","Removed: (11, 1)\n","11 2\n","(cand circuit / full) %: 80.1393\n","Removed: (11, 2)\n","11 3\n","(cand circuit / full) %: 80.4090\n","Removed: (11, 3)\n","11 4\n","(cand circuit / full) %: 81.2363\n","Removed: (11, 4)\n","11 5\n","(cand circuit / full) %: 81.4122\n","Removed: (11, 5)\n","11 6\n","(cand circuit / full) %: 81.4379\n","Removed: (11, 6)\n","11 7\n","(cand circuit / full) %: 81.2840\n","Removed: (11, 7)\n","11 8\n","(cand circuit / full) %: 81.3602\n","Removed: (11, 8)\n","11 9\n","(cand circuit / full) %: 81.1801\n","Removed: (11, 9)\n","11 10\n","(cand circuit / full) %: 80.4192\n","Removed: (11, 10)\n","11 11\n","(cand circuit / full) %: 80.4411\n","Removed: (11, 11)\n","10\n","(cand circuit / full) %: 50.5763\n","10 0\n","(cand circuit / full) %: 80.4554\n","Removed: (10, 0)\n","10 1\n","(cand circuit / full) %: 80.2112\n","Removed: (10, 1)\n","10 2\n","(cand circuit / full) %: 82.7652\n","Removed: (10, 2)\n","10 3\n","(cand circuit / full) %: 82.7489\n","Removed: (10, 3)\n","10 4\n","(cand circuit / full) %: 83.0825\n","Removed: (10, 4)\n","10 5\n","(cand circuit / full) %: 83.2809\n","Removed: (10, 5)\n","10 6\n","(cand circuit / full) %: 83.2830\n","Removed: (10, 6)\n","10 7\n","(cand circuit / full) %: 74.3231\n","10 8\n","(cand circuit / full) %: 83.1718\n","Removed: (10, 8)\n","10 9\n","(cand circuit / full) %: 83.2974\n","Removed: (10, 9)\n","10 10\n","(cand circuit / full) %: 83.3914\n","Removed: (10, 10)\n","10 11\n","(cand circuit / full) %: 83.2245\n","Removed: (10, 11)\n","9\n","(cand circuit / full) %: 18.8555\n","9 0\n","(cand circuit / full) %: 83.0069\n","Removed: (9, 0)\n","9 1\n","(cand circuit / full) %: 65.9847\n","9 2\n"]}]},{"cell_type":"code","source":["import pickle\n","from google.colab import files\n","\n","with open('numerals_bf_20_scores.pkl', 'wb') as file:\n","    pickle.dump(all_comp_scores, file)\n","files.download('numerals_bf_20_scores.pkl')"],"metadata":{"id":"V93FIJs2MiU9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circ_heads"],"metadata":{"id":"oPlS7M_vyBSG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circ_mlps"],"metadata":{"id":"zrSFmCgtyFwY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## loop rmv and check for most impt heads"],"metadata":{"id":"8At2Kqx69liS"}},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = add_mean_ablation_hook_MLP_head(model, dataset_2, curr_circ_heads, curr_circ_mlps)\n","\n","new_logits = model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","circ_score = (100 * new_score / orig_score).item()\n","print(f\"(cand circuit / full) %: {circ_score:.4f}\")\n","\n","# len(curr_circ_heads)\n","# len(curr_circ_mlps)"],"metadata":{"id":"ivoDzNKY9liS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in curr_circ_heads:\n","    copy_circuit = curr_circ_heads.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    model = add_mean_ablation_hook_MLP_head(model, dataset_2, copy_circuit, curr_circ_mlps)\n","\n","    new_logits = model(dataset.toks)\n","    new_score = logits_to_ave_logit_diff(new_logits, dataset).item()\n","    new_perc = 100 * new_score / orig_score\n","    print(f\"(cand circuit / full) %: {new_perc:.4f}\")\n","    lh_scores[lh] = new_perc"],"metadata":{"id":"vsUtHR-y9liS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"id":"MNzdWLFj9liT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score.item(), 2))"],"metadata":{"id":"RPCynBNH9liT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# try other tasks circs, thres 20"],"metadata":{"id":"xbZkzn0nrrxt"}},{"cell_type":"code","source":["heads_not_ablate = [(0, 1), (1, 5), (4, 4), (4, 10), (5, 0), (6, 1), (6, 6), (6, 10), (7, 11), (8, 1), (8, 6), (8, 8), (8, 9), (9, 1)]\n","mlps_not_ablate = [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11]\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","new_logits = model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","circ_score = (100 * new_score / orig_score).item()\n","print(f\"(cand circuit / full) %: {circ_score:.4f}\")"],"metadata":{"id":"i0GzjXOWFYkO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numwords\n","heads_not_ablate = [(0, 1), (1, 5), (4, 4), (4, 10), (5, 8), (6, 1), (6, 6), (6, 10), (7, 2), (7, 6), (7, 11), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (9, 5), (9, 7)]\n","mlps_not_ablate = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","new_logits = model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","circ_score = (100 * new_score / orig_score).item()\n","print(f\"(cand circuit / full) %: {circ_score:.4f}\")"],"metadata":{"id":"XgtbBeiarrx3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# months\n","heads_not_ablate = [(0, 1), (0, 5), (4, 4), (6, 1), (6, 6), (6, 10), (7, 6), (7, 9), (7, 10), (7, 11), (8, 8), (9, 1), (10, 7)]\n","mlps_not_ablate = [0, 1, 2, 3, 4, 6, 7, 8, 9, 10]\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","new_logits = model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","circ_score = (100 * new_score / orig_score).item()\n","print(f\"(cand circuit / full) %: {circ_score:.4f}\")"],"metadata":{"id":"IYcsLUjIrrx3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CIRCUIT = {\n","    \"name mover\": [(9, 9), (10, 0), (9, 6)],\n","    \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n","    \"negative name mover\": [(10, 7), (11, 10)],\n","    \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n","    \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n","    \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n","    \"previous token\": [(2, 2), (4, 11)],\n","}\n","\n","import itertools\n","a = [val for val in CIRCUIT.values()]\n","IOI_heads = list(itertools.chain.from_iterable(a))\n","\n","mlps_not_ablate = list(range(12))\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = add_mean_ablation_hook_MLP_head(model, dataset_2, IOI_heads, mlps_not_ablate)\n","\n","new_logits = model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","circ_score = (100 * new_score / orig_score).item()\n","print(f\"(cand circuit / full) %: {circ_score:.4f}\")"],"metadata":{"id":"e2_0-p-pn4xw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### months w/ MLP 11\n","\n","heads_not_ablate = [(0, 1),\n"," (4, 4),\n"," (4, 10),\n"," (6, 1),\n"," (6, 6),\n"," (6, 10),\n"," (7, 2),\n"," (7, 10),\n"," (7, 11),\n"," (8, 8),\n"," (9, 1)]\n","mlps_not_ablate = [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11] # incl 5 makes it 66.1155%\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = add_mean_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","new_logits = model(dataset.toks)\n","new_score = logits_to_ave_logit_diff(new_logits, dataset)\n","circ_score = (100 * new_score / orig_score).item()\n","print(f\"(cand circuit / full) %: {circ_score:.4f}\")"],"metadata":{"id":"DYJ29X3Dn4-b"},"execution_count":null,"outputs":[]}]}