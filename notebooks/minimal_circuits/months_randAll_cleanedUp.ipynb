{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["DcZG9rm2IAiA","cGX9iHAz_UKX","BHHvz84w70vh","LyPMS_Gkrrx2","EpQyRtS2rrx2"],"gpuType":"T4","authorship_tag":"ABX9TyOW6SgPpXIDOVUEhvrI2GWn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b5f2092a54ea4526bc12693b7f03ab44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed77ee0c8d3e41d391257b849dd2290c","IPY_MODEL_9ac915d9ad2c43e0b7b24ea3002f347e","IPY_MODEL_69add81bbf2d42699b097d999eb12b8c"],"layout":"IPY_MODEL_1c462236570c41c19a94b88bd503f77e"}},"ed77ee0c8d3e41d391257b849dd2290c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70516c4ae0d746ed93e2ce81d2a21f92","placeholder":"​","style":"IPY_MODEL_2b2721a486ce4e61af654abcec6053d8","value":"Downloading (…)lve/main/config.json: 100%"}},"9ac915d9ad2c43e0b7b24ea3002f347e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c875579691ec4257862852c77192e70c","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42fabf7a232b48e78fddfd6a4720e9fa","value":665}},"69add81bbf2d42699b097d999eb12b8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a50d3c39726f45dd9c316bf094a64688","placeholder":"​","style":"IPY_MODEL_cd1f6ac04bdd4bfa81ac9b58cbefe1b4","value":" 665/665 [00:00&lt;00:00, 43.7kB/s]"}},"1c462236570c41c19a94b88bd503f77e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70516c4ae0d746ed93e2ce81d2a21f92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b2721a486ce4e61af654abcec6053d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c875579691ec4257862852c77192e70c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42fabf7a232b48e78fddfd6a4720e9fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a50d3c39726f45dd9c316bf094a64688":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd1f6ac04bdd4bfa81ac9b58cbefe1b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a246a07c36a49ae87da59084dbe8a48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4911e86c8a154833a338af1f77992cdc","IPY_MODEL_7c40f4b4e1ef46f49e1ae603eeeb3b1b","IPY_MODEL_9e18db2102c540bdb61ef8379ad90443"],"layout":"IPY_MODEL_dbe7b314777c41a9893d5b67385b1801"}},"4911e86c8a154833a338af1f77992cdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec3d1cdf328246618a48fb1f1e2017e8","placeholder":"​","style":"IPY_MODEL_093dd28f29d8447b9679c6915d9d03f5","value":"Downloading model.safetensors: 100%"}},"7c40f4b4e1ef46f49e1ae603eeeb3b1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c76b4f5e618d418782de9e31162b3c79","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccfb3eabd66e4cd3a122f72884baeca0","value":548105171}},"9e18db2102c540bdb61ef8379ad90443":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e11d0d260720493197ab38baab6ce36f","placeholder":"​","style":"IPY_MODEL_cd40c62494534842881f12cc2f931669","value":" 548M/548M [00:02&lt;00:00, 207MB/s]"}},"dbe7b314777c41a9893d5b67385b1801":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec3d1cdf328246618a48fb1f1e2017e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"093dd28f29d8447b9679c6915d9d03f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c76b4f5e618d418782de9e31162b3c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccfb3eabd66e4cd3a122f72884baeca0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e11d0d260720493197ab38baab6ce36f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd40c62494534842881f12cc2f931669":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23e91b0ddb03490d9d2ee060a16b8bea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a989cc6f793c44e8a316cb5461d4edb8","IPY_MODEL_b3099d792255429e8c11ed03068718cb","IPY_MODEL_7df413f9925647e982f48d32affaccfd"],"layout":"IPY_MODEL_6a05ba9d19b749f98ce885c171a07cb6"}},"a989cc6f793c44e8a316cb5461d4edb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_569049c67a524476a39896f1dd19ea5e","placeholder":"​","style":"IPY_MODEL_e0afe60bb65a4de5b07f5c4e0c31fe9d","value":"Downloading (…)neration_config.json: 100%"}},"b3099d792255429e8c11ed03068718cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_509c0fa1f7d14663a26c080681bb2914","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49e9ca3eb89b4d9793e2b0cd1c9a733c","value":124}},"7df413f9925647e982f48d32affaccfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a2a754739dc40c5b815df1510691a00","placeholder":"​","style":"IPY_MODEL_e2ff39737fe849bf8c5e6fade212c793","value":" 124/124 [00:00&lt;00:00, 4.74kB/s]"}},"6a05ba9d19b749f98ce885c171a07cb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"569049c67a524476a39896f1dd19ea5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0afe60bb65a4de5b07f5c4e0c31fe9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"509c0fa1f7d14663a26c080681bb2914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49e9ca3eb89b4d9793e2b0cd1c9a733c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a2a754739dc40c5b815df1510691a00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2ff39737fe849bf8c5e6fade212c793":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7ccc7202a00413ca4513676c57ca8b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_daa3a88eb0b2482987f3a46c46180805","IPY_MODEL_e2c4efa3f6d7462ba5664b379befc3e0","IPY_MODEL_0ee14003d36b4eefbc846c1e6ba6c40d"],"layout":"IPY_MODEL_01eb14e600ae4fb1b4b8df35506e0709"}},"daa3a88eb0b2482987f3a46c46180805":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_040289dbf766424081e2bc3540d46663","placeholder":"​","style":"IPY_MODEL_11307eb9f89346da8c803a164e35b54f","value":"Downloading (…)olve/main/vocab.json: 100%"}},"e2c4efa3f6d7462ba5664b379befc3e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4a3f4d1db614153ba1d8955f0bd1386","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b6d6b7cce8b4bed96111c82fde03379","value":1042301}},"0ee14003d36b4eefbc846c1e6ba6c40d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f77346c084f9493ca43b351432726582","placeholder":"​","style":"IPY_MODEL_c3e199b3579e4616ba8c877da0be1cfe","value":" 1.04M/1.04M [00:00&lt;00:00, 5.17MB/s]"}},"01eb14e600ae4fb1b4b8df35506e0709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"040289dbf766424081e2bc3540d46663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11307eb9f89346da8c803a164e35b54f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4a3f4d1db614153ba1d8955f0bd1386":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b6d6b7cce8b4bed96111c82fde03379":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f77346c084f9493ca43b351432726582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e199b3579e4616ba8c877da0be1cfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00d5fc68805144939c275ac5d61038f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99d85d39cb214bd19e12c3b8122c6c0e","IPY_MODEL_9babf9d2c7c04e9983749696464bc8fc","IPY_MODEL_288e29c69db14b48b9bcbaf7cd64efd8"],"layout":"IPY_MODEL_7791e62253974859a6eaf8abe30a641e"}},"99d85d39cb214bd19e12c3b8122c6c0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de90014b7698448bb4a60d496ee10cb6","placeholder":"​","style":"IPY_MODEL_08afdc01df854b66a64804f535b9e51b","value":"Downloading (…)olve/main/merges.txt: 100%"}},"9babf9d2c7c04e9983749696464bc8fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f9bd0fd5e0447b3987aeda20f2ea033","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81e58075835c456f89807d3e986a3a6a","value":456318}},"288e29c69db14b48b9bcbaf7cd64efd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d573bb3f19864b6db1d5439528cf7a66","placeholder":"​","style":"IPY_MODEL_9e0be936597e44509d2ceb3dfa60a055","value":" 456k/456k [00:00&lt;00:00, 5.71MB/s]"}},"7791e62253974859a6eaf8abe30a641e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de90014b7698448bb4a60d496ee10cb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08afdc01df854b66a64804f535b9e51b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f9bd0fd5e0447b3987aeda20f2ea033":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e58075835c456f89807d3e986a3a6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d573bb3f19864b6db1d5439528cf7a66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e0be936597e44509d2ceb3dfa60a055":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b940c72f536e437aaa9c34d04424b8f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce6d070d9598472bbb34a059d8d81c1e","IPY_MODEL_630fc89bfd95487ba9f6aa2885b9d172","IPY_MODEL_4b749fa4b27f422e8299922e656902aa"],"layout":"IPY_MODEL_7bf70e001dcf4c35847f7a3433a6fd20"}},"ce6d070d9598472bbb34a059d8d81c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89ceaaa416f24fe1b19ece3a607af333","placeholder":"​","style":"IPY_MODEL_631950adc93f4e289bc0e3c5daa76b49","value":"Downloading (…)/main/tokenizer.json: 100%"}},"630fc89bfd95487ba9f6aa2885b9d172":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_819808ff366c4b10b698eb4c32926b7a","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd222b35c7d64739a59ce85a77fd1fcc","value":1355256}},"4b749fa4b27f422e8299922e656902aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_814ca89cdf994f0e96f7693c8c5f983c","placeholder":"​","style":"IPY_MODEL_ae7b9369d9124908adabcb79c104b65c","value":" 1.36M/1.36M [00:00&lt;00:00, 4.09MB/s]"}},"7bf70e001dcf4c35847f7a3433a6fd20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89ceaaa416f24fe1b19ece3a607af333":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"631950adc93f4e289bc0e3c5daa76b49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"819808ff366c4b10b698eb4c32926b7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd222b35c7d64739a59ce85a77fd1fcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"814ca89cdf994f0e96f7693c8c5f983c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae7b9369d9124908adabcb79c104b65c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d934ff73-4643-4cc3-cb51-9e93f51ce29a","executionInfo":{"status":"ok","timestamp":1699130928215,"user_tz":240,"elapsed":112816,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-n2fbz_qh\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-n2fbz_qh\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit fa287750606075574df2c538058e67d648e2f952\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate>=0.23.0 (from transformer-lens==0.0.0)\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n","Collecting numpy>=1.24 (from transformer-lens==0.0.0)\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cublas_cu12-12.3.2.9-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (24.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cudnn_cu12-8.9.6.50-py3-none-manylinux1_x86_64.whl (704.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cufft_cu12-11.0.11.19-py3-none-manylinux1_x86_64.whl (98.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_curand_cu12-10.3.4.52-py3-none-manylinux1_x86_64.whl (56.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusolver_cu12-11.5.3.52-py3-none-manylinux1_x86_64.whl (125.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusparse_cu12-12.1.3.153-py3-none-manylinux1_x86_64.whl (195.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nvtx_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.6)\n","Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens==0.0.0)\n","  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=116436 sha256=303c258b4ff833ed9eeb722f1ee890c64ad784434a6e8fcdd12952925d99a48c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4hjfwoze/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=a4f9f5c70aecf66815d09bef8f477b78e4cd8c4dbf16a07f71ebaf9a1d3fb046\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, huggingface-hub, gitdb, tokenizers, nvidia-cusolver-cu12, GitPython, accelerate, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.24.1 beartype-0.14.1 datasets-2.14.6 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 huggingface-hub-0.17.3 jaxtyping-0.2.23 multiprocess-0.70.15 numpy-1.26.1 nvidia-cublas-cu12-12.3.2.9 nvidia-cuda-cupti-cu12-12.3.52 nvidia-cuda-nvrtc-cu12-12.3.52 nvidia-cuda-runtime-cu12-12.3.52 nvidia-cudnn-cu12-8.9.6.50 nvidia-cufft-cu12-11.0.11.19 nvidia-curand-cu12-10.3.4.52 nvidia-cusolver-cu12-11.5.3.52 nvidia-cusparse-cu12-12.1.3.153 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.3.52 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.34.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.35.0 typeguard-2.13.3 wandb-0.15.12\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKoTs7VBIAiD"},"outputs":[],"source":["# # Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","# import plotly.io as pio\n","\n","# if IN_COLAB or not DEBUG_MODE:\n","#     # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","#     pio.renderers.default = \"colab\"\n","# else:\n","#     pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6b1n2tvIAiD"},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuhzYxbsIAiE"},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFMTUcQiIAiF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699130940515,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"feb5bc40-38b0-4566-9474-3d855162ccea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7871730af850>"]},"metadata":{},"execution_count":5}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFs9BrbzIAiH"},"outputs":[],"source":["# def imshow(tensor, renderer=None, **kwargs):\n","#     px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","# def line(tensor, renderer=None, **kwargs):\n","#     px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","# def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","#     x = utils.to_numpy(x)\n","#     y = utils.to_numpy(y)\n","#     px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLwDyosvIAiJ","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["b5f2092a54ea4526bc12693b7f03ab44","ed77ee0c8d3e41d391257b849dd2290c","9ac915d9ad2c43e0b7b24ea3002f347e","69add81bbf2d42699b097d999eb12b8c","1c462236570c41c19a94b88bd503f77e","70516c4ae0d746ed93e2ce81d2a21f92","2b2721a486ce4e61af654abcec6053d8","c875579691ec4257862852c77192e70c","42fabf7a232b48e78fddfd6a4720e9fa","a50d3c39726f45dd9c316bf094a64688","cd1f6ac04bdd4bfa81ac9b58cbefe1b4","2a246a07c36a49ae87da59084dbe8a48","4911e86c8a154833a338af1f77992cdc","7c40f4b4e1ef46f49e1ae603eeeb3b1b","9e18db2102c540bdb61ef8379ad90443","dbe7b314777c41a9893d5b67385b1801","ec3d1cdf328246618a48fb1f1e2017e8","093dd28f29d8447b9679c6915d9d03f5","c76b4f5e618d418782de9e31162b3c79","ccfb3eabd66e4cd3a122f72884baeca0","e11d0d260720493197ab38baab6ce36f","cd40c62494534842881f12cc2f931669","23e91b0ddb03490d9d2ee060a16b8bea","a989cc6f793c44e8a316cb5461d4edb8","b3099d792255429e8c11ed03068718cb","7df413f9925647e982f48d32affaccfd","6a05ba9d19b749f98ce885c171a07cb6","569049c67a524476a39896f1dd19ea5e","e0afe60bb65a4de5b07f5c4e0c31fe9d","509c0fa1f7d14663a26c080681bb2914","49e9ca3eb89b4d9793e2b0cd1c9a733c","0a2a754739dc40c5b815df1510691a00","e2ff39737fe849bf8c5e6fade212c793","d7ccc7202a00413ca4513676c57ca8b7","daa3a88eb0b2482987f3a46c46180805","e2c4efa3f6d7462ba5664b379befc3e0","0ee14003d36b4eefbc846c1e6ba6c40d","01eb14e600ae4fb1b4b8df35506e0709","040289dbf766424081e2bc3540d46663","11307eb9f89346da8c803a164e35b54f","d4a3f4d1db614153ba1d8955f0bd1386","1b6d6b7cce8b4bed96111c82fde03379","f77346c084f9493ca43b351432726582","c3e199b3579e4616ba8c877da0be1cfe","00d5fc68805144939c275ac5d61038f4","99d85d39cb214bd19e12c3b8122c6c0e","9babf9d2c7c04e9983749696464bc8fc","288e29c69db14b48b9bcbaf7cd64efd8","7791e62253974859a6eaf8abe30a641e","de90014b7698448bb4a60d496ee10cb6","08afdc01df854b66a64804f535b9e51b","7f9bd0fd5e0447b3987aeda20f2ea033","81e58075835c456f89807d3e986a3a6a","d573bb3f19864b6db1d5439528cf7a66","9e0be936597e44509d2ceb3dfa60a055","b940c72f536e437aaa9c34d04424b8f9","ce6d070d9598472bbb34a059d8d81c1e","630fc89bfd95487ba9f6aa2885b9d172","4b749fa4b27f422e8299922e656902aa","7bf70e001dcf4c35847f7a3433a6fd20","89ceaaa416f24fe1b19ece3a607af333","631950adc93f4e289bc0e3c5daa76b49","819808ff366c4b10b698eb4c32926b7a","bd222b35c7d64739a59ce85a77fd1fcc","814ca89cdf994f0e96f7693c8c5f983c","ae7b9369d9124908adabcb79c104b65c"]},"executionInfo":{"status":"ok","timestamp":1699130963980,"user_tz":240,"elapsed":23470,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4bbb773d-9475-4546-c31d-8dcd94cbb30b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5f2092a54ea4526bc12693b7f03ab44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a246a07c36a49ae87da59084dbe8a48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23e91b0ddb03490d9d2ee060a16b8bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7ccc7202a00413ca4513676c57ca8b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d5fc68805144939c275ac5d61038f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b940c72f536e437aaa9c34d04424b8f9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"id":"Fdh5--MfYw7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699130975177,"user_tz":240,"elapsed":11313,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"76a383d2-ff2f-48f8-fd72-f6737a0e523f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9165, done.\u001b[K\n","remote: Counting objects: 100% (1877/1877), done.\u001b[K\n","remote: Compressing objects: 100% (319/319), done.\u001b[K\n","remote: Total 9165 (delta 1649), reused 1655 (delta 1554), pack-reused 7288\u001b[K\n","Receiving objects: 100% (9165/9165), 156.33 MiB | 23.19 MiB/s, done.\n","Resolving deltas: 100% (5544/5544), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"id":"iZ4C_bsXZFfj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699130975178,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bc65ea6c-9af4-4a6a-c578-7d8ae0475f7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"8cDWqgJTRWjT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pos_dict = {\n","    'S1': 0,\n","    'S2': 1,\n","    'S3': 2,\n","    'S4': 3,\n","}"],"metadata":{"id":"sGHl4RZTE98L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        prompt_dict = {\n","            'S1': months[i],\n","            'S2': months[i+1],\n","            'S3': months[i+2],\n","            'S4': months[i+3],\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{months[i]} {months[i+1]} {months[i+2]} {months[i+3]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 11)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"Eu7ZChRPRWjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        r1 = random.choice(months)\n","        r2 = random.choice(months)\n","        while True:\n","            r3_ind = random.randint(0,len(months)-1)\n","            r4_ind = random.randint(0,len(months)-1)\n","            if months[r3_ind] != months[r4_ind-1]:\n","                break\n","        r3 = months[r3_ind]\n","        r4 = months[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(1, 11)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list_2"],"metadata":{"id":"enLc-f0aRWjV","executionInfo":{"status":"ok","timestamp":1699130975179,"user_tz":240,"elapsed":22,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"457dc83e-5181-42c8-d1b8-b493403a324e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': 'August',\n","  'S2': 'December',\n","  'S3': 'January',\n","  'S4': 'May',\n","  'corr': 'May',\n","  'incorr': 'April',\n","  'text': 'August December January May'},\n"," {'S1': 'December',\n","  'S2': 'April',\n","  'S3': 'July',\n","  'S4': 'May',\n","  'corr': 'June',\n","  'incorr': 'May',\n","  'text': 'December April July May'},\n"," {'S1': 'March',\n","  'S2': 'December',\n","  'S3': 'February',\n","  'S4': 'September',\n","  'corr': 'July',\n","  'incorr': 'June',\n","  'text': 'March December February September'},\n"," {'S1': 'May',\n","  'S2': 'November',\n","  'S3': 'July',\n","  'S4': 'October',\n","  'corr': 'August',\n","  'incorr': 'July',\n","  'text': 'May November July October'},\n"," {'S1': 'July',\n","  'S2': 'June',\n","  'S3': 'February',\n","  'S4': 'June',\n","  'corr': 'September',\n","  'incorr': 'August',\n","  'text': 'July June February June'},\n"," {'S1': 'November',\n","  'S2': 'May',\n","  'S3': 'September',\n","  'S4': 'June',\n","  'corr': 'October',\n","  'incorr': 'September',\n","  'text': 'November May September June'},\n"," {'S1': 'July',\n","  'S2': 'July',\n","  'S3': 'April',\n","  'S4': 'February',\n","  'corr': 'November',\n","  'incorr': 'October',\n","  'text': 'July July April February'},\n"," {'S1': 'July',\n","  'S2': 'January',\n","  'S3': 'October',\n","  'S4': 'March',\n","  'corr': 'December',\n","  'incorr': 'November',\n","  'text': 'July January October March'}]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["prompts_list_2 = [{'S1': 'October',\n","  'S2': 'July',\n","  'S3': 'February',\n","  'S4': 'May',\n","  'corr': 'May',\n","  'incorr': 'April',\n","  'text': 'October July February May'},\n"," {'S1': 'August',\n","  'S2': 'March',\n","  'S3': 'March',\n","  'S4': 'March',\n","  'corr': 'June',\n","  'incorr': 'May',\n","  'text': 'August March March March'},\n"," {'S1': 'May',\n","  'S2': 'August',\n","  'S3': 'October',\n","  'S4': 'July',\n","  'corr': 'July',\n","  'incorr': 'June',\n","  'text': 'May August October July'},\n"," {'S1': 'October',\n","  'S2': 'April',\n","  'S3': 'February',\n","  'S4': 'February',\n","  'corr': 'August',\n","  'incorr': 'July',\n","  'text': 'October April February February'},\n"," {'S1': 'April',\n","  'S2': 'March',\n","  'S3': 'June',\n","  'S4': 'September',\n","  'corr': 'September',\n","  'incorr': 'August',\n","  'text': 'April March June September'},\n"," {'S1': 'April',\n","  'S2': 'March',\n","  'S3': 'March',\n","  'S4': 'August',\n","  'corr': 'October',\n","  'incorr': 'September',\n","  'text': 'April March March August'},\n"," {'S1': 'August',\n","  'S2': 'February',\n","  'S3': 'December',\n","  'S4': 'September',\n","  'corr': 'November',\n","  'incorr': 'October',\n","  'text': 'August February December September'},\n"," {'S1': 'November',\n","  'S2': 'August',\n","  'S3': 'March',\n","  'S4': 'December',\n","  'corr': 'December',\n","  'incorr': 'November',\n","  'text': 'November August March December'}]\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"2CkR822QWwZp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"BHHvz84w70vh"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"AFYffMoP70vh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"id":"OI3FcmpMaNxB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, orig_score, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        # \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        # \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    # ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    # orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"QLK5m1Ps70vh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"ybrqaAul70vi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"p7jLJcMH70vi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# iter backw fwd, threshold 3"],"metadata":{"id":"0NYZB-G19liQ"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698864250920,"user_tz":240,"elapsed":523909,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d04bc958-ed40-4ad7-c69a-02f92332a373","id":"-r7d7uel9liR"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","99.86515808105469\n","\n","Removed: (11, 1)\n","99.70606231689453\n","\n","Removed: (11, 2)\n","99.49992370605469\n","\n","Removed: (11, 3)\n","99.38542938232422\n","\n","Removed: (11, 4)\n","99.53096008300781\n","\n","Removed: (11, 5)\n","99.47246551513672\n","\n","Removed: (11, 6)\n","98.66363525390625\n","\n","Removed: (11, 7)\n","98.82321166992188\n","\n","Removed: (11, 9)\n","98.42066955566406\n","\n","Removed: (11, 10)\n","97.1253662109375\n","\n","Removed: (11, 11)\n","97.68685150146484\n","\n","Removed: (10, 0)\n","97.6208724975586\n","\n","Removed: (10, 1)\n","97.27182006835938\n","\n","Removed: (10, 4)\n","97.25872039794922\n","\n","Removed: (10, 5)\n","97.16763305664062\n","\n","Removed: (10, 7)\n","98.66638946533203\n","\n","Removed: (10, 8)\n","98.82259368896484\n","\n","Removed: (10, 9)\n","98.74352264404297\n","\n","Removed: (10, 10)\n","97.57072448730469\n","\n","Removed: (10, 11)\n","97.70975494384766\n","\n","Removed: (9, 0)\n","97.74153137207031\n","\n","Removed: (9, 1)\n","105.21685791015625\n","\n","Removed: (9, 2)\n","104.90479278564453\n","\n","Removed: (9, 3)\n","103.66998291015625\n","\n","Removed: (9, 4)\n","103.63906860351562\n","\n","Removed: (9, 5)\n","110.19441223144531\n","\n","Removed: (9, 6)\n","109.9915542602539\n","\n","Removed: (9, 7)\n","108.26524353027344\n","\n","Removed: (9, 8)\n","108.28204345703125\n","\n","Removed: (9, 9)\n","106.68913269042969\n","\n","Removed: (9, 10)\n","106.58171081542969\n","\n","Removed: (9, 11)\n","103.0827407836914\n","\n","Removed: (8, 0)\n","105.71223449707031\n","\n","Removed: (8, 1)\n","101.04597473144531\n","\n","Removed: (8, 2)\n","100.24053192138672\n","\n","Removed: (8, 3)\n","100.06781768798828\n","\n","Removed: (8, 4)\n","100.05077362060547\n","\n","Removed: (8, 5)\n","100.01148223876953\n","\n","Removed: (8, 7)\n","99.85475158691406\n","\n","Removed: (8, 9)\n","97.89384460449219\n","\n","Removed: (8, 10)\n","98.88445281982422\n","\n","Removed: (7, 0)\n","99.03631591796875\n","\n","Removed: (7, 1)\n","99.02143096923828\n","\n","Removed: (7, 2)\n","98.20072937011719\n","\n","Removed: (7, 3)\n","98.5347900390625\n","\n","Removed: (7, 4)\n","98.52735137939453\n","\n","Removed: (7, 5)\n","97.813232421875\n","\n","Removed: (7, 6)\n","97.33908081054688\n","\n","Removed: (7, 7)\n","97.52716064453125\n","\n","Removed: (7, 8)\n","97.2000503540039\n","\n","Removed: (7, 9)\n","97.15987396240234\n","\n","Removed: (6, 2)\n","97.32890319824219\n","\n","Removed: (6, 3)\n","97.25093841552734\n","\n","Removed: (6, 4)\n","97.24279022216797\n","\n","Removed: (6, 6)\n","97.30945587158203\n","\n","Removed: (6, 7)\n","97.22103118896484\n","\n","Removed: (6, 8)\n","97.81580352783203\n","\n","Removed: (6, 11)\n","97.58025360107422\n","\n","Removed: (5, 2)\n","97.51708221435547\n","\n","Removed: (5, 3)\n","97.28436279296875\n","\n","Removed: (5, 5)\n","98.51979064941406\n","\n","Removed: (5, 6)\n","100.35521697998047\n","\n","Removed: (5, 7)\n","100.31343078613281\n","\n","Removed: (5, 9)\n","100.4271240234375\n","\n","Removed: (5, 10)\n","101.48290252685547\n","\n","Removed: (5, 11)\n","99.20173645019531\n","\n","Removed: (4, 0)\n","99.66248321533203\n","\n","Removed: (4, 1)\n","99.6325454711914\n","\n","Removed: (4, 2)\n","99.7059555053711\n","\n","Removed: (4, 3)\n","99.7529296875\n","\n","Removed: (4, 5)\n","99.81338500976562\n","\n","Removed: (4, 6)\n","99.18519592285156\n","\n","Removed: (4, 7)\n","98.8156509399414\n","\n","Removed: (4, 8)\n","98.7540512084961\n","\n","Removed: (4, 9)\n","98.66223907470703\n","\n","Removed: (4, 10)\n","98.99163055419922\n","\n","Removed: (4, 11)\n","98.23118591308594\n","\n","Removed: (3, 0)\n","98.66072082519531\n","\n","Removed: (3, 1)\n","98.4151611328125\n","\n","Removed: (3, 2)\n","98.81522369384766\n","\n","Removed: (3, 3)\n","98.59254455566406\n","\n","Removed: (3, 4)\n","98.47972106933594\n","\n","Removed: (3, 5)\n","98.43270874023438\n","\n","Removed: (3, 6)\n","98.2032470703125\n","\n","Removed: (3, 8)\n","97.77738189697266\n","\n","Removed: (3, 9)\n","97.65203094482422\n","\n","Removed: (3, 11)\n","97.5272216796875\n","\n","Removed: (2, 0)\n","97.70133972167969\n","\n","Removed: (2, 1)\n","97.63310241699219\n","\n","Removed: (2, 3)\n","97.34881591796875\n","\n","Removed: (2, 4)\n","97.21691131591797\n","\n","Removed: (2, 6)\n","97.0937728881836\n","\n","Removed: (2, 8)\n","97.29627227783203\n","\n","Removed: (2, 10)\n","97.31609344482422\n","\n","Removed: (2, 11)\n","97.4222640991211\n","\n","Removed: (1, 1)\n","97.51689147949219\n","\n","Removed: (1, 2)\n","97.63140869140625\n","\n","Removed: (1, 3)\n","97.7210464477539\n","\n","Removed: (1, 4)\n","97.60981750488281\n","\n","Removed: (1, 6)\n","97.53196716308594\n","\n","Removed: (1, 7)\n","97.46855163574219\n","\n","Removed: (1, 8)\n","97.5976791381836\n","\n","Removed: (1, 9)\n","97.30552673339844\n","\n","Removed: (1, 10)\n","97.43289184570312\n","\n","Removed: (1, 11)\n","97.90592956542969\n","\n","Removed: (0, 2)\n","98.10641479492188\n","\n","Removed: (0, 4)\n","98.04987335205078\n","\n","Removed: (0, 6)\n","98.2245101928711\n","\n","Removed: (0, 7)\n","99.02149200439453\n","\n","Removed: (0, 8)\n","99.51190948486328\n","\n","Removed: (0, 9)\n","99.8602066040039\n","\n","Removed: (0, 10)\n","99.8405990600586\n","\n","Removed: (0, 11)\n","99.43394470214844\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","98.60706329345703\n","\n","Removed: (0, 3)\n","97.32479095458984\n","\n","Removed: (2, 5)\n","97.15216064453125\n","\n","Removed: (10, 6)\n","97.02217102050781\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698864250921,"user_tz":240,"elapsed":27,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b338a53-2d9d-4e20-ca26-def8fc3a8c56","id":"JBXczdVO9liR"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 5),\n"," (1, 0),\n"," (1, 5),\n"," (2, 2),\n"," (2, 7),\n"," (2, 9),\n"," (3, 7),\n"," (3, 10),\n"," (4, 4),\n"," (5, 0),\n"," (5, 1),\n"," (5, 4),\n"," (5, 8),\n"," (6, 0),\n"," (6, 1),\n"," (6, 5),\n"," (6, 9),\n"," (6, 10),\n"," (7, 10),\n"," (7, 11),\n"," (8, 6),\n"," (8, 8),\n"," (8, 11),\n"," (10, 2),\n"," (10, 3),\n"," (11, 8)]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864250921,"user_tz":240,"elapsed":23,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"acfcef36-d072-453c-acb0-5eb33dd70754","id":"5oCXGBxj9liS"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## loop rmv and check for most impt heads"],"metadata":{"id":"8At2Kqx69liS"}},{"cell_type":"code","source":["circ = bf_3\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864252925,"user_tz":240,"elapsed":2026,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c63cebab-b98e-42fd-8af6-40fd46165952","id":"ivoDzNKY9liS"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0222\n"]}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864323666,"user_tz":240,"elapsed":70746,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3d8e7189-eae2-4246-c30c-9626a9973465","id":"vsUtHR-y9liS"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 90.5230\n","removed: (0, 5)\n","Average logit difference (circuit / full) %: 95.8878\n","removed: (1, 0)\n","Average logit difference (circuit / full) %: 95.7988\n","removed: (1, 5)\n","Average logit difference (circuit / full) %: 92.9287\n","removed: (2, 2)\n","Average logit difference (circuit / full) %: 95.9326\n","removed: (2, 7)\n","Average logit difference (circuit / full) %: 96.7999\n","removed: (2, 9)\n","Average logit difference (circuit / full) %: 96.4289\n","removed: (3, 7)\n","Average logit difference (circuit / full) %: 95.0207\n","removed: (3, 10)\n","Average logit difference (circuit / full) %: 96.1482\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 41.1407\n","removed: (5, 0)\n","Average logit difference (circuit / full) %: 93.3619\n","removed: (5, 1)\n","Average logit difference (circuit / full) %: 96.0624\n","removed: (5, 4)\n","Average logit difference (circuit / full) %: 96.5859\n","removed: (5, 8)\n","Average logit difference (circuit / full) %: 90.8191\n","removed: (6, 0)\n","Average logit difference (circuit / full) %: 96.6470\n","removed: (6, 1)\n","Average logit difference (circuit / full) %: 95.3798\n","removed: (6, 5)\n","Average logit difference (circuit / full) %: 96.2903\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 94.6375\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 81.4386\n","removed: (7, 10)\n","Average logit difference (circuit / full) %: 91.1558\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 82.6383\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 90.7607\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 92.8269\n","removed: (8, 11)\n","Average logit difference (circuit / full) %: 84.3821\n","removed: (10, 2)\n","Average logit difference (circuit / full) %: 95.4302\n","removed: (10, 3)\n","Average logit difference (circuit / full) %: 96.0380\n","removed: (11, 8)\n","Average logit difference (circuit / full) %: 92.7269\n"]}]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864323666,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"08266ac1-68e2-4e62-a9c4-1fb31accdbcc","id":"MNzdWLFj9liT"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 41.14067840576172,\n"," (6, 10): 81.43862915039062,\n"," (7, 11): 82.63829803466797,\n"," (8, 11): 84.38214111328125,\n"," (0, 1): 90.52302551269531,\n"," (8, 6): 90.76065826416016,\n"," (5, 8): 90.81907653808594,\n"," (7, 10): 91.15576171875,\n"," (11, 8): 92.72691345214844,\n"," (8, 8): 92.82693481445312,\n"," (1, 5): 92.92874145507812,\n"," (5, 0): 93.36192321777344,\n"," (6, 9): 94.63748168945312,\n"," (3, 7): 95.02069091796875,\n"," (6, 1): 95.37979888916016,\n"," (10, 2): 95.4301986694336,\n"," (1, 0): 95.79875183105469,\n"," (0, 5): 95.88780212402344,\n"," (2, 2): 95.9326400756836,\n"," (10, 3): 96.03795623779297,\n"," (5, 1): 96.06241607666016,\n"," (3, 10): 96.148193359375,\n"," (6, 5): 96.29025268554688,\n"," (2, 9): 96.42891693115234,\n"," (5, 4): 96.58585357666016,\n"," (6, 0): 96.64701080322266,\n"," (2, 7): 96.79991149902344}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698864323666,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ae12ab82-a9c8-4f91-b7c5-d397388b5fed","id":"RPCynBNH9liT"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4) -55.88\n","(6, 10) -15.58\n","(7, 11) -14.38\n","(8, 11) -12.64\n","(0, 1) -6.5\n","(8, 6) -6.26\n","(5, 8) -6.2\n","(7, 10) -5.87\n","(11, 8) -4.3\n","(8, 8) -4.2\n","(1, 5) -4.09\n","(5, 0) -3.66\n","(6, 9) -2.38\n","(3, 7) -2.0\n","(6, 1) -1.64\n","(10, 2) -1.59\n","(1, 0) -1.22\n","(0, 5) -1.13\n","(2, 2) -1.09\n","(10, 3) -0.98\n","(5, 1) -0.96\n","(3, 10) -0.87\n","(6, 5) -0.73\n","(2, 9) -0.59\n","(5, 4) -0.44\n","(6, 0) -0.38\n","(2, 7) -0.22\n"]}]},{"cell_type":"markdown","source":["# try other tasks circs"],"metadata":{"id":"xbZkzn0nrrxt"}},{"cell_type":"markdown","source":["## iter backw fwd, threshold 20"],"metadata":{"id":"_DLiKxrBp-Wt"}},{"cell_type":"code","source":["threshold = 20\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698889310575,"user_tz":240,"elapsed":488629,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6437c7cf-5ecb-4847-b4c2-f2a62d1a9d74","id":"kHht_0gCp-W0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","99.86518859863281\n","\n","Removed: (11, 1)\n","99.7060546875\n","\n","Removed: (11, 2)\n","99.49995422363281\n","\n","Removed: (11, 3)\n","99.38541412353516\n","\n","Removed: (11, 4)\n","99.53091430664062\n","\n","Removed: (11, 5)\n","99.47248840332031\n","\n","Removed: (11, 6)\n","98.66361999511719\n","\n","Removed: (11, 7)\n","98.82323455810547\n","\n","Removed: (11, 8)\n","95.578125\n","\n","Removed: (11, 9)\n","95.16633605957031\n","\n","Removed: (11, 10)\n","93.87151336669922\n","\n","Removed: (11, 11)\n","94.37239074707031\n","\n","Removed: (10, 0)\n","94.30249786376953\n","\n","Removed: (10, 1)\n","94.0016098022461\n","\n","Removed: (10, 2)\n","92.67064666748047\n","\n","Removed: (10, 3)\n","91.27398681640625\n","\n","Removed: (10, 4)\n","91.2550048828125\n","\n","Removed: (10, 5)\n","91.16800689697266\n","\n","Removed: (10, 6)\n","90.92051696777344\n","\n","Removed: (10, 7)\n","93.1395492553711\n","\n","Removed: (10, 8)\n","93.26133728027344\n","\n","Removed: (10, 9)\n","93.16360473632812\n","\n","Removed: (10, 10)\n","92.06661987304688\n","\n","Removed: (10, 11)\n","92.10260009765625\n","\n","Removed: (9, 0)\n","92.12821960449219\n","\n","Removed: (9, 1)\n","96.14894104003906\n","\n","Removed: (9, 2)\n","95.83226013183594\n","\n","Removed: (9, 3)\n","94.78255462646484\n","\n","Removed: (9, 4)\n","94.76577758789062\n","\n","Removed: (9, 5)\n","100.9559555053711\n","\n","Removed: (9, 6)\n","100.85633087158203\n","\n","Removed: (9, 7)\n","99.45118713378906\n","\n","Removed: (9, 8)\n","99.4732894897461\n","\n","Removed: (9, 9)\n","97.54808044433594\n","\n","Removed: (9, 10)\n","97.46912384033203\n","\n","Removed: (9, 11)\n","94.468505859375\n","\n","Removed: (8, 0)\n","96.79902648925781\n","\n","Removed: (8, 1)\n","92.39085388183594\n","\n","Removed: (8, 2)\n","91.80685424804688\n","\n","Removed: (8, 3)\n","91.67072296142578\n","\n","Removed: (8, 4)\n","91.65507507324219\n","\n","Removed: (8, 5)\n","91.65496063232422\n","\n","Removed: (8, 6)\n","87.48326873779297\n","\n","Removed: (8, 7)\n","87.34211730957031\n","\n","Removed: (8, 8)\n","82.95215606689453\n","\n","Removed: (8, 9)\n","81.09823608398438\n","\n","Removed: (8, 10)\n","82.65345764160156\n","\n","Removed: (7, 0)\n","82.73021697998047\n","\n","Removed: (7, 1)\n","82.69589233398438\n","\n","Removed: (7, 2)\n","81.91190338134766\n","\n","Removed: (7, 3)\n","82.53009033203125\n","\n","Removed: (7, 4)\n","82.50971221923828\n","\n","Removed: (7, 5)\n","81.92635345458984\n","\n","Removed: (7, 6)\n","81.2965316772461\n","\n","Removed: (7, 7)\n","81.98314666748047\n","\n","Removed: (7, 8)\n","81.76214599609375\n","\n","Removed: (7, 9)\n","81.72695922851562\n","\n","Removed: (6, 0)\n","81.56105041503906\n","\n","Removed: (6, 2)\n","81.64810180664062\n","\n","Removed: (6, 3)\n","81.55990600585938\n","\n","Removed: (6, 4)\n","81.58758544921875\n","\n","Removed: (6, 5)\n","80.77394104003906\n","\n","Removed: (6, 6)\n","81.30230712890625\n","\n","Removed: (6, 7)\n","81.12293243408203\n","\n","Removed: (6, 8)\n","81.29823303222656\n","\n","Removed: (6, 11)\n","81.11498260498047\n","\n","Removed: (5, 2)\n","81.05313873291016\n","\n","Removed: (5, 3)\n","80.75106811523438\n","\n","Removed: (5, 4)\n","80.37481689453125\n","\n","Removed: (5, 5)\n","81.16126251220703\n","\n","Removed: (5, 6)\n","82.50946807861328\n","\n","Removed: (5, 7)\n","82.47903442382812\n","\n","Removed: (5, 9)\n","82.49557495117188\n","\n","Removed: (5, 10)\n","83.3790283203125\n","\n","Removed: (5, 11)\n","81.96197509765625\n","\n","Removed: (4, 0)\n","82.2674560546875\n","\n","Removed: (4, 1)\n","82.21936798095703\n","\n","Removed: (4, 2)\n","82.2502670288086\n","\n","Removed: (4, 3)\n","82.3552474975586\n","\n","Removed: (4, 5)\n","82.38338470458984\n","\n","Removed: (4, 6)\n","81.90027618408203\n","\n","Removed: (4, 7)\n","81.46260070800781\n","\n","Removed: (4, 8)\n","81.54116821289062\n","\n","Removed: (4, 9)\n","81.49246978759766\n","\n","Removed: (4, 10)\n","81.3137435913086\n","\n","Removed: (4, 11)\n","80.74346923828125\n","\n","Removed: (3, 0)\n","80.97449493408203\n","\n","Removed: (3, 1)\n","80.78272247314453\n","\n","Removed: (3, 2)\n","81.08100891113281\n","\n","Removed: (3, 3)\n","80.9294662475586\n","\n","Removed: (3, 4)\n","80.8184814453125\n","\n","Removed: (3, 5)\n","80.8135986328125\n","\n","Removed: (3, 6)\n","80.64786529541016\n","\n","Removed: (3, 8)\n","80.3583755493164\n","\n","Removed: (3, 9)\n","80.23963165283203\n","\n","Removed: (3, 11)\n","80.1695327758789\n","\n","Removed: (2, 0)\n","80.25171661376953\n","\n","Removed: (2, 1)\n","80.22557067871094\n","\n","Removed: (2, 4)\n","80.12006378173828\n","\n","Removed: (2, 6)\n","80.09027862548828\n","\n","Removed: (2, 8)\n","80.2798080444336\n","\n","Removed: (2, 10)\n","80.34614562988281\n","\n","Removed: (2, 11)\n","80.38719177246094\n","\n","Removed: (1, 0)\n","80.20559692382812\n","\n","Removed: (1, 1)\n","80.16349029541016\n","\n","Removed: (1, 2)\n","80.32844543457031\n","\n","Removed: (1, 3)\n","80.42151641845703\n","\n","Removed: (1, 4)\n","80.24034881591797\n","\n","Removed: (1, 6)\n","80.23273468017578\n","\n","Removed: (1, 7)\n","80.28260040283203\n","\n","Removed: (1, 8)\n","80.32550048828125\n","\n","Removed: (1, 9)\n","80.22738647460938\n","\n","Removed: (1, 10)\n","80.29183197021484\n","\n","Removed: (1, 11)\n","80.53520202636719\n","\n","Removed: (0, 2)\n","80.71465301513672\n","\n","Removed: (0, 4)\n","80.6524429321289\n","\n","Removed: (0, 6)\n","80.94548797607422\n","\n","Removed: (0, 7)\n","81.3222427368164\n","\n","Removed: (0, 8)\n","81.76115417480469\n","\n","Removed: (0, 9)\n","81.90074157714844\n","\n","Removed: (0, 10)\n","82.2391586303711\n","\n","Removed: (0, 11)\n","81.96708679199219\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","81.26959228515625\n","\n","Removed: (0, 3)\n","80.16162109375\n","\n","Removed: (2, 7)\n","80.0051498413086\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_20 = curr_circuit.copy()\n","bf_20"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698889310576,"user_tz":240,"elapsed":31,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1cd763a7-2d1c-4aec-bfe4-227b786800d7","id":"Pj3RPOWBp-W0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 5),\n"," (1, 5),\n"," (2, 2),\n"," (2, 3),\n"," (2, 5),\n"," (2, 9),\n"," (3, 7),\n"," (3, 10),\n"," (4, 4),\n"," (5, 0),\n"," (5, 1),\n"," (5, 8),\n"," (6, 1),\n"," (6, 9),\n"," (6, 10),\n"," (7, 10),\n"," (7, 11),\n"," (8, 11)]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["len(bf_20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698889310576,"user_tz":240,"elapsed":27,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ff96a658-cd61-475a-84ef-bdb7468e304b","id":"Xm61sbUlp-W1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["### loop rmv and check for most impt heads"],"metadata":{"id":"hBNCoEtip-W1"}},{"cell_type":"code","source":["circ = bf_20\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698889313271,"user_tz":240,"elapsed":2720,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e0bf9870-22bd-48b7-f5da-ca8503c1c34b","id":"JuPRwkynp-W1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 80.0051\n"]}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698889362662,"user_tz":240,"elapsed":49416,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8eddbca0-8d1d-4c59-a836-875dffd74774","id":"a-kx176Qp-W2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 74.3332\n","removed: (0, 5)\n","Average logit difference (circuit / full) %: 78.9162\n","removed: (1, 5)\n","Average logit difference (circuit / full) %: 76.7735\n","removed: (2, 2)\n","Average logit difference (circuit / full) %: 78.9474\n","removed: (2, 3)\n","Average logit difference (circuit / full) %: 79.7928\n","removed: (2, 5)\n","Average logit difference (circuit / full) %: 79.8287\n","removed: (2, 9)\n","Average logit difference (circuit / full) %: 79.5261\n","removed: (3, 7)\n","Average logit difference (circuit / full) %: 78.4577\n","removed: (3, 10)\n","Average logit difference (circuit / full) %: 79.4427\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 35.9684\n","removed: (5, 0)\n","Average logit difference (circuit / full) %: 76.7337\n","removed: (5, 1)\n","Average logit difference (circuit / full) %: 78.9997\n","removed: (5, 8)\n","Average logit difference (circuit / full) %: 76.6089\n","removed: (6, 1)\n","Average logit difference (circuit / full) %: 75.3679\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 77.8192\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 67.3873\n","removed: (7, 10)\n","Average logit difference (circuit / full) %: 71.7315\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 65.2316\n","removed: (8, 11)\n","Average logit difference (circuit / full) %: 65.6867\n"]}]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698889362662,"user_tz":240,"elapsed":26,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5dc65d1c-b360-4f0d-e9c4-74626e9158e8","id":"wiG04I6gp-W2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 35.96836853027344,\n"," (7, 11): 65.2315673828125,\n"," (8, 11): 65.68665313720703,\n"," (6, 10): 67.38734436035156,\n"," (7, 10): 71.73152160644531,\n"," (0, 1): 74.33316040039062,\n"," (6, 1): 75.36791229248047,\n"," (5, 8): 76.60887145996094,\n"," (5, 0): 76.73367309570312,\n"," (1, 5): 76.7734603881836,\n"," (6, 9): 77.81916809082031,\n"," (3, 7): 78.45770263671875,\n"," (0, 5): 78.91622924804688,\n"," (2, 2): 78.94742584228516,\n"," (5, 1): 78.9997329711914,\n"," (3, 10): 79.4427490234375,\n"," (2, 9): 79.52606201171875,\n"," (2, 3): 79.79278564453125,\n"," (2, 5): 79.82872772216797}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698889362662,"user_tz":240,"elapsed":24,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"65137adc-99ee-4042-df08-d983ae5a3e98","id":"LkatbMdmp-W2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4) -44.04\n","(7, 11) -14.77\n","(8, 11) -14.32\n","(6, 10) -12.62\n","(7, 10) -8.27\n","(0, 1) -5.67\n","(6, 1) -4.64\n","(5, 8) -3.4\n","(5, 0) -3.27\n","(1, 5) -3.23\n","(6, 9) -2.19\n","(3, 7) -1.55\n","(0, 5) -1.09\n","(2, 2) -1.06\n","(5, 1) -1.01\n","(3, 10) -0.56\n","(2, 9) -0.48\n","(2, 3) -0.21\n","(2, 5) -0.18\n"]}]},{"cell_type":"markdown","source":["# try again using incorr logit i"],"metadata":{"id":"jd3YYf6dNzDm"}},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        prompt_dict = {\n","            'S1': months[i],\n","            'S2': months[i+1],\n","            'S3': months[i+2],\n","            'S4': months[i+3],\n","            'corr': months[i+4],\n","            'incorr': months[i],\n","            'text': f\"{months[i]} {months[i+1]} {months[i+2]} {months[i+2]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 11)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"woWuxNIKN1OJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"id":"n1QTujmwRMQx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## after ipp"],"metadata":{"id":"TO7OhfN1FuUR"}},{"cell_type":"code","source":["# bf 80 after rmv 8,9 and 2,9\n","\n","circuit = [(0, 1), (2, 2), (4, 4), (5, 0), (5, 1), (5, 4), (5, 6), (6, 6), (6, 9), (6, 10), (7, 7), (7, 11), (8, 8), (9, 1)]\n","\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emDa-KEmFwyk","executionInfo":{"status":"ok","timestamp":1699131117893,"user_tz":240,"elapsed":3671,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9b4ea098-f9ff-4a83-c7a2-628d658f3703"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 76.4315\n"]},{"output_type":"execute_result","data":{"text/plain":["76.43152618408203"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["circuit = [(0, 1), (2, 2), (2, 9), (4, 4), (5, 0), (5, 1), (5, 4), (5, 6), (6, 6), (6, 9), (6, 10), (7, 7), (7, 11), (8, 8), (8, 9), (9, 1)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_s8cMF3IGkQu","executionInfo":{"status":"ok","timestamp":1699131120643,"user_tz":240,"elapsed":2777,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4a152b09-3521-4b5d-f154-db79af9b1167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 80.0188\n"]},{"output_type":"execute_result","data":{"text/plain":["80.01876068115234"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["## iter backw fwd, threshold 3"],"metadata":{"id":"KVw7I5BQN7AO"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698865899559,"user_tz":240,"elapsed":494085,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6a3ed31-012b-499c-f3f0-6a0515877c93","id":"3zRyTSrqN7AO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","100.27477264404297\n","\n","Removed: (11, 1)\n","100.23351287841797\n","\n","Removed: (11, 2)\n","100.46318817138672\n","\n","Removed: (11, 3)\n","100.17131042480469\n","\n","Removed: (11, 4)\n","100.55448150634766\n","\n","Removed: (11, 5)\n","100.61019134521484\n","\n","Removed: (11, 6)\n","101.81040954589844\n","\n","Removed: (11, 7)\n","101.80139923095703\n","\n","Removed: (11, 8)\n","98.91886138916016\n","\n","Removed: (11, 9)\n","98.89364624023438\n","\n","Removed: (11, 11)\n","99.15338134765625\n","\n","Removed: (10, 0)\n","99.13613891601562\n","\n","Removed: (10, 1)\n","100.12897491455078\n","\n","Removed: (10, 2)\n","100.70376586914062\n","\n","Removed: (10, 3)\n","101.1800308227539\n","\n","Removed: (10, 4)\n","101.31055450439453\n","\n","Removed: (10, 5)\n","101.12251281738281\n","\n","Removed: (10, 6)\n","100.38468933105469\n","\n","Removed: (10, 8)\n","100.62175750732422\n","\n","Removed: (10, 9)\n","100.5606689453125\n","\n","Removed: (10, 10)\n","99.8133544921875\n","\n","Removed: (10, 11)\n","99.99896240234375\n","\n","Removed: (9, 0)\n","100.01261901855469\n","\n","Removed: (9, 2)\n","99.6978530883789\n","\n","Removed: (9, 3)\n","98.97310638427734\n","\n","Removed: (9, 4)\n","99.01006317138672\n","\n","Removed: (9, 5)\n","98.32669830322266\n","\n","Removed: (9, 6)\n","98.0379638671875\n","\n","Removed: (9, 8)\n","98.02532958984375\n","\n","Removed: (9, 9)\n","97.29544067382812\n","\n","Removed: (9, 10)\n","97.25281524658203\n","\n","Removed: (8, 0)\n","98.64603424072266\n","\n","Removed: (8, 2)\n","98.29534149169922\n","\n","Removed: (8, 3)\n","98.02164459228516\n","\n","Removed: (8, 4)\n","98.00370788574219\n","\n","Removed: (8, 5)\n","97.98628997802734\n","\n","Removed: (8, 7)\n","97.99247741699219\n","\n","Removed: (8, 10)\n","99.04789733886719\n","\n","Removed: (8, 11)\n","99.68678283691406\n","\n","Removed: (7, 0)\n","100.27881622314453\n","\n","Removed: (7, 1)\n","100.26317596435547\n","\n","Removed: (7, 2)\n","99.81619262695312\n","\n","Removed: (7, 3)\n","99.64189147949219\n","\n","Removed: (7, 4)\n","99.66586303710938\n","\n","Removed: (7, 5)\n","99.04739379882812\n","\n","Removed: (7, 6)\n","97.87159729003906\n","\n","Removed: (7, 7)\n","97.15158081054688\n","\n","Removed: (7, 9)\n","97.18389892578125\n","\n","Removed: (7, 10)\n","98.15860748291016\n","\n","Removed: (6, 0)\n","97.75288391113281\n","\n","Removed: (6, 1)\n","99.24651336669922\n","\n","Removed: (6, 2)\n","99.20854187011719\n","\n","Removed: (6, 3)\n","99.19878387451172\n","\n","Removed: (6, 4)\n","99.10107421875\n","\n","Removed: (6, 5)\n","99.02191925048828\n","\n","Removed: (6, 6)\n","98.5276870727539\n","\n","Removed: (6, 7)\n","98.27660369873047\n","\n","Removed: (6, 8)\n","98.61332702636719\n","\n","Removed: (6, 11)\n","98.45637512207031\n","\n","Removed: (5, 1)\n","97.66431427001953\n","\n","Removed: (5, 2)\n","97.7006607055664\n","\n","Removed: (5, 3)\n","97.65064239501953\n","\n","Removed: (5, 4)\n","97.1858901977539\n","\n","Removed: (5, 5)\n","98.51045989990234\n","\n","Removed: (5, 7)\n","98.5235824584961\n","\n","Removed: (5, 8)\n","101.39987182617188\n","\n","Removed: (5, 9)\n","101.502685546875\n","\n","Removed: (5, 10)\n","101.99901580810547\n","\n","Removed: (5, 11)\n","101.2509536743164\n","\n","Removed: (4, 0)\n","100.84490203857422\n","\n","Removed: (4, 1)\n","100.8598861694336\n","\n","Removed: (4, 2)\n","100.74022674560547\n","\n","Removed: (4, 3)\n","100.18172454833984\n","\n","Removed: (4, 5)\n","100.19821166992188\n","\n","Removed: (4, 6)\n","100.5010986328125\n","\n","Removed: (4, 7)\n","100.22283935546875\n","\n","Removed: (4, 8)\n","100.64716339111328\n","\n","Removed: (4, 9)\n","100.64530944824219\n","\n","Removed: (4, 10)\n","99.49542999267578\n","\n","Removed: (4, 11)\n","98.6583023071289\n","\n","Removed: (3, 0)\n","99.02839660644531\n","\n","Removed: (3, 1)\n","99.25535583496094\n","\n","Removed: (3, 2)\n","100.05171966552734\n","\n","Removed: (3, 3)\n","99.6327133178711\n","\n","Removed: (3, 4)\n","100.84308624267578\n","\n","Removed: (3, 5)\n","100.88224029541016\n","\n","Removed: (3, 6)\n","100.16543579101562\n","\n","Removed: (3, 7)\n","99.39244842529297\n","\n","Removed: (3, 8)\n","98.56494140625\n","\n","Removed: (3, 9)\n","98.00251007080078\n","\n","Removed: (3, 10)\n","97.1229248046875\n","\n","Removed: (3, 11)\n","97.00479125976562\n","\n","Removed: (2, 0)\n","97.01956939697266\n","\n","Removed: (2, 1)\n","97.05145263671875\n","\n","Removed: (2, 4)\n","97.04536437988281\n","\n","Removed: (2, 6)\n","97.1332778930664\n","\n","Removed: (2, 10)\n","97.61698913574219\n","\n","Removed: (2, 11)\n","97.5558090209961\n","\n","Removed: (1, 0)\n","97.2438735961914\n","\n","Removed: (1, 1)\n","97.54288482666016\n","\n","Removed: (1, 2)\n","97.8648910522461\n","\n","Removed: (1, 3)\n","97.64124298095703\n","\n","Removed: (1, 4)\n","97.425537109375\n","\n","Removed: (1, 5)\n","99.27580261230469\n","\n","Removed: (1, 6)\n","99.59795379638672\n","\n","Removed: (1, 7)\n","99.34895324707031\n","\n","Removed: (1, 8)\n","99.5550308227539\n","\n","Removed: (1, 9)\n","99.1781005859375\n","\n","Removed: (1, 10)\n","99.46469116210938\n","\n","Removed: (1, 11)\n","99.58702087402344\n","\n","Removed: (0, 0)\n","99.10199737548828\n","\n","Removed: (0, 2)\n","98.86730194091797\n","\n","Removed: (0, 3)\n","97.80921936035156\n","\n","Removed: (0, 4)\n","98.07965087890625\n","\n","Removed: (0, 5)\n","97.06893920898438\n","\n","Removed: (0, 6)\n","97.3018798828125\n","\n","Removed: (0, 7)\n","97.49102020263672\n","\n","Removed: (0, 8)\n","97.2193832397461\n","\n","Removed: (0, 10)\n","99.70881652832031\n","\n","Removed: (0, 11)\n","99.64701080322266\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 9)\n","99.06260681152344\n","\n","Removed: (2, 2)\n","97.02288055419922\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698865899559,"user_tz":240,"elapsed":23,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d34b225d-8224-4479-af2d-22510058a201","id":"b_fMrKD5N7AP"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (2, 3),\n"," (2, 5),\n"," (2, 7),\n"," (2, 8),\n"," (2, 9),\n"," (4, 4),\n"," (5, 0),\n"," (5, 6),\n"," (6, 9),\n"," (6, 10),\n"," (7, 8),\n"," (7, 11),\n"," (8, 1),\n"," (8, 6),\n"," (8, 8),\n"," (8, 9),\n"," (9, 1),\n"," (9, 7),\n"," (9, 11),\n"," (10, 7),\n"," (11, 10)]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865899559,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7c12c357-491e-4c34-c712-8496c5a78e9f","id":"_UR3P5ZtN7AP"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["### loop rmv and check for most impt heads"],"metadata":{"id":"TvUXAq0lN7AP"}},{"cell_type":"code","source":["circ = bf_3\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865901963,"user_tz":240,"elapsed":2421,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"97210e45-215a-488e-f95f-31f217f4fa7e","id":"SH8u_sXXN7AP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0229\n"]}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865959235,"user_tz":240,"elapsed":57276,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"40cc0d91-539d-4834-d470-306970ee919a","id":"Z61lZ7rsN7AQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 89.3814\n","removed: (2, 3)\n","Average logit difference (circuit / full) %: 96.9478\n","removed: (2, 5)\n","Average logit difference (circuit / full) %: 96.8179\n","removed: (2, 7)\n","Average logit difference (circuit / full) %: 96.6588\n","removed: (2, 8)\n","Average logit difference (circuit / full) %: 96.6361\n","removed: (2, 9)\n","Average logit difference (circuit / full) %: 96.5452\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 24.7081\n","removed: (5, 0)\n","Average logit difference (circuit / full) %: 93.0373\n","removed: (5, 6)\n","Average logit difference (circuit / full) %: 94.2867\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 94.3910\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 88.5307\n","removed: (7, 8)\n","Average logit difference (circuit / full) %: 96.6392\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 82.5906\n","removed: (8, 1)\n","Average logit difference (circuit / full) %: 93.5788\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 92.0341\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 94.9877\n","removed: (8, 9)\n","Average logit difference (circuit / full) %: 93.6339\n","removed: (9, 1)\n","Average logit difference (circuit / full) %: 35.3323\n","removed: (9, 7)\n","Average logit difference (circuit / full) %: 94.7443\n","removed: (9, 11)\n","Average logit difference (circuit / full) %: 94.2776\n","removed: (10, 7)\n","Average logit difference (circuit / full) %: 91.8446\n","removed: (11, 10)\n","Average logit difference (circuit / full) %: 95.5536\n"]}]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865959235,"user_tz":240,"elapsed":22,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"372dd408-7311-4e65-ec44-981e442986ed","id":"8EyMfrgiN7AQ"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 24.708080291748047,\n"," (9, 1): 35.33229064941406,\n"," (7, 11): 82.59058380126953,\n"," (6, 10): 88.53067016601562,\n"," (0, 1): 89.3814468383789,\n"," (10, 7): 91.84457397460938,\n"," (8, 6): 92.03407287597656,\n"," (5, 0): 93.03734588623047,\n"," (8, 1): 93.57878875732422,\n"," (8, 9): 93.63392639160156,\n"," (9, 11): 94.2775650024414,\n"," (5, 6): 94.28670501708984,\n"," (6, 9): 94.3909683227539,\n"," (9, 7): 94.74427032470703,\n"," (8, 8): 94.98773193359375,\n"," (11, 10): 95.5536117553711,\n"," (2, 9): 96.54518127441406,\n"," (2, 8): 96.63613891601562,\n"," (7, 8): 96.63919067382812,\n"," (2, 7): 96.65879821777344,\n"," (2, 5): 96.81787109375,\n"," (2, 3): 96.94779205322266}"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698865959235,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"172bd801-8fa0-40e9-83e1-8f18f5d5fdb4","id":"uJKt-0nLN7AR"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4) -72.31\n","(9, 1) -61.69\n","(7, 11) -14.43\n","(6, 10) -8.49\n","(0, 1) -7.64\n","(10, 7) -5.18\n","(8, 6) -4.99\n","(5, 0) -3.99\n","(8, 1) -3.44\n","(8, 9) -3.39\n","(9, 11) -2.75\n","(5, 6) -2.74\n","(6, 9) -2.63\n","(9, 7) -2.28\n","(8, 8) -2.04\n","(11, 10) -1.47\n","(2, 9) -0.48\n","(2, 8) -0.39\n","(7, 8) -0.38\n","(2, 7) -0.36\n","(2, 5) -0.21\n","(2, 3) -0.08\n"]}]},{"cell_type":"markdown","source":["## iter backw fwd, threshold 20"],"metadata":{"id":"lycKzLOVs_z9"}},{"cell_type":"code","source":["threshold = 20\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698889962648,"user_tz":240,"elapsed":483116,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"56464b2d-a15b-4faf-82d5-79274adbd194","id":"DrWgEhNFs_0F"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","99.81829833984375\n","\n","Removed: (11, 1)\n","99.77723693847656\n","\n","Removed: (11, 2)\n","100.00584411621094\n","\n","Removed: (11, 3)\n","99.71531677246094\n","\n","Removed: (11, 4)\n","100.09679412841797\n","\n","Removed: (11, 5)\n","100.15222930908203\n","\n","Removed: (11, 6)\n","101.34697723388672\n","\n","Removed: (11, 7)\n","101.33797454833984\n","\n","Removed: (11, 8)\n","98.46856689453125\n","\n","Removed: (11, 9)\n","98.4434814453125\n","\n","Removed: (11, 10)\n","96.54823303222656\n","\n","Removed: (11, 11)\n","96.78971862792969\n","\n","Removed: (10, 0)\n","96.77925109863281\n","\n","Removed: (10, 1)\n","97.79193115234375\n","\n","Removed: (10, 2)\n","98.43711853027344\n","\n","Removed: (10, 3)\n","98.9050064086914\n","\n","Removed: (10, 4)\n","99.03523254394531\n","\n","Removed: (10, 5)\n","98.84487915039062\n","\n","Removed: (10, 6)\n","98.0883560180664\n","\n","Removed: (10, 7)\n","93.26271057128906\n","\n","Removed: (10, 8)\n","93.51444244384766\n","\n","Removed: (10, 9)\n","93.46068572998047\n","\n","Removed: (10, 10)\n","92.99003601074219\n","\n","Removed: (10, 11)\n","93.23729705810547\n","\n","Removed: (9, 0)\n","93.25186920166016\n","\n","Removed: (9, 2)\n","92.9366683959961\n","\n","Removed: (9, 3)\n","92.23115539550781\n","\n","Removed: (9, 4)\n","92.2659912109375\n","\n","Removed: (9, 5)\n","91.7385482788086\n","\n","Removed: (9, 6)\n","91.48719024658203\n","\n","Removed: (9, 7)\n","89.68614959716797\n","\n","Removed: (9, 8)\n","89.67253112792969\n","\n","Removed: (9, 9)\n","89.17647552490234\n","\n","Removed: (9, 10)\n","89.12943267822266\n","\n","Removed: (9, 11)\n","87.1956558227539\n","\n","Removed: (8, 0)\n","88.36494445800781\n","\n","Removed: (8, 1)\n","86.51425170898438\n","\n","Removed: (8, 2)\n","86.12648010253906\n","\n","Removed: (8, 3)\n","85.67924499511719\n","\n","Removed: (8, 4)\n","85.6641845703125\n","\n","Removed: (8, 5)\n","85.6551284790039\n","\n","Removed: (8, 6)\n","80.76129150390625\n","\n","Removed: (8, 7)\n","80.79131317138672\n","\n","Removed: (8, 10)\n","81.94499969482422\n","\n","Removed: (8, 11)\n","82.00041961669922\n","\n","Removed: (7, 0)\n","82.39391326904297\n","\n","Removed: (7, 1)\n","82.36041259765625\n","\n","Removed: (7, 2)\n","81.96427154541016\n","\n","Removed: (7, 3)\n","82.02488708496094\n","\n","Removed: (7, 4)\n","82.0435791015625\n","\n","Removed: (7, 5)\n","81.52130126953125\n","\n","Removed: (7, 6)\n","80.47592163085938\n","\n","Removed: (7, 8)\n","80.12800598144531\n","\n","Removed: (7, 9)\n","80.15367126464844\n","\n","Removed: (7, 10)\n","80.4768295288086\n","\n","Removed: (6, 0)\n","80.0603256225586\n","\n","Removed: (6, 1)\n","80.2370376586914\n","\n","Removed: (6, 2)\n","80.19761657714844\n","\n","Removed: (6, 3)\n","80.14242553710938\n","\n","Removed: (6, 4)\n","80.058837890625\n","\n","Removed: (6, 5)\n","80.25361633300781\n","\n","Removed: (6, 7)\n","80.07858276367188\n","\n","Removed: (6, 8)\n","80.09918212890625\n","\n","Removed: (6, 11)\n","80.00590515136719\n","\n","Removed: (5, 2)\n","80.05277252197266\n","\n","Removed: (5, 5)\n","80.87420654296875\n","\n","Removed: (5, 7)\n","80.86872100830078\n","\n","Removed: (5, 8)\n","85.12238311767578\n","\n","Removed: (5, 9)\n","85.14610290527344\n","\n","Removed: (5, 10)\n","84.62877655029297\n","\n","Removed: (5, 11)\n","83.89703369140625\n","\n","Removed: (4, 0)\n","83.55741882324219\n","\n","Removed: (4, 1)\n","83.56339263916016\n","\n","Removed: (4, 2)\n","83.44432067871094\n","\n","Removed: (4, 3)\n","82.8915786743164\n","\n","Removed: (4, 5)\n","82.9041748046875\n","\n","Removed: (4, 6)\n","82.81397247314453\n","\n","Removed: (4, 7)\n","82.64771270751953\n","\n","Removed: (4, 8)\n","83.07672119140625\n","\n","Removed: (4, 9)\n","83.06954956054688\n","\n","Removed: (4, 10)\n","82.72938537597656\n","\n","Removed: (4, 11)\n","81.60745239257812\n","\n","Removed: (3, 0)\n","82.08474731445312\n","\n","Removed: (3, 1)\n","82.10531616210938\n","\n","Removed: (3, 2)\n","82.9670181274414\n","\n","Removed: (3, 3)\n","82.53992462158203\n","\n","Removed: (3, 4)\n","83.67379760742188\n","\n","Removed: (3, 5)\n","83.73133850097656\n","\n","Removed: (3, 6)\n","83.01022338867188\n","\n","Removed: (3, 7)\n","82.38104248046875\n","\n","Removed: (3, 8)\n","81.80024719238281\n","\n","Removed: (3, 9)\n","81.32850646972656\n","\n","Removed: (3, 10)\n","80.84830474853516\n","\n","Removed: (3, 11)\n","80.77293395996094\n","\n","Removed: (2, 0)\n","80.85124206542969\n","\n","Removed: (2, 1)\n","80.89108276367188\n","\n","Removed: (2, 3)\n","80.69588470458984\n","\n","Removed: (2, 4)\n","80.67989349365234\n","\n","Removed: (2, 5)\n","80.4645767211914\n","\n","Removed: (2, 6)\n","80.42129516601562\n","\n","Removed: (2, 7)\n","80.16873168945312\n","\n","Removed: (2, 8)\n","80.0088119506836\n","\n","Removed: (2, 10)\n","80.3616714477539\n","\n","Removed: (2, 11)\n","80.31006622314453\n","\n","Removed: (1, 1)\n","80.51734924316406\n","\n","Removed: (1, 2)\n","80.83193969726562\n","\n","Removed: (1, 3)\n","80.54833221435547\n","\n","Removed: (1, 4)\n","80.43030548095703\n","\n","Removed: (1, 5)\n","80.87605285644531\n","\n","Removed: (1, 6)\n","81.25692749023438\n","\n","Removed: (1, 7)\n","81.42386627197266\n","\n","Removed: (1, 8)\n","81.46475219726562\n","\n","Removed: (1, 9)\n","81.07868957519531\n","\n","Removed: (1, 10)\n","81.13765716552734\n","\n","Removed: (1, 11)\n","81.56059265136719\n","\n","Removed: (0, 0)\n","81.24693298339844\n","\n","Removed: (0, 2)\n","81.08755493164062\n","\n","Removed: (0, 3)\n","80.11866760253906\n","\n","Removed: (0, 4)\n","80.59432220458984\n","\n","Removed: (0, 6)\n","80.83451843261719\n","\n","Removed: (0, 7)\n","81.3188705444336\n","\n","Removed: (0, 8)\n","80.86360931396484\n","\n","Removed: (0, 10)\n","82.67503356933594\n","\n","Removed: (0, 11)\n","82.73494720458984\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 5)\n","81.8953628540039\n","\n","Removed: (0, 9)\n","81.21231079101562\n","\n","Removed: (1, 0)\n","80.37764739990234\n","\n","Removed: (5, 3)\n","80.01876831054688\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_20 = curr_circuit.copy()\n","bf_20"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698889962649,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"90b98e62-cf22-4f1b-8ea6-69025044c406","id":"sk-fR31Ls_0G"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (2, 2),\n"," (2, 9),\n"," (4, 4),\n"," (5, 0),\n"," (5, 1),\n"," (5, 4),\n"," (5, 6),\n"," (6, 6),\n"," (6, 9),\n"," (6, 10),\n"," (7, 7),\n"," (7, 11),\n"," (8, 8),\n"," (8, 9),\n"," (9, 1)]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["len(bf_20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698889962649,"user_tz":240,"elapsed":25,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ed865105-86a1-4457-8750-574e4e06a937","id":"KNcSuF9Ps_0G"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["### loop rmv and check for most impt heads"],"metadata":{"id":"TF7LbeOXs_0G"}},{"cell_type":"code","source":["circ = bf_20\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698889964899,"user_tz":240,"elapsed":2272,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b9a17be5-7dd0-446e-a0a2-27c77f715c0e","id":"6vy552Egs_0G"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 80.0188\n"]}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698890007517,"user_tz":240,"elapsed":42625,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bfb9fc2f-976c-4768-c0b7-b8b9ad2e9c71","id":"7qSojHsrs_0G"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 73.6033\n","removed: (2, 2)\n","Average logit difference (circuit / full) %: 78.1361\n","removed: (2, 9)\n","Average logit difference (circuit / full) %: 79.6444\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 20.8427\n","removed: (5, 0)\n","Average logit difference (circuit / full) %: 75.6994\n","removed: (5, 1)\n","Average logit difference (circuit / full) %: 79.5243\n","removed: (5, 4)\n","Average logit difference (circuit / full) %: 79.9790\n","removed: (5, 6)\n","Average logit difference (circuit / full) %: 77.3481\n","removed: (6, 6)\n","Average logit difference (circuit / full) %: 79.4478\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 77.0189\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 71.9496\n","removed: (7, 7)\n","Average logit difference (circuit / full) %: 78.5723\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 65.4579\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 76.9234\n","removed: (8, 9)\n","Average logit difference (circuit / full) %: 76.7907\n","removed: (9, 1)\n","Average logit difference (circuit / full) %: 21.0339\n"]}]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698890007518,"user_tz":240,"elapsed":23,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d517ae2b-01c0-4a3a-ef77-3867fb764bed","id":"bXsrBC_Ms_0H"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 20.842721939086914,\n"," (9, 1): 21.033855438232422,\n"," (7, 11): 65.4579086303711,\n"," (6, 10): 71.94964599609375,\n"," (0, 1): 73.60332489013672,\n"," (5, 0): 75.69940185546875,\n"," (8, 9): 76.79069519042969,\n"," (8, 8): 76.9233627319336,\n"," (6, 9): 77.0189208984375,\n"," (5, 6): 77.34809875488281,\n"," (2, 2): 78.13613891601562,\n"," (7, 7): 78.5722885131836,\n"," (6, 6): 79.44776916503906,\n"," (5, 1): 79.52426147460938,\n"," (2, 9): 79.64443969726562,\n"," (5, 4): 79.97897338867188}"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698890007518,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"08613989-e403-4b21-f839-fbf7003e60b5","id":"FhyzV4Yqs_0H"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4) -59.18\n","(9, 1) -58.98\n","(7, 11) -14.56\n","(6, 10) -8.07\n","(0, 1) -6.42\n","(5, 0) -4.32\n","(8, 9) -3.23\n","(8, 8) -3.1\n","(6, 9) -3.0\n","(5, 6) -2.67\n","(2, 2) -1.88\n","(7, 7) -1.45\n","(6, 6) -0.57\n","(5, 1) -0.49\n","(2, 9) -0.37\n","(5, 4) -0.04\n"]}]},{"cell_type":"markdown","source":["## try other tasks circs"],"metadata":{"id":"us1d5RRwN7AT"}},{"cell_type":"markdown","source":["### gt, IOI"],"metadata":{"id":"QZqbx0eNN7AT"}},{"cell_type":"code","source":["# greater-than\n","circuit = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867133143,"user_tz":240,"elapsed":2614,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7806b903-6e1b-4466-c5af-677d10c9745f","id":"vXU_R6dwN7AU"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 27.5909\n"]},{"output_type":"execute_result","data":{"text/plain":["27.590892791748047"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["# IOI\n","circuit = [(0, 1), (0, 10), (2, 2), (3, 0), (4, 11), (5, 5), (5, 8), (5, 9), (6, 9), (7, 3), (7, 9), (8, 6), (8, 10), (9, 0), (9, 6), (9, 7), (9, 9), (10, 0), (10, 1), (10, 2), (10, 6), (10, 7), (10, 10), (11, 2), (11, 9), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867152420,"user_tz":240,"elapsed":3376,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4910e12c-69a5-4043-b3c7-df306bee6bf1","id":"LVTf-5xWN7AU"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 4.3136\n"]},{"output_type":"execute_result","data":{"text/plain":["4.313619613647461"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","source":["### bf 80"],"metadata":{"id":"1Zg7b7gh0qT4"}},{"cell_type":"code","source":["# digits\n","circuit = [(0, 1), (0, 2), (0, 5), (0, 7), (0, 8), (0, 10), (1, 0), (1, 1), (1, 5), (1, 7), (1, 11), (2, 0), (2, 1), (2, 2), (2, 3), (2, 6), (2, 8), (2, 9), (2, 10), (2, 11), (3, 3), (3, 4), (3, 5), (3, 7), (3, 8), (3, 9), (3, 11), (4, 4), (4, 10), (5, 1), (5, 4), (5, 6), (5, 8), (5, 11), (6, 4), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (7, 11), (9, 1)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698890294279,"user_tz":240,"elapsed":2598,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"63bba60b-a9a8-4642-97ec-b67e7200042d","id":"6Z2ugGH00qT4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 69.7072\n"]},{"output_type":"execute_result","data":{"text/plain":["69.70720672607422"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# numwords\n","circuit = [(0, 1), (0, 9), (0, 10), (1, 5), (4, 4), (4, 7), (5, 6), (5, 8), (6, 1), (6, 6), (6, 10), (7, 5), (7, 6), (7, 10), (7, 11), (8, 7), (8, 8), (8, 10), (8, 11), (9, 1)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698890297223,"user_tz":240,"elapsed":2948,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"21844bee-7ab0-49c6-b77c-58d4a8eff164","id":"04ILHSBb0qT4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 70.6112\n"]},{"output_type":"execute_result","data":{"text/plain":["70.6111831665039"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["# months\n","circuit = [(0, 1), (2, 2), (2, 9), (4, 4), (5, 0), (5, 1), (5, 4), (5, 6), (6, 6), (6, 9), (6, 10), (7, 7), (7, 11), (8, 8), (8, 9), (9, 1)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698890317738,"user_tz":240,"elapsed":7440,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3509c0f7-a0d7-4d99-a6a0-4bbc3097d0da","id":"yOmeaD8T0qT4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 80.0188\n"]},{"output_type":"execute_result","data":{"text/plain":["80.01876831054688"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["### bf 97"],"metadata":{"id":"50eM-EzBN7AX"}},{"cell_type":"code","source":["# digits incr\n","# incorr i+3\n","circuit = [(0, 1), (0, 2), (0, 5), (0, 7), (0, 8), (0, 10), (1, 0), (1, 1), (1, 3), (1, 5), (1, 7), (1, 11), (2, 0), (2, 1), (2, 2), (2, 3), (2, 5), (2, 6), (2, 8), (2, 9), (2, 10), (3, 3), (3, 7), (3, 8), (3, 10), (3, 11), (4, 2), (4, 4), (4, 6), (4, 10), (4, 11), (5, 1), (5, 4), (5, 8), (5, 10), (5, 11), (6, 2), (6, 3), (6, 4), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (7, 11), (8, 6), (8, 8), (9, 1), (10, 7), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867158384,"user_tz":240,"elapsed":2303,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"32f07cb9-4daa-4b1b-dbe3-cfbb3ac32ec2","id":"DwwDm1_SN7AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 82.0537\n"]},{"output_type":"execute_result","data":{"text/plain":["82.05374145507812"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["# numwords\n","# incorr i+3\n","circuit = [(0, 1), (0, 6), (0, 7), (0, 9), (0, 10), (1, 0), (1, 5), (3, 3), (4, 4), (4, 10), (5, 4), (5, 6), (5, 8), (6, 6), (6, 10), (7, 6), (7, 10), (7, 11), (8, 8), (9, 1), (10, 7)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698867160977,"user_tz":240,"elapsed":2614,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"83f017fe-3da5-4d59-a1bf-2bb63e7cf8b8","id":"QWNHoRklN7AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 70.6149\n"]},{"output_type":"execute_result","data":{"text/plain":["70.61485290527344"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["# months\n","# incorr i\n","circuit = [(0, 1), (2, 3), (2, 5), (2, 7), (2, 8), (2, 9), (4, 4), (5, 0), (5, 6), (6, 9), (6, 10), (7, 8), (7, 11), (8, 1), (8, 6), (8, 8), (8, 9), (9, 1), (9, 7), (9, 11), (10, 7), (11, 10)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=True).item()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698867125134,"user_tz":240,"elapsed":2278,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"dWxR-ZVVN7AY","outputId":"f41689b6-41b5-476f-addf-9a6f4b3a408c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 96.5812\n"]},{"output_type":"execute_result","data":{"text/plain":["96.5811996459961"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","source":["# try incorr i+3 again"],"metadata":{"id":"UCsBj6jxUlnY"}},{"cell_type":"markdown","source":["## Generate dataset with multiple prompts"],"metadata":{"id":"cYwtu-K-UneI"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"lvqq7DttUneQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pos_dict = {\n","    'S1': 0,\n","    'S2': 1,\n","    'S3': 2,\n","    'S4': 3,\n","}"],"metadata":{"id":"dhkFFx2LUneR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        prompt_dict = {\n","            'S1': months[i],\n","            'S2': months[i+1],\n","            'S3': months[i+2],\n","            'S4': months[i+3],\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{months[i]} {months[i+1]} {months[i+2]} {months[i+2]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 11)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"1Tvj5HECUneR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n","    prompts_list = []\n","    # for i in range(x, y):\n","    for i in range(0, 8):\n","        r1 = random.choice(months)\n","        r2 = random.choice(months)\n","        while True:\n","            r3_ind = random.randint(0,len(months)-1)\n","            r4_ind = random.randint(0,len(months)-1)\n","            if months[r3_ind] != months[r4_ind-1]:\n","                break\n","        r3 = months[r3_ind]\n","        r4 = months[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': months[i+4],\n","            'incorr': months[i+3],\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(1, 11)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list_2"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698866322661,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a844a321-00ab-4967-e941-91e4af6bfd3b","id":"HIYRruzHUneR"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': 'June',\n","  'S2': 'December',\n","  'S3': 'April',\n","  'S4': 'November',\n","  'corr': 'May',\n","  'incorr': 'April',\n","  'text': 'June December April November'},\n"," {'S1': 'July',\n","  'S2': 'June',\n","  'S3': 'November',\n","  'S4': 'February',\n","  'corr': 'June',\n","  'incorr': 'May',\n","  'text': 'July June November February'},\n"," {'S1': 'February',\n","  'S2': 'October',\n","  'S3': 'September',\n","  'S4': 'July',\n","  'corr': 'July',\n","  'incorr': 'June',\n","  'text': 'February October September July'},\n"," {'S1': 'January',\n","  'S2': 'November',\n","  'S3': 'August',\n","  'S4': 'March',\n","  'corr': 'August',\n","  'incorr': 'July',\n","  'text': 'January November August March'},\n"," {'S1': 'January',\n","  'S2': 'December',\n","  'S3': 'March',\n","  'S4': 'August',\n","  'corr': 'September',\n","  'incorr': 'August',\n","  'text': 'January December March August'},\n"," {'S1': 'July',\n","  'S2': 'July',\n","  'S3': 'September',\n","  'S4': 'February',\n","  'corr': 'October',\n","  'incorr': 'September',\n","  'text': 'July July September February'},\n"," {'S1': 'July',\n","  'S2': 'October',\n","  'S3': 'January',\n","  'S4': 'July',\n","  'corr': 'November',\n","  'incorr': 'October',\n","  'text': 'July October January July'},\n"," {'S1': 'May',\n","  'S2': 'June',\n","  'S3': 'July',\n","  'S4': 'November',\n","  'corr': 'December',\n","  'incorr': 'November',\n","  'text': 'May June July November'}]"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["## Ablation Expm Functions"],"metadata":{"id":"EVxTYHXEUneS"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"-UlxBGiHUneS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"id":"F9AvkRfVUneS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, orig_score, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        # \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        # \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    # ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    # orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"vZmic9i9UneT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"eW51m3ZsUneT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, orig_score=100, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"Rig2XCKxUneT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## iter backw fwd, threshold 3"],"metadata":{"id":"n0h7PHSEUneT"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, orig_score=orig_score, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"error","timestamp":1698866464068,"user_tz":240,"elapsed":141412,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1aeaecbc-25af-48bc-9e51-8e1a1aa4ede3","id":"3X9ObWncUneU"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","187.2841339111328\n","\n","Removed: (11, 1)\n","186.7925262451172\n","\n","Removed: (11, 2)\n","186.4005126953125\n","\n","Removed: (11, 3)\n","186.14523315429688\n","\n","Removed: (11, 4)\n","186.22230529785156\n","\n","Removed: (11, 5)\n","186.20193481445312\n","\n","Removed: (11, 6)\n","183.9085235595703\n","\n","Removed: (11, 7)\n","184.41839599609375\n","\n","Removed: (11, 8)\n","181.02496337890625\n","\n","Removed: (11, 9)\n","180.13568115234375\n","\n","Removed: (11, 10)\n","178.2689666748047\n","\n","Removed: (11, 11)\n","179.22093200683594\n","\n","Removed: (10, 0)\n","179.03067016601562\n","\n","Removed: (10, 1)\n","179.2295684814453\n","\n","Removed: (10, 2)\n","175.9254150390625\n","\n","Removed: (10, 3)\n","173.44964599609375\n","\n","Removed: (10, 4)\n","173.47613525390625\n","\n","Removed: (10, 5)\n","173.3822021484375\n","\n","Removed: (10, 6)\n","173.35984802246094\n","\n","Removed: (10, 7)\n","177.2030487060547\n","\n","Removed: (10, 8)\n","177.2852783203125\n","\n","Removed: (10, 9)\n","177.1464385986328\n","\n","Removed: (10, 10)\n","176.1490020751953\n","\n","Removed: (10, 11)\n","176.11376953125\n","\n","Removed: (9, 0)\n","176.1731719970703\n","\n","Removed: (9, 1)\n","179.74916076660156\n","\n","Removed: (9, 2)\n","179.41571044921875\n","\n","Removed: (9, 3)\n","178.2351531982422\n","\n","Removed: (9, 4)\n","178.22581481933594\n","\n","Removed: (9, 5)\n","192.50941467285156\n","\n","Removed: (9, 6)\n","192.15103149414062\n","\n","Removed: (9, 7)\n","189.66514587402344\n","\n","Removed: (9, 8)\n","189.71932983398438\n","\n","Removed: (9, 9)\n","186.24066162109375\n","\n","Removed: (9, 10)\n","186.14337158203125\n","\n","Removed: (9, 11)\n","181.2935028076172\n","\n","Removed: (8, 0)\n","183.14523315429688\n","\n","Removed: (8, 1)\n","174.85647583007812\n","\n","Removed: (8, 2)\n","174.5783233642578\n","\n","Removed: (8, 3)\n","174.2814178466797\n","\n","Removed: (8, 4)\n","174.2689971923828\n","\n","Removed: (8, 5)\n","174.23858642578125\n","\n","Removed: (8, 6)\n","167.22935485839844\n","\n","Removed: (8, 7)\n","167.0890655517578\n","\n","Removed: (8, 8)\n","158.5823516845703\n","\n","Removed: (8, 9)\n","155.63206481933594\n","\n","Removed: (8, 10)\n","159.5412139892578\n","\n","Removed: (8, 11)\n","136.0602264404297\n","\n","Removed: (7, 0)\n","136.0953369140625\n","\n","Removed: (7, 1)\n","135.97268676757812\n","\n","Removed: (7, 2)\n","134.2304229736328\n","\n","Removed: (7, 3)\n","135.75765991210938\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-d1b782a87c4c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# prev_score = new_score # save old score before finding new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mold_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save old before finding new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcurr_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_circuit_backw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_circuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurr_circuit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mold_circuit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-e0ef3a87cd53>\u001b[0m in \u001b[0;36mfind_circuit_backw\u001b[0;34m(curr_circuit, orig_score, threshold)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcopy_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_ablate_by_lst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# If the result is less than the threshold, remove the tuple from the original list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-67-9d6e9137c5d5>\u001b[0m in \u001b[0;36mmean_ablate_by_lst\u001b[0;34m(lst, model, orig_score, print_output)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_circuit_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mean_ablation_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mioi_logits_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36madd_mean_ablation_hook\u001b[0;34m(model, means_dataset, circuit, seq_pos_to_keep, is_permanent)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# Compute the mean of each head's output on the ABC dataset, grouped by template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_means_by_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Convert this into a boolean map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mcompute_means_by_template\u001b[0;34m(means_dataset, model)\u001b[0m\n\u001b[1;32m    123\u001b[0m     '''\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Cache the outputs of every head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     _, means_cache = model.run_with_cache(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mHookedRootModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m--> 630\u001b[0;31m         out, cache_dict = super().run_with_cache(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_batch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mrun_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mclear_contexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_contexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         ):\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincl_bwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mmodel_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;31m# Eg: start_at_layer==None + stop_at_layer==0 means to only run the embed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# Eg: start_at_layer==3 + stop_at_layer==-1 means to run from layer 3 until the end of the PENULTIMATE layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mblocks_and_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks_and_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_at_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop_at_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;31m# Note that each block includes skip connections, so we don't need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"id":"2gT3PhdmUneU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"id":"vKbg8wJRUneU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## loop rmv and check for most impt heads"],"metadata":{"id":"WlWlM4D_UneU"}},{"cell_type":"code","source":["circ = bf_3\n","circ_score = mean_ablate_by_lst(circ, model, orig_score, print_output=True).item()"],"metadata":{"id":"ZdbmU4nsUnea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"id":"rEa8EhGZUnea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sorted_lh_scores = dict(sorted(lh_scores.items(), key=lambda item: item[1]))\n","sorted_lh_scores"],"metadata":{"id":"e8Qbb5PqUnea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for lh, score in sorted_lh_scores.items():\n","    print(lh, -round(circ_score-score, 2))"],"metadata":{"id":"h2Y8-x3WUneb"},"execution_count":null,"outputs":[]}]}