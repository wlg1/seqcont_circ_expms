{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DcZG9rm2IAiA","OLkInsdjyHMx","DQF0lzuokQer","cGX9iHAz_UKX","GyMsBAOg5kEj","7Hl3NU_i29Sa"],"gpuType":"T4","authorship_tag":"ABX9TyNh2Dltim5u46zTLPojk0DM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"b13177b7"},"source":["<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698871058416,"user_tz":240,"elapsed":123110,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a5c5e5d0-bf25-4a7e-b20c-6f995a104506"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-d7qmvrxp\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-d7qmvrxp\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit fa287750606075574df2c538058e67d648e2f952\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate>=0.23.0 (from transformer-lens==0.0.0)\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n","Collecting numpy>=1.24 (from transformer-lens==0.0.0)\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cublas_cu12-12.3.2.9-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (24.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cudnn_cu12-8.9.5.30-py3-none-manylinux1_x86_64.whl (701.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.6/701.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cufft_cu12-11.0.11.19-py3-none-manylinux1_x86_64.whl (98.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_curand_cu12-10.3.4.52-py3-none-manylinux1_x86_64.whl (56.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusolver_cu12-11.5.3.52-py3-none-manylinux1_x86_64.whl (125.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusparse_cu12-12.1.3.153-py3-none-manylinux1_x86_64.whl (195.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nvtx_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.6)\n","Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens==0.0.0)\n","  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.33.1-py2.py3-none-any.whl (243 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=116436 sha256=303c258b4ff833ed9eeb722f1ee890c64ad784434a6e8fcdd12952925d99a48c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7av1r6eo/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=b937a93f4250f3fd475bb732a5c8dcf0e89d3611cd5a82bcd382fcf3b9058f90\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, huggingface-hub, gitdb, tokenizers, nvidia-cusolver-cu12, GitPython, accelerate, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.24.1 beartype-0.14.1 datasets-2.14.6 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 huggingface-hub-0.17.3 jaxtyping-0.2.23 multiprocess-0.70.15 numpy-1.26.1 nvidia-cublas-cu12-12.3.2.9 nvidia-cuda-cupti-cu12-12.3.52 nvidia-cuda-nvrtc-cu12-12.3.52 nvidia-cuda-runtime-cu12-12.3.52 nvidia-cudnn-cu12-8.9.5.30 nvidia-cufft-cu12-11.0.11.19 nvidia-curand-cu12-10.3.4.52 nvidia-cusolver-cu12-11.5.3.52 nvidia-cusparse-cu12-12.1.3.153 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.3.52 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.33.1 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.34.1 typeguard-2.13.3 wandb-0.15.12\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1698871058417,"user_tz":240,"elapsed":196,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","import plotly.io as pio\n","\n","if IN_COLAB or not DEBUG_MODE:\n","    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","    pio.renderers.default = \"colab\"\n","else:\n","    pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6b1n2tvIAiD"},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuhzYxbsIAiE"},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFMTUcQiIAiF"},"outputs":[],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFs9BrbzIAiH"},"outputs":[],"source":["def imshow(tensor, renderer=None, **kwargs):\n","    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","def line(tensor, renderer=None, **kwargs):\n","    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","    x = utils.to_numpy(x)\n","    y = utils.to_numpy(y)\n","    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"markdown","source":["Decide which model to use (eg. gpt2-small vs -medium)"],"metadata":{"id":"ssJgoKr2yI8O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLwDyosvIAiJ"},"outputs":[],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"id":"Fdh5--MfYw7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"id":"iZ4C_bsXZFfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# test prompts"],"metadata":{"id":"DQF0lzuokQer"}},{"cell_type":"code","source":["# modeltest = HookedTransformer.from_pretrained(\"gpt2-small\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FW7ZRS0wtqs4","executionInfo":{"status":"ok","timestamp":1698588583907,"user_tz":240,"elapsed":11963,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"318c5bcf-71dc-42c4-d051-ae4f64112871"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}]},{"cell_type":"code","source":["# example_prompt = \"The war lasted from the year 1750 to the year 17\"\n","# example_answer = \" 51\"\n","# utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"OQpqlEjwED7b","executionInfo":{"status":"ok","timestamp":1698588637916,"user_tz":240,"elapsed":451,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bb2070a6-f0c3-4e25-ce0c-ba83599418ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'The', ' war', ' lasted', ' from', ' the', ' year', ' 17', '50', ' to', ' the', ' year', ' 17']\n","Tokenized answer: [' 51']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m1096\u001b[0m\u001b[1m     Logit: \u001b[0m\u001b[1;36m11.83\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m51\u001b[0m\u001b[1m|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1096</span><span style=\"font-weight: bold\">     Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.83</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"font-weight: bold\">|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 30.08 Prob: 26.90% Token: |60|\n","Top 1th token. Logit: 29.10 Prob: 10.12% Token: |75|\n","Top 2th token. Logit: 29.02 Prob:  9.33% Token: |70|\n","Top 3th token. Logit: 28.62 Prob:  6.29% Token: |90|\n","Top 4th token. Logit: 28.43 Prob:  5.19% Token: |80|\n","Top 5th token. Logit: 28.28 Prob:  4.45% Token: |50|\n","Top 6th token. Logit: 27.82 Prob:  2.83% Token: |55|\n","Top 7th token. Logit: 27.41 Prob:  1.87% Token: |65|\n","Top 8th token. Logit: 27.34 Prob:  1.75% Token: |76|\n","Top 9th token. Logit: 27.17 Prob:  1.47% Token: |71|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 51'\u001b[0m, \u001b[1;36m1096\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 51'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1096</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"markdown","source":["greater-than paper, p2: use 10k examples of \"The <noun> lasted from the year XXYY to the year XX”\"\n","\n","120 random nouns, years from 1000 to 1899 where YY in {2...98} inclusive\n","\n","Here, we use the same noun (war), and the same prefix XX (17), so there are 97 examples. If we start at 11 to avoid front '0' if single digit, it's 98-11+1 = 88 examples\n","\n","Thus our 01-corruption only needs 1 sample"],"metadata":{"id":"r9OqqrAyXnV8"}},{"cell_type":"code","source":["def get_prompts_pos_dicts(input_text, YY):\n","    pos_dict = {}\n","    prompt_dict = {}\n","    tokens_list = model.tokenizer(input_text)['input_ids']\n","\n","    for index, token in enumerate(tokens_list):\n","        token_as_string = model.tokenizer.decode(token)\n","        if token_as_string == str(YY):\n","            key = 'YY'\n","        else:\n","            key = 'T'+str(index)\n","        # key = 'T'+str(index)\n","        pos_dict[key] = index\n","        prompt_dict[key] = token_as_string\n","    prompt_dict['text'] = input_text\n","\n","    return pos_dict, prompt_dict"],"metadata":{"id":"DLmqcJXklmWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, YY_int_list):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","\n","        # list of YY as int for each prompt\n","        self.YY_int_list = YY_int_list\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x, y):\n","    prompts_list = []\n","    for YY in range(x, y):\n","        input_text = f'The war lasted from the year 17{YY} to the year 17'\n","        pos_dict, prompt_dict = get_prompts_pos_dicts(input_text, YY)\n","        prompts_list.append(prompt_dict)\n","    return pos_dict, prompts_list\n","\n","# pos_dict, prompts_list = generate_prompts_list(45, 55)\n","pos_dict, prompts_list = generate_prompts_list(10, 90)\n","YY_int_list = [i for i in range(10, 90)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)"],"metadata":{"id":"u0NPSKcZ1iDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_corr(x, y):\n","    prompts_list = []\n","    # for i in range(x, y):\n","    YY = '01'\n","    input_text = f'The war lasted from the year 17{YY} to the year 17'\n","    pos_dict, prompt_dict = get_prompts_pos_dicts(input_text, YY)\n","    prompts_list.append(prompt_dict)\n","    return pos_dict, prompts_list\n","\n","# prompts_list = generate_prompts_list(45, 55)\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(10, 90)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)"],"metadata":{"id":"ViiKAFwBvmEG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"GCCCoO0V7L7J"}},{"cell_type":"code","source":["# obtain the logits of each number between YY and 99, where YY is a two digit integer\n","\n","import torch\n","\n","def get_logits_for_range(logits, start_num, end_num):\n","    \"\"\"\n","    :param logits: The logits tensor with dimensions [batch size, seq len, vocab size]\n","    :param start_num: The starting number\n","    :param end_num: The ending number\n","    :return: A tensor containing logits for numbers between start_num and end_num\n","    \"\"\"\n","    # Getting indices for numbers between start_num and end_num\n","    indices = []\n","    for num in range(start_num, end_num+1):\n","        num_as_vocabID = model.tokenizer(str(num))['input_ids'][0]\n","        indices.append(num_as_vocabID)\n","\n","    # Extract logits for these indices\n","    # logits_for_range = logits[:, logits.size(1)-1, indices]\n","    logits_for_range = logits[logits.size(0)-1, indices]\n","\n","    return logits_for_range"],"metadata":{"id":"tD_ZaBNug7l1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Each sample in the batch has a different indices due to having a different YY."],"metadata":{"id":"4gtEfPyPmjjR"}},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","ioi_logits_original.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8nvUWnGoGvI","executionInfo":{"status":"ok","timestamp":1698798382772,"user_tz":240,"elapsed":4680,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9aec44b6-2eb4-4d97-c5b2-b738ef73fa56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([87, 12, 50257])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["ioi_logits_original.size(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5jB8r2MrAyt","executionInfo":{"status":"ok","timestamp":1698798382772,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"47fc461f-f753-429b-a08d-0da84da8d757"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["87"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["ioi_logits_original[0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ct5JcM-7oOz6","executionInfo":{"status":"ok","timestamp":1698798382772,"user_tz":240,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9f31fb7e-e5ae-40a4-e2fc-1c41ed80a3eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 50257])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["YY = dataset.YY_int_list[0]"],"metadata":{"id":"r1eCZMi6ppqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ioi_logits_original[0, :, :].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHoHhFJbr4AZ","executionInfo":{"status":"ok","timestamp":1698798382772,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8ec9d929-f2d6-4e56-b689-242cf2238875"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 50257])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["logits_greaterThan = get_logits_for_range(ioi_logits_original[0, :, :], YY, 99)\n","logits_greaterThan.size() # output size is 1 dim tensor with size number of tokens between YY and 99 inclusive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWkCw9CAp1xJ","executionInfo":{"status":"ok","timestamp":1698798382773,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"694bd4c6-6adf-461a-9ab8-f4f0cdd5d744"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([89])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["sum(logits_greaterThan)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdWAL-HysXQ3","executionInfo":{"status":"ok","timestamp":1698798382773,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7f3ba90e-4119-457e-b483-6687fe7156ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2033.8448, device='cuda:0')"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[" answer_logit_perSamp = []\n"," answer_logit_perSamp.append(sum(logits_greaterThan).item())\n"," sum(answer_logit_perSamp)/len(answer_logit_perSamp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IPTE8tRszlH","executionInfo":{"status":"ok","timestamp":1698798382773,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b323bdac-167d-48aa-ed8d-d34e48347ea8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2033.8448486328125"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Get the right logits; anything greater than YY\n","    # range(logits.size(0)) for every input in the batch\n","    # dataset.word_idx[\"end\"]: at the last pos, so \"what's the next prediction after end?\"\n","    # what's the logit of the YY token (whose pos at an input seq is recorded in the dataset by dataset.YY_tokenIDs)\n","    # only correct dataset indices of corr and incorr tokens matters\n","\n","    # we need to measure the greaterThan and lessThan differently for each prompt\n","    answer_logit_perSamp = []\n","    for samp_id in range(logits.size(0)):\n","        YY = dataset.YY_int_list[samp_id]\n","\n","        logits_greaterThan = get_logits_for_range(logits[samp_id, :, :], YY, 99)\n","        # logits_greaterThan_sum = logits_greaterThan.sum(dim=1)\n","        logits_greaterThan_sum = sum(logits_greaterThan)\n","\n","        # get the wrong logits; anything less than YY\n","        logits_lessThan = get_logits_for_range(logits[samp_id, :, :], 00, YY-1)\n","        # logits_lessThan_sum = logits_lessThan.sum(dim=1)\n","        logits_lessThan_sum = sum(logits_lessThan)\n","\n","        # Find logit difference of corr minus incorr; sum up all tokens between YY and 99, minus sum of all YY and 00\n","        GL_diff = logits_greaterThan_sum - logits_lessThan_sum\n","        answer_logit_perSamp.append(GL_diff.item())\n","\n","    return answer_logit_perSamp if per_prompt else sum(answer_logit_perSamp)/len(answer_logit_perSamp)"],"metadata":{"id":"CgD41x5nbKKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","orig_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMXEXSrzvkAv","executionInfo":{"status":"ok","timestamp":1698798383465,"user_tz":240,"elapsed":701,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3411ad2a-254a-4b85-ab4a-98fd539cfec2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["94.07917592717313"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["CIRCUIT = {}\n","SEQ_POS_TO_KEEP = {}\n","lst =  [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","for ind, key in enumerate(pos_dict.keys()):\n","    headName = \"head\" + str(ind)\n","    CIRCUIT[headName] = lst\n","    SEQ_POS_TO_KEEP[headName] = key"],"metadata":{"id":"LUuSTJqbv5SM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)"],"metadata":{"id":"IwolLBSqvwHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SoKvXekwAeW","executionInfo":{"status":"ok","timestamp":1698798384571,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9b78bffa-11e6-4a1d-87ed-0e549ce01345"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["38.141064874057115"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, print_output=True):\n","    # CIRCUIT = {\n","    #     \"number mover\": lst,\n","    #     \"number mover 2\": lst,\n","    # }\n","\n","    # SEQ_POS_TO_KEEP = {\n","    #     \"number mover\": \"end\",\n","    #     \"number mover 2\": \"YY\",\n","    # }\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","\n","    for ind, key in enumerate(pos_dict.keys()):\n","        headName = \"head\" + str(ind)\n","        CIRCUIT[headName] = lst\n","        SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return (100 * new_score / orig_score)"],"metadata":{"id":"LqsdFmbVMntG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# try other tasks circs"],"metadata":{"id":"dC4VKp97r1-e"}},{"cell_type":"code","source":["# fb 80, digits incr\n","# https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\n","circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","mean_ablate_by_lst(circuit, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgvJ4VYB5F2s","executionInfo":{"status":"ok","timestamp":1698798628230,"user_tz":240,"elapsed":2164,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cac80809-29e5-4e7a-c35d-8f8fa79351f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 64.1249\n"]},{"output_type":"execute_result","data":{"text/plain":["64.12491445516194"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# fb 80, numwords\n","# https://colab.research.google.com/drive/1QTv-4osLHadCAay0beew-xlXszPCG88s#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","circuit = [(3, 2), (4, 4), (4, 8), (4, 10), (4, 11), (5, 5), (5, 6), (5, 7), (5, 8), (6, 1), (6, 7), (6, 9), (6, 10), (7, 0), (7, 2), (7, 5), (7, 6), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 11), (9, 1), (10, 2)]\n","mean_ablate_by_lst(circuit, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-DO40-mr6N1","executionInfo":{"status":"ok","timestamp":1698798630293,"user_tz":240,"elapsed":2088,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6644e326-9866-411e-9c83-b74c3df4392c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 81.7744\n"]},{"output_type":"execute_result","data":{"text/plain":["81.77439646862463"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# fb 80, months\n","# https://colab.research.google.com/drive/1lhQqlizYGMC11vzp6I9mJ3dyxIr8tV3l#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","circuit = [(4, 4), (7, 11), (8, 6), (8, 9), (8, 11), (9, 1), (9, 5), (11, 10)]\n","mean_ablate_by_lst(circuit, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hFkNI31osLHI","executionInfo":{"status":"ok","timestamp":1698798633893,"user_tz":240,"elapsed":3615,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f3449a0d-6163-48fc-b5fe-b28b4d656048"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 48.0494\n"]},{"output_type":"execute_result","data":{"text/plain":["48.049414541567856"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# greater-than\n","circuit = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","mean_ablate_by_lst(circuit, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZffKcon6IOI","executionInfo":{"status":"ok","timestamp":1698798638187,"user_tz":240,"elapsed":4316,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1dd3f569-678c-43ad-cb07-12c2e13a35ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.3844\n"]},{"output_type":"execute_result","data":{"text/plain":["85.38436010989578"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["# IOI\n","circuit = [(0, 1), (0, 10), (2, 2), (3, 0), (4, 11), (5, 5), (5, 8), (5, 9), (6, 9), (7, 3), (7, 9), (8, 6), (8, 10), (9, 0), (9, 6), (9, 7), (9, 9), (10, 0), (10, 1), (10, 2), (10, 6), (10, 7), (10, 10), (11, 2), (11, 9), (11, 10)]\n","mean_ablate_by_lst(circuit, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyVcwmUksWoO","executionInfo":{"status":"ok","timestamp":1698798640368,"user_tz":240,"elapsed":2204,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"652cd74e-f3f7-4c79-a6b5-2db00d9cc157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 28.5169\n"]},{"output_type":"execute_result","data":{"text/plain":["28.51689814059981"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["# Ablate the model tests"],"metadata":{"id":"Lk3bffnCYq-p"}},{"cell_type":"markdown","source":["Check on original 1 sample instead to check it has same score (it must have, else error)"],"metadata":{"id":"HSRMHUg3wc7y"}},{"cell_type":"code","source":["pos_dict, prompts_list = generate_prompts_list(50, 51)\n","YY_int_list = [i for i in range(50, 51)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(50, 51)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]"],"metadata":{"id":"uHd7U8MxxfCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","orig_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxAk-OFWw9S1","executionInfo":{"status":"ok","timestamp":1698605336057,"user_tz":240,"elapsed":204,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1d392cff-1413-42f6-aaab-ac80f7b25cf3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["303.3883056640625"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)"],"metadata":{"id":"UM226tx1w5M-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emqdE-k8w63p","executionInfo":{"status":"ok","timestamp":1698605282826,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fee502d1-e3b7-4ae5-ae27-e75a6a9ef097"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["258.4454345703125"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["(100 * new_score / orig_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfeAFTMqxKNV","executionInfo":{"status":"ok","timestamp":1698605356043,"user_tz":240,"elapsed":356,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d5805315-1238-4554-ffa3-1722b4a69563"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["85.18635350977746"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"id":"HS2ONKTgwM2G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698605386505,"user_tz":240,"elapsed":2121,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"badec8f2-78c1-45ce-fc36-f96077ee439b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.1864\n"]}]},{"cell_type":"markdown","source":["## check on 45 to 55"],"metadata":{"id":"BqJ4bicSxppo"}},{"cell_type":"code","source":["pos_dict, prompts_list = generate_prompts_list(45, 55)\n","YY_int_list = [i for i in range(45, 55)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(45, 55)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXsmE7oVxrpI","executionInfo":{"status":"ok","timestamp":1698605498027,"user_tz":240,"elapsed":2125,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3899d5e4-bafd-4fbd-d991-30c6db233c44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 90.6458\n"]}]},{"cell_type":"markdown","source":["## check on 11 to 98"],"metadata":{"id":"qfT05MIJxz0f"}},{"cell_type":"code","source":["x, y = 11, 98\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzZfVWHfx1Xj","executionInfo":{"status":"ok","timestamp":1698605575510,"user_tz":240,"elapsed":7104,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"89371feb-6e78-4922-f971-1e32cc6f45cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 40.5413\n"]}]},{"cell_type":"markdown","source":["## check on 11 to 90"],"metadata":{"id":"Z3IwDdxDyMTY"}},{"cell_type":"code","source":["x, y = 11, 90\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698605639418,"user_tz":240,"elapsed":6073,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7c7c6426-2511-49ce-b463-dd8b50a0cc8f","id":"pdwucxHEyMTh"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 84.0732\n"]}]},{"cell_type":"code","source":["x, y = 11, 97\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhkVgVJ8yTy3","executionInfo":{"status":"ok","timestamp":1698605655642,"user_tz":240,"elapsed":6183,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3afe89be-5e21-4cfd-ed11-d7b2a9b382cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 53.3356\n"]}]},{"cell_type":"code","source":["x, y = 11, 93\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwbhuQAVyXOj","executionInfo":{"status":"ok","timestamp":1698605669029,"user_tz":240,"elapsed":4379,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"178a06ab-afea-4910-c433-ebd676df5da8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 76.6722\n"]}]},{"cell_type":"code","source":["x, y = 11, 91\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhSQ8XRYycku","executionInfo":{"status":"ok","timestamp":1698605690287,"user_tz":240,"elapsed":4889,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e4851aa8-90ae-4f97-c43d-ec5e36c08faa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 82.1590\n"]}]},{"cell_type":"code","source":["x, y = 11, 80\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1JgJxBFqygV6","executionInfo":{"status":"ok","timestamp":1698605707066,"user_tz":240,"elapsed":3228,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e0e2f384-b22d-4170-acf5-21bc105366cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 94.5349\n"]}]},{"cell_type":"code","source":["x, y = 11, 89\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLXdlbsiyj8F","executionInfo":{"status":"ok","timestamp":1698605720464,"user_tz":240,"elapsed":5369,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e9ad88b7-0c50-4843-e23d-ee47d83b056b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.8438\n"]}]},{"cell_type":"code","source":["x, y = 11, 85\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpdI732aynLK","executionInfo":{"status":"ok","timestamp":1698605731528,"user_tz":240,"elapsed":3152,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8b855fb4-3c9e-4536-8b86-01b4afbe0612"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 91.1493\n"]}]},{"cell_type":"code","source":["x, y = 11, 70\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTWXHDe8yrg4","executionInfo":{"status":"ok","timestamp":1698605751796,"user_tz":240,"elapsed":5384,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2c863368-684d-4e31-d57a-ac2303391db4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 98.9650\n"]}]},{"cell_type":"code","source":["x, y = 11, 60\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KPemL4CyvLh","executionInfo":{"status":"ok","timestamp":1698605764400,"user_tz":240,"elapsed":2866,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"51f35959-ddc6-4eb2-8126-05ae32a908cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 101.2740\n"]}]},{"cell_type":"code","source":["x, y = 10, 90\n","pos_dict, prompts_list = generate_prompts_list(x, y)\n","YY_int_list = [i for i in range(x, y)]\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, YY_int_list)\n","\n","pos_dict, prompts_list_2 = generate_prompts_list_corr(x, y)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, YY_int_list)\n","\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THSIaYGyzWXt","executionInfo":{"status":"ok","timestamp":1698605937673,"user_tz":240,"elapsed":5227,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d698f9a3-6075-4162-841e-ea512777e704"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.3843\n"]}]},{"cell_type":"markdown","source":["So the closer y is to the end, the worse this gets, due to the inequality between less than and greater than. To avoid skewing the data either way, stick with 10 to 90"],"metadata":{"id":"-yUXpw09yyTp"}},{"cell_type":"code","source":["dataset.N"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cKzsetdzL0E","executionInfo":{"status":"ok","timestamp":1698605959121,"user_tz":240,"elapsed":272,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ec22a611-df8e-4ea2-ccc1-3a47e56868d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["80"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","source":["## Test Greater-Than vs other circuits"],"metadata":{"id":"GyMsBAOg5kEj"}},{"cell_type":"markdown","source":["See how greater-than circuit performs on the greater-than task; it should be similar to the paper. Else, either greater-than paper has issues (less likely) or this mean ablation code/setup was not generalized correctly (more likely)."],"metadata":{"id":"Y1JSjFGW4sSw"}},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)\n","new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBXAXcFN_UxT","executionInfo":{"status":"ok","timestamp":1698605968673,"user_tz":240,"elapsed":2772,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"88deaa60-ca84-4952-a68b-cffab1bfec37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.3843\n"]},{"output_type":"execute_result","data":{"text/plain":["85.38428847602803"]},"metadata":{},"execution_count":94}]},{"cell_type":"markdown","source":["## sanity check tests"],"metadata":{"id":"49nxie05eRMF"}},{"cell_type":"code","source":["greater_than = []\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sy7MVh7jkpND","executionInfo":{"status":"ok","timestamp":1698605970403,"user_tz":240,"elapsed":1734,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ad48dfef-17c1-421d-e849-2b2d8206acb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 15.7910\n"]}]},{"cell_type":"markdown","source":["Likely still has score due to MLPs"],"metadata":{"id":"KmMRkLIc204W"}},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (9,1)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMcTXbkveQeD","executionInfo":{"status":"ok","timestamp":1698605972146,"user_tz":240,"elapsed":1750,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dae6a93e-53e7-455f-b441-f283501677eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 40.9717\n"]}]},{"cell_type":"code","source":["greater_than = [(layer, head) for layer in range(12) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0iD62A1k2Gtf","executionInfo":{"status":"ok","timestamp":1698605975320,"user_tz":240,"elapsed":3180,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"64783e3a-6704-4b1c-ca23-11c7114a11a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 100.0000\n"]}]},{"cell_type":"code","source":["import random\n","num_of_tuples = 9  # Number of tuples you want\n","greater_than = [(random.randint(0, 9), random.randint(0, 9)) for _ in range(num_of_tuples)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsxdwJCEyCs5","executionInfo":{"status":"ok","timestamp":1698605975321,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5f9d9239-d013-4c0b-8289-33f7f239740f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 15.4973\n"]}]},{"cell_type":"markdown","source":["### add heads to orig paper circ"],"metadata":{"id":"7Hl3NU_i29Sa"}},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(10, 7)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52p8CGbg2_h3","executionInfo":{"status":"ok","timestamp":1698605977055,"user_tz":240,"elapsed":1741,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2ca14401-fded-48fe-e391-c64559b81d0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.3383\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqonWDSj3yby","executionInfo":{"status":"ok","timestamp":1698605978814,"user_tz":240,"elapsed":1765,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4cbdb3cb-e879-454c-e6c8-75fa41eb1316"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.3843\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0, 4) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjyqSN0p361x","executionInfo":{"status":"ok","timestamp":1698605981394,"user_tz":240,"elapsed":2585,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5c83e191-876c-4f1c-c5dd-220336fa8e29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 81.8693\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0, 6) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6AGUcI73_8u","executionInfo":{"status":"ok","timestamp":1698605984881,"user_tz":240,"elapsed":3492,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b490cde7-3e73-4fb6-8720-56ee787dcffb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 85.6789\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(0, 9) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdKTtmOO4EHQ","executionInfo":{"status":"ok","timestamp":1698605986377,"user_tz":240,"elapsed":1502,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"19cfac64-3a3b-4eb2-d3c6-c67152df9fdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 91.4473\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(8, 9) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4M-CxPxP4IJf","executionInfo":{"status":"ok","timestamp":1698605988371,"user_tz":240,"elapsed":1999,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fe8c3909-bf6d-4386-9ce1-10f35a3bc8e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 90.2036\n"]}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9,1)] + [(layer, head) for layer in range(5, 9) for head in range(12)]\n","new_score = mean_ablate_by_lst(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBM_g-Eu4NZf","executionInfo":{"status":"ok","timestamp":1698605990096,"user_tz":240,"elapsed":1734,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d4827062-bfcb-406d-c7f1-b22c968e17ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 94.2599\n"]}]},{"cell_type":"markdown","source":["# Ablate by seq pos"],"metadata":{"id":"o7d6V0Cz5hV3"}},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    for ind, key in enumerate([\"YY\", \"end\"]):\n","        headName = \"head\" + str(ind)\n","        CIRCUIT[headName] = lst\n","        SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"_4hXcIcZ5jOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxYqvBnr5vIr","executionInfo":{"status":"ok","timestamp":1698600319805,"user_tz":240,"elapsed":2558,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dbf0e188-78e4-4d7e-b396-4ed9521a21db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 90.9373\n"]}]},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"end\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)],\n","        \"YY\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9)],\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"end\": \"end\",\n","        \"YY\": \"YY\",\n","    }\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","\n","    # # for ind, key in enumerate(pos_dict.keys()):\n","    # # ind = 7\n","    # # key = \"T7\"\n","\n","    # for ind, key in enumerate([\"T7\", \"end\"]):\n","    #     headName = \"head\" + str(ind)\n","    #     CIRCUIT[headName] = lst\n","    #     SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"nFwZO0nq6J94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698600335507,"user_tz":240,"elapsed":2247,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5ce86565-d3a0-42f9-a8dc-7a1541944021","id":"sWYJpyBB6J95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 91.0982\n"]}]},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"end\": [(9, 1)],\n","        \"YY\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11)],\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"end\": \"end\",\n","        \"YY\": \"YY\",\n","    }\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","\n","    # # for ind, key in enumerate(pos_dict.keys()):\n","    # # ind = 7\n","    # # key = \"T7\"\n","\n","    # for ind, key in enumerate([\"T7\", \"end\"]):\n","    #     headName = \"head\" + str(ind)\n","    #     CIRCUIT[headName] = lst\n","    #     SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"CffrMRgt6klD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698600345718,"user_tz":240,"elapsed":1264,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"60b24127-34be-4475-f80d-0aeeb1fb5f8f","id":"OO0m6DkS6klE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 36.1281\n"]}]},{"cell_type":"code","source":["def mean_ablate_by_seqpos(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"end\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)],\n","        # \"YY\": [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11)],\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"end\": \"end\",\n","        # \"YY\": \"T7\",\n","    }\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","\n","    # # for ind, key in enumerate(pos_dict.keys()):\n","    # # ind = 7\n","    # # key = \"T7\"\n","\n","    # for ind, key in enumerate([\"T7\", \"end\"]):\n","    #     headName = \"head\" + str(ind)\n","    #     CIRCUIT[headName] = lst\n","    #     SEQ_POS_TO_KEEP[headName] = key\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)  # make sure text in clean vs corr have same num tokens for each prompt\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    return new_score"],"metadata":{"id":"pQ-PxR5663gS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","new_score = mean_ablate_by_seqpos(greater_than, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698600352178,"user_tz":240,"elapsed":1058,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5980c2fe-b5e0-4e30-d8f3-c6dea163f9f3","id":"SMkzD9rd63gg"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 82.2822\n"]}]},{"cell_type":"markdown","source":["# Prune backwards"],"metadata":{"id":"e6N5MU1wRZog"}},{"cell_type":"markdown","source":["You need to modify this because the prev \"scores\" were just of ONE token, whereas here they are sums of MULTIPLE tokens so they will be greater than 100 at times. So can't do 100-new_score if return raw score, must return newscore/oldscore as percentage."],"metadata":{"id":"NHh8OSXa_EbY"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False)\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bfiwe5d3SgVP","executionInfo":{"status":"ok","timestamp":1698606337849,"user_tz":240,"elapsed":283336,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4a58fea2-f24a-4e26-82c8-d4f5bee86bbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","98.43448974119529\n","\n","\n","Removed: (11, 1)\n","98.57008671326153\n","\n","\n","Removed: (11, 2)\n","98.62260420787868\n","\n","\n","Removed: (11, 3)\n","98.6062238146972\n","\n","\n","Removed: (11, 4)\n","98.36458469047959\n","\n","\n","Removed: (11, 5)\n","98.38953423263045\n","\n","\n","Removed: (11, 6)\n","98.4319515733463\n","\n","\n","Removed: (11, 7)\n","98.41585562771179\n","\n","\n","Removed: (11, 9)\n","98.37635180830902\n","\n","\n","Removed: (11, 10)\n","97.97124838318094\n","\n","\n","Removed: (11, 11)\n","97.95907738715684\n","\n","\n","Removed: (10, 0)\n","97.99258141603245\n","\n","\n","Removed: (10, 1)\n","98.03429630193449\n","\n","\n","Removed: (10, 2)\n","98.29856913340076\n","\n","\n","Removed: (10, 3)\n","98.21821869956787\n","\n","\n","Removed: (10, 5)\n","98.2302404072824\n","\n","\n","Removed: (10, 6)\n","98.3037494377429\n","\n","\n","Removed: (10, 8)\n","98.6005337974124\n","\n","\n","Removed: (10, 9)\n","98.58944967359925\n","\n","\n","Removed: (10, 10)\n","98.43119020296747\n","\n","\n","Removed: (10, 11)\n","98.42999483014583\n","\n","\n","Removed: (9, 0)\n","98.46547293032926\n","\n","\n","Removed: (9, 2)\n","98.56369237505905\n","\n","\n","Removed: (9, 3)\n","98.42277274158404\n","\n","\n","Removed: (9, 4)\n","98.51721625842676\n","\n","\n","Removed: (9, 5)\n","99.17450975905143\n","\n","\n","Removed: (9, 6)\n","101.00485987831254\n","\n","\n","Removed: (9, 7)\n","101.02560935382539\n","\n","\n","Removed: (9, 8)\n","100.88187403619733\n","\n","\n","Removed: (9, 9)\n","101.11129711131174\n","\n","\n","Removed: (9, 10)\n","101.15705824357568\n","\n","\n","Removed: (9, 11)\n","101.05491278289043\n","\n","\n","Removed: (8, 0)\n","101.8855089506126\n","\n","\n","Removed: (8, 1)\n","102.17565557881775\n","\n","\n","Removed: (8, 2)\n","102.07490782993085\n","\n","\n","Removed: (8, 3)\n","102.03749164758567\n","\n","\n","Removed: (8, 4)\n","102.06195680248923\n","\n","\n","Removed: (8, 5)\n","101.78614665055575\n","\n","\n","Removed: (8, 6)\n","102.5989631137805\n","\n","\n","Removed: (8, 7)\n","102.52284900231794\n","\n","\n","Removed: (8, 9)\n","102.68903434925663\n","\n","\n","Removed: (8, 10)\n","102.1912948621767\n","\n","\n","Removed: (7, 0)\n","102.33495926785771\n","\n","\n","Removed: (7, 1)\n","102.2069525399881\n","\n","\n","Removed: (7, 2)\n","102.10491424698219\n","\n","\n","Removed: (7, 3)\n","102.29465275720472\n","\n","\n","Removed: (7, 4)\n","102.22405378243577\n","\n","\n","Removed: (7, 5)\n","102.11680532742584\n","\n","\n","Removed: (7, 6)\n","101.12816375784438\n","\n","\n","Removed: (7, 7)\n","101.00011570910337\n","\n","\n","Removed: (7, 8)\n","100.86294187926725\n","\n","\n","Removed: (7, 9)\n","101.459407858157\n","\n","\n","Removed: (7, 11)\n","100.00967921418558\n","\n","\n","Removed: (6, 0)\n","100.32142386199175\n","\n","\n","Removed: (6, 1)\n","101.2147848338518\n","\n","\n","Removed: (6, 2)\n","101.20749796482711\n","\n","\n","Removed: (6, 3)\n","101.10892156108567\n","\n","\n","Removed: (6, 4)\n","100.59705486795376\n","\n","\n","Removed: (6, 5)\n","100.42607363407008\n","\n","\n","Removed: (6, 6)\n","101.51334359171507\n","\n","\n","Removed: (6, 7)\n","101.74527630994787\n","\n","\n","Removed: (6, 8)\n","101.72195667623399\n","\n","\n","Removed: (6, 10)\n","101.63753866913778\n","\n","\n","Removed: (6, 11)\n","101.05540889993345\n","\n","\n","Removed: (5, 0)\n","101.37552222383619\n","\n","\n","Removed: (5, 2)\n","101.66619322722873\n","\n","\n","Removed: (5, 3)\n","101.56435727319955\n","\n","\n","Removed: (5, 4)\n","101.19723012816378\n","\n","\n","Removed: (5, 6)\n","100.88011909880106\n","\n","\n","Removed: (5, 7)\n","100.82769437620487\n","\n","\n","Removed: (5, 8)\n","101.13723702144486\n","\n","\n","Removed: (5, 9)\n","101.0199627901021\n","\n","\n","Removed: (5, 10)\n","101.28646881472781\n","\n","\n","Removed: (5, 11)\n","100.51423317942492\n","\n","\n","Removed: (4, 0)\n","100.83731520799796\n","\n","\n","Removed: (4, 1)\n","100.72207876208084\n","\n","\n","Removed: (4, 2)\n","100.75950240884151\n","\n","\n","Removed: (4, 3)\n","100.41423187208585\n","\n","\n","Removed: (4, 4)\n","101.07537487840732\n","\n","\n","Removed: (4, 5)\n","100.37011131170958\n","\n","\n","Removed: (4, 6)\n","100.86559547896988\n","\n","\n","Removed: (4, 7)\n","101.34696443656021\n","\n","\n","Removed: (4, 8)\n","101.79013691380159\n","\n","\n","Removed: (4, 9)\n","101.85039260799361\n","\n","\n","Removed: (4, 10)\n","102.51547122737617\n","\n","\n","Removed: (4, 11)\n","102.36601096966231\n","\n","\n","Removed: (3, 0)\n","102.15993791909627\n","\n","\n","Removed: (3, 1)\n","102.15091584005906\n","\n","\n","Removed: (3, 2)\n","101.91092075335061\n","\n","\n","Removed: (3, 3)\n","101.76655975775368\n","\n","\n","Removed: (3, 4)\n","102.56966048447426\n","\n","\n","Removed: (3, 5)\n","102.22212663031098\n","\n","\n","Removed: (3, 6)\n","102.10035455546985\n","\n","\n","Removed: (3, 7)\n","102.04532528504416\n","\n","\n","Removed: (3, 8)\n","102.20561027813329\n","\n","\n","Removed: (3, 9)\n","101.94885757867542\n","\n","\n","Removed: (3, 10)\n","102.10888771529319\n","\n","\n","Removed: (3, 11)\n","102.02752985195697\n","\n","\n","Removed: (2, 0)\n","101.92130855383412\n","\n","\n","Removed: (2, 1)\n","103.25037385524924\n","\n","\n","Removed: (2, 2)\n","103.34875805029212\n","\n","\n","Removed: (2, 3)\n","103.23717197013032\n","\n","\n","Removed: (2, 4)\n","101.66044962610422\n","\n","\n","Removed: (2, 5)\n","101.74885869620505\n","\n","\n","Removed: (2, 6)\n","101.94491023581858\n","\n","\n","Removed: (2, 7)\n","101.93331240026875\n","\n","\n","Removed: (2, 8)\n","102.02169881053685\n","\n","\n","Removed: (2, 9)\n","101.60061540480048\n","\n","\n","Removed: (2, 10)\n","101.13316704890516\n","\n","\n","Removed: (2, 11)\n","101.27717854990591\n","\n","\n","Removed: (1, 0)\n","101.63996113854687\n","\n","\n","Removed: (1, 1)\n","101.69414373098826\n","\n","\n","Removed: (1, 2)\n","101.59874743482698\n","\n","\n","Removed: (1, 3)\n","101.6044046620009\n","\n","\n","Removed: (1, 4)\n","101.57941566508251\n","\n","\n","Removed: (1, 5)\n","102.5595395368441\n","\n","\n","Removed: (1, 6)\n","102.08088522721158\n","\n","\n","Removed: (1, 7)\n","102.46234858193273\n","\n","\n","Removed: (1, 8)\n","102.50951542358308\n","\n","\n","Removed: (1, 9)\n","102.59419495180728\n","\n","\n","Removed: (1, 10)\n","102.55968322684205\n","\n","\n","Removed: (1, 11)\n","102.53900439669\n","\n","\n","Removed: (0, 0)\n","102.62599949323017\n","\n","\n","Removed: (0, 1)\n","97.07659233523535\n","\n","\n","Removed: (0, 2)\n","98.25345020745424\n","\n","\n","Removed: (0, 4)\n","99.06289968612559\n","\n","\n","Removed: (0, 6)\n","99.0025440220834\n","\n","\n","Removed: (0, 7)\n","98.36845019135242\n","\n","\n","Removed: (0, 8)\n","97.84185434037738\n","\n","\n","Removed: (0, 9)\n","97.70554078442518\n","\n","\n","Removed: (0, 10)\n","99.81733322368461\n","\n","\n","Removed: (0, 11)\n","99.43581415243364\n","\n","\n"]}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True)"],"metadata":{"id":"qgpGMTWLbibq","executionInfo":{"status":"ok","timestamp":1698606340256,"user_tz":240,"elapsed":2421,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b64c96b-279f-43b6-e12a-f5a07411b498"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 99.4358\n"]},{"output_type":"execute_result","data":{"text/plain":["99.43581415243364"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["backw_3 = curr_circuit.copy()\n","backw_3"],"metadata":{"id":"7_ZC4-k2blg2","executionInfo":{"status":"ok","timestamp":1698606340256,"user_tz":240,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e686d1ff-d878-4dab-efd8-a386a39a9d78"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 3),\n"," (0, 5),\n"," (5, 1),\n"," (5, 5),\n"," (6, 9),\n"," (7, 10),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (10, 4),\n"," (10, 7),\n"," (11, 8)]"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["len(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dry8ANsOMgvg","executionInfo":{"status":"ok","timestamp":1698606340256,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"edb84e1d-5a1e-490b-995b-f3d1aae9905c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":110}]},{"cell_type":"markdown","source":["## prune by 10% threshold"],"metadata":{"id":"Gt7Vv4939hfR"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 10  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False)\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698606620944,"user_tz":240,"elapsed":280696,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9b6bd719-d935-443a-c22d-0f0aea24abd1","id":"OEYO88Hv9jZ-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","98.43448974119529\n","\n","\n","Removed: (11, 1)\n","98.57008671326153\n","\n","\n","Removed: (11, 2)\n","98.62260420787868\n","\n","\n","Removed: (11, 3)\n","98.6062238146972\n","\n","\n","Removed: (11, 4)\n","98.36458469047959\n","\n","\n","Removed: (11, 5)\n","98.38953423263045\n","\n","\n","Removed: (11, 6)\n","98.4319515733463\n","\n","\n","Removed: (11, 7)\n","98.41585562771179\n","\n","\n","Removed: (11, 8)\n","96.93358933008298\n","\n","\n","Removed: (11, 9)\n","96.89825012134473\n","\n","\n","Removed: (11, 10)\n","96.4948229906641\n","\n","\n","Removed: (11, 11)\n","96.48109806328915\n","\n","\n","Removed: (10, 0)\n","96.54533868900167\n","\n","\n","Removed: (10, 1)\n","96.58525491735963\n","\n","\n","Removed: (10, 2)\n","96.81215342052467\n","\n","\n","Removed: (10, 3)\n","96.76442034964302\n","\n","\n","Removed: (10, 5)\n","96.77290019221297\n","\n","\n","Removed: (10, 6)\n","96.8510606198617\n","\n","\n","Removed: (10, 7)\n","95.40291789759321\n","\n","\n","Removed: (10, 8)\n","95.67583692146007\n","\n","\n","Removed: (10, 9)\n","95.67065821663553\n","\n","\n","Removed: (10, 10)\n","95.54388684952765\n","\n","\n","Removed: (10, 11)\n","95.54294073486571\n","\n","\n","Removed: (9, 0)\n","95.5713479009008\n","\n","\n","Removed: (9, 2)\n","95.66676632372227\n","\n","\n","Removed: (9, 3)\n","95.5422540086417\n","\n","\n","Removed: (9, 4)\n","95.6389141902953\n","\n","\n","Removed: (9, 5)\n","96.19109832411716\n","\n","\n","Removed: (9, 6)\n","98.15580552271626\n","\n","\n","Removed: (9, 7)\n","98.1591015953226\n","\n","\n","Removed: (9, 8)\n","98.05969850756689\n","\n","\n","Removed: (9, 9)\n","98.31648239761802\n","\n","\n","Removed: (9, 10)\n","98.3414132787302\n","\n","\n","Removed: (9, 11)\n","98.25769639351648\n","\n","\n","Removed: (8, 0)\n","99.01523006277552\n","\n","\n","Removed: (8, 1)\n","99.20135313004376\n","\n","\n","Removed: (8, 2)\n","99.13651028595385\n","\n","\n","Removed: (8, 3)\n","99.06455598660303\n","\n","\n","Removed: (8, 4)\n","99.07883727951743\n","\n","\n","Removed: (8, 5)\n","98.85425701053103\n","\n","\n","Removed: (8, 6)\n","99.51094962570969\n","\n","\n","Removed: (8, 7)\n","99.4505225165479\n","\n","\n","Removed: (8, 8)\n","93.56265983312936\n","\n","\n","Removed: (8, 9)\n","93.85982674409215\n","\n","\n","Removed: (8, 10)\n","93.54776059324786\n","\n","\n","Removed: (7, 0)\n","93.64403102577896\n","\n","\n","Removed: (7, 1)\n","93.55391260453352\n","\n","\n","Removed: (7, 2)\n","93.4599811999099\n","\n","\n","Removed: (7, 3)\n","93.62469045868768\n","\n","\n","Removed: (7, 4)\n","93.57493693048774\n","\n","\n","Removed: (7, 5)\n","93.43647282311892\n","\n","\n","Removed: (7, 6)\n","92.67815565682089\n","\n","\n","Removed: (7, 7)\n","92.49086787415173\n","\n","\n","Removed: (7, 8)\n","92.3765228927118\n","\n","\n","Removed: (7, 9)\n","92.92988160562648\n","\n","\n","Removed: (7, 11)\n","91.40869957790008\n","\n","\n","Removed: (6, 0)\n","91.6505551701666\n","\n","\n","Removed: (6, 1)\n","92.01469894828732\n","\n","\n","Removed: (6, 2)\n","92.0050152021352\n","\n","\n","Removed: (6, 3)\n","91.92518887690342\n","\n","\n","Removed: (6, 4)\n","91.75165108071833\n","\n","\n","Removed: (6, 5)\n","91.62446943734537\n","\n","\n","Removed: (6, 6)\n","92.68213419027096\n","\n","\n","Removed: (6, 7)\n","92.81681517192351\n","\n","\n","Removed: (6, 8)\n","92.70913991229993\n","\n","\n","Removed: (6, 10)\n","92.65635983020971\n","\n","\n","Removed: (6, 11)\n","92.04130185846671\n","\n","\n","Removed: (5, 0)\n","92.31422354819625\n","\n","\n","Removed: (5, 2)\n","92.50883632172628\n","\n","\n","Removed: (5, 3)\n","92.48119799048551\n","\n","\n","Removed: (5, 4)\n","92.2227807263759\n","\n","\n","Removed: (5, 6)\n","91.97208913228665\n","\n","\n","Removed: (5, 7)\n","91.83573612156691\n","\n","\n","Removed: (5, 8)\n","91.90348742183079\n","\n","\n","Removed: (5, 9)\n","91.96874560732478\n","\n","\n","Removed: (5, 10)\n","92.089520649527\n","\n","\n","Removed: (5, 11)\n","91.52234583673399\n","\n","\n","Removed: (4, 0)\n","91.7280134095878\n","\n","\n","Removed: (4, 1)\n","91.71845202653228\n","\n","\n","Removed: (4, 2)\n","91.77328482287912\n","\n","\n","Removed: (4, 3)\n","91.51060111215098\n","\n","\n","Removed: (4, 4)\n","91.97211019260175\n","\n","\n","Removed: (4, 5)\n","91.41505472792132\n","\n","\n","Removed: (4, 6)\n","91.76003201978318\n","\n","\n","Removed: (4, 7)\n","92.09094608629712\n","\n","\n","Removed: (4, 8)\n","92.43627847106676\n","\n","\n","Removed: (4, 9)\n","92.50835113472017\n","\n","\n","Removed: (4, 10)\n","93.28305509227009\n","\n","\n","Removed: (4, 11)\n","93.08116531340724\n","\n","\n","Removed: (3, 0)\n","92.90821480676857\n","\n","\n","Removed: (3, 1)\n","92.86111754413393\n","\n","\n","Removed: (3, 2)\n","92.72491115586111\n","\n","\n","Removed: (3, 3)\n","92.4897242190659\n","\n","\n","Removed: (3, 4)\n","93.12486440089525\n","\n","\n","Removed: (3, 5)\n","92.80144993924714\n","\n","\n","Removed: (3, 6)\n","92.77838222955565\n","\n","\n","Removed: (3, 7)\n","93.00013161897178\n","\n","\n","Removed: (3, 8)\n","93.0651021578836\n","\n","\n","Removed: (3, 9)\n","92.89381568272411\n","\n","\n","Removed: (3, 10)\n","92.7871462530863\n","\n","\n","Removed: (3, 11)\n","92.74068559845749\n","\n","\n","Removed: (2, 0)\n","92.67429628743221\n","\n","\n","Removed: (2, 1)\n","94.19435918600934\n","\n","\n","Removed: (2, 2)\n","94.18185975570418\n","\n","\n","Removed: (2, 3)\n","94.12711626575681\n","\n","\n","Removed: (2, 4)\n","92.88912723004478\n","\n","\n","Removed: (2, 5)\n","93.07918511061526\n","\n","\n","Removed: (2, 6)\n","93.27796196163729\n","\n","\n","Removed: (2, 7)\n","93.1667168453111\n","\n","\n","Removed: (2, 8)\n","93.2805670426393\n","\n","\n","Removed: (2, 9)\n","93.01347666091615\n","\n","\n","Removed: (2, 10)\n","92.49437241721894\n","\n","\n","Removed: (2, 11)\n","92.57199247450428\n","\n","\n","Removed: (1, 0)\n","92.83205244319169\n","\n","\n","Removed: (1, 1)\n","92.95221806918731\n","\n","\n","Removed: (1, 2)\n","92.84350578898477\n","\n","\n","Removed: (1, 3)\n","92.84309844516865\n","\n","\n","Removed: (1, 4)\n","92.81991850265872\n","\n","\n","Removed: (1, 5)\n","94.09899674630394\n","\n","\n","Removed: (1, 6)\n","93.80699547743862\n","\n","\n","Removed: (1, 7)\n","94.24456644403585\n","\n","\n","Removed: (1, 8)\n","94.2877304928858\n","\n","\n","Removed: (1, 9)\n","94.3383115048588\n","\n","\n","Removed: (1, 10)\n","94.27662051020474\n","\n","\n","Removed: (1, 11)\n","94.28110449121722\n","\n","\n","Removed: (0, 0)\n","94.44638344484777\n","\n","\n","Removed: (0, 2)\n","95.4661396305929\n","\n","\n","Removed: (0, 3)\n","94.08117118896857\n","\n","\n","Removed: (0, 4)\n","94.80808875838343\n","\n","\n","Removed: (0, 5)\n","92.32691625354504\n","\n","\n","Removed: (0, 6)\n","92.24505054336998\n","\n","\n","Removed: (0, 7)\n","91.63539547550214\n","\n","\n","Removed: (0, 8)\n","91.30690254546592\n","\n","\n","Removed: (0, 9)\n","91.16108678860948\n","\n","\n","Removed: (0, 10)\n","92.39858717169395\n","\n","\n","Removed: (0, 11)\n","92.23174415643436\n","\n","\n"]}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698606622717,"user_tz":240,"elapsed":1790,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"acf4cc05-e666-4fce-9462-af53e8f3104e","id":"saFoB5jJ9jaI"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 92.2317\n"]},{"output_type":"execute_result","data":{"text/plain":["92.23174415643436"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["backw_10 = curr_circuit.copy()\n","backw_10"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698606622717,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c94fc671-0dba-444a-820a-924d63c49dba","id":"7zLXLcBP9jaI"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1), (5, 1), (5, 5), (6, 9), (7, 10), (8, 11), (9, 1), (10, 4)]"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["len(backw_10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698606622718,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"402f9283-df52-4613-94c4-a6bd1f849b46","id":"ksCz3a539jaJ"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["greater_than = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]"],"metadata":{"id":"WZl2yDK9BPtA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_ablate_by_lst([(0, 1), (5, 5), (6, 9), (7, 10), (8, 11), (9, 1)], model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrOIM-5sghxF","executionInfo":{"status":"ok","timestamp":1698606624426,"user_tz":240,"elapsed":1721,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4788fed4-9565-4562-c50a-f28f44ed3942"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 81.5705\n"]},{"output_type":"execute_result","data":{"text/plain":["81.57053386373906"]},"metadata":{},"execution_count":116}]},{"cell_type":"markdown","source":["# Prune fwds-backwds iteratively"],"metadata":{"id":"w7bys5l5uleW"}},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False)\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"GTOk3N3evb3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False)\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"flTHN2eQvapG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 3"],"metadata":{"id":"e8OFeKuxzM3R"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKZjydkhBfTD","executionInfo":{"status":"ok","timestamp":1698607032006,"user_tz":240,"elapsed":317128,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f617ad95-93bc-43f1-96cf-a13b64fbc34a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","100.20776640653463\n","\n","Removed: (0, 2)\n","101.16978347244907\n","\n","Removed: (0, 3)\n","99.25190188507842\n","\n","Removed: (0, 4)\n","99.42954244391403\n","\n","Removed: (0, 6)\n","99.39908496289875\n","\n","Removed: (0, 7)\n","98.74450424412802\n","\n","Removed: (0, 8)\n","98.57850017585096\n","\n","Removed: (0, 9)\n","98.4728363096126\n","\n","Removed: (0, 10)\n","99.19824446758318\n","\n","Removed: (0, 11)\n","99.02801927235299\n","\n","Removed: (1, 0)\n","99.2378589202868\n","\n","Removed: (1, 1)\n","99.30176897902813\n","\n","Removed: (1, 2)\n","99.26472841673328\n","\n","Removed: (1, 3)\n","99.01089030493353\n","\n","Removed: (1, 4)\n","99.12583803792336\n","\n","Removed: (1, 5)\n","100.31772204508688\n","\n","Removed: (1, 6)\n","100.17648490736778\n","\n","Removed: (1, 7)\n","100.65617970320078\n","\n","Removed: (1, 8)\n","100.6652345723488\n","\n","Removed: (1, 9)\n","100.56871381531292\n","\n","Removed: (1, 10)\n","100.59008070462035\n","\n","Removed: (1, 11)\n","100.92439187993585\n","\n","Removed: (2, 0)\n","101.07729323318533\n","\n","Removed: (2, 1)\n","102.02257641252812\n","\n","Removed: (2, 2)\n","102.1973778276192\n","\n","Removed: (2, 3)\n","102.17504456309356\n","\n","Removed: (2, 4)\n","100.44306104418172\n","\n","Removed: (2, 5)\n","100.39972531377575\n","\n","Removed: (2, 6)\n","99.98459451279726\n","\n","Removed: (2, 7)\n","100.03321318325818\n","\n","Removed: (2, 8)\n","100.00784883287571\n","\n","Removed: (2, 9)\n","99.65709408343344\n","\n","Removed: (2, 10)\n","99.38675961342602\n","\n","Removed: (2, 11)\n","99.43023130282819\n","\n","Removed: (3, 0)\n","98.87096530482103\n","\n","Removed: (3, 1)\n","98.88700819978835\n","\n","Removed: (3, 2)\n","98.83389275217412\n","\n","Removed: (3, 3)\n","98.61320144365206\n","\n","Removed: (3, 4)\n","99.98239304340363\n","\n","Removed: (3, 5)\n","100.04003512583307\n","\n","Removed: (3, 6)\n","99.56975002546966\n","\n","Removed: (3, 7)\n","99.49900309532248\n","\n","Removed: (3, 8)\n","99.62529194128696\n","\n","Removed: (3, 9)\n","99.44430545821305\n","\n","Removed: (3, 10)\n","99.55077628108191\n","\n","Removed: (3, 11)\n","99.57790703207013\n","\n","Removed: (4, 0)\n","99.62220060693375\n","\n","Removed: (4, 1)\n","99.36575368192423\n","\n","Removed: (4, 2)\n","99.40605166181666\n","\n","Removed: (4, 3)\n","99.18223116369148\n","\n","Removed: (4, 4)\n","99.34328045960837\n","\n","Removed: (4, 5)\n","99.01884523914356\n","\n","Removed: (4, 6)\n","99.05683244927285\n","\n","Removed: (4, 7)\n","98.8512461852305\n","\n","Removed: (4, 8)\n","100.06397937117076\n","\n","Removed: (4, 9)\n","100.09136337911275\n","\n","Removed: (4, 10)\n","100.5462661852787\n","\n","Removed: (4, 11)\n","100.24175295655365\n","\n","Removed: (5, 0)\n","100.4984443411701\n","\n","Removed: (5, 2)\n","100.83026879978617\n","\n","Removed: (5, 3)\n","100.84536504691907\n","\n","Removed: (5, 4)\n","100.89547873316585\n","\n","Removed: (5, 6)\n","100.24057384549431\n","\n","Removed: (5, 7)\n","100.54042421382162\n","\n","Removed: (5, 8)\n","101.17882341276616\n","\n","Removed: (5, 9)\n","101.12235724236085\n","\n","Removed: (5, 10)\n","100.75368549649356\n","\n","Removed: (5, 11)\n","101.09672177374472\n","\n","Removed: (6, 0)\n","100.94747131942309\n","\n","Removed: (6, 1)\n","101.32328811042095\n","\n","Removed: (6, 2)\n","101.44792412152947\n","\n","Removed: (6, 3)\n","101.53944931850634\n","\n","Removed: (6, 4)\n","102.21095240033954\n","\n","Removed: (6, 5)\n","102.5364209091756\n","\n","Removed: (6, 6)\n","103.51113734509552\n","\n","Removed: (6, 7)\n","103.14150615525298\n","\n","Removed: (6, 8)\n","103.0070189818166\n","\n","Removed: (6, 10)\n","102.99972598130778\n","\n","Removed: (6, 11)\n","102.92417783249029\n","\n","Removed: (7, 0)\n","103.01928328303417\n","\n","Removed: (7, 1)\n","102.75759207297844\n","\n","Removed: (7, 2)\n","102.69790447412159\n","\n","Removed: (7, 3)\n","103.08550837691895\n","\n","Removed: (7, 4)\n","103.16352964653625\n","\n","Removed: (7, 5)\n","103.17252400060167\n","\n","Removed: (7, 6)\n","101.85941175458186\n","\n","Removed: (7, 7)\n","101.59478116434516\n","\n","Removed: (7, 8)\n","101.57555602910753\n","\n","Removed: (7, 9)\n","101.79921870816261\n","\n","Removed: (7, 11)\n","100.40177482899716\n","\n","Removed: (8, 0)\n","100.84347548345791\n","\n","Removed: (8, 1)\n","101.62262396725279\n","\n","Removed: (8, 2)\n","101.67389543765756\n","\n","Removed: (8, 3)\n","101.6220601372979\n","\n","Removed: (8, 4)\n","101.61111357199856\n","\n","Removed: (8, 5)\n","101.41654851741033\n","\n","Removed: (8, 6)\n","102.85348235349268\n","\n","Removed: (8, 7)\n","102.61726266149876\n","\n","Removed: (8, 9)\n","102.9300752538909\n","\n","Removed: (8, 10)\n","100.81032174893728\n","\n","Removed: (9, 0)\n","100.85829901283957\n","\n","Removed: (9, 2)\n","100.96344890075498\n","\n","Removed: (9, 3)\n","100.89898114354291\n","\n","Removed: (9, 4)\n","101.01030223695524\n","\n","Removed: (9, 5)\n","101.38309194089027\n","\n","Removed: (9, 6)\n","103.94786270005353\n","\n","Removed: (9, 7)\n","103.98214222838008\n","\n","Removed: (9, 8)\n","103.8289001778813\n","\n","Removed: (9, 9)\n","104.0794246223811\n","\n","Removed: (9, 10)\n","104.13507370587776\n","\n","Removed: (9, 11)\n","104.08953757242324\n","\n","Removed: (10, 0)\n","104.06884248050888\n","\n","Removed: (10, 1)\n","104.08686104630164\n","\n","Removed: (10, 2)\n","104.07568894902032\n","\n","Removed: (10, 3)\n","103.95654754746286\n","\n","Removed: (10, 5)\n","103.94892717901803\n","\n","Removed: (10, 6)\n","103.98813108887032\n","\n","Removed: (10, 7)\n","103.81586917455955\n","\n","Removed: (10, 8)\n","104.14461936034353\n","\n","Removed: (10, 9)\n","104.15329381088843\n","\n","Removed: (10, 10)\n","103.91308012344096\n","\n","Removed: (10, 11)\n","103.91325687013604\n","\n","Removed: (11, 0)\n","102.65701813833766\n","\n","Removed: (11, 1)\n","102.80209998320079\n","\n","Removed: (11, 2)\n","102.83475466822945\n","\n","Removed: (11, 3)\n","102.82251382660337\n","\n","Removed: (11, 4)\n","102.4737867323086\n","\n","Removed: (11, 5)\n","102.4866591168014\n","\n","Removed: (11, 6)\n","102.51039569143701\n","\n","Removed: (11, 7)\n","102.5135342115595\n","\n","Removed: (11, 8)\n","100.69338768167134\n","\n","Removed: (11, 9)\n","100.67502655252537\n","\n","Removed: (11, 10)\n","100.29454850064738\n","\n","Removed: (11, 11)\n","100.26508885202983\n","\n","backw prune, iter  1\n","\n","Removed: (0, 5)\n","97.85758452965342\n","\n","fwd prune, iter  2\n"]}]},{"cell_type":"code","source":["fb_3 = curr_circuit.copy()\n","fb_3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET--8aulD8pE","executionInfo":{"status":"ok","timestamp":1698607032006,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"125c12c1-d2f9-4173-9213-63d6466a4a52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1), (5, 1), (5, 5), (6, 9), (7, 10), (8, 8), (8, 11), (9, 1), (10, 4)]"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["mean_ablate_by_lst(fb_3, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLOevwFnbAEK","executionInfo":{"status":"ok","timestamp":1698607034024,"user_tz":240,"elapsed":2022,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1437cabf-59da-44db-9a4c-14a55bc763e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.8576\n"]},{"output_type":"execute_result","data":{"text/plain":["97.85758452965342"]},"metadata":{},"execution_count":124}]},{"cell_type":"markdown","source":["#### compare"],"metadata":{"id":"KvRRtGHxScYH"}},{"cell_type":"code","source":["set(backw_3) - set(fb_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLDzDrR9Sa-O","executionInfo":{"status":"ok","timestamp":1698607034024,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6b6a89b5-8e7b-4c64-c45b-378a86a850cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 3), (0, 5), (10, 7), (11, 8)}"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["set(fb_3) - set(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGKbGobdSiPG","executionInfo":{"status":"ok","timestamp":1698607034025,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a7864e1f-3024-4253-9dd2-5c4ca71c5ffe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 1)}"]},"metadata":{},"execution_count":126}]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 20"],"metadata":{"id":"C2fvsn5SFnrO"}},{"cell_type":"code","source":["# threshold = 20\n","# curr_circuit = []\n","# prev_score = 100\n","# new_score = 0\n","# iter = 1\n","# while prev_score != new_score:\n","#     print('\\nfwd prune, iter ', str(iter))\n","#     # track changes in circuit as for some reason it doesn't work with scores\n","#     old_circuit = curr_circuit.copy() # save old before finding new one\n","#     curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","#     if curr_circuit == old_circuit:\n","#         break\n","#     print('\\nbackw prune, iter ', str(iter))\n","#     # prev_score = new_score # save old score before finding new one\n","#     old_circuit = curr_circuit.copy() # save old before finding new one\n","#     curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","#     if curr_circuit == old_circuit:\n","#         break\n","#     iter += 1"],"metadata":{"id":"smR_M0B7FnrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# curr_circuit"],"metadata":{"id":"78x6pmqkFnrP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prune backwds-fwds iteratively"],"metadata":{"id":"1putaGukK8at"}},{"cell_type":"markdown","source":["### iter fwd backw, threshold 3"],"metadata":{"id":"E69b948rS4qQ"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698607354063,"user_tz":240,"elapsed":320044,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"2EJaexibS4qb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b14b095-a4ac-4376-9b7e-de676f34850f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","98.43448974119529\n","\n","Removed: (11, 1)\n","98.57008671326153\n","\n","Removed: (11, 2)\n","98.62260420787868\n","\n","Removed: (11, 3)\n","98.6062238146972\n","\n","Removed: (11, 4)\n","98.36458469047959\n","\n","Removed: (11, 5)\n","98.38953423263045\n","\n","Removed: (11, 6)\n","98.4319515733463\n","\n","Removed: (11, 7)\n","98.41585562771179\n","\n","Removed: (11, 9)\n","98.37635180830902\n","\n","Removed: (11, 10)\n","97.97124838318094\n","\n","Removed: (11, 11)\n","97.95907738715684\n","\n","Removed: (10, 0)\n","97.99258141603245\n","\n","Removed: (10, 1)\n","98.03429630193449\n","\n","Removed: (10, 2)\n","98.29856913340076\n","\n","Removed: (10, 3)\n","98.21821869956787\n","\n","Removed: (10, 5)\n","98.2302404072824\n","\n","Removed: (10, 6)\n","98.3037494377429\n","\n","Removed: (10, 8)\n","98.6005337974124\n","\n","Removed: (10, 9)\n","98.58944967359925\n","\n","Removed: (10, 10)\n","98.43119020296747\n","\n","Removed: (10, 11)\n","98.42999483014583\n","\n","Removed: (9, 0)\n","98.46547293032926\n","\n","Removed: (9, 2)\n","98.56369237505905\n","\n","Removed: (9, 3)\n","98.42277274158404\n","\n","Removed: (9, 4)\n","98.51721625842676\n","\n","Removed: (9, 5)\n","99.17450975905143\n","\n","Removed: (9, 6)\n","101.00485987831254\n","\n","Removed: (9, 7)\n","101.02560935382539\n","\n","Removed: (9, 8)\n","100.88187403619733\n","\n","Removed: (9, 9)\n","101.11129711131174\n","\n","Removed: (9, 10)\n","101.15705824357568\n","\n","Removed: (9, 11)\n","101.05491278289043\n","\n","Removed: (8, 0)\n","101.8855089506126\n","\n","Removed: (8, 1)\n","102.17565557881775\n","\n","Removed: (8, 2)\n","102.07490782993085\n","\n","Removed: (8, 3)\n","102.03749164758567\n","\n","Removed: (8, 4)\n","102.06195680248923\n","\n","Removed: (8, 5)\n","101.78614665055575\n","\n","Removed: (8, 6)\n","102.5989631137805\n","\n","Removed: (8, 7)\n","102.52284900231794\n","\n","Removed: (8, 9)\n","102.68903434925663\n","\n","Removed: (8, 10)\n","102.1912948621767\n","\n","Removed: (7, 0)\n","102.33495926785771\n","\n","Removed: (7, 1)\n","102.2069525399881\n","\n","Removed: (7, 2)\n","102.10491424698219\n","\n","Removed: (7, 3)\n","102.29465275720472\n","\n","Removed: (7, 4)\n","102.22405378243577\n","\n","Removed: (7, 5)\n","102.11680532742584\n","\n","Removed: (7, 6)\n","101.12816375784438\n","\n","Removed: (7, 7)\n","101.00011570910337\n","\n","Removed: (7, 8)\n","100.86294187926725\n","\n","Removed: (7, 9)\n","101.459407858157\n","\n","Removed: (7, 11)\n","100.00967921418558\n","\n","Removed: (6, 0)\n","100.32142386199175\n","\n","Removed: (6, 1)\n","101.2147848338518\n","\n","Removed: (6, 2)\n","101.20749796482711\n","\n","Removed: (6, 3)\n","101.10892156108567\n","\n","Removed: (6, 4)\n","100.59705486795376\n","\n","Removed: (6, 5)\n","100.42607363407008\n","\n","Removed: (6, 6)\n","101.51334359171507\n","\n","Removed: (6, 7)\n","101.74527630994787\n","\n","Removed: (6, 8)\n","101.72195667623399\n","\n","Removed: (6, 10)\n","101.63753866913778\n","\n","Removed: (6, 11)\n","101.05540889993345\n","\n","Removed: (5, 0)\n","101.37552222383619\n","\n","Removed: (5, 2)\n","101.66619322722873\n","\n","Removed: (5, 3)\n","101.56435727319955\n","\n","Removed: (5, 4)\n","101.19723012816378\n","\n","Removed: (5, 6)\n","100.88011909880106\n","\n","Removed: (5, 7)\n","100.82769437620487\n","\n","Removed: (5, 8)\n","101.13723702144486\n","\n","Removed: (5, 9)\n","101.0199627901021\n","\n","Removed: (5, 10)\n","101.28646881472781\n","\n","Removed: (5, 11)\n","100.51423317942492\n","\n","Removed: (4, 0)\n","100.83731520799796\n","\n","Removed: (4, 1)\n","100.72207876208084\n","\n","Removed: (4, 2)\n","100.75950240884151\n","\n","Removed: (4, 3)\n","100.41423187208585\n","\n","Removed: (4, 4)\n","101.07537487840732\n","\n","Removed: (4, 5)\n","100.37011131170958\n","\n","Removed: (4, 6)\n","100.86559547896988\n","\n","Removed: (4, 7)\n","101.34696443656021\n","\n","Removed: (4, 8)\n","101.79013691380159\n","\n","Removed: (4, 9)\n","101.85039260799361\n","\n","Removed: (4, 10)\n","102.51547122737617\n","\n","Removed: (4, 11)\n","102.36601096966231\n","\n","Removed: (3, 0)\n","102.15993791909627\n","\n","Removed: (3, 1)\n","102.15091584005906\n","\n","Removed: (3, 2)\n","101.91092075335061\n","\n","Removed: (3, 3)\n","101.76655975775368\n","\n","Removed: (3, 4)\n","102.56966048447426\n","\n","Removed: (3, 5)\n","102.22212663031098\n","\n","Removed: (3, 6)\n","102.10035455546985\n","\n","Removed: (3, 7)\n","102.04532528504416\n","\n","Removed: (3, 8)\n","102.20561027813329\n","\n","Removed: (3, 9)\n","101.94885757867542\n","\n","Removed: (3, 10)\n","102.10888771529319\n","\n","Removed: (3, 11)\n","102.02752985195697\n","\n","Removed: (2, 0)\n","101.92130855383412\n","\n","Removed: (2, 1)\n","103.25037385524924\n","\n","Removed: (2, 2)\n","103.34875805029212\n","\n","Removed: (2, 3)\n","103.23717197013032\n","\n","Removed: (2, 4)\n","101.66044962610422\n","\n","Removed: (2, 5)\n","101.74885869620505\n","\n","Removed: (2, 6)\n","101.94491023581858\n","\n","Removed: (2, 7)\n","101.93331240026875\n","\n","Removed: (2, 8)\n","102.02169881053685\n","\n","Removed: (2, 9)\n","101.60061540480048\n","\n","Removed: (2, 10)\n","101.13316704890516\n","\n","Removed: (2, 11)\n","101.27717854990591\n","\n","Removed: (1, 0)\n","101.63996113854687\n","\n","Removed: (1, 1)\n","101.69414373098826\n","\n","Removed: (1, 2)\n","101.59874743482698\n","\n","Removed: (1, 3)\n","101.6044046620009\n","\n","Removed: (1, 4)\n","101.57941566508251\n","\n","Removed: (1, 5)\n","102.5595395368441\n","\n","Removed: (1, 6)\n","102.08088522721158\n","\n","Removed: (1, 7)\n","102.46234858193273\n","\n","Removed: (1, 8)\n","102.50951542358308\n","\n","Removed: (1, 9)\n","102.59419495180728\n","\n","Removed: (1, 10)\n","102.55968322684205\n","\n","Removed: (1, 11)\n","102.53900439669\n","\n","Removed: (0, 0)\n","102.62599949323017\n","\n","Removed: (0, 1)\n","97.07659233523535\n","\n","Removed: (0, 2)\n","98.25345020745424\n","\n","Removed: (0, 4)\n","99.06289968612559\n","\n","Removed: (0, 6)\n","99.0025440220834\n","\n","Removed: (0, 7)\n","98.36845019135242\n","\n","Removed: (0, 8)\n","97.84185434037738\n","\n","Removed: (0, 9)\n","97.70554078442518\n","\n","Removed: (0, 10)\n","99.81733322368461\n","\n","Removed: (0, 11)\n","99.43581415243364\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 3)\n","97.29678086205767\n","\n","Removed: (10, 7)\n","97.23187963557528\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698607354064,"user_tz":240,"elapsed":47,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"C2EgKgmJS4qb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2aeb9a09-6ce9-4946-fad3-c59ebff8964e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 5),\n"," (5, 1),\n"," (5, 5),\n"," (6, 9),\n"," (7, 10),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (10, 4),\n"," (11, 8)]"]},"metadata":{},"execution_count":130}]},{"cell_type":"markdown","source":["#### compare"],"metadata":{"id":"ZXouisDpS4qb"}},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"id":"kPspQ2ZCVeID","executionInfo":{"status":"ok","timestamp":1698607354064,"user_tz":240,"elapsed":44,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0ca46cc4-37d7-4794-e2dc-3f5ebb9f0d93"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":131}]},{"cell_type":"code","source":["len(fb_3)"],"metadata":{"id":"4b2csbQpVg5H","executionInfo":{"status":"ok","timestamp":1698607354064,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"640badc1-4186-4366-8ec5-6a85b09b4d00"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["set(backw_3) - set(bf_3)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698607354064,"user_tz":240,"elapsed":41,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"TthWjv5IS4qc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2ad2577b-ff5c-4b3c-d741-26e170a9aab0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 3), (10, 7)}"]},"metadata":{},"execution_count":133}]},{"cell_type":"code","source":["set(bf_3) - set(backw_3)"],"metadata":{"id":"yMADPA_oTFb8","executionInfo":{"status":"ok","timestamp":1698607354064,"user_tz":240,"elapsed":40,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4afdfb82-b790-4335-a8c5-9ec7ad11f477"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["set()"]},"metadata":{},"execution_count":134}]},{"cell_type":"code","source":["set(fb_3) - (set(fb_3) - set(bf_3))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698607354064,"user_tz":240,"elapsed":39,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"epw2Vlh2S4qc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"812aed14-ca5f-4142-8b10-2166bdc99118"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(5, 1), (5, 5), (6, 9), (7, 10), (8, 8), (8, 11), (9, 1), (10, 4)}"]},"metadata":{},"execution_count":135}]},{"cell_type":"code","source":["set(bf_3) - set(fb_3)"],"metadata":{"id":"1KXH3MTsTHm9","executionInfo":{"status":"ok","timestamp":1698607354064,"user_tz":240,"elapsed":38,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4b291a8-2010-40cc-e4c4-1cbf048ef2ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 5), (11, 8)}"]},"metadata":{},"execution_count":136}]},{"cell_type":"markdown","source":["Get score of fb_3 without nodes it has that bf_3 doesn't have\n","\n","this is set intersection"],"metadata":{"id":"lfdQ7oy4ttdb"}},{"cell_type":"code","source":["mean_ablate_by_lst(list(set(fb_3) - (set(fb_3) - set(bf_3))), model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_YvvGGutjg3","executionInfo":{"status":"ok","timestamp":1698607355652,"user_tz":240,"elapsed":1626,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b824cb42-1785-4284-d816-42f882cd7556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 91.7935\n"]},{"output_type":"execute_result","data":{"text/plain":["91.79345500643358"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","source":["mean_ablate_by_lst(list(set(bf_3) - (set(bf_3) - set(fb_3))), model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbM0-Ml1tmzl","executionInfo":{"status":"ok","timestamp":1698607357434,"user_tz":240,"elapsed":1541,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0d5bb024-a69e-4bbc-ff09-8a1f49ee2492"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 91.7935\n"]},{"output_type":"execute_result","data":{"text/plain":["91.79345500643358"]},"metadata":{},"execution_count":138}]},{"cell_type":"code","source":["(set(fb_3) - (set(fb_3) - set(bf_3))) == (set(bf_3) - (set(bf_3) - set(fb_3)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVT9R1xTt9qC","executionInfo":{"status":"ok","timestamp":1698607357435,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5958993c-6a7b-47da-d3d9-569d5005eb1b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":139}]}]}