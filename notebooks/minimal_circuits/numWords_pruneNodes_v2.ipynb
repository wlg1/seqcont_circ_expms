{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["DcZG9rm2IAiA","Z4iJEGh6b56v","GCCCoO0V7L7J","X3Iera3OlvQL","1putaGukK8at"],"authorship_tag":"ABX9TyPqvq/PFltpZSn4X/WuCFpI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"07c5fec72fb8430ca2802eaa7575c7ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_095b2de7fec44499a3fb3fdec1db68e4","IPY_MODEL_3dad823834394c289b698ad4fe1c6811","IPY_MODEL_5f71b1f2014c4a7a9658a1293e3f9e22"],"layout":"IPY_MODEL_5dde6233e28a46e18ed2df6273c50652"}},"095b2de7fec44499a3fb3fdec1db68e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66b28f56566f4c8d893ee5f310963074","placeholder":"​","style":"IPY_MODEL_78cdb3e6b7304ef88eec62c9e51cfe01","value":"Downloading (…)lve/main/config.json: 100%"}},"3dad823834394c289b698ad4fe1c6811":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0650d84c9cb64fe481a66535b2cf5648","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc495f2660e545bc8f646f32cdfe7e64","value":665}},"5f71b1f2014c4a7a9658a1293e3f9e22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7067047da7d941bbb7029c8678f36394","placeholder":"​","style":"IPY_MODEL_0dfcd4db718a4e5a928c369d8e923958","value":" 665/665 [00:00&lt;00:00, 51.2kB/s]"}},"5dde6233e28a46e18ed2df6273c50652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66b28f56566f4c8d893ee5f310963074":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78cdb3e6b7304ef88eec62c9e51cfe01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0650d84c9cb64fe481a66535b2cf5648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc495f2660e545bc8f646f32cdfe7e64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7067047da7d941bbb7029c8678f36394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dfcd4db718a4e5a928c369d8e923958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f5cc52042654893ac32e9e9b10af61c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6ee07f197804b398502ebd00291234f","IPY_MODEL_5e55826d122b45f4b41ef340feb31418","IPY_MODEL_b25aa698163e41b69be3af4957fd266a"],"layout":"IPY_MODEL_3f143cbf32244705b6cffd66f3b1a3fb"}},"b6ee07f197804b398502ebd00291234f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95c94a5ba7bc4096b27b1b14ca2dc2a5","placeholder":"​","style":"IPY_MODEL_08a3a6a38b444424adf588c449097373","value":"Downloading model.safetensors: 100%"}},"5e55826d122b45f4b41ef340feb31418":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e71e76694b114abf9b31e181303f7db5","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d146885cbb0148318aa089c56a60861a","value":548105171}},"b25aa698163e41b69be3af4957fd266a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c08ff1753a542648a955ae2f8cb3318","placeholder":"​","style":"IPY_MODEL_7793cd3ab6054e079aefbe95c6b2b2fc","value":" 548M/548M [00:01&lt;00:00, 421MB/s]"}},"3f143cbf32244705b6cffd66f3b1a3fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95c94a5ba7bc4096b27b1b14ca2dc2a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08a3a6a38b444424adf588c449097373":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e71e76694b114abf9b31e181303f7db5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d146885cbb0148318aa089c56a60861a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c08ff1753a542648a955ae2f8cb3318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7793cd3ab6054e079aefbe95c6b2b2fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c10fb2640faf4a439aae780ce82a6e67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd7c60083bdb4b6f806c40a03473797d","IPY_MODEL_75a57aa534e84e488ec0a5ed91c23b19","IPY_MODEL_9e6f2938bded4eadb08fbb952a48ac44"],"layout":"IPY_MODEL_b454aef5ab0d4b46801b9ade109fd5d2"}},"cd7c60083bdb4b6f806c40a03473797d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95ac6203ec004ed483677f5ed2e94d45","placeholder":"​","style":"IPY_MODEL_1a572220d51c49dd8c3c729e3602afa6","value":"Downloading (…)neration_config.json: 100%"}},"75a57aa534e84e488ec0a5ed91c23b19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39ced776a90943ba996625d7b4134947","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8656befd4bea4eebba0c035e462e78b7","value":124}},"9e6f2938bded4eadb08fbb952a48ac44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_790aba9a04e045e59c1988c0e6b0af26","placeholder":"​","style":"IPY_MODEL_13a94bd2a0dc45979658487bca0ac761","value":" 124/124 [00:00&lt;00:00, 6.67kB/s]"}},"b454aef5ab0d4b46801b9ade109fd5d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ac6203ec004ed483677f5ed2e94d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a572220d51c49dd8c3c729e3602afa6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39ced776a90943ba996625d7b4134947":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8656befd4bea4eebba0c035e462e78b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"790aba9a04e045e59c1988c0e6b0af26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13a94bd2a0dc45979658487bca0ac761":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82789ec85e0648c7ab9a9f379f2dd6aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c23e28121a1747c7baebce4f06017d7b","IPY_MODEL_a8dc1416348b4b819f64d2dc7bbbfdb6","IPY_MODEL_020ac756b67f4f809faee8b4c3c2339c"],"layout":"IPY_MODEL_34a552a255464ef0b05944be4fdfd6f3"}},"c23e28121a1747c7baebce4f06017d7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3aa8f10967a74d919d89499ad71d0b08","placeholder":"​","style":"IPY_MODEL_1d522b715f5e49d797b45d5c469ae730","value":"Downloading (…)olve/main/vocab.json: 100%"}},"a8dc1416348b4b819f64d2dc7bbbfdb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aecbd8f31d7442ead1d26447e3b3cf4","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_706aff79d8624c0aa3e70c8f8ec1d71f","value":1042301}},"020ac756b67f4f809faee8b4c3c2339c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_677b083adb104b56a89c54196ebe34be","placeholder":"​","style":"IPY_MODEL_1550f960aa194988bc9be7c02304b3e0","value":" 1.04M/1.04M [00:00&lt;00:00, 26.1MB/s]"}},"34a552a255464ef0b05944be4fdfd6f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aa8f10967a74d919d89499ad71d0b08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d522b715f5e49d797b45d5c469ae730":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8aecbd8f31d7442ead1d26447e3b3cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706aff79d8624c0aa3e70c8f8ec1d71f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"677b083adb104b56a89c54196ebe34be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1550f960aa194988bc9be7c02304b3e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04361fe4706e44749e6b928884488040":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_118ea1c635d947b5bb265a3a4bacd1c9","IPY_MODEL_1d0530ba92474057877f327a8d5785e0","IPY_MODEL_2854dbcc290543ba95c8692e4f8300dc"],"layout":"IPY_MODEL_9f2a37add2374a4895338031592164bb"}},"118ea1c635d947b5bb265a3a4bacd1c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d89218c830864029a0b58fbc9e554818","placeholder":"​","style":"IPY_MODEL_9e55b835b0c948228ad8165b297e2454","value":"Downloading (…)olve/main/merges.txt: 100%"}},"1d0530ba92474057877f327a8d5785e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_272207fac03240108583f1837ad2d6a8","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_433e4d75afdc465f808796e10ac5a289","value":456318}},"2854dbcc290543ba95c8692e4f8300dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a51d492b337340aa82b8fdf78e50fc8b","placeholder":"​","style":"IPY_MODEL_aab3ffe921e64a15acb384822f434566","value":" 456k/456k [00:00&lt;00:00, 30.7MB/s]"}},"9f2a37add2374a4895338031592164bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d89218c830864029a0b58fbc9e554818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e55b835b0c948228ad8165b297e2454":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"272207fac03240108583f1837ad2d6a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433e4d75afdc465f808796e10ac5a289":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a51d492b337340aa82b8fdf78e50fc8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aab3ffe921e64a15acb384822f434566":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13ae26fb7ca64df596244f0593ae01f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e29bd7ebc3ca40d6a14e402788c5e70d","IPY_MODEL_b14aab6c600c48039cdb3a6d7563fe49","IPY_MODEL_574494d9b2cf4430b7f8e3b85cdc3f22"],"layout":"IPY_MODEL_93c930f97dff45f7be0fe56c8d5e1194"}},"e29bd7ebc3ca40d6a14e402788c5e70d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2b5195126184cd1a6b1763d79407f8e","placeholder":"​","style":"IPY_MODEL_b47696fb4c3b4ef49995317510dbe353","value":"Downloading (…)/main/tokenizer.json: 100%"}},"b14aab6c600c48039cdb3a6d7563fe49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_806b23eb486c40659eda3ad6f1ded73d","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_776cf9cd62364c7a8c0c9b59844cc059","value":1355256}},"574494d9b2cf4430b7f8e3b85cdc3f22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c30e755d4da4443d9cb1d0940aab6628","placeholder":"​","style":"IPY_MODEL_be728b68f4bb4e129014c9c3f9781f0f","value":" 1.36M/1.36M [00:00&lt;00:00, 5.72MB/s]"}},"93c930f97dff45f7be0fe56c8d5e1194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b5195126184cd1a6b1763d79407f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b47696fb4c3b4ef49995317510dbe353":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"806b23eb486c40659eda3ad6f1ded73d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"776cf9cd62364c7a8c0c9b59844cc059":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c30e755d4da4443d9cb1d0940aab6628":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be728b68f4bb4e129014c9c3f9781f0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"b13177b7"},"source":["<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"840864b4-26f3-4fc0-d910-022c56381ef5","executionInfo":{"status":"ok","timestamp":1698808355678,"user_tz":240,"elapsed":99488,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-qpdo1o_w\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-qpdo1o_w\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit fa287750606075574df2c538058e67d648e2f952\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate>=0.23.0 (from transformer-lens==0.0.0)\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n","Collecting numpy>=1.24 (from transformer-lens==0.0.0)\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cublas_cu12-12.3.2.9-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (24.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cudnn_cu12-8.9.5.30-py3-none-manylinux1_x86_64.whl (701.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.6/701.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cufft_cu12-11.0.11.19-py3-none-manylinux1_x86_64.whl (98.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_curand_cu12-10.3.4.52-py3-none-manylinux1_x86_64.whl (56.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusolver_cu12-11.5.3.52-py3-none-manylinux1_x86_64.whl (125.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusparse_cu12-12.1.3.153-py3-none-manylinux1_x86_64.whl (195.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nvtx_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.6)\n","Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens==0.0.0)\n","  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.33.1-py2.py3-none-any.whl (243 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=116436 sha256=303c258b4ff833ed9eeb722f1ee890c64ad784434a6e8fcdd12952925d99a48c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-qko3aelp/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=b79a753eb95dc70ccd9d3b282d08ba4b93037604cc2e7f8574d39ed2b8114592\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, huggingface-hub, gitdb, tokenizers, nvidia-cusolver-cu12, GitPython, accelerate, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.24.1 beartype-0.14.1 datasets-2.14.6 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 huggingface-hub-0.17.3 jaxtyping-0.2.23 multiprocess-0.70.15 numpy-1.26.1 nvidia-cublas-cu12-12.3.2.9 nvidia-cuda-cupti-cu12-12.3.52 nvidia-cuda-nvrtc-cu12-12.3.52 nvidia-cuda-runtime-cu12-12.3.52 nvidia-cudnn-cu12-8.9.5.30 nvidia-cufft-cu12-11.0.11.19 nvidia-curand-cu12-10.3.4.52 nvidia-cusolver-cu12-11.5.3.52 nvidia-cusparse-cu12-12.1.3.153 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.3.52 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.33.1 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.34.1 typeguard-2.13.3 wandb-0.15.12\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1698808355678,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","import plotly.io as pio\n","\n","if IN_COLAB or not DEBUG_MODE:\n","    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","    pio.renderers.default = \"colab\"\n","else:\n","    pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1698808361556,"user_tz":240,"elapsed":5885,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1698808363192,"user_tz":240,"elapsed":1641,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698808363193,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bd5f5e83-5870-49f0-9bee-0cccc5ad6820"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x78e83e32b6d0>"]},"metadata":{},"execution_count":5}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KFs9BrbzIAiH","executionInfo":{"status":"ok","timestamp":1698808363193,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def imshow(tensor, renderer=None, **kwargs):\n","    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","def line(tensor, renderer=None, **kwargs):\n","    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","    x = utils.to_numpy(x)\n","    y = utils.to_numpy(y)\n","    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"markdown","source":["Decide which model to use (eg. gpt2-small vs -medium)"],"metadata":{"id":"ssJgoKr2yI8O"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"xLwDyosvIAiJ","colab":{"base_uri":"https://localhost:8080/","height":226,"referenced_widgets":["07c5fec72fb8430ca2802eaa7575c7ea","095b2de7fec44499a3fb3fdec1db68e4","3dad823834394c289b698ad4fe1c6811","5f71b1f2014c4a7a9658a1293e3f9e22","5dde6233e28a46e18ed2df6273c50652","66b28f56566f4c8d893ee5f310963074","78cdb3e6b7304ef88eec62c9e51cfe01","0650d84c9cb64fe481a66535b2cf5648","bc495f2660e545bc8f646f32cdfe7e64","7067047da7d941bbb7029c8678f36394","0dfcd4db718a4e5a928c369d8e923958","7f5cc52042654893ac32e9e9b10af61c","b6ee07f197804b398502ebd00291234f","5e55826d122b45f4b41ef340feb31418","b25aa698163e41b69be3af4957fd266a","3f143cbf32244705b6cffd66f3b1a3fb","95c94a5ba7bc4096b27b1b14ca2dc2a5","08a3a6a38b444424adf588c449097373","e71e76694b114abf9b31e181303f7db5","d146885cbb0148318aa089c56a60861a","6c08ff1753a542648a955ae2f8cb3318","7793cd3ab6054e079aefbe95c6b2b2fc","c10fb2640faf4a439aae780ce82a6e67","cd7c60083bdb4b6f806c40a03473797d","75a57aa534e84e488ec0a5ed91c23b19","9e6f2938bded4eadb08fbb952a48ac44","b454aef5ab0d4b46801b9ade109fd5d2","95ac6203ec004ed483677f5ed2e94d45","1a572220d51c49dd8c3c729e3602afa6","39ced776a90943ba996625d7b4134947","8656befd4bea4eebba0c035e462e78b7","790aba9a04e045e59c1988c0e6b0af26","13a94bd2a0dc45979658487bca0ac761","82789ec85e0648c7ab9a9f379f2dd6aa","c23e28121a1747c7baebce4f06017d7b","a8dc1416348b4b819f64d2dc7bbbfdb6","020ac756b67f4f809faee8b4c3c2339c","34a552a255464ef0b05944be4fdfd6f3","3aa8f10967a74d919d89499ad71d0b08","1d522b715f5e49d797b45d5c469ae730","8aecbd8f31d7442ead1d26447e3b3cf4","706aff79d8624c0aa3e70c8f8ec1d71f","677b083adb104b56a89c54196ebe34be","1550f960aa194988bc9be7c02304b3e0","04361fe4706e44749e6b928884488040","118ea1c635d947b5bb265a3a4bacd1c9","1d0530ba92474057877f327a8d5785e0","2854dbcc290543ba95c8692e4f8300dc","9f2a37add2374a4895338031592164bb","d89218c830864029a0b58fbc9e554818","9e55b835b0c948228ad8165b297e2454","272207fac03240108583f1837ad2d6a8","433e4d75afdc465f808796e10ac5a289","a51d492b337340aa82b8fdf78e50fc8b","aab3ffe921e64a15acb384822f434566","13ae26fb7ca64df596244f0593ae01f8","e29bd7ebc3ca40d6a14e402788c5e70d","b14aab6c600c48039cdb3a6d7563fe49","574494d9b2cf4430b7f8e3b85cdc3f22","93c930f97dff45f7be0fe56c8d5e1194","a2b5195126184cd1a6b1763d79407f8e","b47696fb4c3b4ef49995317510dbe353","806b23eb486c40659eda3ad6f1ded73d","776cf9cd62364c7a8c0c9b59844cc059","c30e755d4da4443d9cb1d0940aab6628","be728b68f4bb4e129014c9c3f9781f0f"]},"executionInfo":{"status":"ok","timestamp":1698808380912,"user_tz":240,"elapsed":17726,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"066cee3a-85a3-4e72-a6c0-11ebedfd9571"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07c5fec72fb8430ca2802eaa7575c7ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f5cc52042654893ac32e9e9b10af61c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c10fb2640faf4a439aae780ce82a6e67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82789ec85e0648c7ab9a9f379f2dd6aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04361fe4706e44749e6b928884488040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ae26fb7ca64df596244f0593ae01f8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"id":"Fdh5--MfYw7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698808396809,"user_tz":240,"elapsed":16092,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3881e8a7-79b1-4653-f9ef-725813f92b32"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9106, done.\u001b[K\n","remote: Counting objects: 100% (1820/1820), done.\u001b[K\n","remote: Compressing objects: 100% (289/289), done.\u001b[K\n","remote: Total 9106 (delta 1614), reused 1608 (delta 1528), pack-reused 7286\u001b[K\n","Receiving objects: 100% (9106/9106), 155.60 MiB | 13.07 MiB/s, done.\n","Resolving deltas: 100% (5507/5507), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"id":"iZ4C_bsXZFfj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698808396810,"user_tz":240,"elapsed":53,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"08c8e687-c032-48b2-d4f1-0c0aa44f0cb0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV","executionInfo":{"status":"ok","timestamp":1698808396810,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# test prompts"],"metadata":{"id":"DQF0lzuokQer"}},{"cell_type":"code","source":["modeltest = HookedTransformer.from_pretrained(\"gpt2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FW7ZRS0wtqs4","executionInfo":{"status":"ok","timestamp":1698810186155,"user_tz":240,"elapsed":7141,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7a4391b2-9303-4ee6-b372-cdcdb3675b34"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2 into HookedTransformer\n"]}]},{"cell_type":"code","source":["example_prompt = \" eleven twelve thirteen fourteen\"\n","example_answer = \" fifteen\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"jTR2muCD-jxb","executionInfo":{"status":"ok","timestamp":1698810195886,"user_tz":240,"elapsed":464,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0e6e61fa-6163-4c47-8b66-0b09a3a61303"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', ' eleven', ' twelve', ' thirteen', ' fourteen']\n","Tokenized answer: [' fifteen']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m17.69\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m45.98\u001b[0m\u001b[1m% Token: | fifteen|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.69</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45.98</span><span style=\"font-weight: bold\">% Token: | fifteen|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 17.69 Prob: 45.98% Token: | fifteen|\n","Top 1th token. Logit: 16.41 Prob: 12.86% Token: | sixteen|\n","Top 2th token. Logit: 16.01 Prob:  8.59% Token: | fourteen|\n","Top 3th token. Logit: 15.49 Prob:  5.12% Token: | twenty|\n","Top 4th token. Logit: 14.70 Prob:  2.31% Token: | thirty|\n","Top 5th token. Logit: 14.65 Prob:  2.21% Token: | thirteen|\n","Top 6th token. Logit: 14.64 Prob:  2.19% Token: | seventeen|\n","Top 7th token. Logit: 14.39 Prob:  1.71% Token: | eighteen|\n","Top 8th token. Logit: 14.13 Prob:  1.31% Token: | eight|\n","Top 9th token. Logit: 13.98 Prob:  1.12% Token: | forty|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' fifteen'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' fifteen'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"eleven twelve thirteen fourteen\"\n","example_answer = \" fifteen\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"U2AdlUrv-oXi","executionInfo":{"status":"ok","timestamp":1698810205458,"user_tz":240,"elapsed":398,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6c90ce2d-dfae-4f06-ca71-1dfa11a7f46c"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'ele', 'ven', ' twelve', ' thirteen', ' fourteen']\n","Tokenized answer: [' fifteen']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.30\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m19.64\u001b[0m\u001b[1m% Token: | fifteen|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.30</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.64</span><span style=\"font-weight: bold\">% Token: | fifteen|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 16.30 Prob: 19.64% Token: | fifteen|\n","Top 1th token. Logit: 16.14 Prob: 16.64% Token: | fourteen|\n","Top 2th token. Logit: 15.92 Prob: 13.40% Token: | sixteen|\n","Top 3th token. Logit: 15.28 Prob:  7.07% Token: | thirteen|\n","Top 4th token. Logit: 14.93 Prob:  4.98% Token: | twenty|\n","Top 5th token. Logit: 14.87 Prob:  4.70% Token: | eighteen|\n","Top 6th token. Logit: 14.87 Prob:  4.69% Token: | seventeen|\n","Top 7th token. Logit: 14.41 Prob:  2.96% Token: | twelve|\n","Top 8th token. Logit: 14.30 Prob:  2.66% Token: | thirty|\n","Top 9th token. Logit: 13.95 Prob:  1.87% Token: | eight|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' fifteen'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' fifteen'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"fifteen sixteen seventeen eighteen\"\n","example_answer = \" nineteen\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"OQpqlEjwED7b","executionInfo":{"status":"ok","timestamp":1698707391141,"user_tz":240,"elapsed":1128,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8fecf252-0059-4bb9-8a7b-9a003278b4c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'fif', 'teen', ' sixteen', ' seventeen', ' eighteen']\n","Tokenized answer: [' nineteen']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.00\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m29.44\u001b[0m\u001b[1m% Token: | nineteen|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.00</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.44</span><span style=\"font-weight: bold\">% Token: | nineteen|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 16.00 Prob: 29.44% Token: | nineteen|\n","Top 1th token. Logit: 15.54 Prob: 18.58% Token: | twenty|\n","Top 2th token. Logit: 15.08 Prob: 11.79% Token: | eighteen|\n","Top 3th token. Logit: 14.78 Prob:  8.69% Token: | seventeen|\n","Top 4th token. Logit: 13.50 Prob:  2.43% Token: | thirty|\n","Top 5th token. Logit: 13.20 Prob:  1.78% Token: | seventy|\n","Top 6th token. Logit: 13.13 Prob:  1.67% Token: | sixteen|\n","Top 7th token. Logit: 13.02 Prob:  1.50% Token: | fifteen|\n","Top 8th token. Logit: 12.92 Prob:  1.36% Token: | nineteenth|\n","Top 9th token. Logit: 12.69 Prob:  1.08% Token: | 19|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' nineteen'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' nineteen'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"fifteen sixteen seventeen eighteen nineteen twenty twenty-\"\n","example_answer = \"one\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"zqBVxYY92c9W","executionInfo":{"status":"ok","timestamp":1698707468471,"user_tz":240,"elapsed":367,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"75b04e1f-8718-4145-92b1-fca7a9759bd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'fif', 'teen', ' sixteen', ' seventeen', ' eighteen', ' nineteen', ' twenty', ' twenty', '-']\n","Tokenized answer: [' one']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m21\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m12.78\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.14\u001b[0m\u001b[1m% Token: | one|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.78</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.14</span><span style=\"font-weight: bold\">% Token: | one|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 18.18 Prob: 31.67% Token: |one|\n","Top 1th token. Logit: 17.21 Prob: 11.96% Token: |four|\n","Top 2th token. Logit: 17.17 Prob: 11.58% Token: |two|\n","Top 3th token. Logit: 16.98 Prob:  9.51% Token: |five|\n","Top 4th token. Logit: 16.73 Prob:  7.43% Token: |nine|\n","Top 5th token. Logit: 16.64 Prob:  6.77% Token: |first|\n","Top 6th token. Logit: 16.32 Prob:  4.94% Token: |three|\n","Top 7th token. Logit: 16.12 Prob:  4.04% Token: |seven|\n","Top 8th token. Logit: 15.82 Prob:  2.99% Token: |eight|\n","Top 9th token. Logit: 15.75 Prob:  2.80% Token: |six|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' one'\u001b[0m, \u001b[1;36m21\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' one'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"fifteen sixteen seventeen eighteen nineteen twenty twenty-one twenty-\"\n","example_answer = \"two\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"3aGqjM762m8a","executionInfo":{"status":"ok","timestamp":1698707465044,"user_tz":240,"elapsed":424,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a6729b3-529d-485b-b4a7-287aa995ee69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'fif', 'teen', ' sixteen', ' seventeen', ' eighteen', ' nineteen', ' twenty', ' twenty', '-', 'one', ' twenty', '-']\n","Tokenized answer: [' two']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m24\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m12.48\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1m% Token: | two|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.48</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03</span><span style=\"font-weight: bold\">% Token: | two|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 19.88 Prob: 43.81% Token: |one|\n","Top 1th token. Logit: 19.11 Prob: 20.35% Token: |two|\n","Top 2th token. Logit: 18.01 Prob:  6.79% Token: |three|\n","Top 3th token. Logit: 17.87 Prob:  5.90% Token: |nine|\n","Top 4th token. Logit: 17.85 Prob:  5.75% Token: |five|\n","Top 5th token. Logit: 17.73 Prob:  5.14% Token: |four|\n","Top 6th token. Logit: 17.47 Prob:  3.93% Token: |seven|\n","Top 7th token. Logit: 17.24 Prob:  3.14% Token: |six|\n","Top 8th token. Logit: 16.50 Prob:  1.50% Token: |eight|\n","Top 9th token. Logit: 16.43 Prob:  1.39% Token: |first|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' two'\u001b[0m, \u001b[1;36m24\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' two'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \"fifteen sixteen seventeen eighteen nineteen twenty twentyone twenty-\"\n","example_answer = \"two\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"-YpPPG7W2xAc","executionInfo":{"status":"ok","timestamp":1698707490632,"user_tz":240,"elapsed":875,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f12cfc16-39a6-4e76-c0db-1bfd298332d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', 'fif', 'teen', ' sixteen', ' seventeen', ' eighteen', ' nineteen', ' twenty', ' twenty', 'one', ' twenty', '-']\n","Tokenized answer: [' two']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m30\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m11.84\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | two|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.84</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | two|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 20.11 Prob: 50.19% Token: |one|\n","Top 1th token. Logit: 18.64 Prob: 11.54% Token: |two|\n","Top 2th token. Logit: 18.30 Prob:  8.22% Token: |four|\n","Top 3th token. Logit: 18.04 Prob:  6.34% Token: |five|\n","Top 4th token. Logit: 17.75 Prob:  4.74% Token: |three|\n","Top 5th token. Logit: 17.59 Prob:  4.03% Token: |first|\n","Top 6th token. Logit: 17.54 Prob:  3.82% Token: |nine|\n","Top 7th token. Logit: 17.38 Prob:  3.27% Token: |six|\n","Top 8th token. Logit: 17.31 Prob:  3.05% Token: |seven|\n","Top 9th token. Logit: 16.66 Prob:  1.60% Token: |eight|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' two'\u001b[0m, \u001b[1;36m30\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' two'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \" twenty twentyone twenty\"\n","example_answer = \"two\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"LWAKBmPqErUK","executionInfo":{"status":"ok","timestamp":1698811829822,"user_tz":240,"elapsed":409,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d5c603ab-d9f7-49b9-f714-1e75d7ff5f3e"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', ' twenty', ' twenty', 'one', ' twenty']\n","Tokenized answer: [' two']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m13.49\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m6.26\u001b[0m\u001b[1m% Token: | two|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.49</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.26</span><span style=\"font-weight: bold\">% Token: | two|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 15.09 Prob: 30.94% Token: |-|\n","Top 1th token. Logit: 14.56 Prob: 18.19% Token: | one|\n","Top 2th token. Logit: 14.03 Prob: 10.75% Token: |two|\n","Top 3th token. Logit: 13.49 Prob:  6.26% Token: | two|\n","Top 4th token. Logit: 12.84 Prob:  3.25% Token: |one|\n","Top 5th token. Logit: 12.84 Prob:  3.24% Token: | twenty|\n","Top 6th token. Logit: 11.94 Prob:  1.32% Token: | five|\n","Top 7th token. Logit: 11.62 Prob:  0.96% Token: | three|\n","Top 8th token. Logit: 11.62 Prob:  0.96% Token: | seven|\n","Top 9th token. Logit: 11.59 Prob:  0.94% Token: |three|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' two'\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' two'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["example_prompt = \" sixty sixtyone sixtytwo sixtythree sixty\"\n","example_answer = \"four\"\n","utils.test_prompt(example_prompt, example_answer, modeltest, prepend_bos=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"Fdicjw_zE3yE","executionInfo":{"status":"ok","timestamp":1698811860512,"user_tz":240,"elapsed":419,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3c15ce34-3193-4e58-f923-49ac8d0aeff8"},"execution_count":141,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized prompt: ['<|endoftext|>', ' sixty', ' sixty', 'one', ' sixty', 'two', ' s', 'ixt', 'yth', 'ree', ' sixty']\n","Tokenized answer: [' four']\n"]},{"output_type":"display_data","data":{"text/plain":["Performance on answer token:\n","\u001b[1mRank: \u001b[0m\u001b[1;36m15\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m11.79\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.57\u001b[0m\u001b[1m% Token: | four|\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n","<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.79</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.57</span><span style=\"font-weight: bold\">% Token: | four|</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Top 0th token. Logit: 16.08 Prob: 41.34% Token: |three|\n","Top 1th token. Logit: 14.59 Prob:  9.31% Token: |seven|\n","Top 2th token. Logit: 14.41 Prob:  7.77% Token: |two|\n","Top 3th token. Logit: 14.31 Prob:  7.05% Token: | three|\n","Top 4th token. Logit: 13.63 Prob:  3.59% Token: |one|\n","Top 5th token. Logit: 13.53 Prob:  3.22% Token: |-|\n","Top 6th token. Logit: 13.43 Prob:  2.93% Token: | one|\n","Top 7th token. Logit: 13.20 Prob:  2.32% Token: |four|\n","Top 8th token. Logit: 12.96 Prob:  1.82% Token: |five|\n","Top 9th token. Logit: 12.71 Prob:  1.43% Token: |six|\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' four'\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' four'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">)]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn","executionInfo":{"status":"ok","timestamp":1698808396811,"user_tz":240,"elapsed":39,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Repalce io_tokens with correct answer (next, which is '5') and s_tokens with incorrect (current, which repeats)"],"metadata":{"id":"exuTCQ_XmmFP"}},{"cell_type":"code","source":["pos_dict = {\n","    'S1': 0,\n","    'S2': 1,\n","    'S3': 2,\n","    'S4': 3,\n","}"],"metadata":{"id":"sGHl4RZTE98L","executionInfo":{"status":"ok","timestamp":1698808396812,"user_tz":240,"elapsed":39,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen']\n","    words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve']\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': words[i],\n","            'S2': words[i+1],\n","            'S3': words[i+2],\n","            'S4': words[i+3],\n","            'corr': words[i+4],\n","            'incorr': words[i],  # this is arbitrary\n","            'text': f\"{words[i]} {words[i+1]} {words[i+2]} {words[i+3]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","# prompts_list = generate_prompts_list(0, 6)\n","# prompts_list = generate_prompts_list(0, 15)\n","prompts_list = generate_prompts_list(0, 8)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list"],"metadata":{"id":"u0NPSKcZ1iDe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698809954537,"user_tz":240,"elapsed":596,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"328a60e8-b139-4cdb-dde5-1709d78e3bc7"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': 'one',\n","  'S2': 'two',\n","  'S3': 'three',\n","  'S4': 'four',\n","  'corr': 'five',\n","  'incorr': 'one',\n","  'text': 'one two three four'},\n"," {'S1': 'two',\n","  'S2': 'three',\n","  'S3': 'four',\n","  'S4': 'five',\n","  'corr': 'six',\n","  'incorr': 'two',\n","  'text': 'two three four five'},\n"," {'S1': 'three',\n","  'S2': 'four',\n","  'S3': 'five',\n","  'S4': 'six',\n","  'corr': 'seven',\n","  'incorr': 'three',\n","  'text': 'three four five six'},\n"," {'S1': 'four',\n","  'S2': 'five',\n","  'S3': 'six',\n","  'S4': 'seven',\n","  'corr': 'eight',\n","  'incorr': 'four',\n","  'text': 'four five six seven'},\n"," {'S1': 'five',\n","  'S2': 'six',\n","  'S3': 'seven',\n","  'S4': 'eight',\n","  'corr': 'nine',\n","  'incorr': 'five',\n","  'text': 'five six seven eight'},\n"," {'S1': 'six',\n","  'S2': 'seven',\n","  'S3': 'eight',\n","  'S4': 'nine',\n","  'corr': 'ten',\n","  'incorr': 'six',\n","  'text': 'six seven eight nine'},\n"," {'S1': 'seven',\n","  'S2': 'eight',\n","  'S3': 'nine',\n","  'S4': 'ten',\n","  'corr': 'eleven',\n","  'incorr': 'seven',\n","  'text': 'seven eight nine ten'},\n"," {'S1': 'eight',\n","  'S2': 'nine',\n","  'S3': 'ten',\n","  'S4': 'eleven',\n","  'corr': 'twelve',\n","  'incorr': 'eight',\n","  'text': 'eight nine ten eleven'}]"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen']\n","    words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve']\n","    prompts_list = []\n","    for i in range(x, y):\n","        r1 = random.choice(words)\n","        r2 = random.choice(words)\n","        while True:\n","            r3_ind = random.randint(0,len(words)-1)\n","            r4_ind = random.randint(0,len(words)-1)\n","            if words[r3_ind] != words[r4_ind-1]:\n","                break\n","        r3 = words[r3_ind]\n","        r4 = words[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': str(r1),\n","            'incorr': str(r4),\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(0, 8)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","# prompts_list_2"],"metadata":{"id":"dzzLlCqZS_wl","executionInfo":{"status":"ok","timestamp":1698809529156,"user_tz":240,"elapsed":1432,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["prompts_list_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTHuAvD58Y4z","executionInfo":{"status":"ok","timestamp":1698809616344,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e7fc5139-2aec-4da0-c966-5cab48d6adbb"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': 'eight',\n","  'S2': 'two',\n","  'S3': 'four',\n","  'S4': 'three',\n","  'corr': 'eight',\n","  'incorr': 'three',\n","  'text': 'eight two four three'},\n"," {'S1': 'seven',\n","  'S2': 'seven',\n","  'S3': 'five',\n","  'S4': 'four',\n","  'corr': 'seven',\n","  'incorr': 'four',\n","  'text': 'seven seven five four'},\n"," {'S1': 'eleven',\n","  'S2': 'twelve',\n","  'S3': 'twelve',\n","  'S4': 'six',\n","  'corr': 'eleven',\n","  'incorr': 'six',\n","  'text': 'eleven twelve twelve six'},\n"," {'S1': 'eight',\n","  'S2': 'six',\n","  'S3': 'two',\n","  'S4': 'four',\n","  'corr': 'eight',\n","  'incorr': 'four',\n","  'text': 'eight six two four'},\n"," {'S1': 'one',\n","  'S2': 'two',\n","  'S3': 'one',\n","  'S4': 'five',\n","  'corr': 'one',\n","  'incorr': 'five',\n","  'text': 'one two one five'},\n"," {'S1': 'ten',\n","  'S2': 'seven',\n","  'S3': 'nine',\n","  'S4': 'seven',\n","  'corr': 'ten',\n","  'incorr': 'seven',\n","  'text': 'ten seven nine seven'},\n"," {'S1': 'eight',\n","  'S2': 'four',\n","  'S3': 'seven',\n","  'S4': 'two',\n","  'corr': 'eight',\n","  'incorr': 'two',\n","  'text': 'eight four seven two'},\n"," {'S1': 'two',\n","  'S2': 'three',\n","  'S3': 'twelve',\n","  'S4': 'eight',\n","  'corr': 'two',\n","  'incorr': 'eight',\n","  'text': 'two three twelve eight'}]"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["dataset.toks.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDUlAdtL8PR7","executionInfo":{"status":"ok","timestamp":1698809596739,"user_tz":240,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"396fcd8c-26bf-4d05-8692-a880381cce0a"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 4])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["dataset_2.toks.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_8T6deI8U9j","executionInfo":{"status":"ok","timestamp":1698809606733,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"96ed55c4-7280-4b1d-f677-4b0b43fb31a9"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 5])"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["dataset_2.toks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0lAe9hlO8m93","executionInfo":{"status":"ok","timestamp":1698809674729,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d651a83d-14e1-481d-ea6f-f032a695832d"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[26022,   734,  1440,  1115, 50256],\n","        [26548,  3598,  1936,  1440, 50256],\n","        [11129,   574, 14104, 14104,  2237],\n","        [26022,  2237,   734,  1440, 50256],\n","        [  505,   734,   530,  1936, 50256],\n","        [ 1452,  3598,  5193,  3598, 50256],\n","        [26022,  1440,  3598,   734, 50256],\n","        [11545,  1115, 14104,  3624, 50256]], dtype=torch.int32)"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["model.tokenizer.decode([26022])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3xt2Ygtj8r1q","executionInfo":{"status":"ok","timestamp":1698809700454,"user_tz":240,"elapsed":3454,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"66a14b3a-f7a6-4c24-b2bf-f8e744b77a7e"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'eight'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["model.tokenizer.decode([50256])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CjvRiCe18u0W","executionInfo":{"status":"ok","timestamp":1698809708296,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"918fb32f-d5aa-4ca2-f107-0405dca6a8c2"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|endoftext|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["model.tokenizer.decode([2237])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"6uDPhirK8wpX","executionInfo":{"status":"ok","timestamp":1698809716654,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2a988cec-24fb-40c8-d240-f819ab17f547"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' six'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["model.tokenizer.decode([14104])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"oaxnlxPr8zgF","executionInfo":{"status":"ok","timestamp":1698809732772,"user_tz":240,"elapsed":356,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"19e4b7d6-db68-4e7f-8e6f-791593521f9a"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' twelve'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["model.tokenizer.decode([11129,   574, 14104, 14104,  2237])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7lDGCBJZ8_-J","executionInfo":{"status":"ok","timestamp":1698809847012,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"519ec05a-84d7-4f05-ee22-23450a6538bd"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'eleven twelve twelve six'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["model.tokenizer.decode([11129])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"x_60aD_S9Yi9","executionInfo":{"status":"ok","timestamp":1698809892308,"user_tz":240,"elapsed":936,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fa5fa2fa-b005-4826-c100-73504e58e72d"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ele'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["model.tokenizer.decode([574])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"X86wGMcS9Ub4","executionInfo":{"status":"ok","timestamp":1698809866644,"user_tz":240,"elapsed":1382,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"35b3aa73-ab33-422f-b7ff-64c2dabd5d3a"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ven'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["dataset.toks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1tvwNr59nPd","executionInfo":{"status":"ok","timestamp":1698809939068,"user_tz":240,"elapsed":376,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e44e0f89-e3e3-42dc-a743-3a15ea11fb4a"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  505,   734,  1115,  1440],\n","        [11545,  1115,  1440,  1936],\n","        [15542,  1440,  1936,  2237],\n","        [14337,  1936,  2237,  3598],\n","        [13261,  2237,  3598,  3624],\n","        [19412,  3598,  3624,  5193],\n","        [26548,  3624,  5193,  3478],\n","        [26022,  5193,  3478, 22216]], dtype=torch.int32)"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["model.tokenizer.decode([26022,  5193,  3478, 22216])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jfQ2ysum93XU","executionInfo":{"status":"ok","timestamp":1698810009989,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"af2f884d-5438-46b5-bf32-c6f0fb9f0eb2"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'eight nine ten eleven'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["model.tokenizer('eleven')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWbJBw3n-ELd","executionInfo":{"status":"ok","timestamp":1698810063979,"user_tz":240,"elapsed":528,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"171e8baf-6e0b-49ad-973f-d30d56198fff"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [11129, 574], 'attention_mask': [1, 1]}"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["model.tokenizer('ten eleven')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Rbq8Tve-Hf6","executionInfo":{"status":"ok","timestamp":1698810072514,"user_tz":240,"elapsed":336,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a224fbe7-c629-48e8-adc5-786ff77de4a2"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [1452, 22216], 'attention_mask': [1, 1]}"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["model.tokenizer(' eleven')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xc9OvaLO-RX7","executionInfo":{"status":"ok","timestamp":1698810112452,"user_tz":240,"elapsed":352,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"948e3b45-99c3-4ba5-b484-48c81931bfbb"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [22216], 'attention_mask': [1]}"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["# [{'S1': 'ten',\n","#   'S2': 'seven',\n","#   'S3': 'five',\n","#   'S4': 'five',\n","#   'corr': 'ten',\n","#   'incorr': 'five',\n","#   'text': 'ten seven five five'},\n","#  {'S1': 'two',\n","#   'S2': 'one',\n","#   'S3': 'ten',\n","#   'S4': 'four',\n","#   'corr': 'two',\n","#   'incorr': 'four',\n","#   'text': 'two one ten four'},\n","#  {'S1': 'one',\n","#   'S2': 'seven',\n","#   'S3': 'five',\n","#   'S4': 'one',\n","#   'corr': 'one',\n","#   'incorr': 'one',\n","#   'text': 'one seven five one'},\n","#  {'S1': 'one',\n","#   'S2': 'six',\n","#   'S3': 'three',\n","#   'S4': 'five',\n","#   'corr': 'one',\n","#   'incorr': 'five',\n","#   'text': 'one six three five'},\n","#  {'S1': 'five',\n","#   'S2': 'nine',\n","#   'S3': 'seven',\n","#   'S4': 'four',\n","#   'corr': 'five',\n","#   'incorr': 'four',\n","#   'text': 'five nine seven four'},\n","#  {'S1': 'eight',\n","#   'S2': 'four',\n","#   'S3': 'ten',\n","#   'S4': 'four',\n","#   'corr': 'eight',\n","#   'incorr': 'four',\n","#   'text': 'eight four ten four'}]"],"metadata":{"id":"mYiNqs9243Zs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompts_list_2 = [{'S1': 'ten',\n","  'S2': 'seven',\n","  'S3': 'nine',\n","  'S4': 'seven',\n","  'corr': 'ten',\n","  'incorr': 'seven',\n","  'text': 'ten seven nine seven'},\n"," {'S1': 'six',\n","  'S2': 'ten',\n","  'S3': 'six',\n","  'S4': 'five',\n","  'corr': 'six',\n","  'incorr': 'five',\n","  'text': 'six ten six five'},\n"," {'S1': 'six',\n","  'S2': 'eight',\n","  'S3': 'six',\n","  'S4': 'three',\n","  'corr': 'six',\n","  'incorr': 'three',\n","  'text': 'six eight six three'},\n"," {'S1': 'two',\n","  'S2': 'two',\n","  'S3': 'six',\n","  'S4': 'one',\n","  'corr': 'two',\n","  'incorr': 'one',\n","  'text': 'two two six one'},\n"," {'S1': 'nine',\n","  'S2': 'five',\n","  'S3': 'nine',\n","  'S4': 'two',\n","  'corr': 'nine',\n","  'incorr': 'two',\n","  'text': 'nine five nine two'},\n"," {'S1': 'five',\n","  'S2': 'ten',\n","  'S3': 'eight',\n","  'S4': 'eight',\n","  'corr': 'five',\n","  'incorr': 'eight',\n","  'text': 'five ten eight eight'}]\n","\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"ach90Fro4ztn","executionInfo":{"status":"ok","timestamp":1698808718091,"user_tz":240,"elapsed":367,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"GCCCoO0V7L7J"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"CgD41x5nbKKP","executionInfo":{"status":"ok","timestamp":1698808396812,"user_tz":240,"elapsed":31,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"LqsdFmbVMntG","executionInfo":{"status":"ok","timestamp":1698808396812,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["We can also prevent redundant computation of the full circuit score by storing it and just passing it in to the function."],"metadata":{"id":"xUlhxzuGUr1y"}},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"GTOk3N3evb3c","executionInfo":{"status":"ok","timestamp":1698808396813,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"flTHN2eQvapG","executionInfo":{"status":"ok","timestamp":1698808396813,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# test"],"metadata":{"id":"GU1gIN_Z5cZG"}},{"cell_type":"code","source":["model.tokenizer('12')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cyd6jCSD6rlc","executionInfo":{"status":"ok","timestamp":1698809169971,"user_tz":240,"elapsed":366,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d5b8cf8c-b009-4c7b-f676-9b098aaeb8dc"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [1065], 'attention_mask': [1]}"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# fb 80, digits incr\n","# https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\n","circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"id":"EGvHDy-e5eD9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1698809539976,"user_tz":240,"elapsed":3666,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0753e373-85f2-4c16-84b1-a4a048843d20"},"execution_count":47,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-af983287933a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[...\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmean_ablate_by_lst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-c26448ca9fee>\u001b[0m in \u001b[0;36mmean_ablate_by_lst\u001b[0;34m(lst, model, print_output)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_circuit_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mean_ablation_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mioi_logits_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0morig_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_to_ave_logit_diff_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_logits_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    549\u001b[0m                     )\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    552\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1036\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, head_index, query_pos, key_pos]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         z = self.hook_z(\n\u001b[0m\u001b[1;32m    610\u001b[0m             einsum(\n\u001b[1;32m    611\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mfull_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfull_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             full_hook.__name__ = (\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mhook_fn_mask_z\u001b[0;34m(z, hook, heads_and_posns_to_keep, means)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Set z values to the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_for_this_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"]}]},{"cell_type":"markdown","source":["# all space in front"],"metadata":{"id":"bqtjOR7t-7cO"}},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty']\n","    words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve']\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': words[i],\n","            'S2': words[i+1],\n","            'S3': words[i+2],\n","            'S4': words[i+3],\n","            'corr': words[i+4],\n","            'incorr': words[i+3],  # this is arbitrary\n","            'text': f\"{words[i]}{words[i+1]}{words[i+2]}{words[i+3]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","# prompts_list = generate_prompts_list(0, 6)\n","# prompts_list = generate_prompts_list(0, 15)\n","prompts_list = generate_prompts_list(0, 8)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698810654444,"user_tz":240,"elapsed":13,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a4aaf4ac-6730-4d8b-8745-19b8cd407fe5","id":"EciTE1If-825"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': ' one',\n","  'S2': ' two',\n","  'S3': ' three',\n","  'S4': ' four',\n","  'corr': ' five',\n","  'incorr': ' four',\n","  'text': ' one two three four'},\n"," {'S1': ' two',\n","  'S2': ' three',\n","  'S3': ' four',\n","  'S4': ' five',\n","  'corr': ' six',\n","  'incorr': ' five',\n","  'text': ' two three four five'},\n"," {'S1': ' three',\n","  'S2': ' four',\n","  'S3': ' five',\n","  'S4': ' six',\n","  'corr': ' seven',\n","  'incorr': ' six',\n","  'text': ' three four five six'},\n"," {'S1': ' four',\n","  'S2': ' five',\n","  'S3': ' six',\n","  'S4': ' seven',\n","  'corr': ' eight',\n","  'incorr': ' seven',\n","  'text': ' four five six seven'},\n"," {'S1': ' five',\n","  'S2': ' six',\n","  'S3': ' seven',\n","  'S4': ' eight',\n","  'corr': ' nine',\n","  'incorr': ' eight',\n","  'text': ' five six seven eight'},\n"," {'S1': ' six',\n","  'S2': ' seven',\n","  'S3': ' eight',\n","  'S4': ' nine',\n","  'corr': ' ten',\n","  'incorr': ' nine',\n","  'text': ' six seven eight nine'},\n"," {'S1': ' seven',\n","  'S2': ' eight',\n","  'S3': ' nine',\n","  'S4': ' ten',\n","  'corr': ' eleven',\n","  'incorr': ' ten',\n","  'text': ' seven eight nine ten'},\n"," {'S1': ' eight',\n","  'S2': ' nine',\n","  'S3': ' ten',\n","  'S4': ' eleven',\n","  'corr': ' twelve',\n","  'incorr': ' eleven',\n","  'text': ' eight nine ten eleven'}]"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen']\n","    words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve']\n","    prompts_list = []\n","    for i in range(x, y):\n","        r1 = random.choice(words)\n","        r2 = random.choice(words)\n","        while True:\n","            r3_ind = random.randint(0,len(words)-1)\n","            r4_ind = random.randint(0,len(words)-1)\n","            if words[r3_ind] != words[r4_ind-1]:\n","                break\n","        r3 = words[r3_ind]\n","        r4 = words[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': str(r1),\n","            'incorr': str(r4),\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(0, 8)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","# prompts_list_2"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698810391013,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"ERzmF3Fr-83C"},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["dataset_2.toks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzGW4X6__fet","executionInfo":{"status":"ok","timestamp":1698810431751,"user_tz":240,"elapsed":442,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c890eb85-e90d-4b54-9016-ed4dcef036e5"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1440,   220,  3478,   220, 14104,   220,  3624],\n","        [ 1440,   220,  1936,   220, 22216,   220,  1936],\n","        [  734,   220,  1115,   220,  3478,   220,  1936],\n","        [ 3598,   220,  3598,   220,  1936,   220,  5193],\n","        [ 1440,   220, 22216,   220,  1936,   220,  1936],\n","        [ 2237,   220,  3624,   220,  1115,   220,  1936],\n","        [ 5193,   220,  3598,   220,  2237,   220,  1440],\n","        [ 3624,   220,  5193,   220, 22216,   220,  2237]], dtype=torch.int32)"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["model.tokenizer.decode([1440,   220,  3478,   220, 14104,   220,  3624])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7zuNNzWi_oAe","executionInfo":{"status":"ok","timestamp":1698810469458,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"88081b0e-c949-4f83-8d04-feb61d67ae5a"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' four  ten  twelve  eight'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["model.tokenizer.decode([1440])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kXMCEe4q_rw7","executionInfo":{"status":"ok","timestamp":1698810485519,"user_tz":240,"elapsed":380,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0fe827fa-661b-47d2-fa81-26e64582df66"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' four'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["model.tokenizer.decode([220,  3478])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"XTy963FM_w_E","executionInfo":{"status":"ok","timestamp":1698810509074,"user_tz":240,"elapsed":491,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"49a2b56e-a2e0-4ee1-ec5e-6a07d4cdca0f"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'  ten'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["# fb 80, digits incr\n","# https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\n","circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"2oDruTJz_YNZ","executionInfo":{"status":"error","timestamp":1698810404286,"user_tz":240,"elapsed":4041,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dc991ce1-0beb-4e08-cd04-61c3ac187c1f"},"execution_count":74,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-74-af983287933a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[...\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmean_ablate_by_lst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-c26448ca9fee>\u001b[0m in \u001b[0;36mmean_ablate_by_lst\u001b[0;34m(lst, model, print_output)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_circuit_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mean_ablation_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mioi_logits_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0morig_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_to_ave_logit_diff_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_logits_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    549\u001b[0m                     )\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 residual = block(\n\u001b[0m\u001b[1;32m    552\u001b[0m                     \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                     \u001b[0;31m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;31m# queries, keys and values, independently.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m             self.attn(\n\u001b[0m\u001b[1;32m   1036\u001b[0m                 \u001b[0mquery_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshortformer_pos_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, head_index, query_pos, key_pos]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         z = self.hook_z(\n\u001b[0m\u001b[1;32m    610\u001b[0m             einsum(\n\u001b[1;32m    611\u001b[0m                 \u001b[0;31m\"\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mkey_pos\u001b[0m \u001b[0mhead_index\u001b[0m \u001b[0md_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m                         \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mfull_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfull_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             full_hook.__name__ = (\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mhook_fn_mask_z\u001b[0;34m(z, hook, heads_and_posns_to_keep, means)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Set z values to the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_for_this_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (4) at non-singleton dimension 1"]}]},{"cell_type":"markdown","source":["Make sure to get rid of the spaces too!"],"metadata":{"id":"IJuVCz2i_5OU"}},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'twenty']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen']\n","    # words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen']\n","    words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve']\n","    prompts_list = []\n","    for i in range(x, y):\n","        r1 = random.choice(words)\n","        r2 = random.choice(words)\n","        while True:\n","            r3_ind = random.randint(0,len(words)-1)\n","            r4_ind = random.randint(0,len(words)-1)\n","            if words[r3_ind] != words[r4_ind-1]:\n","                break\n","        r3 = words[r3_ind]\n","        r4 = words[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': str(r1),\n","            'incorr': str(r4),\n","            'text': f\"{r1}{r2}{r3}{r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(0, 8)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPeSB2QV_7Yf","executionInfo":{"status":"ok","timestamp":1698810598106,"user_tz":240,"elapsed":417,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cc3317a0-464a-42e6-cb90-744fef8cb09e"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': ' ten',\n","  'S2': ' eleven',\n","  'S3': ' five',\n","  'S4': ' two',\n","  'corr': ' ten',\n","  'incorr': ' two',\n","  'text': ' ten eleven five two'},\n"," {'S1': ' eight',\n","  'S2': ' four',\n","  'S3': ' twelve',\n","  'S4': ' five',\n","  'corr': ' eight',\n","  'incorr': ' five',\n","  'text': ' eight four twelve five'},\n"," {'S1': ' ten',\n","  'S2': ' two',\n","  'S3': ' nine',\n","  'S4': ' two',\n","  'corr': ' ten',\n","  'incorr': ' two',\n","  'text': ' ten two nine two'},\n"," {'S1': ' two',\n","  'S2': ' twelve',\n","  'S3': ' twelve',\n","  'S4': ' five',\n","  'corr': ' two',\n","  'incorr': ' five',\n","  'text': ' two twelve twelve five'},\n"," {'S1': ' twelve',\n","  'S2': ' one',\n","  'S3': ' twelve',\n","  'S4': ' twelve',\n","  'corr': ' twelve',\n","  'incorr': ' twelve',\n","  'text': ' twelve one twelve twelve'},\n"," {'S1': ' five',\n","  'S2': ' seven',\n","  'S3': ' five',\n","  'S4': ' four',\n","  'corr': ' five',\n","  'incorr': ' four',\n","  'text': ' five seven five four'},\n"," {'S1': ' six',\n","  'S2': ' nine',\n","  'S3': ' five',\n","  'S4': ' two',\n","  'corr': ' six',\n","  'incorr': ' two',\n","  'text': ' six nine five two'},\n"," {'S1': ' eleven',\n","  'S2': ' six',\n","  'S3': ' seven',\n","  'S4': ' ten',\n","  'corr': ' eleven',\n","  'incorr': ' ten',\n","  'text': ' eleven six seven ten'}]"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["# fb 80, digits incr\n","# https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\n","circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D50EvEaiADuc","executionInfo":{"status":"ok","timestamp":1698810707677,"user_tz":240,"elapsed":2950,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"587190fb-8c9b-4a2a-c6d9-d1c41756f086"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: nan\n"]},{"output_type":"execute_result","data":{"text/plain":["nan"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["lst = circuit\n","CIRCUIT = {\n","        \"number mover\": lst,\n","        \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","SEQ_POS_TO_KEEP = {\n","    \"number mover\": \"end\",\n","    \"number mover 4\": \"S4\",\n","    \"number mover 3\": \"S3\",\n","    \"number mover 2\": \"S2\",\n","    \"number mover 1\": \"S1\",\n","}\n","\n","\n","model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)\n","\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)"],"metadata":{"id":"OvEGzkuaApcZ","executionInfo":{"status":"ok","timestamp":1698810770542,"user_tz":240,"elapsed":2423,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["io_logits = ioi_logits_original[range(ioi_logits_original.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]"],"metadata":{"id":"3XFR_JwfA5S6","executionInfo":{"status":"ok","timestamp":1698810905252,"user_tz":240,"elapsed":558,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["s_logits = ioi_logits_original[range(ioi_logits_original.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","# Find logit difference\n","answer_logit_diff = io_logits - s_logits\n","answer_logit_diff.mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n32sL4ZVBLo7","executionInfo":{"status":"ok","timestamp":1698810905748,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0466fc3d-9b8b-445f-d6f1-584ef186eb74"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0., device='cuda:0')"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["io_logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndxk-midBYCX","executionInfo":{"status":"ok","timestamp":1698810924468,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"71728d03-7011-4195-d474-8760174bedbf"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5.8010, 5.0481, 6.4777, 6.5491, 7.3650, 6.9085, 7.0106, 7.5116],\n","       device='cuda:0')"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["s_logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzDvYw9oBWlf","executionInfo":{"status":"ok","timestamp":1698810919127,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"45e1ea44-3206-447d-a1b8-43845479a579"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5.8010, 5.0481, 6.4777, 6.5491, 7.3650, 6.9085, 7.0106, 7.5116],\n","       device='cuda:0')"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["dataset.io_tokenIDs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FoavpxJdBZ8R","executionInfo":{"status":"ok","timestamp":1698810931865,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"eedd802d-d60f-4f9f-f622-391894c197c6"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[220, 220, 220, 220, 220, 220, 220, 220]"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["dataset.s_tokenIDs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pi1ETVgGBb0M","executionInfo":{"status":"ok","timestamp":1698810939199,"user_tz":240,"elapsed":383,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"40190d4e-21cb-471b-acb9-e9fdc6a9193d"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[220, 220, 220, 220, 220, 220, 220, 220]"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["model.tokenizer.decode([220])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SDTP0hiWBsDZ","executionInfo":{"status":"ok","timestamp":1698811011155,"user_tz":240,"elapsed":393,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4d514675-9176-4c7a-c13e-3482c0437535"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["orig_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0sMxn6JAz0L","executionInfo":{"status":"ok","timestamp":1698810775418,"user_tz":240,"elapsed":395,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4913446f-ebfc-4322-c86a-ab901b6b91be"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0., device='cuda:0')"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GSsoq4i3A023","executionInfo":{"status":"ok","timestamp":1698810779221,"user_tz":240,"elapsed":381,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"90e31e7a-690f-402c-b495-6085ec232b70"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0., device='cuda:0')"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve']\n","\n","i=0\n","print(words[i+4])\n","print(words[i+3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JEaSCMKYBxsp","executionInfo":{"status":"ok","timestamp":1698811063306,"user_tz":240,"elapsed":359,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"855e05f1-2066-49c7-8be5-e7842206abba"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":[" five\n"," four\n"]}]},{"cell_type":"code","source":["model.tokenizer.encode(\" \" + words[i+4])[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUMQovWkCESV","executionInfo":{"status":"ok","timestamp":1698811123895,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e9735433-d00e-4167-91f0-dbdadcb34227"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["220"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["model.tokenizer.encode(\" \" + words[i+4])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XYhWf86jCLPW","executionInfo":{"status":"ok","timestamp":1698811134078,"user_tz":240,"elapsed":393,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"79bc879b-8513-488d-9149-fdc723014c83"},"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[220, 1936]"]},"metadata":{},"execution_count":103}]},{"cell_type":"markdown","source":["The issue is that it tries to add a space in front! Redo dataset making without spaces"],"metadata":{"id":"mU1GddXQCM5z"}},{"cell_type":"markdown","source":["# redo dataset without spaces"],"metadata":{"id":"YyiuksuLCQSA"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"o3UpGhV6CXE7","executionInfo":{"status":"ok","timestamp":1698811240552,"user_tz":240,"elapsed":412,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve', ' thirteen', ' fourteen', ' fifteen', ' sixteen', ' seventeen', ' eighteen', ' nineteen', ' twenty']\n","    # words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve']\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': words[i],\n","            'S2': words[i+1],\n","            'S3': words[i+2],\n","            'S4': words[i+3],\n","            'corr': words[i+4],\n","            'incorr': words[i+3],  # this is arbitrary\n","            'text': f\"{words[i]}{words[i+1]}{words[i+2]}{words[i+3]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","# prompts_list = generate_prompts_list(0, 8)\n","prompts_list = generate_prompts_list(0, 16)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698811385495,"user_tz":240,"elapsed":387,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"1qdMRW7kCWBR"},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve', ' thirteen', ' fourteen', ' fifteen', ' sixteen', ' seventeen', ' eighteen', ' nineteen', ' twenty']\n","    # words = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten', ' eleven', ' twelve']\n","    prompts_list = []\n","    for i in range(x, y):\n","        r1 = random.choice(words)\n","        r2 = random.choice(words)\n","        while True:\n","            r3_ind = random.randint(0,len(words)-1)\n","            r4_ind = random.randint(0,len(words)-1)\n","            if words[r3_ind] != words[r4_ind-1]:\n","                break\n","        r3 = words[r3_ind]\n","        r4 = words[r4_ind]\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': str(r1),\n","            'incorr': str(r4),\n","            'text': f\"{r1}{r2}{r3}{r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","# prompts_list_2 = generate_prompts_list_corr(0, 8)\n","prompts_list_2 = generate_prompts_list_corr(0, 16)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698811701310,"user_tz":240,"elapsed":368,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"szdRVzFPCWBS"},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61QILI7yChjM","executionInfo":{"status":"ok","timestamp":1698811705194,"user_tz":240,"elapsed":2420,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"46c9eb63-a74f-446a-8cc8-a621c0511d5d"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 57.2228\n"]},{"output_type":"execute_result","data":{"text/plain":["57.222774505615234"]},"metadata":{},"execution_count":137}]},{"cell_type":"markdown","source":["# try other tasks circs"],"metadata":{"id":"dC4VKp97r1-e"}},{"cell_type":"markdown","source":["## gt, IOI"],"metadata":{"id":"86CvoL8v2_HD"}},{"cell_type":"code","source":["# greater-than\n","circuit = [(0, 1), (0, 3), (0, 5), (5, 5), (6, 1), (6, 9), (7, 10), (8, 11), (9, 1)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZffKcon6IOI","executionInfo":{"status":"ok","timestamp":1698797491805,"user_tz":240,"elapsed":2837,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b2548434-7231-4d1b-990b-2b6fc062d257"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 20.8534\n"]},{"output_type":"execute_result","data":{"text/plain":["20.853376388549805"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# IOI\n","circuit = [(0, 1), (0, 10), (2, 2), (3, 0), (4, 11), (5, 5), (5, 8), (5, 9), (6, 9), (7, 3), (7, 9), (8, 6), (8, 10), (9, 0), (9, 6), (9, 7), (9, 9), (10, 0), (10, 1), (10, 2), (10, 6), (10, 7), (10, 10), (11, 2), (11, 9), (11, 10)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyVcwmUksWoO","executionInfo":{"status":"ok","timestamp":1698797493976,"user_tz":240,"elapsed":2190,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"199b78fb-7e0c-4eb7-c52e-95f221f7bbb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 12.2694\n"]},{"output_type":"execute_result","data":{"text/plain":["12.269357681274414"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["## fb 80"],"metadata":{"id":"keXfoIUr25zM"}},{"cell_type":"code","source":["# fb 80, digits incr\n","# https://colab.research.google.com/drive/1mFWmGAKtigFcqqWWMCwU7wWQY2HT5ZOo#scrollTo=lJEY-Zs2g_a5&line=1&uniqifier=1\n","circuit = [(1, 5), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 10), (4, 11), (5, 0), (5, 2), (5, 3), (5, 4), (5, 6), (6, 3), (6, 8), (6, 10), (7, 0), (7, 2), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 9), (8, 11), (9, 1), (11, 8)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgvJ4VYB5F2s","executionInfo":{"status":"ok","timestamp":1698797484798,"user_tz":240,"elapsed":5373,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e0b3f714-3a53-4989-fe08-c84c1d003b53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 74.7523\n"]},{"output_type":"execute_result","data":{"text/plain":["74.7523422241211"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# fb 80, numwords\n","# https://colab.research.google.com/drive/1QTv-4osLHadCAay0beew-xlXszPCG88s#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","circuit = [(3, 2), (4, 4), (4, 8), (4, 10), (4, 11), (5, 5), (5, 6), (5, 7), (5, 8), (6, 1), (6, 7), (6, 9), (6, 10), (7, 0), (7, 2), (7, 5), (7, 6), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 11), (9, 1), (10, 2)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-DO40-mr6N1","executionInfo":{"status":"ok","timestamp":1698797486730,"user_tz":240,"elapsed":1958,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ea3ed332-0897-4697-d33b-667e0e3e2754"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 81.9778\n"]},{"output_type":"execute_result","data":{"text/plain":["81.9777603149414"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# fb 80, months\n","# https://colab.research.google.com/drive/1lhQqlizYGMC11vzp6I9mJ3dyxIr8tV3l#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","circuit = [(4, 4), (7, 11), (8, 6), (8, 9), (8, 11), (9, 1), (9, 5), (11, 10)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hFkNI31osLHI","executionInfo":{"status":"ok","timestamp":1698797488976,"user_tz":240,"elapsed":2257,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1a625e99-704b-46c7-b5d0-b5a0fcd79815"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 36.0939\n"]},{"output_type":"execute_result","data":{"text/plain":["36.09392547607422"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## bf 97"],"metadata":{"id":"W2rrj4EK3Ej5"}},{"cell_type":"code","source":["# digits incr\n","circuit = [(0, 1), (0, 2), (0, 3), (0, 5), (0, 8), (0, 9), (0, 10), (1, 0), (1, 5), (1, 7), (2, 0), (2, 2), (2, 3), (2, 4), (2, 6), (2, 9), (3, 3), (3, 7), (3, 11), (4, 4), (4, 7), (4, 10), (5, 2), (5, 3), (5, 4), (5, 6), (5, 8), (5, 11), (6, 1), (6, 3), (6, 6), (6, 8), (6, 10), (7, 2), (7, 6), (7, 8), (7, 10), (7, 11), (8, 6), (8, 8), (8, 11), (9, 1), (11, 10)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698808503218,"user_tz":240,"elapsed":5734,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"534fd62f-1566-412a-94e3-b767dfa50d6e","id":"O208OQsF3Ej6"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 74.0674\n"]},{"output_type":"execute_result","data":{"text/plain":["74.06744384765625"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# numwords\n","# https://colab.research.google.com/drive/1QTv-4osLHadCAay0beew-xlXszPCG88s#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","circuit = [(0, 1), (1, 0), (1, 5), (3, 2), (4, 4), (4, 8), (4, 10), (5, 4), (5, 6), (5, 8), (6, 9), (6, 10), (7, 7), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 11), (9, 1), (9, 5), (10, 2), (11, 8)]\n","mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698808727479,"user_tz":240,"elapsed":3473,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ecb1af2f-d153-4719-ceb7-eadd623c5576","id":"8rHKa9jK3Ej6"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 93.0875\n"]},{"output_type":"execute_result","data":{"text/plain":["93.0875015258789"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# months\n","# https://colab.research.google.com/drive/1lhQqlizYGMC11vzp6I9mJ3dyxIr8tV3l#scrollTo=563kZf_4r_mw&line=2&uniqifier=1\n","# circuit = [(4, 4), (7, 11), (8, 6), (8, 9), (8, 11), (9, 1), (9, 5), (11, 10)]\n","# mean_ablate_by_lst(circuit, model, print_output=True).item()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698808505689,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"5krPveJ_3Ej7"},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Prune fwds-backwds iteratively"],"metadata":{"id":"w7bys5l5uleW"}},{"cell_type":"markdown","source":["### iter fwd backw, threshold 3"],"metadata":{"id":"e8OFeKuxzM3R"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKZjydkhBfTD","executionInfo":{"status":"ok","timestamp":1698710965261,"user_tz":240,"elapsed":428860,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e62170a8-2393-416c-a71a-2e2402e194b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","99.6773910522461\n","\n","Removed: (0, 2)\n","100.02043914794922\n","\n","Removed: (0, 3)\n","98.45348358154297\n","\n","Removed: (0, 4)\n","99.20835876464844\n","\n","Removed: (0, 5)\n","97.02346801757812\n","\n","Removed: (0, 6)\n","97.01580810546875\n","\n","Removed: (0, 9)\n","98.982666015625\n","\n","Removed: (0, 10)\n","98.61641693115234\n","\n","Removed: (0, 11)\n","98.89505004882812\n","\n","Removed: (1, 0)\n","98.81217956542969\n","\n","Removed: (1, 1)\n","97.33100891113281\n","\n","Removed: (1, 2)\n","97.43998718261719\n","\n","Removed: (1, 3)\n","98.00090026855469\n","\n","Removed: (1, 4)\n","97.64048767089844\n","\n","Removed: (1, 6)\n","97.73833465576172\n","\n","Removed: (1, 7)\n","99.25526428222656\n","\n","Removed: (1, 8)\n","100.56314849853516\n","\n","Removed: (1, 9)\n","100.19857025146484\n","\n","Removed: (1, 10)\n","100.46278381347656\n","\n","Removed: (1, 11)\n","100.2510757446289\n","\n","Removed: (2, 0)\n","100.60169219970703\n","\n","Removed: (2, 1)\n","101.95899200439453\n","\n","Removed: (2, 2)\n","101.20800018310547\n","\n","Removed: (2, 3)\n","100.92581939697266\n","\n","Removed: (2, 4)\n","99.52203369140625\n","\n","Removed: (2, 5)\n","100.21537017822266\n","\n","Removed: (2, 6)\n","99.31548309326172\n","\n","Removed: (2, 7)\n","100.27664184570312\n","\n","Removed: (2, 8)\n","99.7633285522461\n","\n","Removed: (2, 9)\n","99.1578140258789\n","\n","Removed: (2, 10)\n","101.48392486572266\n","\n","Removed: (2, 11)\n","101.47329711914062\n","\n","Removed: (3, 0)\n","101.95543670654297\n","\n","Removed: (3, 1)\n","101.71906280517578\n","\n","Removed: (3, 2)\n","98.21212768554688\n","\n","Removed: (3, 3)\n","98.52771759033203\n","\n","Removed: (3, 4)\n","98.96311950683594\n","\n","Removed: (3, 5)\n","99.25824737548828\n","\n","Removed: (3, 6)\n","99.96598815917969\n","\n","Removed: (3, 7)\n","100.94210815429688\n","\n","Removed: (3, 8)\n","100.9061050415039\n","\n","Removed: (3, 9)\n","101.02205657958984\n","\n","Removed: (3, 10)\n","100.17637634277344\n","\n","Removed: (3, 11)\n","98.99824523925781\n","\n","Removed: (4, 0)\n","99.02629089355469\n","\n","Removed: (4, 1)\n","98.1909408569336\n","\n","Removed: (4, 2)\n","98.15457916259766\n","\n","Removed: (4, 3)\n","98.14803314208984\n","\n","Removed: (4, 5)\n","98.04829406738281\n","\n","Removed: (4, 6)\n","98.28951263427734\n","\n","Removed: (4, 8)\n","97.18266296386719\n","\n","Removed: (4, 11)\n","97.61665344238281\n","\n","Removed: (5, 0)\n","97.79710388183594\n","\n","Removed: (5, 1)\n","97.83121490478516\n","\n","Removed: (5, 2)\n","97.78245544433594\n","\n","Removed: (5, 3)\n","98.08040618896484\n","\n","Removed: (5, 5)\n","98.0332260131836\n","\n","Removed: (5, 7)\n","97.76838684082031\n","\n","Removed: (5, 9)\n","97.80699157714844\n","\n","Removed: (5, 10)\n","97.76527404785156\n","\n","Removed: (5, 11)\n","99.5809097290039\n","\n","Removed: (6, 0)\n","99.35858917236328\n","\n","Removed: (6, 1)\n","98.90982055664062\n","\n","Removed: (6, 2)\n","99.32217407226562\n","\n","Removed: (6, 3)\n","98.7576675415039\n","\n","Removed: (6, 4)\n","98.41150665283203\n","\n","Removed: (6, 5)\n","98.21231079101562\n","\n","Removed: (6, 7)\n","97.32810974121094\n","\n","Removed: (6, 8)\n","97.39798736572266\n","\n","Removed: (6, 11)\n","97.6593017578125\n","\n","Removed: (7, 0)\n","97.54385375976562\n","\n","Removed: (7, 1)\n","97.56343841552734\n","\n","Removed: (7, 3)\n","98.37451171875\n","\n","Removed: (7, 4)\n","97.79420471191406\n","\n","Removed: (7, 5)\n","97.16417694091797\n","\n","Removed: (7, 9)\n","97.1504898071289\n","\n","Removed: (8, 2)\n","97.3227767944336\n","\n","Removed: (8, 3)\n","99.54764556884766\n","\n","Removed: (8, 4)\n","99.48845672607422\n","\n","Removed: (8, 5)\n","98.96015930175781\n","\n","Removed: (8, 7)\n","98.60163116455078\n","\n","Removed: (8, 9)\n","98.78800201416016\n","\n","Removed: (8, 10)\n","102.12190246582031\n","\n","Removed: (9, 0)\n","102.1485595703125\n","\n","Removed: (9, 2)\n","101.75108337402344\n","\n","Removed: (9, 3)\n","100.76087951660156\n","\n","Removed: (9, 4)\n","101.14542388916016\n","\n","Removed: (9, 6)\n","101.63499450683594\n","\n","Removed: (9, 7)\n","102.47193908691406\n","\n","Removed: (9, 8)\n","102.33238220214844\n","\n","Removed: (9, 9)\n","102.12323760986328\n","\n","Removed: (9, 10)\n","101.85543823242188\n","\n","Removed: (9, 11)\n","101.66206359863281\n","\n","Removed: (10, 0)\n","101.62964630126953\n","\n","Removed: (10, 1)\n","101.71995544433594\n","\n","Removed: (10, 3)\n","101.640625\n","\n","Removed: (10, 4)\n","101.59054565429688\n","\n","Removed: (10, 5)\n","101.12647247314453\n","\n","Removed: (10, 6)\n","101.06792449951172\n","\n","Removed: (10, 7)\n","105.70602416992188\n","\n","Removed: (10, 8)\n","105.26214599609375\n","\n","Removed: (10, 9)\n","104.94229888916016\n","\n","Removed: (10, 10)\n","105.10586547851562\n","\n","Removed: (10, 11)\n","105.04019165039062\n","\n","Removed: (11, 0)\n","104.4366683959961\n","\n","Removed: (11, 1)\n","103.64432525634766\n","\n","Removed: (11, 2)\n","103.66157531738281\n","\n","Removed: (11, 3)\n","103.0504379272461\n","\n","Removed: (11, 4)\n","102.99916076660156\n","\n","Removed: (11, 5)\n","103.04955291748047\n","\n","Removed: (11, 6)\n","103.05855560302734\n","\n","Removed: (11, 7)\n","102.94672393798828\n","\n","Removed: (11, 8)\n","100.18824005126953\n","\n","Removed: (11, 9)\n","100.28038787841797\n","\n","Removed: (11, 10)\n","98.9267578125\n","\n","Removed: (11, 11)\n","98.93220520019531\n","\n","backw prune, iter  1\n","\n","Removed: (8, 1)\n","97.35671997070312\n","\n","Removed: (6, 9)\n","97.11428833007812\n","\n","fwd prune, iter  2\n"]}]},{"cell_type":"code","source":["fb_3 = curr_circuit.copy()\n","fb_3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET--8aulD8pE","executionInfo":{"status":"ok","timestamp":1698710965261,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5475dcbc-f7fb-49eb-e33c-6362f9f41111"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 7),\n"," (0, 8),\n"," (1, 5),\n"," (4, 4),\n"," (4, 7),\n"," (4, 9),\n"," (4, 10),\n"," (5, 4),\n"," (5, 6),\n"," (5, 8),\n"," (6, 6),\n"," (6, 10),\n"," (7, 2),\n"," (7, 6),\n"," (7, 7),\n"," (7, 8),\n"," (7, 10),\n"," (7, 11),\n"," (8, 0),\n"," (8, 6),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (9, 5),\n"," (10, 2)]"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","source":["#### loop rmv and check for most impt heads"],"metadata":{"id":"6znEyQfbCXf9"}},{"cell_type":"code","source":["circ = fb_3\n","mean_ablate_by_lst(circ, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698710968486,"user_tz":240,"elapsed":3244,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2662f548-8a32-4ac8-8ad4-88e93b9fac8c","id":"VGLZF6htCXf-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.1143\n"]},{"output_type":"execute_result","data":{"text/plain":["97.11428833007812"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698711023655,"user_tz":240,"elapsed":55179,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e0dc960b-38bb-499e-a83f-f194497c12b7","id":"pOvljLS8CXf_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 85.3010\n","removed: (0, 7)\n","Average logit difference (circuit / full) %: 96.2253\n","removed: (0, 8)\n","Average logit difference (circuit / full) %: 96.7433\n","removed: (1, 5)\n","Average logit difference (circuit / full) %: 92.4179\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 68.2523\n","removed: (4, 7)\n","Average logit difference (circuit / full) %: 96.2778\n","removed: (4, 9)\n","Average logit difference (circuit / full) %: 96.9809\n","removed: (4, 10)\n","Average logit difference (circuit / full) %: 95.4617\n","removed: (5, 4)\n","Average logit difference (circuit / full) %: 94.5391\n","removed: (5, 6)\n","Average logit difference (circuit / full) %: 91.3686\n","removed: (5, 8)\n","Average logit difference (circuit / full) %: 96.0476\n","removed: (6, 6)\n","Average logit difference (circuit / full) %: 95.3563\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 89.6346\n","removed: (7, 2)\n","Average logit difference (circuit / full) %: 95.5758\n","removed: (7, 6)\n","Average logit difference (circuit / full) %: 94.8825\n","removed: (7, 7)\n","Average logit difference (circuit / full) %: 96.5082\n","removed: (7, 8)\n","Average logit difference (circuit / full) %: 96.7304\n","removed: (7, 10)\n","Average logit difference (circuit / full) %: 94.4488\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 76.1490\n","removed: (8, 0)\n","Average logit difference (circuit / full) %: 95.1382\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 92.7655\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 88.1669\n","removed: (8, 11)\n","Average logit difference (circuit / full) %: 86.6013\n","removed: (9, 1)\n","Average logit difference (circuit / full) %: 66.3959\n","removed: (9, 5)\n","Average logit difference (circuit / full) %: 94.2131\n","removed: (10, 2)\n","Average logit difference (circuit / full) %: 82.1600\n"]}]},{"cell_type":"code","source":["dict(sorted(lh_scores.items(), key=lambda item: item[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698711023655,"user_tz":240,"elapsed":13,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"42cf17e5-c5a9-485b-eb45-97d4537384a0","id":"JdwILut4CXf_"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(9, 1): 66.3958969116211,\n"," (4, 4): 68.25231170654297,\n"," (7, 11): 76.1490249633789,\n"," (10, 2): 82.1600341796875,\n"," (0, 1): 85.30104064941406,\n"," (8, 11): 86.6012954711914,\n"," (8, 8): 88.16691589355469,\n"," (6, 10): 89.63456726074219,\n"," (5, 6): 91.36856842041016,\n"," (1, 5): 92.41793823242188,\n"," (8, 6): 92.7655258178711,\n"," (9, 5): 94.21306610107422,\n"," (7, 10): 94.44884490966797,\n"," (5, 4): 94.53907775878906,\n"," (7, 6): 94.88253021240234,\n"," (8, 0): 95.13815307617188,\n"," (6, 6): 95.35630798339844,\n"," (4, 10): 95.46166229248047,\n"," (7, 2): 95.5757827758789,\n"," (5, 8): 96.04763793945312,\n"," (0, 7): 96.22527313232422,\n"," (4, 7): 96.27782440185547,\n"," (7, 7): 96.50817108154297,\n"," (7, 8): 96.73036193847656,\n"," (0, 8): 96.7433090209961,\n"," (4, 9): 96.98094940185547}"]},"metadata":{},"execution_count":117}]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 20"],"metadata":{"id":"C2fvsn5SFnrO"}},{"cell_type":"code","source":["threshold = 20\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"id":"smR_M0B7FnrP","executionInfo":{"status":"ok","timestamp":1698709127390,"user_tz":240,"elapsed":442474,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e173b465-8b92-4a6c-8b97-5210463e4b51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","99.6773910522461\n","\n","Removed: (0, 1)\n","87.98929595947266\n","\n","Removed: (0, 2)\n","88.6512451171875\n","\n","Removed: (0, 3)\n","86.90736389160156\n","\n","Removed: (0, 4)\n","87.87069702148438\n","\n","Removed: (0, 5)\n","85.47981262207031\n","\n","Removed: (0, 6)\n","85.468994140625\n","\n","Removed: (0, 7)\n","85.32069396972656\n","\n","Removed: (0, 8)\n","84.54505920410156\n","\n","Removed: (0, 9)\n","84.93225860595703\n","\n","Removed: (0, 10)\n","87.507568359375\n","\n","Removed: (0, 11)\n","87.77931213378906\n","\n","Removed: (1, 0)\n","87.68569946289062\n","\n","Removed: (1, 1)\n","86.57756805419922\n","\n","Removed: (1, 2)\n","86.78600311279297\n","\n","Removed: (1, 3)\n","86.860107421875\n","\n","Removed: (1, 4)\n","86.6047592163086\n","\n","Removed: (1, 5)\n","81.6650619506836\n","\n","Removed: (1, 6)\n","81.76591491699219\n","\n","Removed: (1, 7)\n","82.36595916748047\n","\n","Removed: (1, 8)\n","83.85513305664062\n","\n","Removed: (1, 9)\n","83.27083587646484\n","\n","Removed: (1, 10)\n","83.19534301757812\n","\n","Removed: (1, 11)\n","82.02559661865234\n","\n","Removed: (2, 0)\n","82.97765350341797\n","\n","Removed: (2, 1)\n","84.57157135009766\n","\n","Removed: (2, 2)\n","83.71525573730469\n","\n","Removed: (2, 3)\n","82.80513000488281\n","\n","Removed: (2, 4)\n","81.32847595214844\n","\n","Removed: (2, 5)\n","81.80723571777344\n","\n","Removed: (2, 6)\n","81.38411712646484\n","\n","Removed: (2, 7)\n","81.2398452758789\n","\n","Removed: (2, 8)\n","81.07991790771484\n","\n","Removed: (2, 9)\n","80.71148681640625\n","\n","Removed: (2, 10)\n","81.35225677490234\n","\n","Removed: (2, 11)\n","81.50079345703125\n","\n","Removed: (3, 0)\n","81.72987365722656\n","\n","Removed: (3, 1)\n","81.71232604980469\n","\n","Removed: (3, 3)\n","81.33444213867188\n","\n","Removed: (3, 4)\n","81.51570892333984\n","\n","Removed: (3, 5)\n","81.71733856201172\n","\n","Removed: (3, 6)\n","81.73771667480469\n","\n","Removed: (3, 7)\n","82.59320068359375\n","\n","Removed: (3, 8)\n","83.68059539794922\n","\n","Removed: (3, 9)\n","83.8067398071289\n","\n","Removed: (3, 10)\n","83.39127349853516\n","\n","Removed: (3, 11)\n","82.6760025024414\n","\n","Removed: (4, 0)\n","82.5655288696289\n","\n","Removed: (4, 1)\n","82.06669616699219\n","\n","Removed: (4, 2)\n","81.94630432128906\n","\n","Removed: (4, 3)\n","82.09005737304688\n","\n","Removed: (4, 5)\n","82.11074829101562\n","\n","Removed: (4, 6)\n","82.40918731689453\n","\n","Removed: (4, 7)\n","80.35093688964844\n","\n","Removed: (4, 9)\n","80.0893325805664\n","\n","Removed: (5, 0)\n","80.036376953125\n","\n","Removed: (5, 3)\n","80.258544921875\n","\n","Removed: (5, 4)\n","80.26361083984375\n","\n","Removed: (5, 9)\n","80.15418243408203\n","\n","Removed: (5, 10)\n","80.1528091430664\n","\n","Removed: (5, 11)\n","81.32190704345703\n","\n","Removed: (6, 0)\n","81.16741943359375\n","\n","Removed: (6, 2)\n","81.4258041381836\n","\n","Removed: (6, 3)\n","80.83519744873047\n","\n","Removed: (6, 4)\n","80.53553009033203\n","\n","Removed: (6, 5)\n","80.1478042602539\n","\n","Removed: (6, 6)\n","80.39918518066406\n","\n","Removed: (6, 8)\n","80.10908508300781\n","\n","Removed: (6, 11)\n","80.15745544433594\n","\n","Removed: (7, 1)\n","80.13391876220703\n","\n","Removed: (7, 3)\n","80.73983001708984\n","\n","Removed: (7, 4)\n","80.28166961669922\n","\n","Removed: (7, 9)\n","80.36904907226562\n","\n","Removed: (8, 2)\n","80.10414123535156\n","\n","Removed: (8, 3)\n","81.40716552734375\n","\n","Removed: (8, 4)\n","81.35189056396484\n","\n","Removed: (8, 5)\n","80.85372924804688\n","\n","Removed: (8, 7)\n","80.57626342773438\n","\n","Removed: (8, 9)\n","81.51364135742188\n","\n","Removed: (8, 10)\n","83.9573745727539\n","\n","Removed: (9, 0)\n","83.9571304321289\n","\n","Removed: (9, 2)\n","83.64604949951172\n","\n","Removed: (9, 3)\n","82.76792907714844\n","\n","Removed: (9, 4)\n","82.90646362304688\n","\n","Removed: (9, 5)\n","81.12696838378906\n","\n","Removed: (9, 6)\n","81.38194274902344\n","\n","Removed: (9, 7)\n","81.87898254394531\n","\n","Removed: (9, 8)\n","81.74932098388672\n","\n","Removed: (9, 9)\n","81.55704498291016\n","\n","Removed: (9, 10)\n","81.36380004882812\n","\n","Removed: (9, 11)\n","81.26004791259766\n","\n","Removed: (10, 0)\n","81.19580078125\n","\n","Removed: (10, 1)\n","81.56745147705078\n","\n","Removed: (10, 3)\n","81.48112487792969\n","\n","Removed: (10, 4)\n","81.53269958496094\n","\n","Removed: (10, 5)\n","81.21153259277344\n","\n","Removed: (10, 6)\n","81.17330169677734\n","\n","Removed: (10, 7)\n","84.83924102783203\n","\n","Removed: (10, 8)\n","84.49568939208984\n","\n","Removed: (10, 9)\n","84.28466033935547\n","\n","Removed: (10, 10)\n","84.3556137084961\n","\n","Removed: (10, 11)\n","84.39238739013672\n","\n","Removed: (11, 0)\n","83.52027893066406\n","\n","Removed: (11, 1)\n","83.39737701416016\n","\n","Removed: (11, 2)\n","83.45730590820312\n","\n","Removed: (11, 3)\n","83.00047302246094\n","\n","Removed: (11, 4)\n","82.75019836425781\n","\n","Removed: (11, 5)\n","82.8283920288086\n","\n","Removed: (11, 6)\n","82.8537368774414\n","\n","Removed: (11, 7)\n","82.76683807373047\n","\n","Removed: (11, 8)\n","81.07522583007812\n","\n","Removed: (11, 9)\n","81.13819122314453\n","\n","Removed: (11, 10)\n","80.1891098022461\n","\n","Removed: (11, 11)\n","80.16375732421875\n","\n","backw prune, iter  1\n","\n","Removed: (5, 1)\n","80.00453186035156\n","\n","Removed: (5, 2)\n","80.01403045654297\n","\n","fwd prune, iter  2\n"]}]},{"cell_type":"code","source":["fb_20 = curr_circuit.copy()\n","fb_20"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709127391,"user_tz":240,"elapsed":26,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"650edd95-8d4d-4093-e630-d4aa6dd932c9","id":"563kZf_4r_mw"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(3, 2),\n"," (4, 4),\n"," (4, 8),\n"," (4, 10),\n"," (4, 11),\n"," (5, 5),\n"," (5, 6),\n"," (5, 7),\n"," (5, 8),\n"," (6, 1),\n"," (6, 7),\n"," (6, 9),\n"," (6, 10),\n"," (7, 0),\n"," (7, 2),\n"," (7, 5),\n"," (7, 6),\n"," (7, 7),\n"," (7, 8),\n"," (7, 10),\n"," (7, 11),\n"," (8, 0),\n"," (8, 1),\n"," (8, 6),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (10, 2)]"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["mean_ablate_by_lst(fb_20, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709129550,"user_tz":240,"elapsed":2181,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ac022aa7-44c4-4c6a-d2cb-0a13842f688f","id":"JGWLTDPVr_mx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 80.0140\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(80.0140, device='cuda:0')"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["len(fb_20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709129552,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7168cb74-43af-4297-c1f3-2c31dc2a1eb2","id":"paQHC_eQr_my"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28"]},"metadata":{},"execution_count":104}]},{"cell_type":"markdown","source":["#### loop rmv and check for most impt heads"],"metadata":{"id":"DVbMRE4Ke30-"}},{"cell_type":"code","source":["circ = fb_20\n","mean_ablate_by_lst(circ, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709132545,"user_tz":240,"elapsed":3002,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ebd42a65-1bfd-463e-9d93-9443831df2cb","id":"HRoe4QR4e30_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 80.0140\n"]},{"output_type":"execute_result","data":{"text/plain":["80.01403045654297"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709192859,"user_tz":240,"elapsed":60324,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"67214e5e-dd74-4cde-f5ef-0a7e4f45cedb","id":"eL46O6zZe30_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (3, 2)\n","Average logit difference (circuit / full) %: 78.5359\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 57.5247\n","removed: (4, 8)\n","Average logit difference (circuit / full) %: 79.5581\n","removed: (4, 10)\n","Average logit difference (circuit / full) %: 77.7767\n","removed: (4, 11)\n","Average logit difference (circuit / full) %: 78.8688\n","removed: (5, 5)\n","Average logit difference (circuit / full) %: 79.1987\n","removed: (5, 6)\n","Average logit difference (circuit / full) %: 74.9998\n","removed: (5, 7)\n","Average logit difference (circuit / full) %: 79.7443\n","removed: (5, 8)\n","Average logit difference (circuit / full) %: 77.3542\n","removed: (6, 1)\n","Average logit difference (circuit / full) %: 78.4455\n","removed: (6, 7)\n","Average logit difference (circuit / full) %: 79.5844\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 79.8339\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 75.6201\n","removed: (7, 0)\n","Average logit difference (circuit / full) %: 79.8278\n","removed: (7, 2)\n","Average logit difference (circuit / full) %: 78.7663\n","removed: (7, 5)\n","Average logit difference (circuit / full) %: 79.6638\n","removed: (7, 6)\n","Average logit difference (circuit / full) %: 78.2938\n","removed: (7, 7)\n","Average logit difference (circuit / full) %: 79.3229\n","removed: (7, 8)\n","Average logit difference (circuit / full) %: 79.7485\n","removed: (7, 10)\n","Average logit difference (circuit / full) %: 77.3432\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 65.4083\n","removed: (8, 0)\n","Average logit difference (circuit / full) %: 78.6507\n","removed: (8, 1)\n","Average logit difference (circuit / full) %: 78.7825\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 77.6606\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 71.7611\n","removed: (8, 11)\n","Average logit difference (circuit / full) %: 73.9245\n","removed: (9, 1)\n","Average logit difference (circuit / full) %: 52.8489\n","removed: (10, 2)\n","Average logit difference (circuit / full) %: 67.6051\n"]}]},{"cell_type":"code","source":["dict(sorted(lh_scores.items(), key=lambda item: item[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709192859,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8a0efb0a-21c2-475c-d285-d06e60afb6e9","id":"S3AxZcsWe30_"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(9, 1): 52.848934173583984,\n"," (4, 4): 57.52471923828125,\n"," (7, 11): 65.4083023071289,\n"," (10, 2): 67.60511016845703,\n"," (8, 8): 71.76107788085938,\n"," (8, 11): 73.92449188232422,\n"," (5, 6): 74.99983978271484,\n"," (6, 10): 75.62007904052734,\n"," (7, 10): 77.34323120117188,\n"," (5, 8): 77.35415649414062,\n"," (8, 6): 77.66063690185547,\n"," (4, 10): 77.77672576904297,\n"," (7, 6): 78.29383087158203,\n"," (6, 1): 78.44552612304688,\n"," (3, 2): 78.53585815429688,\n"," (8, 0): 78.65070343017578,\n"," (7, 2): 78.7663345336914,\n"," (8, 1): 78.78251647949219,\n"," (4, 11): 78.86881256103516,\n"," (5, 5): 79.1987075805664,\n"," (7, 7): 79.32286071777344,\n"," (4, 8): 79.5581283569336,\n"," (6, 7): 79.58438873291016,\n"," (7, 5): 79.66378021240234,\n"," (5, 7): 79.74430847167969,\n"," (7, 8): 79.74847412109375,\n"," (7, 0): 79.8277816772461,\n"," (6, 9): 79.83391571044922}"]},"metadata":{},"execution_count":107}]},{"cell_type":"markdown","source":["# Prune backwds-fwds iteratively"],"metadata":{"id":"1putaGukK8at"}},{"cell_type":"markdown","source":["### threshold 3 (OLD, DO NOT RUN)"],"metadata":{"id":"E69b948rS4qQ"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698709628042,"user_tz":240,"elapsed":435201,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"2EJaexibS4qb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"85de7d80-75d9-463e-c105-6e7b7dddc235"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","99.36744689941406\n","\n","Removed: (11, 1)\n","98.15276336669922\n","\n","Removed: (11, 2)\n","98.11139678955078\n","\n","Removed: (11, 3)\n","97.8514404296875\n","\n","Removed: (11, 4)\n","98.47762298583984\n","\n","Removed: (11, 5)\n","98.56700897216797\n","\n","Removed: (11, 6)\n","98.57281494140625\n","\n","Removed: (11, 7)\n","98.51939392089844\n","\n","Removed: (11, 9)\n","98.4183349609375\n","\n","Removed: (11, 10)\n","97.51922607421875\n","\n","Removed: (11, 11)\n","97.42621612548828\n","\n","Removed: (10, 0)\n","97.4111099243164\n","\n","Removed: (10, 1)\n","97.25757598876953\n","\n","Removed: (10, 3)\n","97.45303344726562\n","\n","Removed: (10, 4)\n","97.4413070678711\n","\n","Removed: (10, 5)\n","97.26394653320312\n","\n","Removed: (10, 6)\n","97.17695617675781\n","\n","Removed: (10, 7)\n","100.68805694580078\n","\n","Removed: (10, 8)\n","99.4012680053711\n","\n","Removed: (10, 9)\n","99.0429916381836\n","\n","Removed: (10, 10)\n","99.18038177490234\n","\n","Removed: (10, 11)\n","98.84198760986328\n","\n","Removed: (9, 0)\n","98.87261962890625\n","\n","Removed: (9, 2)\n","98.37891387939453\n","\n","Removed: (9, 3)\n","97.85379791259766\n","\n","Removed: (9, 4)\n","98.12966918945312\n","\n","Removed: (9, 6)\n","98.41926574707031\n","\n","Removed: (9, 7)\n","99.12520599365234\n","\n","Removed: (9, 8)\n","98.9166488647461\n","\n","Removed: (9, 9)\n","98.46714782714844\n","\n","Removed: (9, 10)\n","98.21356201171875\n","\n","Removed: (9, 11)\n","97.92180633544922\n","\n","Removed: (8, 3)\n","99.19644927978516\n","\n","Removed: (8, 4)\n","99.13751983642578\n","\n","Removed: (8, 5)\n","98.67320251464844\n","\n","Removed: (8, 7)\n","98.42920684814453\n","\n","Removed: (8, 9)\n","98.02721405029297\n","\n","Removed: (8, 10)\n","100.64110565185547\n","\n","Removed: (7, 0)\n","100.5676498413086\n","\n","Removed: (7, 1)\n","100.64105987548828\n","\n","Removed: (7, 2)\n","99.40424346923828\n","\n","Removed: (7, 3)\n","99.86193084716797\n","\n","Removed: (7, 4)\n","99.43075561523438\n","\n","Removed: (7, 5)\n","99.27657318115234\n","\n","Removed: (7, 6)\n","97.25787353515625\n","\n","Removed: (7, 9)\n","97.35004425048828\n","\n","Removed: (6, 0)\n","97.25596618652344\n","\n","Removed: (6, 1)\n","97.80369567871094\n","\n","Removed: (6, 2)\n","97.88685607910156\n","\n","Removed: (6, 3)\n","97.2624740600586\n","\n","Removed: (6, 5)\n","97.97137451171875\n","\n","Removed: (6, 6)\n","97.213623046875\n","\n","Removed: (6, 7)\n","97.22826385498047\n","\n","Removed: (6, 11)\n","97.35549926757812\n","\n","Removed: (5, 0)\n","98.30097961425781\n","\n","Removed: (5, 1)\n","97.8623046875\n","\n","Removed: (5, 2)\n","98.12240600585938\n","\n","Removed: (5, 3)\n","97.9328384399414\n","\n","Removed: (5, 5)\n","98.44056701660156\n","\n","Removed: (5, 7)\n","98.15804290771484\n","\n","Removed: (5, 9)\n","98.10342407226562\n","\n","Removed: (5, 10)\n","98.01700592041016\n","\n","Removed: (5, 11)\n","98.36988830566406\n","\n","Removed: (4, 0)\n","98.31590270996094\n","\n","Removed: (4, 1)\n","97.9467544555664\n","\n","Removed: (4, 2)\n","97.90135192871094\n","\n","Removed: (4, 3)\n","97.83689880371094\n","\n","Removed: (4, 5)\n","97.7868423461914\n","\n","Removed: (4, 6)\n","97.5942153930664\n","\n","Removed: (4, 7)\n","97.0208969116211\n","\n","Removed: (4, 11)\n","99.23262786865234\n","\n","Removed: (3, 0)\n","99.37177276611328\n","\n","Removed: (3, 1)\n","99.14813232421875\n","\n","Removed: (3, 3)\n","99.62802124023438\n","\n","Removed: (3, 4)\n","100.14939880371094\n","\n","Removed: (3, 5)\n","100.42291259765625\n","\n","Removed: (3, 6)\n","100.5746078491211\n","\n","Removed: (3, 7)\n","101.49930572509766\n","\n","Removed: (3, 8)\n","101.57323455810547\n","\n","Removed: (3, 9)\n","101.6858139038086\n","\n","Removed: (3, 10)\n","101.49724578857422\n","\n","Removed: (3, 11)\n","100.6989974975586\n","\n","Removed: (2, 0)\n","100.70922088623047\n","\n","Removed: (2, 1)\n","101.33828735351562\n","\n","Removed: (2, 2)\n","99.84856414794922\n","\n","Removed: (2, 3)\n","99.11868286132812\n","\n","Removed: (2, 4)\n","97.39958190917969\n","\n","Removed: (2, 5)\n","98.49139404296875\n","\n","Removed: (2, 6)\n","97.9125747680664\n","\n","Removed: (2, 7)\n","98.69065856933594\n","\n","Removed: (2, 8)\n","98.02969360351562\n","\n","Removed: (2, 9)\n","97.09965515136719\n","\n","Removed: (2, 10)\n","98.54045867919922\n","\n","Removed: (2, 11)\n","98.73418426513672\n","\n","Removed: (1, 1)\n","98.158447265625\n","\n","Removed: (1, 2)\n","98.41730499267578\n","\n","Removed: (1, 3)\n","99.07966613769531\n","\n","Removed: (1, 4)\n","99.18553161621094\n","\n","Removed: (1, 6)\n","99.07948303222656\n","\n","Removed: (1, 7)\n","100.82086944580078\n","\n","Removed: (1, 8)\n","101.76687622070312\n","\n","Removed: (1, 9)\n","101.51785278320312\n","\n","Removed: (1, 10)\n","101.62344360351562\n","\n","Removed: (1, 11)\n","100.79917907714844\n","\n","Removed: (0, 0)\n","100.94058227539062\n","\n","Removed: (0, 2)\n","101.41983032226562\n","\n","Removed: (0, 3)\n","99.58993530273438\n","\n","Removed: (0, 4)\n","100.15782165527344\n","\n","Removed: (0, 5)\n","98.27175903320312\n","\n","Removed: (0, 6)\n","98.35609436035156\n","\n","Removed: (0, 7)\n","97.19634246826172\n","\n","Removed: (0, 9)\n","97.1219711303711\n","\n","Removed: (0, 10)\n","99.377685546875\n","\n","Removed: (0, 11)\n","98.71470642089844\n","\n","fwd prune, iter  1\n","\n","Removed: (0, 8)\n","98.00428009033203\n","\n","Removed: (4, 9)\n","97.8288345336914\n","\n","Removed: (6, 4)\n","97.4392318725586\n","\n","Removed: (6, 8)\n","97.09876251220703\n","\n","Removed: (8, 2)\n","97.41226959228516\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698709628043,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"C2EgKgmJS4qb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7619a721-536f-4433-8814-16e27d54deb6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (1, 0),\n"," (1, 5),\n"," (3, 2),\n"," (4, 4),\n"," (4, 8),\n"," (4, 10),\n"," (5, 4),\n"," (5, 6),\n"," (5, 8),\n"," (6, 9),\n"," (6, 10),\n"," (7, 7),\n"," (7, 8),\n"," (7, 10),\n"," (7, 11),\n"," (8, 0),\n"," (8, 1),\n"," (8, 6),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (9, 5),\n"," (10, 2),\n"," (11, 8)]"]},"metadata":{},"execution_count":109}]},{"cell_type":"markdown","source":["#### loop rmv and check for most impt heads"],"metadata":{"id":"b-HmQqqX--wP"}},{"cell_type":"code","source":["circ = bf_3\n","mean_ablate_by_lst(circ, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709641174,"user_tz":240,"elapsed":2987,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8e9415b8-4702-4ef6-fe50-849c8413d7ec","id":"sJBAcNfH--wZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.4123\n"]},{"output_type":"execute_result","data":{"text/plain":["97.41226959228516"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["lh_scores = {}\n","for lh in circ:\n","    copy_circuit = circ.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, print_output=True).item()\n","    lh_scores[lh] = new_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709693781,"user_tz":240,"elapsed":52617,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"120363f5-0e3c-4276-b755-698d14398d1a","id":"DsmLZCDG--wZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["removed: (0, 1)\n","Average logit difference (circuit / full) %: 85.8583\n","removed: (1, 0)\n","Average logit difference (circuit / full) %: 94.9495\n","removed: (1, 5)\n","Average logit difference (circuit / full) %: 90.7815\n","removed: (3, 2)\n","Average logit difference (circuit / full) %: 94.8821\n","removed: (4, 4)\n","Average logit difference (circuit / full) %: 64.8832\n","removed: (4, 8)\n","Average logit difference (circuit / full) %: 96.5330\n","removed: (4, 10)\n","Average logit difference (circuit / full) %: 96.0251\n","removed: (5, 4)\n","Average logit difference (circuit / full) %: 94.7940\n","removed: (5, 6)\n","Average logit difference (circuit / full) %: 91.8178\n","removed: (5, 8)\n","Average logit difference (circuit / full) %: 95.4617\n","removed: (6, 9)\n","Average logit difference (circuit / full) %: 96.9442\n","removed: (6, 10)\n","Average logit difference (circuit / full) %: 88.7927\n","removed: (7, 7)\n","Average logit difference (circuit / full) %: 96.6616\n","removed: (7, 8)\n","Average logit difference (circuit / full) %: 96.9658\n","removed: (7, 10)\n","Average logit difference (circuit / full) %: 95.5882\n","removed: (7, 11)\n","Average logit difference (circuit / full) %: 73.2670\n","removed: (8, 0)\n","Average logit difference (circuit / full) %: 94.7021\n","removed: (8, 1)\n","Average logit difference (circuit / full) %: 96.0725\n","removed: (8, 6)\n","Average logit difference (circuit / full) %: 92.2819\n","removed: (8, 8)\n","Average logit difference (circuit / full) %: 88.1222\n","removed: (8, 11)\n","Average logit difference (circuit / full) %: 87.1588\n","removed: (9, 1)\n","Average logit difference (circuit / full) %: 66.9690\n","removed: (9, 5)\n","Average logit difference (circuit / full) %: 93.9635\n","removed: (10, 2)\n","Average logit difference (circuit / full) %: 83.1231\n","removed: (11, 8)\n","Average logit difference (circuit / full) %: 94.7928\n"]}]},{"cell_type":"code","source":["dict(sorted(lh_scores.items(), key=lambda item: item[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698709693782,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cfeb6954-4efb-4c3b-b019-4cb4034fb417","id":"PTD9knZJ--wa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(4, 4): 64.88319396972656,\n"," (9, 1): 66.968994140625,\n"," (7, 11): 73.26703643798828,\n"," (10, 2): 83.12308502197266,\n"," (0, 1): 85.8582534790039,\n"," (8, 11): 87.15882873535156,\n"," (8, 8): 88.12217712402344,\n"," (6, 10): 88.79270935058594,\n"," (1, 5): 90.781494140625,\n"," (5, 6): 91.81783294677734,\n"," (8, 6): 92.28190612792969,\n"," (9, 5): 93.96353912353516,\n"," (8, 0): 94.70207214355469,\n"," (11, 8): 94.79283142089844,\n"," (5, 4): 94.7939682006836,\n"," (3, 2): 94.88208770751953,\n"," (1, 0): 94.94954681396484,\n"," (5, 8): 95.46170806884766,\n"," (7, 10): 95.58817291259766,\n"," (4, 10): 96.02513122558594,\n"," (8, 1): 96.072509765625,\n"," (4, 8): 96.53302001953125,\n"," (7, 7): 96.66156768798828,\n"," (6, 9): 96.94415283203125,\n"," (7, 8): 96.96578979492188}"]},"metadata":{},"execution_count":112}]},{"cell_type":"markdown","source":["#### compare fb and bf"],"metadata":{"id":"y7asi9grEcRm"}},{"cell_type":"code","source":["print(len(fb_3))\n","print(len(bf_3))"],"metadata":{"id":"RDFeNUKjEeQZ","executionInfo":{"status":"ok","timestamp":1698711102956,"user_tz":240,"elapsed":1320,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"104ec4f7-68ad-4fb1-9f7b-43cf94485c7e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["26\n","25\n"]}]},{"cell_type":"code","source":["set(fb_3) - set(bf_3)"],"metadata":{"id":"5iEIPb6hEmpA","executionInfo":{"status":"ok","timestamp":1698711117629,"user_tz":240,"elapsed":326,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b8988c09-0f8a-49ec-95a6-5a0abe8fd391","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 7), (0, 8), (4, 7), (4, 9), (6, 6), (7, 2), (7, 6)}"]},"metadata":{},"execution_count":119}]}]}