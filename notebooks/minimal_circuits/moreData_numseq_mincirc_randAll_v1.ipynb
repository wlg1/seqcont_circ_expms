{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["DcZG9rm2IAiA","Z4iJEGh6b56v","1putaGukK8at"],"toc_visible":true,"authorship_tag":"ABX9TyPeNKnKYjsx49aOsKoDoNLi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"60ce628395944c11983bd1031023d3aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efcce593e4d84f6d97c7b195e9fff0c9","IPY_MODEL_5040b72f2960443fb949e021981369d8","IPY_MODEL_59c08307e73f40339149645f5df485e1"],"layout":"IPY_MODEL_166ba525ed494037bc8c647c5d01977a"}},"efcce593e4d84f6d97c7b195e9fff0c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3736fa8746e4c56b6b1f357a1f618be","placeholder":"​","style":"IPY_MODEL_d35ae28b98d34bb990c9a0389992f8f1","value":"Downloading (…)lve/main/config.json: 100%"}},"5040b72f2960443fb949e021981369d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae623976de974c79acf3041ac86d0781","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88575e78221942378565f05de450f019","value":665}},"59c08307e73f40339149645f5df485e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ebd27c881b6426b92618f7fe2c44995","placeholder":"​","style":"IPY_MODEL_9ff27a3ebc2945a7891dbd408c84a280","value":" 665/665 [00:00&lt;00:00, 50.5kB/s]"}},"166ba525ed494037bc8c647c5d01977a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3736fa8746e4c56b6b1f357a1f618be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d35ae28b98d34bb990c9a0389992f8f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae623976de974c79acf3041ac86d0781":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88575e78221942378565f05de450f019":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ebd27c881b6426b92618f7fe2c44995":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff27a3ebc2945a7891dbd408c84a280":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62038a0925f04a919c91cbffcdda3d27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a63e212a9f7415e867893e30f9e1c34","IPY_MODEL_8ca44fe1f7af4d77b41e176a40e526a4","IPY_MODEL_6e04b1a73c9642f382f7c41baebc60a7"],"layout":"IPY_MODEL_ca3a77e74b1745668ee12ed5d48d464d"}},"8a63e212a9f7415e867893e30f9e1c34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e9ead04e1134067b210757dcdd0ee3f","placeholder":"​","style":"IPY_MODEL_7c9e4ce21cd449a9a835ee304bf1fb5e","value":"Downloading model.safetensors: 100%"}},"8ca44fe1f7af4d77b41e176a40e526a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4dc04a2ec80415b9478f06f00d405ea","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d5a343127264c8486d8c681cab0ab7d","value":548105171}},"6e04b1a73c9642f382f7c41baebc60a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21568f2410ad451794ccb6999dc2fe85","placeholder":"​","style":"IPY_MODEL_e85df91a90a24fb0aa066a4c2600a6fb","value":" 548M/548M [00:01&lt;00:00, 335MB/s]"}},"ca3a77e74b1745668ee12ed5d48d464d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e9ead04e1134067b210757dcdd0ee3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c9e4ce21cd449a9a835ee304bf1fb5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4dc04a2ec80415b9478f06f00d405ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d5a343127264c8486d8c681cab0ab7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21568f2410ad451794ccb6999dc2fe85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e85df91a90a24fb0aa066a4c2600a6fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1b34f6a8cf94bc49cfdb75bc3878ceb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb8417b8d86c40abbdc6f4aebc5dca4d","IPY_MODEL_e1fa71ea1c70401bbc55e30c4145691c","IPY_MODEL_44ef1c6b82d14857bd527f9fd32e89e4"],"layout":"IPY_MODEL_04eb259d60ec4451a454dd74b183c74a"}},"bb8417b8d86c40abbdc6f4aebc5dca4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01694aa63094486389d201a6de87dc0d","placeholder":"​","style":"IPY_MODEL_d6d6afc5928441c9b93f23d2b00578f1","value":"Downloading (…)neration_config.json: 100%"}},"e1fa71ea1c70401bbc55e30c4145691c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cb1f43844f745e5aa892c655aeea010","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53ee023489454836be57d66c218e30d7","value":124}},"44ef1c6b82d14857bd527f9fd32e89e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_374ed7e737374692a2010801362d9e47","placeholder":"​","style":"IPY_MODEL_b5020a5aab2848fa86e33c46a5cda489","value":" 124/124 [00:00&lt;00:00, 9.64kB/s]"}},"04eb259d60ec4451a454dd74b183c74a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01694aa63094486389d201a6de87dc0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d6afc5928441c9b93f23d2b00578f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cb1f43844f745e5aa892c655aeea010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53ee023489454836be57d66c218e30d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"374ed7e737374692a2010801362d9e47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5020a5aab2848fa86e33c46a5cda489":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b93fec7f90c045b68ba4f8c6d3356a41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_faa1605f98ff49358daabf4d6daed9a5","IPY_MODEL_452b69544d194006bd31eb0f15af6e39","IPY_MODEL_ed109a179a4545b888bf8aa490d5c66c"],"layout":"IPY_MODEL_7f16c519d10f42b68bab28ea6c4fa5bd"}},"faa1605f98ff49358daabf4d6daed9a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c8d437b959745afb30e5ca2ae078532","placeholder":"​","style":"IPY_MODEL_11c421eec4b040b8a91454e4668aed4a","value":"Downloading (…)olve/main/vocab.json: 100%"}},"452b69544d194006bd31eb0f15af6e39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97acbffca6184813a4d712adf8363819","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0dccd869bfeb4685b14472110e071dba","value":1042301}},"ed109a179a4545b888bf8aa490d5c66c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87a1876237a4494b992d648ac2973397","placeholder":"​","style":"IPY_MODEL_36f0776a178d40abb45273dfe9329df2","value":" 1.04M/1.04M [00:00&lt;00:00, 2.72MB/s]"}},"7f16c519d10f42b68bab28ea6c4fa5bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c8d437b959745afb30e5ca2ae078532":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11c421eec4b040b8a91454e4668aed4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97acbffca6184813a4d712adf8363819":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dccd869bfeb4685b14472110e071dba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87a1876237a4494b992d648ac2973397":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36f0776a178d40abb45273dfe9329df2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0991ad7964a345629a7892e224c3c682":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70d47aea0f504f358c719ffe126fda17","IPY_MODEL_8690dcde5a57420697b00eaf531e0670","IPY_MODEL_8e2c3ca0c72b49909cf356afa7b6f7f0"],"layout":"IPY_MODEL_66cee6e56e8746c49922eaec44e6d2ec"}},"70d47aea0f504f358c719ffe126fda17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84d2f3ce2c1145c986a30a94f8104017","placeholder":"​","style":"IPY_MODEL_5fc08c4c8d4e4566a0d713b6d7c0f959","value":"Downloading (…)olve/main/merges.txt: 100%"}},"8690dcde5a57420697b00eaf531e0670":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75e524bc395b43d2b339202b6983b568","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48ee5bb79efa416fac9df45f85063135","value":456318}},"8e2c3ca0c72b49909cf356afa7b6f7f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ea42dba2ca4a71b2a731a12e2461b1","placeholder":"​","style":"IPY_MODEL_b3084142174f4fb7a3b70f53325d4fb6","value":" 456k/456k [00:00&lt;00:00, 1.59MB/s]"}},"66cee6e56e8746c49922eaec44e6d2ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84d2f3ce2c1145c986a30a94f8104017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc08c4c8d4e4566a0d713b6d7c0f959":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75e524bc395b43d2b339202b6983b568":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48ee5bb79efa416fac9df45f85063135":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03ea42dba2ca4a71b2a731a12e2461b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3084142174f4fb7a3b70f53325d4fb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce86feeab54944b2bdeadf46f5606fe5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c82faad36f94a33be99b5bc0d068a0f","IPY_MODEL_db9eb966db5648839dc69d17888a5e7d","IPY_MODEL_64dff687216c41daa26c2c7a694ae661"],"layout":"IPY_MODEL_46b65afe60a44a8f85c30c26695c779d"}},"7c82faad36f94a33be99b5bc0d068a0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3377e1993c9644a29b52d93f61f9c8f6","placeholder":"​","style":"IPY_MODEL_b7e75e7f095b4251bfc550934447cb89","value":"Downloading (…)/main/tokenizer.json: 100%"}},"db9eb966db5648839dc69d17888a5e7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d18d4b87faa4163be4720172a3c5987","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_97469481337747a9be4e098da03574d4","value":1355256}},"64dff687216c41daa26c2c7a694ae661":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4339c1ce1744fdf82e4366b3dfd29a6","placeholder":"​","style":"IPY_MODEL_e3aa1db548ac4ff5b4fd027b0564d53c","value":" 1.36M/1.36M [00:00&lt;00:00, 13.9MB/s]"}},"46b65afe60a44a8f85c30c26695c779d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3377e1993c9644a29b52d93f61f9c8f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7e75e7f095b4251bfc550934447cb89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d18d4b87faa4163be4720172a3c5987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97469481337747a9be4e098da03574d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4339c1ce1744fdf82e4366b3dfd29a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3aa1db548ac4ff5b4fd027b0564d53c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"b13177b7"},"source":["<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698697096257,"user_tz":240,"elapsed":172327,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"91eff40e-4fed-428e-cae3-ddcedf356a7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-nqh0hroo\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-nqh0hroo\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit fa287750606075574df2c538058e67d648e2f952\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate>=0.23.0 (from transformer-lens==0.0.0)\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n","Collecting numpy>=1.24 (from transformer-lens==0.0.0)\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cublas_cu12-12.3.2.9-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (24.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cudnn_cu12-8.9.5.30-py3-none-manylinux1_x86_64.whl (701.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.6/701.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cufft_cu12-11.0.11.19-py3-none-manylinux1_x86_64.whl (98.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_curand_cu12-10.3.4.52-py3-none-manylinux1_x86_64.whl (56.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusolver_cu12-11.5.3.52-py3-none-manylinux1_x86_64.whl (125.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusparse_cu12-12.1.3.153-py3-none-manylinux1_x86_64.whl (195.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nvtx_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m136.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.6)\n","Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens==0.0.0)\n","  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=116432 sha256=c797ec6c169bd4dd3b94c94a6a6e6c77438ff526c16d7937b5c638131c77e4db\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rpr1aia6/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=73f3792e0391ad01d015da84be4e799b4ee2f5c3fe9e525989193d35d2e1aa05\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, huggingface-hub, gitdb, tokenizers, nvidia-cusolver-cu12, GitPython, accelerate, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.24.1 beartype-0.14.1 datasets-2.14.6 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 huggingface-hub-0.17.3 jaxtyping-0.2.23 multiprocess-0.70.15 numpy-1.26.1 nvidia-cublas-cu12-12.3.2.9 nvidia-cuda-cupti-cu12-12.3.52 nvidia-cuda-nvrtc-cu12-12.3.52 nvidia-cuda-runtime-cu12-12.3.52 nvidia-cudnn-cu12-8.9.5.30 nvidia-cufft-cu12-11.0.11.19 nvidia-curand-cu12-10.3.4.52 nvidia-cusolver-cu12-11.5.3.52 nvidia-cusparse-cu12-12.1.3.153 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.3.52 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.34.1 typeguard-2.13.3 wandb-0.15.12\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n","\n","  \n","  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n","  install Node.js is deprecated now and will eventually be made inactive.\n","\n","  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n","  instructions to migrate your repo.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n","  information about which versions of Node.js and which Linux distributions\n","  are supported and how to install it.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","\n","                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n","Continuing in 60 seconds (press Ctrl-C to abort) ...\n","\n","\n","## Installing the NodeSource Node.js 16.x repo...\n","\n","\n","## Populating apt-get cache...\n","\n","+ apt-get update\n","Get:1 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:10 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,231 kB]\n","Get:11 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,145 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,306 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,278 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,010 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,134 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,410 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,453 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [34.1 kB]\n","Fetched 11.4 MB in 2s (6,736 kB/s)\n","Reading package lists... Done\n","\n","## Confirming \"jammy\" is supported...\n","\n","+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n","\n","## Adding the NodeSource signing key to your keyring...\n","\n","+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n","\n","## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n","\n","+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n","+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n","\n","## Running `apt-get update` for you...\n","\n","+ apt-get update\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:4 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n","Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Get:11 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [776 B]\n","Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Fetched 5,359 B in 1s (6,026 B/s)\n","Reading package lists... Done\n","\n","## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n","## You may also need development tools to build native addons:\n","     sudo apt-get install gcc g++ make\n","## To install the Yarn package manager, run:\n","     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n","     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n","     sudo apt-get update && sudo apt-get install yarn\n","\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  nodejs\n","0 upgraded, 1 newly installed, 0 to remove and 22 not upgraded.\n","Need to get 27.2 MB of archives.\n","After this operation, 128 MB of additional disk space will be used.\n","Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.2-deb-1nodesource1 [27.2 MB]\n","Fetched 27.2 MB in 1s (54.0 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package nodejs.\n","(Reading database ... 120874 files and directories currently installed.)\n","Preparing to unpack .../nodejs_16.20.2-deb-1nodesource1_amd64.deb ...\n","Unpacking nodejs (16.20.2-deb-1nodesource1) ...\n","Setting up nodejs (16.20.2-deb-1nodesource1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Collecting git+https://github.com/neelnanda-io/PySvelte.git\n","  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-_g37lhnr\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-_g37lhnr\n","  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1698697096258,"user_tz":240,"elapsed":33,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","import plotly.io as pio\n","\n","if IN_COLAB or not DEBUG_MODE:\n","    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","    pio.renderers.default = \"colab\"\n","else:\n","    pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1698697102673,"user_tz":240,"elapsed":6446,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1698697103291,"user_tz":240,"elapsed":630,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","outputId":"aff53f29-3a91-4727-d8b6-41284f2defd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698697103292,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7be216d3bc70>"]},"metadata":{},"execution_count":5}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KFs9BrbzIAiH","executionInfo":{"status":"ok","timestamp":1698697103792,"user_tz":240,"elapsed":506,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def imshow(tensor, renderer=None, **kwargs):\n","    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","def line(tensor, renderer=None, **kwargs):\n","    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","    x = utils.to_numpy(x)\n","    y = utils.to_numpy(y)\n","    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"markdown","source":["Decide which model to use (eg. gpt2-small vs -medium)"],"metadata":{"id":"ssJgoKr2yI8O"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"xLwDyosvIAiJ","executionInfo":{"status":"ok","timestamp":1698697120743,"user_tz":240,"elapsed":16956,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["60ce628395944c11983bd1031023d3aa","efcce593e4d84f6d97c7b195e9fff0c9","5040b72f2960443fb949e021981369d8","59c08307e73f40339149645f5df485e1","166ba525ed494037bc8c647c5d01977a","c3736fa8746e4c56b6b1f357a1f618be","d35ae28b98d34bb990c9a0389992f8f1","ae623976de974c79acf3041ac86d0781","88575e78221942378565f05de450f019","3ebd27c881b6426b92618f7fe2c44995","9ff27a3ebc2945a7891dbd408c84a280","62038a0925f04a919c91cbffcdda3d27","8a63e212a9f7415e867893e30f9e1c34","8ca44fe1f7af4d77b41e176a40e526a4","6e04b1a73c9642f382f7c41baebc60a7","ca3a77e74b1745668ee12ed5d48d464d","0e9ead04e1134067b210757dcdd0ee3f","7c9e4ce21cd449a9a835ee304bf1fb5e","f4dc04a2ec80415b9478f06f00d405ea","1d5a343127264c8486d8c681cab0ab7d","21568f2410ad451794ccb6999dc2fe85","e85df91a90a24fb0aa066a4c2600a6fb","e1b34f6a8cf94bc49cfdb75bc3878ceb","bb8417b8d86c40abbdc6f4aebc5dca4d","e1fa71ea1c70401bbc55e30c4145691c","44ef1c6b82d14857bd527f9fd32e89e4","04eb259d60ec4451a454dd74b183c74a","01694aa63094486389d201a6de87dc0d","d6d6afc5928441c9b93f23d2b00578f1","4cb1f43844f745e5aa892c655aeea010","53ee023489454836be57d66c218e30d7","374ed7e737374692a2010801362d9e47","b5020a5aab2848fa86e33c46a5cda489","b93fec7f90c045b68ba4f8c6d3356a41","faa1605f98ff49358daabf4d6daed9a5","452b69544d194006bd31eb0f15af6e39","ed109a179a4545b888bf8aa490d5c66c","7f16c519d10f42b68bab28ea6c4fa5bd","0c8d437b959745afb30e5ca2ae078532","11c421eec4b040b8a91454e4668aed4a","97acbffca6184813a4d712adf8363819","0dccd869bfeb4685b14472110e071dba","87a1876237a4494b992d648ac2973397","36f0776a178d40abb45273dfe9329df2","0991ad7964a345629a7892e224c3c682","70d47aea0f504f358c719ffe126fda17","8690dcde5a57420697b00eaf531e0670","8e2c3ca0c72b49909cf356afa7b6f7f0","66cee6e56e8746c49922eaec44e6d2ec","84d2f3ce2c1145c986a30a94f8104017","5fc08c4c8d4e4566a0d713b6d7c0f959","75e524bc395b43d2b339202b6983b568","48ee5bb79efa416fac9df45f85063135","03ea42dba2ca4a71b2a731a12e2461b1","b3084142174f4fb7a3b70f53325d4fb6","ce86feeab54944b2bdeadf46f5606fe5","7c82faad36f94a33be99b5bc0d068a0f","db9eb966db5648839dc69d17888a5e7d","64dff687216c41daa26c2c7a694ae661","46b65afe60a44a8f85c30c26695c779d","3377e1993c9644a29b52d93f61f9c8f6","b7e75e7f095b4251bfc550934447cb89","8d18d4b87faa4163be4720172a3c5987","97469481337747a9be4e098da03574d4","f4339c1ce1744fdf82e4366b3dfd29a6","e3aa1db548ac4ff5b4fd027b0564d53c"],"height":226},"outputId":"48e54318-03bf-47f7-ecef-000fe7d8e45f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ce628395944c11983bd1031023d3aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62038a0925f04a919c91cbffcdda3d27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1b34f6a8cf94bc49cfdb75bc3878ceb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93fec7f90c045b68ba4f8c6d3356a41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0991ad7964a345629a7892e224c3c682"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce86feeab54944b2bdeadf46f5606fe5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fdh5--MfYw7-","executionInfo":{"status":"ok","timestamp":1698697130950,"user_tz":240,"elapsed":10264,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"335e4f22-e2ee-49b3-ba1e-f2eba9042ee5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9106, done.\u001b[K\n","remote: Counting objects: 100% (1820/1820), done.\u001b[K\n","remote: Compressing objects: 100% (289/289), done.\u001b[K\n","remote: Total 9106 (delta 1614), reused 1608 (delta 1528), pack-reused 7286\u001b[K\n","Receiving objects: 100% (9106/9106), 155.60 MiB | 23.64 MiB/s, done.\n","Resolving deltas: 100% (5507/5507), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ4C_bsXZFfj","executionInfo":{"status":"ok","timestamp":1698697130951,"user_tz":240,"elapsed":30,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1972ddbc-12c1-4de8-8aa8-0309d6ca6709"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV","executionInfo":{"status":"ok","timestamp":1698697130951,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn","executionInfo":{"status":"ok","timestamp":1698697130952,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Repalce io_tokens with correct answer (next, which is '5') and s_tokens with incorrect (current, which repeats)"],"metadata":{"id":"exuTCQ_XmmFP"}},{"cell_type":"code","source":["pos_dict = {\n","    'S1': 0,\n","    'S2': 1,\n","    'S3': 2,\n","    'S4': 3,\n","}"],"metadata":{"id":"sGHl4RZTE98L","executionInfo":{"status":"ok","timestamp":1698697130952,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': str(i),\n","            'S2': str(i+1),\n","            'S3': str(i+2),\n","            'S4': str(i+3),\n","            'corr': str(i+4),\n","            'incorr': str(i),\n","            'text': f\"{i} {i+1} {i+2} {i+3}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 101)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"u0NPSKcZ1iDe","executionInfo":{"status":"ok","timestamp":1698697130952,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        r1 = random.randint(15, 30)\n","        r2 = random.randint(15, 30)\n","        r3 = random.randint(15, 30)\n","        r4 = random.randint(15, 30)\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': str(r1),\n","            'incorr': str(i+4),\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(1, 101)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list_2"],"metadata":{"id":"dzzLlCqZS_wl","executionInfo":{"status":"ok","timestamp":1698697130952,"user_tz":240,"elapsed":27,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"169b7c4f-8fc1-454b-b944-256b43089e7e"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': '21',\n","  'S2': '22',\n","  'S3': '21',\n","  'S4': '15',\n","  'corr': '21',\n","  'incorr': '5',\n","  'text': '21 22 21 15'},\n"," {'S1': '21',\n","  'S2': '20',\n","  'S3': '17',\n","  'S4': '28',\n","  'corr': '21',\n","  'incorr': '6',\n","  'text': '21 20 17 28'},\n"," {'S1': '25',\n","  'S2': '17',\n","  'S3': '19',\n","  'S4': '29',\n","  'corr': '25',\n","  'incorr': '7',\n","  'text': '25 17 19 29'},\n"," {'S1': '27',\n","  'S2': '23',\n","  'S3': '25',\n","  'S4': '28',\n","  'corr': '27',\n","  'incorr': '8',\n","  'text': '27 23 25 28'},\n"," {'S1': '18',\n","  'S2': '15',\n","  'S3': '27',\n","  'S4': '20',\n","  'corr': '18',\n","  'incorr': '9',\n","  'text': '18 15 27 20'},\n"," {'S1': '23',\n","  'S2': '18',\n","  'S3': '25',\n","  'S4': '22',\n","  'corr': '23',\n","  'incorr': '10',\n","  'text': '23 18 25 22'},\n"," {'S1': '22',\n","  'S2': '28',\n","  'S3': '23',\n","  'S4': '22',\n","  'corr': '22',\n","  'incorr': '11',\n","  'text': '22 28 23 22'},\n"," {'S1': '16',\n","  'S2': '19',\n","  'S3': '15',\n","  'S4': '26',\n","  'corr': '16',\n","  'incorr': '12',\n","  'text': '16 19 15 26'},\n"," {'S1': '30',\n","  'S2': '21',\n","  'S3': '23',\n","  'S4': '15',\n","  'corr': '30',\n","  'incorr': '13',\n","  'text': '30 21 23 15'},\n"," {'S1': '25',\n","  'S2': '22',\n","  'S3': '20',\n","  'S4': '21',\n","  'corr': '25',\n","  'incorr': '14',\n","  'text': '25 22 20 21'},\n"," {'S1': '25',\n","  'S2': '16',\n","  'S3': '18',\n","  'S4': '26',\n","  'corr': '25',\n","  'incorr': '15',\n","  'text': '25 16 18 26'},\n"," {'S1': '25',\n","  'S2': '20',\n","  'S3': '23',\n","  'S4': '23',\n","  'corr': '25',\n","  'incorr': '16',\n","  'text': '25 20 23 23'},\n"," {'S1': '27',\n","  'S2': '29',\n","  'S3': '18',\n","  'S4': '22',\n","  'corr': '27',\n","  'incorr': '17',\n","  'text': '27 29 18 22'},\n"," {'S1': '29',\n","  'S2': '23',\n","  'S3': '16',\n","  'S4': '17',\n","  'corr': '29',\n","  'incorr': '18',\n","  'text': '29 23 16 17'},\n"," {'S1': '22',\n","  'S2': '24',\n","  'S3': '28',\n","  'S4': '27',\n","  'corr': '22',\n","  'incorr': '19',\n","  'text': '22 24 28 27'},\n"," {'S1': '15',\n","  'S2': '30',\n","  'S3': '18',\n","  'S4': '26',\n","  'corr': '15',\n","  'incorr': '20',\n","  'text': '15 30 18 26'},\n"," {'S1': '21',\n","  'S2': '15',\n","  'S3': '22',\n","  'S4': '23',\n","  'corr': '21',\n","  'incorr': '21',\n","  'text': '21 15 22 23'},\n"," {'S1': '19',\n","  'S2': '26',\n","  'S3': '29',\n","  'S4': '18',\n","  'corr': '19',\n","  'incorr': '22',\n","  'text': '19 26 29 18'},\n"," {'S1': '22',\n","  'S2': '20',\n","  'S3': '17',\n","  'S4': '16',\n","  'corr': '22',\n","  'incorr': '23',\n","  'text': '22 20 17 16'},\n"," {'S1': '17',\n","  'S2': '29',\n","  'S3': '18',\n","  'S4': '22',\n","  'corr': '17',\n","  'incorr': '24',\n","  'text': '17 29 18 22'},\n"," {'S1': '23',\n","  'S2': '21',\n","  'S3': '17',\n","  'S4': '17',\n","  'corr': '23',\n","  'incorr': '25',\n","  'text': '23 21 17 17'},\n"," {'S1': '24',\n","  'S2': '24',\n","  'S3': '17',\n","  'S4': '29',\n","  'corr': '24',\n","  'incorr': '26',\n","  'text': '24 24 17 29'},\n"," {'S1': '20',\n","  'S2': '23',\n","  'S3': '26',\n","  'S4': '17',\n","  'corr': '20',\n","  'incorr': '27',\n","  'text': '20 23 26 17'},\n"," {'S1': '23',\n","  'S2': '21',\n","  'S3': '28',\n","  'S4': '20',\n","  'corr': '23',\n","  'incorr': '28',\n","  'text': '23 21 28 20'},\n"," {'S1': '30',\n","  'S2': '25',\n","  'S3': '19',\n","  'S4': '19',\n","  'corr': '30',\n","  'incorr': '29',\n","  'text': '30 25 19 19'},\n"," {'S1': '22',\n","  'S2': '17',\n","  'S3': '30',\n","  'S4': '25',\n","  'corr': '22',\n","  'incorr': '30',\n","  'text': '22 17 30 25'},\n"," {'S1': '20',\n","  'S2': '25',\n","  'S3': '21',\n","  'S4': '15',\n","  'corr': '20',\n","  'incorr': '31',\n","  'text': '20 25 21 15'},\n"," {'S1': '16',\n","  'S2': '24',\n","  'S3': '18',\n","  'S4': '27',\n","  'corr': '16',\n","  'incorr': '32',\n","  'text': '16 24 18 27'},\n"," {'S1': '26',\n","  'S2': '26',\n","  'S3': '19',\n","  'S4': '26',\n","  'corr': '26',\n","  'incorr': '33',\n","  'text': '26 26 19 26'},\n"," {'S1': '15',\n","  'S2': '19',\n","  'S3': '30',\n","  'S4': '24',\n","  'corr': '15',\n","  'incorr': '34',\n","  'text': '15 19 30 24'},\n"," {'S1': '16',\n","  'S2': '19',\n","  'S3': '15',\n","  'S4': '19',\n","  'corr': '16',\n","  'incorr': '35',\n","  'text': '16 19 15 19'},\n"," {'S1': '18',\n","  'S2': '20',\n","  'S3': '15',\n","  'S4': '17',\n","  'corr': '18',\n","  'incorr': '36',\n","  'text': '18 20 15 17'},\n"," {'S1': '21',\n","  'S2': '21',\n","  'S3': '16',\n","  'S4': '22',\n","  'corr': '21',\n","  'incorr': '37',\n","  'text': '21 21 16 22'},\n"," {'S1': '15',\n","  'S2': '23',\n","  'S3': '22',\n","  'S4': '23',\n","  'corr': '15',\n","  'incorr': '38',\n","  'text': '15 23 22 23'},\n"," {'S1': '15',\n","  'S2': '28',\n","  'S3': '21',\n","  'S4': '27',\n","  'corr': '15',\n","  'incorr': '39',\n","  'text': '15 28 21 27'},\n"," {'S1': '29',\n","  'S2': '20',\n","  'S3': '15',\n","  'S4': '17',\n","  'corr': '29',\n","  'incorr': '40',\n","  'text': '29 20 15 17'},\n"," {'S1': '17',\n","  'S2': '17',\n","  'S3': '30',\n","  'S4': '18',\n","  'corr': '17',\n","  'incorr': '41',\n","  'text': '17 17 30 18'},\n"," {'S1': '24',\n","  'S2': '22',\n","  'S3': '17',\n","  'S4': '16',\n","  'corr': '24',\n","  'incorr': '42',\n","  'text': '24 22 17 16'},\n"," {'S1': '19',\n","  'S2': '27',\n","  'S3': '22',\n","  'S4': '19',\n","  'corr': '19',\n","  'incorr': '43',\n","  'text': '19 27 22 19'},\n"," {'S1': '17',\n","  'S2': '26',\n","  'S3': '27',\n","  'S4': '28',\n","  'corr': '17',\n","  'incorr': '44',\n","  'text': '17 26 27 28'},\n"," {'S1': '19',\n","  'S2': '23',\n","  'S3': '25',\n","  'S4': '17',\n","  'corr': '19',\n","  'incorr': '45',\n","  'text': '19 23 25 17'},\n"," {'S1': '18',\n","  'S2': '23',\n","  'S3': '23',\n","  'S4': '23',\n","  'corr': '18',\n","  'incorr': '46',\n","  'text': '18 23 23 23'},\n"," {'S1': '17',\n","  'S2': '20',\n","  'S3': '25',\n","  'S4': '30',\n","  'corr': '17',\n","  'incorr': '47',\n","  'text': '17 20 25 30'},\n"," {'S1': '21',\n","  'S2': '24',\n","  'S3': '30',\n","  'S4': '18',\n","  'corr': '21',\n","  'incorr': '48',\n","  'text': '21 24 30 18'},\n"," {'S1': '21',\n","  'S2': '20',\n","  'S3': '24',\n","  'S4': '26',\n","  'corr': '21',\n","  'incorr': '49',\n","  'text': '21 20 24 26'},\n"," {'S1': '22',\n","  'S2': '25',\n","  'S3': '27',\n","  'S4': '21',\n","  'corr': '22',\n","  'incorr': '50',\n","  'text': '22 25 27 21'},\n"," {'S1': '17',\n","  'S2': '19',\n","  'S3': '23',\n","  'S4': '27',\n","  'corr': '17',\n","  'incorr': '51',\n","  'text': '17 19 23 27'},\n"," {'S1': '18',\n","  'S2': '25',\n","  'S3': '27',\n","  'S4': '17',\n","  'corr': '18',\n","  'incorr': '52',\n","  'text': '18 25 27 17'},\n"," {'S1': '22',\n","  'S2': '26',\n","  'S3': '15',\n","  'S4': '27',\n","  'corr': '22',\n","  'incorr': '53',\n","  'text': '22 26 15 27'},\n"," {'S1': '25',\n","  'S2': '23',\n","  'S3': '17',\n","  'S4': '15',\n","  'corr': '25',\n","  'incorr': '54',\n","  'text': '25 23 17 15'},\n"," {'S1': '18',\n","  'S2': '29',\n","  'S3': '29',\n","  'S4': '29',\n","  'corr': '18',\n","  'incorr': '55',\n","  'text': '18 29 29 29'},\n"," {'S1': '19',\n","  'S2': '22',\n","  'S3': '22',\n","  'S4': '22',\n","  'corr': '19',\n","  'incorr': '56',\n","  'text': '19 22 22 22'},\n"," {'S1': '23',\n","  'S2': '19',\n","  'S3': '18',\n","  'S4': '21',\n","  'corr': '23',\n","  'incorr': '57',\n","  'text': '23 19 18 21'},\n"," {'S1': '15',\n","  'S2': '16',\n","  'S3': '25',\n","  'S4': '24',\n","  'corr': '15',\n","  'incorr': '58',\n","  'text': '15 16 25 24'},\n"," {'S1': '16',\n","  'S2': '28',\n","  'S3': '23',\n","  'S4': '27',\n","  'corr': '16',\n","  'incorr': '59',\n","  'text': '16 28 23 27'},\n"," {'S1': '19',\n","  'S2': '30',\n","  'S3': '30',\n","  'S4': '26',\n","  'corr': '19',\n","  'incorr': '60',\n","  'text': '19 30 30 26'},\n"," {'S1': '21',\n","  'S2': '20',\n","  'S3': '23',\n","  'S4': '27',\n","  'corr': '21',\n","  'incorr': '61',\n","  'text': '21 20 23 27'},\n"," {'S1': '18',\n","  'S2': '16',\n","  'S3': '24',\n","  'S4': '24',\n","  'corr': '18',\n","  'incorr': '62',\n","  'text': '18 16 24 24'},\n"," {'S1': '20',\n","  'S2': '23',\n","  'S3': '21',\n","  'S4': '18',\n","  'corr': '20',\n","  'incorr': '63',\n","  'text': '20 23 21 18'},\n"," {'S1': '28',\n","  'S2': '16',\n","  'S3': '25',\n","  'S4': '16',\n","  'corr': '28',\n","  'incorr': '64',\n","  'text': '28 16 25 16'},\n"," {'S1': '19',\n","  'S2': '26',\n","  'S3': '20',\n","  'S4': '26',\n","  'corr': '19',\n","  'incorr': '65',\n","  'text': '19 26 20 26'},\n"," {'S1': '16',\n","  'S2': '18',\n","  'S3': '26',\n","  'S4': '21',\n","  'corr': '16',\n","  'incorr': '66',\n","  'text': '16 18 26 21'},\n"," {'S1': '19',\n","  'S2': '19',\n","  'S3': '16',\n","  'S4': '23',\n","  'corr': '19',\n","  'incorr': '67',\n","  'text': '19 19 16 23'},\n"," {'S1': '21',\n","  'S2': '24',\n","  'S3': '17',\n","  'S4': '22',\n","  'corr': '21',\n","  'incorr': '68',\n","  'text': '21 24 17 22'},\n"," {'S1': '30',\n","  'S2': '15',\n","  'S3': '16',\n","  'S4': '27',\n","  'corr': '30',\n","  'incorr': '69',\n","  'text': '30 15 16 27'},\n"," {'S1': '21',\n","  'S2': '15',\n","  'S3': '19',\n","  'S4': '19',\n","  'corr': '21',\n","  'incorr': '70',\n","  'text': '21 15 19 19'},\n"," {'S1': '25',\n","  'S2': '15',\n","  'S3': '24',\n","  'S4': '18',\n","  'corr': '25',\n","  'incorr': '71',\n","  'text': '25 15 24 18'},\n"," {'S1': '19',\n","  'S2': '20',\n","  'S3': '21',\n","  'S4': '19',\n","  'corr': '19',\n","  'incorr': '72',\n","  'text': '19 20 21 19'},\n"," {'S1': '26',\n","  'S2': '24',\n","  'S3': '18',\n","  'S4': '19',\n","  'corr': '26',\n","  'incorr': '73',\n","  'text': '26 24 18 19'},\n"," {'S1': '21',\n","  'S2': '24',\n","  'S3': '25',\n","  'S4': '26',\n","  'corr': '21',\n","  'incorr': '74',\n","  'text': '21 24 25 26'},\n"," {'S1': '23',\n","  'S2': '16',\n","  'S3': '20',\n","  'S4': '22',\n","  'corr': '23',\n","  'incorr': '75',\n","  'text': '23 16 20 22'},\n"," {'S1': '15',\n","  'S2': '15',\n","  'S3': '15',\n","  'S4': '28',\n","  'corr': '15',\n","  'incorr': '76',\n","  'text': '15 15 15 28'},\n"," {'S1': '24',\n","  'S2': '18',\n","  'S3': '15',\n","  'S4': '27',\n","  'corr': '24',\n","  'incorr': '77',\n","  'text': '24 18 15 27'},\n"," {'S1': '19',\n","  'S2': '15',\n","  'S3': '21',\n","  'S4': '26',\n","  'corr': '19',\n","  'incorr': '78',\n","  'text': '19 15 21 26'},\n"," {'S1': '18',\n","  'S2': '17',\n","  'S3': '30',\n","  'S4': '26',\n","  'corr': '18',\n","  'incorr': '79',\n","  'text': '18 17 30 26'},\n"," {'S1': '30',\n","  'S2': '25',\n","  'S3': '16',\n","  'S4': '29',\n","  'corr': '30',\n","  'incorr': '80',\n","  'text': '30 25 16 29'},\n"," {'S1': '27',\n","  'S2': '26',\n","  'S3': '20',\n","  'S4': '20',\n","  'corr': '27',\n","  'incorr': '81',\n","  'text': '27 26 20 20'},\n"," {'S1': '30',\n","  'S2': '19',\n","  'S3': '17',\n","  'S4': '17',\n","  'corr': '30',\n","  'incorr': '82',\n","  'text': '30 19 17 17'},\n"," {'S1': '27',\n","  'S2': '25',\n","  'S3': '25',\n","  'S4': '30',\n","  'corr': '27',\n","  'incorr': '83',\n","  'text': '27 25 25 30'},\n"," {'S1': '28',\n","  'S2': '21',\n","  'S3': '16',\n","  'S4': '20',\n","  'corr': '28',\n","  'incorr': '84',\n","  'text': '28 21 16 20'},\n"," {'S1': '18',\n","  'S2': '27',\n","  'S3': '20',\n","  'S4': '29',\n","  'corr': '18',\n","  'incorr': '85',\n","  'text': '18 27 20 29'},\n"," {'S1': '18',\n","  'S2': '23',\n","  'S3': '30',\n","  'S4': '30',\n","  'corr': '18',\n","  'incorr': '86',\n","  'text': '18 23 30 30'},\n"," {'S1': '20',\n","  'S2': '28',\n","  'S3': '26',\n","  'S4': '29',\n","  'corr': '20',\n","  'incorr': '87',\n","  'text': '20 28 26 29'},\n"," {'S1': '24',\n","  'S2': '29',\n","  'S3': '26',\n","  'S4': '24',\n","  'corr': '24',\n","  'incorr': '88',\n","  'text': '24 29 26 24'},\n"," {'S1': '27',\n","  'S2': '16',\n","  'S3': '21',\n","  'S4': '16',\n","  'corr': '27',\n","  'incorr': '89',\n","  'text': '27 16 21 16'},\n"," {'S1': '17',\n","  'S2': '25',\n","  'S3': '29',\n","  'S4': '20',\n","  'corr': '17',\n","  'incorr': '90',\n","  'text': '17 25 29 20'},\n"," {'S1': '20',\n","  'S2': '17',\n","  'S3': '15',\n","  'S4': '26',\n","  'corr': '20',\n","  'incorr': '91',\n","  'text': '20 17 15 26'},\n"," {'S1': '19',\n","  'S2': '17',\n","  'S3': '22',\n","  'S4': '24',\n","  'corr': '19',\n","  'incorr': '92',\n","  'text': '19 17 22 24'},\n"," {'S1': '16',\n","  'S2': '25',\n","  'S3': '24',\n","  'S4': '24',\n","  'corr': '16',\n","  'incorr': '93',\n","  'text': '16 25 24 24'},\n"," {'S1': '16',\n","  'S2': '15',\n","  'S3': '21',\n","  'S4': '26',\n","  'corr': '16',\n","  'incorr': '94',\n","  'text': '16 15 21 26'},\n"," {'S1': '17',\n","  'S2': '20',\n","  'S3': '20',\n","  'S4': '24',\n","  'corr': '17',\n","  'incorr': '95',\n","  'text': '17 20 20 24'},\n"," {'S1': '20',\n","  'S2': '25',\n","  'S3': '19',\n","  'S4': '22',\n","  'corr': '20',\n","  'incorr': '96',\n","  'text': '20 25 19 22'},\n"," {'S1': '20',\n","  'S2': '19',\n","  'S3': '16',\n","  'S4': '17',\n","  'corr': '20',\n","  'incorr': '97',\n","  'text': '20 19 16 17'},\n"," {'S1': '18',\n","  'S2': '22',\n","  'S3': '22',\n","  'S4': '21',\n","  'corr': '18',\n","  'incorr': '98',\n","  'text': '18 22 22 21'},\n"," {'S1': '19',\n","  'S2': '23',\n","  'S3': '17',\n","  'S4': '22',\n","  'corr': '19',\n","  'incorr': '99',\n","  'text': '19 23 17 22'},\n"," {'S1': '18',\n","  'S2': '30',\n","  'S3': '30',\n","  'S4': '25',\n","  'corr': '18',\n","  'incorr': '100',\n","  'text': '18 30 30 25'},\n"," {'S1': '30',\n","  'S2': '29',\n","  'S3': '20',\n","  'S4': '25',\n","  'corr': '30',\n","  'incorr': '101',\n","  'text': '30 29 20 25'},\n"," {'S1': '24',\n","  'S2': '15',\n","  'S3': '26',\n","  'S4': '29',\n","  'corr': '24',\n","  'incorr': '102',\n","  'text': '24 15 26 29'},\n"," {'S1': '18',\n","  'S2': '22',\n","  'S3': '17',\n","  'S4': '19',\n","  'corr': '18',\n","  'incorr': '103',\n","  'text': '18 22 17 19'},\n"," {'S1': '20',\n","  'S2': '30',\n","  'S3': '19',\n","  'S4': '15',\n","  'corr': '20',\n","  'incorr': '104',\n","  'text': '20 30 19 15'}]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Logit diff is correct - incorr token. Here, correct is S5, and incorr is S4.\n","\n","Because of this, it's possible to have logit diffs HIGHER than the \"full circuit\" because the correct token will still be at first place, but the logit scores assigned will just be bigger (perhaps incorrect is scored even lower in the non-full circuit with a higher logit diff score)?"],"metadata":{"id":"A0W-GaM6Vfm-"}},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"GCCCoO0V7L7J"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"CgD41x5nbKKP","executionInfo":{"status":"ok","timestamp":1698697472420,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)"],"metadata":{"id":"OI3FcmpMaNxB","executionInfo":{"status":"ok","timestamp":1698697472913,"user_tz":240,"elapsed":273,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, orig_score, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        # \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        # \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    # ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    # orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"LqsdFmbVMntG","executionInfo":{"status":"ok","timestamp":1698697472913,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"GTOk3N3evb3c","executionInfo":{"status":"ok","timestamp":1698697472913,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"flTHN2eQvapG","executionInfo":{"status":"ok","timestamp":1698697472914,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["# Ablate the model and compare with original"],"metadata":{"id":"Lk3bffnCYq-p"}},{"cell_type":"markdown","source":["### try full circuit from repeatLast iter fb"],"metadata":{"id":"x2IM79qgcx4F"}},{"cell_type":"code","source":["curr_circuit = [(0, 1), (0, 3), (0, 5), (0, 7), (0, 8), (0, 9), (0, 10), (1, 0), (1, 5), (3, 0), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 8), (4, 10), (4, 11), (5, 4), (5, 5), (5, 9), (6, 1), (6, 6), (6, 10), (7, 6), (7, 10), (7, 11), (8, 1), (8, 2), (8, 6), (8, 8), (9, 1), (9, 5), (10, 7), (11, 10)]\n","mean_ablate_by_lst(curr_circuit, model, orig_score, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESPP2WGsc0E2","executionInfo":{"status":"ok","timestamp":1698683793042,"user_tz":240,"elapsed":2153,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d8080f81-b75b-4c31-87ac-db4eb7a9bc60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 55.3844\n"]},{"output_type":"execute_result","data":{"text/plain":["55.38440704345703"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["curr_circuit = [(9, 1)]\n","mean_ablate_by_lst(curr_circuit, model, orig_score, print_output=True).item()"],"metadata":{"id":"iWDb4eskc7WF","executionInfo":{"status":"ok","timestamp":1698683795295,"user_tz":240,"elapsed":2261,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e218c843-c38a-4cbb-f4a8-65ed317b57e2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 1.4608\n"]},{"output_type":"execute_result","data":{"text/plain":["1.4607776403427124"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Prune backwards"],"metadata":{"id":"e6N5MU1wRZog"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bfiwe5d3SgVP","executionInfo":{"status":"ok","timestamp":1698684220799,"user_tz":240,"elapsed":323180,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6a31a2b8-6405-419f-b9e1-de990a42d9c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","97.85265350341797\n","\n","\n","Removed: (11, 1)\n","97.83056640625\n","\n","\n","Removed: (11, 2)\n","98.08329010009766\n","\n","\n","Removed: (11, 3)\n","97.8642807006836\n","\n","\n","Removed: (11, 4)\n","98.09476470947266\n","\n","\n","Removed: (11, 5)\n","98.19351196289062\n","\n","\n","Removed: (11, 6)\n","98.30775451660156\n","\n","\n","Removed: (11, 7)\n","98.28131866455078\n","\n","\n","Removed: (11, 9)\n","98.12042999267578\n","\n","\n","Removed: (11, 11)\n","99.49564361572266\n","\n","\n","Removed: (10, 0)\n","99.5240249633789\n","\n","\n","Removed: (10, 1)\n","99.18901824951172\n","\n","\n","Removed: (10, 2)\n","99.78797149658203\n","\n","\n","Removed: (10, 3)\n","99.53922271728516\n","\n","\n","Removed: (10, 4)\n","99.09219360351562\n","\n","\n","Removed: (10, 5)\n","98.38536834716797\n","\n","\n","Removed: (10, 6)\n","98.42536926269531\n","\n","\n","Removed: (10, 7)\n","98.42119598388672\n","\n","\n","Removed: (10, 8)\n","98.67456817626953\n","\n","\n","Removed: (10, 9)\n","98.50550079345703\n","\n","\n","Removed: (10, 10)\n","98.72576904296875\n","\n","\n","Removed: (10, 11)\n","98.79467010498047\n","\n","\n","Removed: (9, 0)\n","98.8804702758789\n","\n","\n","Removed: (9, 2)\n","98.96058654785156\n","\n","\n","Removed: (9, 3)\n","98.78217315673828\n","\n","\n","Removed: (9, 4)\n","98.94293212890625\n","\n","\n","Removed: (9, 5)\n","99.04121398925781\n","\n","\n","Removed: (9, 6)\n","98.49115753173828\n","\n","\n","Removed: (9, 7)\n","97.98028564453125\n","\n","\n","Removed: (9, 8)\n","98.06395721435547\n","\n","\n","Removed: (9, 9)\n","98.58573913574219\n","\n","\n","Removed: (9, 10)\n","98.45941925048828\n","\n","\n","Removed: (9, 11)\n","97.72251892089844\n","\n","\n","Removed: (8, 1)\n","97.18115234375\n","\n","\n","Removed: (8, 2)\n","97.73296356201172\n","\n","\n","Removed: (8, 3)\n","98.16990661621094\n","\n","\n","Removed: (8, 4)\n","98.10066223144531\n","\n","\n","Removed: (8, 7)\n","97.45613098144531\n","\n","\n","Removed: (8, 9)\n","98.106689453125\n","\n","\n","Removed: (8, 10)\n","100.14085388183594\n","\n","\n","Removed: (7, 0)\n","97.0658950805664\n","\n","\n","Removed: (7, 1)\n","97.01699829101562\n","\n","\n","Removed: (7, 3)\n","99.27842712402344\n","\n","\n","Removed: (7, 4)\n","99.24436950683594\n","\n","\n","Removed: (7, 5)\n","98.38958740234375\n","\n","\n","Removed: (7, 7)\n","98.1119384765625\n","\n","\n","Removed: (7, 9)\n","97.86329650878906\n","\n","\n","Removed: (7, 10)\n","97.62041473388672\n","\n","\n","Removed: (6, 0)\n","97.97258758544922\n","\n","\n","Removed: (6, 2)\n","97.9571762084961\n","\n","\n","Removed: (6, 4)\n","97.56224822998047\n","\n","\n","Removed: (6, 5)\n","98.39904022216797\n","\n","\n","Removed: (6, 6)\n","97.04492950439453\n","\n","\n","Removed: (6, 7)\n","97.04459381103516\n","\n","\n","Removed: (5, 0)\n","97.28005981445312\n","\n","\n","Removed: (5, 5)\n","97.14088439941406\n","\n","\n","Removed: (5, 7)\n","97.20795440673828\n","\n","\n","Removed: (5, 9)\n","98.22527313232422\n","\n","\n","Removed: (5, 10)\n","98.18107604980469\n","\n","\n","Removed: (4, 0)\n","98.27295684814453\n","\n","\n","Removed: (4, 1)\n","97.9930191040039\n","\n","\n","Removed: (4, 2)\n","98.21531677246094\n","\n","\n","Removed: (4, 3)\n","98.24832153320312\n","\n","\n","Removed: (4, 5)\n","98.25909423828125\n","\n","\n","Removed: (4, 6)\n","97.1562271118164\n","\n","\n","Removed: (4, 7)\n","97.31117248535156\n","\n","\n","Removed: (4, 8)\n","97.02899169921875\n","\n","\n","Removed: (4, 11)\n","97.04920196533203\n","\n","\n","Removed: (3, 0)\n","98.07057189941406\n","\n","\n","Removed: (3, 2)\n","97.89415740966797\n","\n","\n","Removed: (3, 4)\n","98.24595642089844\n","\n","\n","Removed: (3, 5)\n","97.3864517211914\n","\n","\n","Removed: (3, 10)\n","98.63945770263672\n","\n","\n","Removed: (3, 11)\n","98.30668640136719\n","\n","\n","Removed: (2, 0)\n","97.94631958007812\n","\n","\n","Removed: (2, 1)\n","97.66520690917969\n","\n","\n","Removed: (2, 3)\n","97.40543365478516\n","\n","\n","Removed: (2, 4)\n","97.29763793945312\n","\n","\n","Removed: (2, 5)\n","97.27460479736328\n","\n","\n","Removed: (2, 7)\n","97.89885711669922\n","\n","\n","Removed: (2, 9)\n","97.27963256835938\n","\n","\n","Removed: (2, 11)\n","97.08016967773438\n","\n","\n","Removed: (1, 6)\n","97.03153991699219\n","\n","\n","Removed: (1, 9)\n","97.7073745727539\n","\n","\n","Removed: (1, 10)\n","97.66471099853516\n","\n","\n","Removed: (1, 11)\n","98.0817642211914\n","\n","\n","Removed: (0, 0)\n","98.40170288085938\n","\n","\n","Removed: (0, 3)\n","97.34912872314453\n","\n","\n","Removed: (0, 6)\n","98.64209747314453\n","\n","\n","Removed: (0, 7)\n","98.02359771728516\n","\n","\n","Removed: (0, 8)\n","97.82231140136719\n","\n","\n"]}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, orig_score, print_output=True)"],"metadata":{"id":"qgpGMTWLbibq","executionInfo":{"status":"ok","timestamp":1698684223548,"user_tz":240,"elapsed":2767,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e9478e25-6e33-4982-8821-6c1db69d5277"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.8223\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(97.8223, device='cuda:0')"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["backw_3 = curr_circuit.copy()\n","backw_3"],"metadata":{"id":"7_ZC4-k2blg2","executionInfo":{"status":"ok","timestamp":1698684223549,"user_tz":240,"elapsed":34,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c9b67f38-5fd9-433f-c04c-94dc4d7d1989"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 2),\n"," (0, 4),\n"," (0, 5),\n"," (0, 9),\n"," (0, 10),\n"," (0, 11),\n"," (1, 0),\n"," (1, 1),\n"," (1, 2),\n"," (1, 3),\n"," (1, 4),\n"," (1, 5),\n"," (1, 7),\n"," (1, 8),\n"," (2, 2),\n"," (2, 6),\n"," (2, 8),\n"," (2, 10),\n"," (3, 1),\n"," (3, 3),\n"," (3, 6),\n"," (3, 7),\n"," (3, 8),\n"," (3, 9),\n"," (4, 4),\n"," (4, 9),\n"," (4, 10),\n"," (5, 1),\n"," (5, 2),\n"," (5, 3),\n"," (5, 4),\n"," (5, 6),\n"," (5, 8),\n"," (5, 11),\n"," (6, 1),\n"," (6, 3),\n"," (6, 8),\n"," (6, 9),\n"," (6, 10),\n"," (6, 11),\n"," (7, 2),\n"," (7, 6),\n"," (7, 8),\n"," (7, 11),\n"," (8, 0),\n"," (8, 5),\n"," (8, 6),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (11, 8),\n"," (11, 10)]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["len(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dry8ANsOMgvg","executionInfo":{"status":"ok","timestamp":1698684223549,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c7a3dc6b-dfb8-48f7-96d4-47bbf84c5485"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["53"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["Now try 10% threshold:"],"metadata":{"id":"7vMvM9iRiPyo"}},{"cell_type":"code","source":["def find_circuit_backw(threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    # Start with full circuit\n","    curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, orig_score,print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"Removed:\", (layer, head))\n","                print(new_score)\n","                print(\"\\n\")\n","\n","    return curr_circuit"],"metadata":{"id":"JL6UvAikiQFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circuit = find_circuit_backw(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1IIpte21ipBz","executionInfo":{"status":"ok","timestamp":1698684546473,"user_tz":240,"elapsed":322945,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4df500b3-0a3a-4868-9103-d741d8733167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","97.85265350341797\n","\n","\n","Removed: (11, 1)\n","97.83056640625\n","\n","\n","Removed: (11, 2)\n","98.08329010009766\n","\n","\n","Removed: (11, 3)\n","97.8642807006836\n","\n","\n","Removed: (11, 4)\n","98.09476470947266\n","\n","\n","Removed: (11, 5)\n","98.19351196289062\n","\n","\n","Removed: (11, 6)\n","98.30775451660156\n","\n","\n","Removed: (11, 7)\n","98.28131866455078\n","\n","\n","Removed: (11, 8)\n","95.95122528076172\n","\n","\n","Removed: (11, 9)\n","95.80072021484375\n","\n","\n","Removed: (11, 10)\n","94.64726257324219\n","\n","\n","Removed: (11, 11)\n","95.88154602050781\n","\n","\n","Removed: (10, 0)\n","95.92694091796875\n","\n","\n","Removed: (10, 1)\n","95.60623168945312\n","\n","\n","Removed: (10, 2)\n","96.33126831054688\n","\n","\n","Removed: (10, 3)\n","96.11638641357422\n","\n","\n","Removed: (10, 4)\n","95.68040466308594\n","\n","\n","Removed: (10, 5)\n","94.96817779541016\n","\n","\n","Removed: (10, 6)\n","95.02008819580078\n","\n","\n","Removed: (10, 7)\n","94.5572280883789\n","\n","\n","Removed: (10, 8)\n","94.81536865234375\n","\n","\n","Removed: (10, 9)\n","94.65853881835938\n","\n","\n","Removed: (10, 10)\n","94.8770523071289\n","\n","\n","Removed: (10, 11)\n","94.94637298583984\n","\n","\n","Removed: (9, 0)\n","95.02518463134766\n","\n","\n","Removed: (9, 2)\n","95.09461212158203\n","\n","\n","Removed: (9, 3)\n","94.93053436279297\n","\n","\n","Removed: (9, 4)\n","95.05610656738281\n","\n","\n","Removed: (9, 5)\n","95.1502685546875\n","\n","\n","Removed: (9, 6)\n","94.6552505493164\n","\n","\n","Removed: (9, 7)\n","94.16295623779297\n","\n","\n","Removed: (9, 8)\n","94.2516098022461\n","\n","\n","Removed: (9, 9)\n","94.72444915771484\n","\n","\n","Removed: (9, 10)\n","94.60787963867188\n","\n","\n","Removed: (9, 11)\n","93.96102905273438\n","\n","\n","Removed: (8, 0)\n","90.96553039550781\n","\n","\n","Removed: (8, 1)\n","90.44296264648438\n","\n","\n","Removed: (8, 2)\n","91.01962280273438\n","\n","\n","Removed: (8, 3)\n","91.39356231689453\n","\n","\n","Removed: (8, 4)\n","91.32501983642578\n","\n","\n","Removed: (8, 7)\n","90.71929168701172\n","\n","\n","Removed: (8, 8)\n","90.16282653808594\n","\n","\n","Removed: (8, 9)\n","90.76614379882812\n","\n","\n","Removed: (8, 10)\n","93.53907775878906\n","\n","\n","Removed: (7, 0)\n","90.78385162353516\n","\n","\n","Removed: (7, 1)\n","90.64532470703125\n","\n","\n","Removed: (7, 2)\n","90.35547637939453\n","\n","\n","Removed: (7, 3)\n","92.80581665039062\n","\n","\n","Removed: (7, 4)\n","92.77647399902344\n","\n","\n","Removed: (7, 5)\n","91.86117553710938\n","\n","\n","Removed: (7, 6)\n","90.48531341552734\n","\n","\n","Removed: (7, 7)\n","90.16948699951172\n","\n","\n","Removed: (7, 10)\n","90.27192687988281\n","\n","\n","Removed: (6, 0)\n","91.00862884521484\n","\n","\n","Removed: (6, 1)\n","90.03446197509766\n","\n","\n","Removed: (6, 5)\n","90.81288146972656\n","\n","\n","Removed: (6, 7)\n","90.68368530273438\n","\n","\n","Removed: (6, 9)\n","90.16411590576172\n","\n","\n","Removed: (5, 7)\n","90.20336151123047\n","\n","\n","Removed: (5, 9)\n","90.92915344238281\n","\n","\n","Removed: (5, 10)\n","90.69828033447266\n","\n","\n","Removed: (4, 0)\n","90.79021453857422\n","\n","\n","Removed: (4, 1)\n","90.74076843261719\n","\n","\n","Removed: (4, 2)\n","91.0529556274414\n","\n","\n","Removed: (4, 3)\n","91.0573501586914\n","\n","\n","Removed: (4, 5)\n","91.05681610107422\n","\n","\n","Removed: (4, 7)\n","91.94995880126953\n","\n","\n","Removed: (4, 8)\n","91.51104736328125\n","\n","\n","Removed: (4, 9)\n","90.87132263183594\n","\n","\n","Removed: (3, 0)\n","92.37528991699219\n","\n","\n","Removed: (3, 1)\n","91.18897247314453\n","\n","\n","Removed: (3, 2)\n","90.86732482910156\n","\n","\n","Removed: (3, 4)\n","92.27013397216797\n","\n","\n","Removed: (3, 5)\n","91.36640167236328\n","\n","\n","Removed: (3, 6)\n","90.78752899169922\n","\n","\n","Removed: (3, 9)\n","90.14845275878906\n","\n","\n","Removed: (3, 10)\n","90.4613037109375\n","\n","\n","Removed: (2, 1)\n","90.19515228271484\n","\n","\n","Removed: (2, 5)\n","90.70201873779297\n","\n","\n","Removed: (2, 7)\n","91.13409423828125\n","\n","\n","Removed: (2, 9)\n","90.58336639404297\n","\n","\n","Removed: (2, 11)\n","90.41545867919922\n","\n","\n","Removed: (1, 2)\n","90.2801742553711\n","\n","\n","Removed: (1, 6)\n","90.1711196899414\n","\n","\n","Removed: (1, 9)\n","90.77684020996094\n","\n","\n","Removed: (1, 10)\n","90.70586395263672\n","\n","\n","Removed: (1, 11)\n","91.16293334960938\n","\n","\n","Removed: (0, 0)\n","91.59757232666016\n","\n","\n","Removed: (0, 2)\n","90.12650299072266\n","\n","\n","Removed: (0, 6)\n","91.55269622802734\n","\n","\n","Removed: (0, 7)\n","90.25750732421875\n","\n","\n","Removed: (0, 11)\n","90.19185638427734\n","\n","\n"]}]},{"cell_type":"code","source":["backw_10 = curr_circuit.copy()\n","backw_10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-mSQqFhksjs","executionInfo":{"status":"ok","timestamp":1698684546474,"user_tz":240,"elapsed":49,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ef72876e-dafb-4f15-a578-e1fcdf31a54c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 3),\n"," (0, 4),\n"," (0, 5),\n"," (0, 8),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 1),\n"," (1, 3),\n"," (1, 4),\n"," (1, 5),\n"," (1, 7),\n"," (1, 8),\n"," (2, 0),\n"," (2, 2),\n"," (2, 3),\n"," (2, 4),\n"," (2, 6),\n"," (2, 8),\n"," (2, 10),\n"," (3, 3),\n"," (3, 7),\n"," (3, 8),\n"," (3, 11),\n"," (4, 4),\n"," (4, 6),\n"," (4, 10),\n"," (4, 11),\n"," (5, 0),\n"," (5, 1),\n"," (5, 2),\n"," (5, 3),\n"," (5, 4),\n"," (5, 5),\n"," (5, 6),\n"," (5, 8),\n"," (5, 11),\n"," (6, 2),\n"," (6, 3),\n"," (6, 4),\n"," (6, 6),\n"," (6, 8),\n"," (6, 10),\n"," (6, 11),\n"," (7, 8),\n"," (7, 9),\n"," (7, 11),\n"," (8, 5),\n"," (8, 6),\n"," (8, 11),\n"," (9, 1)]"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, orig_score, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdW57VjOKmQO","executionInfo":{"status":"ok","timestamp":1698684548737,"user_tz":240,"elapsed":2291,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7e6a01a8-b9cd-44a5-c4a7-5e73a5f6e634"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 90.1919\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(90.1919, device='cuda:0')"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["len(backw_10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoaCgwKgKtOX","executionInfo":{"status":"ok","timestamp":1698684548738,"user_tz":240,"elapsed":51,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"51b137f8-d87a-45b5-ced1-5a4d4ec8de3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["52"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["20%:"],"metadata":{"id":"wzmTkj-AKrXG"}},{"cell_type":"code","source":["# %%capture\n","# curr_circuit = find_circuit_backw(20)"],"metadata":{"id":"vp7F1qFGlv-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# backw_20 = curr_circuit.copy()\n","# backw_20"],"metadata":{"id":"Liy24wbtnGF3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mean_ablate_by_lst(curr_circuit, model, orig_score, print_output=True)"],"metadata":{"id":"cdL7_maZKyt7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# len(backw_20)"],"metadata":{"id":"aLYJuXyCKyuE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### set diffs of the three perf lvls"],"metadata":{"id":"M26o5W55NCOd"}},{"cell_type":"code","source":["set(backw_3) - set(backw_10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArPAmmaBNFmP","executionInfo":{"status":"ok","timestamp":1698684548739,"user_tz":240,"elapsed":46,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e7db9558-9f97-49ab-995e-0a132da97f38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 2),\n"," (0, 11),\n"," (1, 2),\n"," (3, 1),\n"," (3, 6),\n"," (3, 9),\n"," (4, 9),\n"," (6, 1),\n"," (6, 9),\n"," (7, 2),\n"," (7, 6),\n"," (8, 0),\n"," (8, 8),\n"," (11, 8),\n"," (11, 10)}"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["set(backw_10) - set(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zRGlGdhENSHR","executionInfo":{"status":"ok","timestamp":1698684548740,"user_tz":240,"elapsed":43,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"924e29d1-cdfb-4fc8-abf6-d0af337cb7b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 3),\n"," (0, 8),\n"," (2, 0),\n"," (2, 3),\n"," (2, 4),\n"," (3, 11),\n"," (4, 6),\n"," (4, 11),\n"," (5, 0),\n"," (5, 5),\n"," (6, 2),\n"," (6, 4),\n"," (6, 6),\n"," (7, 9)}"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# set(backw_3) - set(backw_20)"],"metadata":{"id":"pE70QPLZNWTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set(backw_10) - set(backw_20)"],"metadata":{"id":"iQ4qRwQHNZvw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prune forwards"],"metadata":{"id":"X3Iera3OlvQL"}},{"cell_type":"code","source":["# # Start with full circuit\n","# curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","# threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","# for layer in range(0, 12):\n","#     for head in range(12):\n","#         # Copying the curr_circuit so we can iterate over one and modify the other\n","#         copy_circuit = curr_circuit.copy()\n","\n","#         # Temporarily removing the current tuple from the copied circuit\n","#         copy_circuit.remove((layer, head))\n","\n","#         new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","#         # print((layer,head), new_score)\n","#         # If the result is less than the threshold, remove the tuple from the original list\n","#         if (100 - new_score) < threshold:\n","#             curr_circuit.remove((layer, head))\n","\n","#             print(\"Removed:\", (layer, head))\n","#             print(new_score)\n","#             print(\"\\n\")"],"metadata":{"id":"mipzZtCCl0x5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prune fwds-backwds iteratively"],"metadata":{"id":"w7bys5l5uleW"}},{"cell_type":"markdown","source":["### iter fwd backw, threshold 3"],"metadata":{"id":"e8OFeKuxzM3R"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKZjydkhBfTD","executionInfo":{"status":"ok","timestamp":1698685115723,"user_tz":240,"elapsed":567018,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"40281a10-dd44-424e-93c9-171e6979d4ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","100.7425765991211\n","\n","Removed: (0, 2)\n","99.4460220336914\n","\n","Removed: (0, 3)\n","99.01410675048828\n","\n","Removed: (0, 4)\n","99.1076889038086\n","\n","Removed: (0, 5)\n","98.4770278930664\n","\n","Removed: (0, 6)\n","98.77283477783203\n","\n","Removed: (0, 7)\n","98.28561401367188\n","\n","Removed: (0, 8)\n","98.60443115234375\n","\n","Removed: (0, 11)\n","97.68379974365234\n","\n","Removed: (1, 1)\n","97.444091796875\n","\n","Removed: (1, 2)\n","97.00460052490234\n","\n","Removed: (1, 6)\n","97.26143646240234\n","\n","Removed: (1, 9)\n","97.76024627685547\n","\n","Removed: (1, 10)\n","97.0715560913086\n","\n","Removed: (2, 0)\n","97.0306396484375\n","\n","Removed: (2, 3)\n","97.39745330810547\n","\n","Removed: (2, 4)\n","97.24488067626953\n","\n","Removed: (2, 5)\n","97.24573516845703\n","\n","Removed: (2, 6)\n","97.56053924560547\n","\n","Removed: (2, 7)\n","98.39006042480469\n","\n","Removed: (2, 8)\n","97.12518310546875\n","\n","Removed: (2, 11)\n","97.07171630859375\n","\n","Removed: (3, 0)\n","98.21617126464844\n","\n","Removed: (3, 1)\n","97.15900421142578\n","\n","Removed: (3, 2)\n","97.48379516601562\n","\n","Removed: (3, 4)\n","98.41328430175781\n","\n","Removed: (3, 5)\n","97.61367797851562\n","\n","Removed: (3, 6)\n","97.11524963378906\n","\n","Removed: (3, 10)\n","97.51116943359375\n","\n","Removed: (3, 11)\n","97.07908630371094\n","\n","Removed: (4, 0)\n","97.17315673828125\n","\n","Removed: (4, 1)\n","97.39512634277344\n","\n","Removed: (4, 2)\n","97.63272094726562\n","\n","Removed: (4, 3)\n","97.61065673828125\n","\n","Removed: (4, 5)\n","97.63452911376953\n","\n","Removed: (4, 7)\n","97.5656509399414\n","\n","Removed: (4, 8)\n","97.29984283447266\n","\n","Removed: (5, 7)\n","97.29231262207031\n","\n","Removed: (5, 9)\n","98.93540954589844\n","\n","Removed: (5, 10)\n","99.01119995117188\n","\n","Removed: (5, 11)\n","97.08229064941406\n","\n","Removed: (6, 0)\n","97.5672607421875\n","\n","Removed: (6, 2)\n","97.66232299804688\n","\n","Removed: (6, 4)\n","98.09921264648438\n","\n","Removed: (6, 5)\n","98.85059356689453\n","\n","Removed: (6, 6)\n","98.29918670654297\n","\n","Removed: (6, 7)\n","98.51520538330078\n","\n","Removed: (6, 8)\n","97.51757049560547\n","\n","Removed: (7, 1)\n","97.51551818847656\n","\n","Removed: (7, 2)\n","97.4226303100586\n","\n","Removed: (7, 3)\n","99.12844848632812\n","\n","Removed: (7, 4)\n","99.27278900146484\n","\n","Removed: (7, 5)\n","98.28092956542969\n","\n","Removed: (7, 7)\n","97.89116668701172\n","\n","Removed: (7, 9)\n","97.7136459350586\n","\n","Removed: (7, 10)\n","97.98389434814453\n","\n","Removed: (8, 1)\n","97.24180603027344\n","\n","Removed: (8, 2)\n","97.66130828857422\n","\n","Removed: (8, 3)\n","98.1246109008789\n","\n","Removed: (8, 4)\n","98.04110717773438\n","\n","Removed: (8, 7)\n","97.04179382324219\n","\n","Removed: (8, 9)\n","97.37264251708984\n","\n","Removed: (8, 10)\n","99.63248443603516\n","\n","Removed: (9, 0)\n","99.69933319091797\n","\n","Removed: (9, 2)\n","99.78860473632812\n","\n","Removed: (9, 3)\n","99.29005432128906\n","\n","Removed: (9, 4)\n","99.66925811767578\n","\n","Removed: (9, 5)\n","98.66978454589844\n","\n","Removed: (9, 6)\n","97.1529541015625\n","\n","Removed: (9, 8)\n","97.26261138916016\n","\n","Removed: (9, 9)\n","97.13475799560547\n","\n","Removed: (10, 0)\n","97.17420959472656\n","\n","Removed: (10, 2)\n","97.82576751708984\n","\n","Removed: (10, 3)\n","97.4941635131836\n","\n","Removed: (10, 4)\n","97.04795837402344\n","\n","Removed: (10, 8)\n","97.40511322021484\n","\n","Removed: (10, 9)\n","97.18131256103516\n","\n","Removed: (10, 11)\n","97.38866424560547\n","\n","Removed: (11, 1)\n","97.3580551147461\n","\n","Removed: (11, 2)\n","97.41818237304688\n","\n","Removed: (11, 3)\n","97.08654022216797\n","\n","Removed: (11, 4)\n","97.28836822509766\n","\n","Removed: (11, 5)\n","97.35948181152344\n","\n","Removed: (11, 6)\n","97.44134521484375\n","\n","Removed: (11, 7)\n","97.45004272460938\n","\n","Removed: (11, 9)\n","97.40989685058594\n","\n","Removed: (11, 11)\n","97.77115631103516\n","\n","backw prune, iter  1\n","\n","Removed: (10, 1)\n","97.51069641113281\n","\n","Removed: (10, 6)\n","97.44248962402344\n","\n","Removed: (10, 7)\n","97.5388412475586\n","\n","Removed: (10, 10)\n","97.4431381225586\n","\n","Removed: (9, 7)\n","97.00286865234375\n","\n","fwd prune, iter  2\n"]}]},{"cell_type":"code","source":["fb_3 = curr_circuit.copy()\n","fb_3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET--8aulD8pE","executionInfo":{"status":"ok","timestamp":1698685115724,"user_tz":240,"elapsed":32,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"60a9cc1c-23c5-431c-a9ca-f6b30e1500e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 3),\n"," (1, 4),\n"," (1, 5),\n"," (1, 7),\n"," (1, 8),\n"," (1, 11),\n"," (2, 1),\n"," (2, 2),\n"," (2, 9),\n"," (2, 10),\n"," (3, 3),\n"," (3, 7),\n"," (3, 8),\n"," (3, 9),\n"," (4, 4),\n"," (4, 6),\n"," (4, 9),\n"," (4, 10),\n"," (4, 11),\n"," (5, 0),\n"," (5, 1),\n"," (5, 2),\n"," (5, 3),\n"," (5, 4),\n"," (5, 5),\n"," (5, 6),\n"," (5, 8),\n"," (6, 1),\n"," (6, 3),\n"," (6, 9),\n"," (6, 10),\n"," (6, 11),\n"," (7, 0),\n"," (7, 6),\n"," (7, 8),\n"," (7, 11),\n"," (8, 0),\n"," (8, 5),\n"," (8, 6),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (9, 10),\n"," (9, 11),\n"," (10, 5),\n"," (11, 0),\n"," (11, 8),\n"," (11, 10)]"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["mean_ablate_by_lst(fb_3, model, orig_score, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLOevwFnbAEK","executionInfo":{"status":"ok","timestamp":1698685118018,"user_tz":240,"elapsed":2320,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"07326a96-3960-4226-975d-62d5e1a51bfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0029\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(97.0029, device='cuda:0')"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["len(fb_3)"],"metadata":{"id":"LrUsg4sdhyfu","executionInfo":{"status":"ok","timestamp":1698685207101,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d82ab47a-6878-4e1f-b3ef-ab042a3b4467","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["52"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["#### compare"],"metadata":{"id":"KvRRtGHxScYH"}},{"cell_type":"code","source":["set(backw_3) - set(fb_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLDzDrR9Sa-O","executionInfo":{"status":"ok","timestamp":1698685118018,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"972cfa42-e585-49c8-b6c8-a5cae87a193b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 2),\n"," (0, 4),\n"," (0, 5),\n"," (0, 11),\n"," (1, 1),\n"," (1, 2),\n"," (2, 6),\n"," (2, 8),\n"," (3, 1),\n"," (3, 6),\n"," (5, 11),\n"," (6, 8),\n"," (7, 2)}"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["set(fb_3) - set(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGKbGobdSiPG","executionInfo":{"status":"ok","timestamp":1698685118018,"user_tz":240,"elapsed":14,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7334c443-f3d7-446e-95e3-b2f1cf12822f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(1, 11),\n"," (2, 1),\n"," (2, 9),\n"," (4, 6),\n"," (4, 11),\n"," (5, 0),\n"," (5, 5),\n"," (7, 0),\n"," (9, 10),\n"," (9, 11),\n"," (10, 5),\n"," (11, 0)}"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 10"],"metadata":{"id":"C2fvsn5SFnrO"}},{"cell_type":"code","source":["threshold = 10\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"id":"smR_M0B7FnrP","executionInfo":{"status":"ok","timestamp":1698698063565,"user_tz":240,"elapsed":587155,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e73730a9-c111-4b9c-c0a2-3792f1e8ca80"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","100.8212661743164\n","\n","Removed: (0, 1)\n","95.169189453125\n","\n","Removed: (0, 2)\n","95.5042495727539\n","\n","Removed: (0, 3)\n","94.88127899169922\n","\n","Removed: (0, 4)\n","94.91898345947266\n","\n","Removed: (0, 5)\n","92.89237976074219\n","\n","Removed: (0, 6)\n","92.08833312988281\n","\n","Removed: (0, 7)\n","92.26124572753906\n","\n","Removed: (0, 8)\n","92.99267578125\n","\n","Removed: (0, 11)\n","91.43850708007812\n","\n","Removed: (1, 0)\n","90.70109558105469\n","\n","Removed: (1, 2)\n","90.29553985595703\n","\n","Removed: (1, 4)\n","90.37667846679688\n","\n","Removed: (1, 6)\n","90.71451568603516\n","\n","Removed: (1, 7)\n","90.42693328857422\n","\n","Removed: (1, 8)\n","90.64578247070312\n","\n","Removed: (1, 9)\n","90.65349578857422\n","\n","Removed: (1, 10)\n","90.44621276855469\n","\n","Removed: (2, 0)\n","90.53362274169922\n","\n","Removed: (2, 1)\n","90.0886459350586\n","\n","Removed: (2, 3)\n","90.11341857910156\n","\n","Removed: (2, 6)\n","90.55094909667969\n","\n","Removed: (2, 7)\n","91.04247283935547\n","\n","Removed: (2, 9)\n","90.68740844726562\n","\n","Removed: (2, 11)\n","90.64917755126953\n","\n","Removed: (3, 0)\n","91.1910629272461\n","\n","Removed: (3, 2)\n","91.53883361816406\n","\n","Removed: (3, 4)\n","93.04419708251953\n","\n","Removed: (3, 5)\n","92.32230377197266\n","\n","Removed: (3, 6)\n","91.22993469238281\n","\n","Removed: (3, 8)\n","90.3803482055664\n","\n","Removed: (4, 0)\n","90.53064727783203\n","\n","Removed: (4, 1)\n","90.60090637207031\n","\n","Removed: (4, 2)\n","90.87782287597656\n","\n","Removed: (4, 3)\n","90.7429428100586\n","\n","Removed: (4, 5)\n","90.81090545654297\n","\n","Removed: (4, 7)\n","91.41478729248047\n","\n","Removed: (4, 8)\n","90.94801330566406\n","\n","Removed: (4, 9)\n","90.23204803466797\n","\n","Removed: (5, 5)\n","90.64178466796875\n","\n","Removed: (5, 7)\n","90.65440368652344\n","\n","Removed: (5, 9)\n","93.31502532958984\n","\n","Removed: (5, 10)\n","93.70193481445312\n","\n","Removed: (5, 11)\n","91.05585479736328\n","\n","Removed: (6, 0)\n","91.68719482421875\n","\n","Removed: (6, 1)\n","91.46617126464844\n","\n","Removed: (6, 2)\n","91.91615295410156\n","\n","Removed: (6, 4)\n","92.61756134033203\n","\n","Removed: (6, 5)\n","93.61048126220703\n","\n","Removed: (6, 6)\n","91.97272491455078\n","\n","Removed: (6, 7)\n","92.2221908569336\n","\n","Removed: (6, 8)\n","90.94187927246094\n","\n","Removed: (6, 11)\n","90.0832748413086\n","\n","Removed: (7, 1)\n","90.0660400390625\n","\n","Removed: (7, 3)\n","91.8376235961914\n","\n","Removed: (7, 4)\n","91.83272552490234\n","\n","Removed: (7, 5)\n","90.84391021728516\n","\n","Removed: (7, 7)\n","90.43096923828125\n","\n","Removed: (7, 9)\n","90.2990951538086\n","\n","Removed: (8, 2)\n","90.74961853027344\n","\n","Removed: (8, 3)\n","91.06265258789062\n","\n","Removed: (8, 4)\n","90.98872375488281\n","\n","Removed: (8, 5)\n","90.07041931152344\n","\n","Removed: (8, 9)\n","90.14128112792969\n","\n","Removed: (8, 10)\n","92.108154296875\n","\n","Removed: (9, 0)\n","92.09085845947266\n","\n","Removed: (9, 2)\n","92.18778228759766\n","\n","Removed: (9, 3)\n","92.10465240478516\n","\n","Removed: (9, 4)\n","92.23516845703125\n","\n","Removed: (9, 5)\n","91.83555603027344\n","\n","Removed: (9, 6)\n","90.70228576660156\n","\n","Removed: (9, 7)\n","90.3257064819336\n","\n","Removed: (9, 8)\n","90.4198226928711\n","\n","Removed: (9, 9)\n","91.55010986328125\n","\n","Removed: (9, 10)\n","91.402099609375\n","\n","Removed: (9, 11)\n","90.82118225097656\n","\n","Removed: (10, 0)\n","90.8482666015625\n","\n","Removed: (10, 1)\n","90.5416259765625\n","\n","Removed: (10, 2)\n","91.03349304199219\n","\n","Removed: (10, 3)\n","90.67867279052734\n","\n","Removed: (10, 4)\n","90.22899627685547\n","\n","Removed: (10, 6)\n","90.16671752929688\n","\n","Removed: (10, 8)\n","90.4738998413086\n","\n","Removed: (10, 9)\n","90.34388732910156\n","\n","Removed: (10, 10)\n","90.22063446044922\n","\n","Removed: (10, 11)\n","90.4143295288086\n","\n","Removed: (11, 1)\n","90.47903442382812\n","\n","Removed: (11, 2)\n","90.49060821533203\n","\n","Removed: (11, 3)\n","90.12969970703125\n","\n","Removed: (11, 4)\n","90.27146911621094\n","\n","Removed: (11, 5)\n","90.32472229003906\n","\n","Removed: (11, 6)\n","90.3756332397461\n","\n","Removed: (11, 7)\n","90.40685272216797\n","\n","Removed: (11, 9)\n","90.43038177490234\n","\n","Removed: (11, 11)\n","90.84011840820312\n","\n","backw prune, iter  1\n","\n","Removed: (10, 5)\n","90.03250885009766\n","\n","fwd prune, iter  2\n"]}]},{"cell_type":"code","source":["curr_circuit"],"metadata":{"id":"78x6pmqkFnrP","executionInfo":{"status":"ok","timestamp":1698698063565,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c75b1ea-c8ed-415c-f549-f0de01f21f95"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 9),\n"," (0, 10),\n"," (1, 1),\n"," (1, 3),\n"," (1, 5),\n"," (1, 11),\n"," (2, 2),\n"," (2, 4),\n"," (2, 5),\n"," (2, 8),\n"," (2, 10),\n"," (3, 1),\n"," (3, 3),\n"," (3, 7),\n"," (3, 9),\n"," (3, 10),\n"," (3, 11),\n"," (4, 4),\n"," (4, 6),\n"," (4, 10),\n"," (4, 11),\n"," (5, 0),\n"," (5, 1),\n"," (5, 2),\n"," (5, 3),\n"," (5, 4),\n"," (5, 6),\n"," (5, 8),\n"," (6, 3),\n"," (6, 9),\n"," (6, 10),\n"," (7, 0),\n"," (7, 2),\n"," (7, 6),\n"," (7, 8),\n"," (7, 10),\n"," (7, 11),\n"," (8, 0),\n"," (8, 1),\n"," (8, 6),\n"," (8, 7),\n"," (8, 8),\n"," (8, 11),\n"," (9, 1),\n"," (10, 7),\n"," (11, 0),\n"," (11, 8),\n"," (11, 10)]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["fb_10 = curr_circuit.copy()\n","len(fb_10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqMvU03xQp8v","executionInfo":{"status":"ok","timestamp":1698698267612,"user_tz":240,"elapsed":242,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"721c16a3-3d53-4693-fab8-5e5c16e2e011"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["48"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["## Prune backwds-fwds iteratively"],"metadata":{"id":"1putaGukK8at"}},{"cell_type":"markdown","source":["### iter fwd backw, threshold 3"],"metadata":{"id":"E69b948rS4qQ"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"error","timestamp":1698685174365,"user_tz":240,"elapsed":56358,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"2EJaexibS4qb","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"00663c4f-b1f4-455d-a34c-22cc7a1bb4f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","97.85265350341797\n","\n","Removed: (11, 1)\n","97.83056640625\n","\n","Removed: (11, 2)\n","98.08329010009766\n","\n","Removed: (11, 3)\n","97.8642807006836\n","\n","Removed: (11, 4)\n","98.09476470947266\n","\n","Removed: (11, 5)\n","98.19351196289062\n","\n","Removed: (11, 6)\n","98.30775451660156\n","\n","Removed: (11, 7)\n","98.28131866455078\n","\n","Removed: (11, 9)\n","98.12042999267578\n","\n","Removed: (11, 11)\n","99.49564361572266\n","\n","Removed: (10, 0)\n","99.5240249633789\n","\n","Removed: (10, 1)\n","99.18901824951172\n","\n","Removed: (10, 2)\n","99.78797149658203\n","\n","Removed: (10, 3)\n","99.53922271728516\n","\n","Removed: (10, 4)\n","99.09219360351562\n","\n","Removed: (10, 5)\n","98.38536834716797\n","\n","Removed: (10, 6)\n","98.42536926269531\n","\n","Removed: (10, 7)\n","98.42119598388672\n","\n","Removed: (10, 8)\n","98.67456817626953\n","\n","Removed: (10, 9)\n","98.50550079345703\n","\n","Removed: (10, 10)\n","98.72576904296875\n","\n","Removed: (10, 11)\n","98.79467010498047\n","\n","Removed: (9, 0)\n","98.8804702758789\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-9b4edda2c2d9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# prev_score = new_score # save old score before finding new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mold_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save old before finding new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcurr_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_circuit_backw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_circuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcurr_circuit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mold_circuit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-dff022307aa4>\u001b[0m in \u001b[0;36mfind_circuit_backw\u001b[0;34m(curr_circuit, threshold)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcopy_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_ablate_by_lst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# If the result is less than the threshold, remove the tuple from the original list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-9d6e9137c5d5>\u001b[0m in \u001b[0;36mmean_ablate_by_lst\u001b[0;34m(lst, model, orig_score, print_output)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_circuit_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mean_ablation_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mioi_logits_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36madd_mean_ablation_hook\u001b[0;34m(model, means_dataset, circuit, seq_pos_to_keep, is_permanent)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Apply hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_permanent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_permanent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36madd_hook\u001b[0;34m(self, name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook_point_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_point_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     self.check_and_add_hook(\n\u001b[0m\u001b[1;32m    259\u001b[0m                         \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                         \u001b[0mhook_point_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mcheck_and_add_hook\u001b[0;34m(self, hook_point, hook_point_name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         )\n\u001b[0;32m--> 231\u001b[0;31m         hook_point.add_hook(\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_permanent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_permanent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36madd_hook\u001b[0;34m(self, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             full_hook.__name__ = (\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             )  # annotate the `full_hook` with the string representation of the `hook` function\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    429\u001b[0m             )\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     def backward(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mguard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableFuncTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         slices = (\n\u001b[0;32m--> 276\u001b[0;31m             [\n\u001b[0m\u001b[1;32m    277\u001b[0m                 _tensor_str_with_formatter(\n\u001b[1;32m    278\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    275\u001b[0m         slices = (\n\u001b[1;32m    276\u001b[0m             [\n\u001b[0;32m--> 277\u001b[0;31m                 _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    281\u001b[0m             ]\n\u001b[1;32m    282\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             + [\n\u001b[0m\u001b[1;32m    284\u001b[0m                 _tensor_str_with_formatter(\n\u001b[1;32m    285\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             + [\n\u001b[0;32m--> 284\u001b[0;31m                 _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    285\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    289\u001b[0m         )\n\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         slices = [\n\u001b[0m\u001b[1;32m    292\u001b[0m             _tensor_str_with_formatter(\n\u001b[1;32m    293\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         slices = [\n\u001b[0;32m--> 292\u001b[0;31m             _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    281\u001b[0m             ]\n\u001b[1;32m    282\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             + [\n\u001b[0m\u001b[1;32m    284\u001b[0m                 _tensor_str_with_formatter(\n\u001b[1;32m    285\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             + [\n\u001b[0;32m--> 284\u001b[0;31m                 _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    285\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_vector_str\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0m_val_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" ...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_val_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         )\n\u001b[1;32m    252\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"id":"C2EgKgmJS4qb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### compare"],"metadata":{"id":"ZXouisDpS4qb"}},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"id":"kPspQ2ZCVeID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(fb_3)"],"metadata":{"id":"4b2csbQpVg5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(backw_3) - set(bf_3)"],"metadata":{"id":"TthWjv5IS4qc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(bf_3) - set(backw_3)"],"metadata":{"id":"yMADPA_oTFb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(fb_3) - (set(fb_3) - set(bf_3))"],"metadata":{"id":"epw2Vlh2S4qc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(bf_3) - set(fb_3)"],"metadata":{"id":"1KXH3MTsTHm9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get score of fb_3 without nodes it has that bf_3 doesn't have\n","\n","this is set intersection: https://chat.openai.com/c/c15f48a7-226b-4c89-8ad9-a39a471867f5"],"metadata":{"id":"lfdQ7oy4ttdb"}},{"cell_type":"code","source":["mean_ablate_by_lst(list(set(fb_3) - (set(fb_3) - set(bf_3))), model, orig_score, print_output=True)"],"metadata":{"id":"t_YvvGGutjg3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_ablate_by_lst(list(set(bf_3) - (set(bf_3) - set(fb_3))), model, orig_score, print_output=True)"],"metadata":{"id":"AbM0-Ml1tmzl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(set(fb_3) - (set(fb_3) - set(bf_3))) == (set(bf_3) - (set(bf_3) - set(fb_3)))"],"metadata":{"id":"DVT9R1xTt9qC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# loop rmv and check for most impt heads"],"metadata":{"id":"8293qqJoGlA_"}},{"cell_type":"markdown","source":["https://colab.research.google.com/drive/12HF5UCvMERizkhOiYJKDziahgVq_3KD9#scrollTo=C2EgKgmJS4qb&line=1&uniqifier=1"],"metadata":{"id":"YVIc8XwD9F8z"}},{"cell_type":"code","source":["mean_ablate_by_lst(fb_3, model, orig_score, print_output=True).item()"],"metadata":{"id":"VFUktsrf8-Xn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for lh in fb_3:\n","    copy_circuit = fb_3.copy()\n","    copy_circuit.remove(lh)\n","    print(\"removed: \" + str(lh))\n","    new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=True).item()"],"metadata":{"id":"VaxbugcfGlBA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# random removal"],"metadata":{"id":"0sZHzHG9Qvla"}},{"cell_type":"markdown","source":["Because order seems to matter for fb and bf, try random\n","\n","Stop condition: if choice of X previous heads don't end up in a better score, stop."],"metadata":{"id":"q54SYOK1SM72"}},{"cell_type":"code","source":["import random\n","\n","def find_circuit_rand(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for r in range(200):  #a little bit more than total number of heads\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        randNum = random.randint(0, len(curr_circuit) - 1)\n","        lh = curr_circuit[randNum]\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove(lh)\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, orig_score, print_output=False).item()\n","\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove(lh)\n","\n","            print(\"\\nRemoved:\", lh)\n","            print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"0tqcoyM7Q0Iy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rand_10, rand_score = find_circuit_rand(None, threshold=10)\n","rand_score"],"metadata":{"id":"kKk79COMRTtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rand_10"],"metadata":{"id":"K1zwCok-SIn3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(rand_10)"],"metadata":{"id":"-7QqYMp3SJZn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# compare with desc"],"metadata":{"id":"64LX2HcmAHIE"}},{"cell_type":"markdown","source":["from: https://colab.research.google.com/drive/1odPpf7w_gBG8ZfAB2L6SXZszsDUk1CGA#scrollTo=ET--8aulD8pE&line=1&uniqifier=1"],"metadata":{"id":"0Am1wAXlALtT"}},{"cell_type":"code","source":["decr_circ = [(0, 1), (0, 3), (0, 5), (0, 7), (0, 9), (1, 0), (1, 5), (2, 2), (2, 4), (2, 9), (3, 0), (3, 3), (3, 7), (3, 10), (4, 6), (4, 7), (4, 10), (4, 11), (5, 1), (5, 5), (5, 6), (6, 1), (6, 7), (6, 9), (7, 2), (7, 10), (7, 11), (8, 1), (8, 6), (8, 8), (8, 10), (9, 5), (10, 7), (11, 0), (11, 8), (11, 11)]"],"metadata":{"id":"heoOgrzXAIey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(incr_circ) - set(decr_circ)"],"metadata":{"id":"cCFjGRVnAI--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(decr_circ) - set(incr_circ)"],"metadata":{"id":"xw6CzoxzAI_B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# manual removal"],"metadata":{"id":"nHcR9YIpULAq"}},{"cell_type":"code","source":["# https://colab.research.google.com/drive/1CHRn-AMko9RNrl1bqiCwB7DS-rz1CoBP#scrollTo=KZiVdGTC6QlP&line=1&uniqifier=1\n","# V1 plus L0, L2, L3, L6 minus 6.3, 6.4\n","circuit = [(0, 1), (0, 3), (0, 5), (0, 7), (0, 9), (0, 10), (1, 5), (2, 2), (2, 9), (3, 0), (3, 3), (3, 7), (4, 4), (5, 5), (6, 1), (6, 6), (6, 9), (6, 10), (7, 10), (7, 11), (8, 8), (9, 1), (10, 7)]\n","mean_ablate_by_lst(circuit, model, orig_score, print_output=False).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhQxNSgAUMbO","executionInfo":{"status":"ok","timestamp":1698698448923,"user_tz":240,"elapsed":2591,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ba963fef-1a72-4275-ffef-c6627713738b"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["41.985618591308594"]},"metadata":{},"execution_count":27}]}]}