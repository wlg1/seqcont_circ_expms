{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["DcZG9rm2IAiA","Z4iJEGh6b56v","GCCCoO0V7L7J","X3Iera3OlvQL","1putaGukK8at"],"authorship_tag":"ABX9TyOb2PIECGCPq8f5uxanyc0z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c28467e499674070a7bd6d38861ef72e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6012ad27d7814514b04ce1f6e8db745c","IPY_MODEL_05f8c6c014fa4e0395abf3b7dcd58d99","IPY_MODEL_d87254f7951843d8996827f371296892"],"layout":"IPY_MODEL_7c52c8d359ea4d738f2ab006fcec5fef"}},"6012ad27d7814514b04ce1f6e8db745c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_989424bdd7bb4c44a4db6cfd68ed49c8","placeholder":"​","style":"IPY_MODEL_6682ff45fa6d40ba8ee7063c25c04c29","value":"Downloading (…)lve/main/config.json: 100%"}},"05f8c6c014fa4e0395abf3b7dcd58d99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b8480dfc7ca4881b8446b8f7d251f95","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_185c4f50732f478b901ce91b7b1cee31","value":665}},"d87254f7951843d8996827f371296892":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d91282724068467783a6d92a055a2a04","placeholder":"​","style":"IPY_MODEL_570dee3ff9b54714acd4bdf0d457b81f","value":" 665/665 [00:00&lt;00:00, 57.4kB/s]"}},"7c52c8d359ea4d738f2ab006fcec5fef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"989424bdd7bb4c44a4db6cfd68ed49c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6682ff45fa6d40ba8ee7063c25c04c29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b8480dfc7ca4881b8446b8f7d251f95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"185c4f50732f478b901ce91b7b1cee31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d91282724068467783a6d92a055a2a04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"570dee3ff9b54714acd4bdf0d457b81f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad1ac00ac2f544cea8042138a232df1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cdaaef53468c4e39bbc474ceb1cc74f1","IPY_MODEL_3923fd0ba13e4dbb82009850730a274b","IPY_MODEL_7d4d90f0e09c4db49e30ab14ed71470a"],"layout":"IPY_MODEL_9784bb5c69d34482b97dd17723b32fb8"}},"cdaaef53468c4e39bbc474ceb1cc74f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aa4ecb4ef394482b8b397ea7bd26de6","placeholder":"​","style":"IPY_MODEL_0ef43b1ea21c4111ac43d013120814ff","value":"Downloading model.safetensors: 100%"}},"3923fd0ba13e4dbb82009850730a274b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f03daa01b84945159afee56154907555","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_947cf8491a4e4feab541667f7b4c3055","value":548105171}},"7d4d90f0e09c4db49e30ab14ed71470a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c16c9ba22fb34ee981439d4b026046e0","placeholder":"​","style":"IPY_MODEL_01fed3079d784f37b78c9532dee64e0f","value":" 548M/548M [00:02&lt;00:00, 197MB/s]"}},"9784bb5c69d34482b97dd17723b32fb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aa4ecb4ef394482b8b397ea7bd26de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ef43b1ea21c4111ac43d013120814ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f03daa01b84945159afee56154907555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"947cf8491a4e4feab541667f7b4c3055":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c16c9ba22fb34ee981439d4b026046e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01fed3079d784f37b78c9532dee64e0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ed1776ece734cb9a715ce8475ddb102":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21b02545cc254ad9856e1cbf58ae4426","IPY_MODEL_070717079eb04e26b7546a25e6d15024","IPY_MODEL_fd7cf085d6394ede9cfe561bc9597d7d"],"layout":"IPY_MODEL_bd7563708d2b4957a5b75424938cbb64"}},"21b02545cc254ad9856e1cbf58ae4426":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_888eae0f639f4af5a2c8ea99ec54875e","placeholder":"​","style":"IPY_MODEL_ccdc588b61604777adb9659a1e12b317","value":"Downloading (…)neration_config.json: 100%"}},"070717079eb04e26b7546a25e6d15024":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a18d0d82d1364fd7b78913bd47d100f1","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_774f544b77ab422c8b920ad069de382e","value":124}},"fd7cf085d6394ede9cfe561bc9597d7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e3c4c71f6774ec8b7307ebc7911ea94","placeholder":"​","style":"IPY_MODEL_f0ac0d2e3a8249c787b220eeb2adec99","value":" 124/124 [00:00&lt;00:00, 7.97kB/s]"}},"bd7563708d2b4957a5b75424938cbb64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"888eae0f639f4af5a2c8ea99ec54875e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccdc588b61604777adb9659a1e12b317":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a18d0d82d1364fd7b78913bd47d100f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"774f544b77ab422c8b920ad069de382e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e3c4c71f6774ec8b7307ebc7911ea94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0ac0d2e3a8249c787b220eeb2adec99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10ba89f47d594a738ef0918b38cdb2cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ca25bec08c245a3a7d7325ee95bf5fa","IPY_MODEL_a3b71c3d1fa84e4aa38ab43356529b99","IPY_MODEL_e5ef83dc78f9492197b2afe83acac018"],"layout":"IPY_MODEL_4fe2eda84d73454a9e135c88325eb893"}},"6ca25bec08c245a3a7d7325ee95bf5fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13e64946dbc24eacab628a459da3233a","placeholder":"​","style":"IPY_MODEL_27bddbe611674c27a13914910b42cb83","value":"Downloading (…)olve/main/vocab.json: 100%"}},"a3b71c3d1fa84e4aa38ab43356529b99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eae8b5bc2bf742648b507f7c0e7c6880","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e15b4ef4c8594972a9e1e8e5a1d886f2","value":1042301}},"e5ef83dc78f9492197b2afe83acac018":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65e39fbee88f4b008dc5d4682e3e2db2","placeholder":"​","style":"IPY_MODEL_8397ec908a954ca5a5476a4f6818aef7","value":" 1.04M/1.04M [00:00&lt;00:00, 9.52MB/s]"}},"4fe2eda84d73454a9e135c88325eb893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13e64946dbc24eacab628a459da3233a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27bddbe611674c27a13914910b42cb83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eae8b5bc2bf742648b507f7c0e7c6880":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e15b4ef4c8594972a9e1e8e5a1d886f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65e39fbee88f4b008dc5d4682e3e2db2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8397ec908a954ca5a5476a4f6818aef7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52d02dd90102468fb4da3100d4a1aa2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_faf5e2e0aee74e419aec7ec56623065a","IPY_MODEL_57737cf4c9bf4177b4fcfd486d8d6673","IPY_MODEL_799a90ede09c4938bacf662fe06217dc"],"layout":"IPY_MODEL_24f4d057e30d42e199dcc9466606be77"}},"faf5e2e0aee74e419aec7ec56623065a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b4133a59d004ad880f348e33aa05bc5","placeholder":"​","style":"IPY_MODEL_d392bab4c7c44054a20a7ee8e15839e1","value":"Downloading (…)olve/main/merges.txt: 100%"}},"57737cf4c9bf4177b4fcfd486d8d6673":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4adb4d7bbc674451a13ec05257cd5566","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14dfbabaf71345b5bcfeffee36019d37","value":456318}},"799a90ede09c4938bacf662fe06217dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10afb4c55972470ebce7c67a3cb10f77","placeholder":"​","style":"IPY_MODEL_1c6c26dfda8a40baae949a04dc83058b","value":" 456k/456k [00:00&lt;00:00, 23.0MB/s]"}},"24f4d057e30d42e199dcc9466606be77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4133a59d004ad880f348e33aa05bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d392bab4c7c44054a20a7ee8e15839e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4adb4d7bbc674451a13ec05257cd5566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14dfbabaf71345b5bcfeffee36019d37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10afb4c55972470ebce7c67a3cb10f77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6c26dfda8a40baae949a04dc83058b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"715ae9b139e747788b332c86c2b81fcb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3451ccac9e443059824ae67afc8c32a","IPY_MODEL_54de919adf004ddb87fe36fb4d6c5454","IPY_MODEL_58ee55b20aa543418255b999b2ded127"],"layout":"IPY_MODEL_a96e2d12fe4240b18fb9c405b72aacc6"}},"c3451ccac9e443059824ae67afc8c32a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bd8824e4926448d8fbc2d93b60d209b","placeholder":"​","style":"IPY_MODEL_7cfc987bd5224064acd03cd3e58f9d88","value":"Downloading (…)/main/tokenizer.json: 100%"}},"54de919adf004ddb87fe36fb4d6c5454":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29772087f9db46c49bb07036000094a1","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8b6a916f2a8490d80d21b0f67b7a036","value":1355256}},"58ee55b20aa543418255b999b2ded127":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8b605b179540a693663f73f8fa4e3b","placeholder":"​","style":"IPY_MODEL_5743836708904722a3e21c0c478f416f","value":" 1.36M/1.36M [00:00&lt;00:00, 16.6MB/s]"}},"a96e2d12fe4240b18fb9c405b72aacc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bd8824e4926448d8fbc2d93b60d209b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cfc987bd5224064acd03cd3e58f9d88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29772087f9db46c49bb07036000094a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8b6a916f2a8490d80d21b0f67b7a036":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba8b605b179540a693663f73f8fa4e3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5743836708904722a3e21c0c478f416f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"b13177b7"},"source":["<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698621356023,"user_tz":240,"elapsed":113003,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1d3603ab-b2db-458e-8efb-170a27863012"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-ftngo3hg\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-ftngo3hg\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit fa287750606075574df2c538058e67d648e2f952\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate>=0.23.0 (from transformer-lens==0.0.0)\n","  Downloading accelerate-0.24.0-py3-none-any.whl (260 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n","Collecting numpy>=1.24 (from transformer-lens==0.0.0)\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cublas_cu12-12.3.2.9-py3-none-manylinux1_x86_64.whl (417.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (14.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (24.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (867 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl (720.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.1/720.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cufft_cu12-11.0.11.19-py3-none-manylinux1_x86_64.whl (98.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_curand_cu12-10.3.4.52-py3-none-manylinux1_x86_64.whl (56.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusolver_cu12-11.5.3.52-py3-none-manylinux1_x86_64.whl (125.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens==0.0.0)\n","  Downloading nvidia_cusparse_cu12-12.1.3.153-py3-none-manylinux1_x86_64.whl (195.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens==0.0.0)\n","  Downloading nvidia_nvtx_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.5.0)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n","Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.6)\n","Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens==0.0.0)\n","  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting huggingface-hub (from accelerate>=0.23.0->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=116432 sha256=c797ec6c169bd4dd3b94c94a6a6e6c77438ff526c16d7937b5c638131c77e4db\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vrvfcocw/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=8f70f098aae89d5b7af5415b720655ca4f5bd01076cff1d9d0b598b9f2f6f214\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, huggingface-hub, gitdb, tokenizers, nvidia-cusolver-cu12, GitPython, accelerate, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.24.0 beartype-0.14.1 datasets-2.14.6 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 huggingface-hub-0.17.3 jaxtyping-0.2.23 multiprocess-0.70.15 numpy-1.26.1 nvidia-cublas-cu12-12.3.2.9 nvidia-cuda-cupti-cu12-12.3.52 nvidia-cuda-nvrtc-cu12-12.3.52 nvidia-cuda-runtime-cu12-12.3.52 nvidia-cudnn-cu12-8.9.4.25 nvidia-cufft-cu12-11.0.11.19 nvidia-curand-cu12-10.3.4.52 nvidia-cusolver-cu12-11.5.3.52 nvidia-cusparse-cu12-12.1.3.153 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.3.52 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.34.1 typeguard-2.13.3 wandb-0.15.12\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKoTs7VBIAiD"},"outputs":[],"source":["# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","import plotly.io as pio\n","\n","if IN_COLAB or not DEBUG_MODE:\n","    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","    pio.renderers.default = \"colab\"\n","else:\n","    pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6b1n2tvIAiD"},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuhzYxbsIAiE"},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cFMTUcQiIAiF","outputId":"308f0cfa-50dc-44e2-dc1b-6a204210d96f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698621364018,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7fe9e08ab5e0>"]},"metadata":{},"execution_count":5}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFs9BrbzIAiH"},"outputs":[],"source":["def imshow(tensor, renderer=None, **kwargs):\n","    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","def line(tensor, renderer=None, **kwargs):\n","    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","    x = utils.to_numpy(x)\n","    y = utils.to_numpy(y)\n","    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"markdown","source":["Decide which model to use (eg. gpt2-small vs -medium)"],"metadata":{"id":"ssJgoKr2yI8O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLwDyosvIAiJ","executionInfo":{"status":"ok","timestamp":1698621381587,"user_tz":240,"elapsed":17577,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["c28467e499674070a7bd6d38861ef72e","6012ad27d7814514b04ce1f6e8db745c","05f8c6c014fa4e0395abf3b7dcd58d99","d87254f7951843d8996827f371296892","7c52c8d359ea4d738f2ab006fcec5fef","989424bdd7bb4c44a4db6cfd68ed49c8","6682ff45fa6d40ba8ee7063c25c04c29","0b8480dfc7ca4881b8446b8f7d251f95","185c4f50732f478b901ce91b7b1cee31","d91282724068467783a6d92a055a2a04","570dee3ff9b54714acd4bdf0d457b81f","ad1ac00ac2f544cea8042138a232df1e","cdaaef53468c4e39bbc474ceb1cc74f1","3923fd0ba13e4dbb82009850730a274b","7d4d90f0e09c4db49e30ab14ed71470a","9784bb5c69d34482b97dd17723b32fb8","9aa4ecb4ef394482b8b397ea7bd26de6","0ef43b1ea21c4111ac43d013120814ff","f03daa01b84945159afee56154907555","947cf8491a4e4feab541667f7b4c3055","c16c9ba22fb34ee981439d4b026046e0","01fed3079d784f37b78c9532dee64e0f","0ed1776ece734cb9a715ce8475ddb102","21b02545cc254ad9856e1cbf58ae4426","070717079eb04e26b7546a25e6d15024","fd7cf085d6394ede9cfe561bc9597d7d","bd7563708d2b4957a5b75424938cbb64","888eae0f639f4af5a2c8ea99ec54875e","ccdc588b61604777adb9659a1e12b317","a18d0d82d1364fd7b78913bd47d100f1","774f544b77ab422c8b920ad069de382e","8e3c4c71f6774ec8b7307ebc7911ea94","f0ac0d2e3a8249c787b220eeb2adec99","10ba89f47d594a738ef0918b38cdb2cb","6ca25bec08c245a3a7d7325ee95bf5fa","a3b71c3d1fa84e4aa38ab43356529b99","e5ef83dc78f9492197b2afe83acac018","4fe2eda84d73454a9e135c88325eb893","13e64946dbc24eacab628a459da3233a","27bddbe611674c27a13914910b42cb83","eae8b5bc2bf742648b507f7c0e7c6880","e15b4ef4c8594972a9e1e8e5a1d886f2","65e39fbee88f4b008dc5d4682e3e2db2","8397ec908a954ca5a5476a4f6818aef7","52d02dd90102468fb4da3100d4a1aa2c","faf5e2e0aee74e419aec7ec56623065a","57737cf4c9bf4177b4fcfd486d8d6673","799a90ede09c4938bacf662fe06217dc","24f4d057e30d42e199dcc9466606be77","1b4133a59d004ad880f348e33aa05bc5","d392bab4c7c44054a20a7ee8e15839e1","4adb4d7bbc674451a13ec05257cd5566","14dfbabaf71345b5bcfeffee36019d37","10afb4c55972470ebce7c67a3cb10f77","1c6c26dfda8a40baae949a04dc83058b","715ae9b139e747788b332c86c2b81fcb","c3451ccac9e443059824ae67afc8c32a","54de919adf004ddb87fe36fb4d6c5454","58ee55b20aa543418255b999b2ded127","a96e2d12fe4240b18fb9c405b72aacc6","7bd8824e4926448d8fbc2d93b60d209b","7cfc987bd5224064acd03cd3e58f9d88","29772087f9db46c49bb07036000094a1","b8b6a916f2a8490d80d21b0f67b7a036","ba8b605b179540a693663f73f8fa4e3b","5743836708904722a3e21c0c478f416f"]},"outputId":"2b22f939-a98a-44a8-dee7-fc340be6a547"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c28467e499674070a7bd6d38861ef72e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad1ac00ac2f544cea8042138a232df1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed1776ece734cb9a715ce8475ddb102"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ba89f47d594a738ef0918b38cdb2cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52d02dd90102468fb4da3100d4a1aa2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"715ae9b139e747788b332c86c2b81fcb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fdh5--MfYw7-","executionInfo":{"status":"ok","timestamp":1698621388367,"user_tz":240,"elapsed":7112,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3682b6ce-3e1c-4b39-f943-201643511288"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9106, done.\u001b[K\n","remote: Counting objects: 100% (1820/1820), done.\u001b[K\n","remote: Compressing objects: 100% (289/289), done.\u001b[K\n","remote: Total 9106 (delta 1614), reused 1608 (delta 1528), pack-reused 7286\u001b[K\n","Receiving objects: 100% (9106/9106), 155.60 MiB | 38.50 MiB/s, done.\n","Resolving deltas: 100% (5507/5507), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ4C_bsXZFfj","executionInfo":{"status":"ok","timestamp":1698621388367,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cc951f7a-9bfa-4dfe-8934-050b33e4d110"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Repalce io_tokens with correct answer (next, which is '5') and s_tokens with incorrect (current, which repeats)"],"metadata":{"id":"exuTCQ_XmmFP"}},{"cell_type":"code","source":["pos_dict = {\n","    'S1': 0,\n","    'S2': 1,\n","    'S3': 2,\n","    'S4': 3,\n","}"],"metadata":{"id":"sGHl4RZTE98L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': words[i],\n","            'S2': words[i+1],\n","            'S3': words[i+2],\n","            'S4': words[i+3],\n","            'corr': words[i+4],\n","            'incorr': words[i],  # this is arbitrary\n","            'text': f\"{words[i]} {words[i+1]} {words[i+2]} {words[i+3]}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 6)\n","dataset = Dataset(prompts_list, pos_dict, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"u0NPSKcZ1iDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(x ,y):\n","    words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten']\n","    prompts_list = []\n","    for i in range(x, y):\n","        r1 = random.choice(words)\n","        r2 = random.choice(words)\n","        r3 = random.choice(words)\n","        r4 = random.choice(words)\n","        prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': str(r1),\n","            'incorr': str(i+4),\n","            'text': f\"{r1} {r2} {r3} {r4}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(1, 6)\n","dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, S1_is_first=True)\n","prompts_list_2"],"metadata":{"id":"dzzLlCqZS_wl","executionInfo":{"status":"ok","timestamp":1698621459228,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3f8dd98-a8f2-46a1-e22f-3fe1332b1034"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': 'four',\n","  'S2': 'one',\n","  'S3': 'four',\n","  'S4': 'eight',\n","  'corr': 'four',\n","  'incorr': '5',\n","  'text': 'four one four eight'},\n"," {'S1': 'nine',\n","  'S2': 'five',\n","  'S3': 'three',\n","  'S4': 'seven',\n","  'corr': 'nine',\n","  'incorr': '6',\n","  'text': 'nine five three seven'},\n"," {'S1': 'five',\n","  'S2': 'two',\n","  'S3': 'four',\n","  'S4': 'three',\n","  'corr': 'five',\n","  'incorr': '7',\n","  'text': 'five two four three'},\n"," {'S1': 'two',\n","  'S2': 'one',\n","  'S3': 'nine',\n","  'S4': 'eight',\n","  'corr': 'two',\n","  'incorr': '8',\n","  'text': 'two one nine eight'},\n"," {'S1': 'eight',\n","  'S2': 'seven',\n","  'S3': 'ten',\n","  'S4': 'seven',\n","  'corr': 'eight',\n","  'incorr': '9',\n","  'text': 'eight seven ten seven'}]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Logit diff is correct - incorr token. Here, correct is S5, and incorr is S4.\n","\n","Because of this, it's possible to have logit diffs HIGHER than the \"full circuit\" because the correct token will still be at first place, but the logit scores assigned will just be bigger (perhaps incorrect is scored even lower in the non-full circuit with a higher logit diff score)?"],"metadata":{"id":"A0W-GaM6Vfm-"}},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"GCCCoO0V7L7J"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"CgD41x5nbKKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        # \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        # \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"LqsdFmbVMntG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also prevent redundant computation of the full circuit score by storing it and just passing it in to the function."],"metadata":{"id":"xUlhxzuGUr1y"}},{"cell_type":"markdown","source":["# Ablate the model and compare with original"],"metadata":{"id":"Lk3bffnCYq-p"}},{"cell_type":"markdown","source":["### try full circuit from repeatLast iter fb"],"metadata":{"id":"x2IM79qgcx4F"}},{"cell_type":"code","source":["curr_circuit = [(0, 1), (0, 3), (0, 5), (0, 7), (0, 8), (0, 9), (0, 10), (1, 0), (1, 5), (3, 0), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 8), (4, 10), (4, 11), (5, 4), (5, 5), (5, 9), (6, 1), (6, 6), (6, 10), (7, 6), (7, 10), (7, 11), (8, 1), (8, 2), (8, 6), (8, 8), (9, 1), (9, 5), (10, 7), (11, 10)]\n","mean_ablate_by_lst(curr_circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESPP2WGsc0E2","executionInfo":{"status":"ok","timestamp":1698621479525,"user_tz":240,"elapsed":5191,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8d533a71-ff3f-4db3-924e-08b89321a420"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 64.6226\n"]},{"output_type":"execute_result","data":{"text/plain":["64.62264251708984"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["curr_circuit = [(9, 1)]\n","mean_ablate_by_lst(curr_circuit, model, print_output=True).item()"],"metadata":{"id":"iWDb4eskc7WF","executionInfo":{"status":"ok","timestamp":1698621481978,"user_tz":240,"elapsed":2471,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f23ece7f-1bf2-46a9-b459-f3b855b2b7f6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 24.9522\n"]},{"output_type":"execute_result","data":{"text/plain":["24.952171325683594"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## compare with repeatRandElem"],"metadata":{"id":"RUl8oHsrg61n"}},{"cell_type":"code","source":["repeatRand_backw_3 = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 8), (0, 9), (0, 10), (1, 0), (1, 5), (1, 7), (2, 0), (2, 2), (2, 9), (3, 0), (4, 2), (4, 4), (4, 7), (4, 8), (4, 9), (4, 10), (5, 0), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 3), (6, 4), (6, 6), (6, 8), (6, 10), (7, 10), (7, 11), (8, 11), (9, 1), (10, 1)]\n","mean_ablate_by_lst(repeatRand_backw_3, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqYUqp0Bg9va","executionInfo":{"status":"ok","timestamp":1698621483418,"user_tz":240,"elapsed":1450,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fae87dd2-c4e0-40db-f0eb-ebfdb884c21e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 61.2811\n"]},{"output_type":"execute_result","data":{"text/plain":["61.2811164855957"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["repeatRand_backw_20 = [(0, 1), (0, 2), (0, 3), (0, 9), (0, 10), (0, 11), (1, 0), (1, 5), (1, 7), (1, 8), (2, 0), (2, 2), (2, 7), (2, 9), (3, 0), (3, 3), (4, 4), (4, 6), (4, 7), (4, 9), (4, 10), (4, 11), (5, 0), (5, 3), (5, 4), (5, 5), (5, 6), (5, 8), (6, 1), (6, 6), (6, 9), (6, 10), (7, 10), (7, 11), (9, 1)]\n","mean_ablate_by_lst(repeatRand_backw_20, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g6JdvVlQigao","executionInfo":{"status":"ok","timestamp":1698621485807,"user_tz":240,"elapsed":2395,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"86910d30-41a1-496c-f67e-7fda3e123d51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 53.9477\n"]},{"output_type":"execute_result","data":{"text/plain":["53.94770050048828"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["repeatRand_fb_3 = [(0, 1), (0, 2), (0, 8), (0, 9), (0, 10), (1, 0), (1, 5), (2, 0), (2, 2), (2, 6), (2, 7), (3, 0), (3, 11), (4, 4), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (5, 0), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 6), (6, 10), (7, 10), (7, 11), (8, 8), (8, 9), (8, 11), (9, 1), (11, 10)]\n","mean_ablate_by_lst(repeatRand_fb_3, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Tgd0_WYibIP","executionInfo":{"status":"ok","timestamp":1698621487683,"user_tz":240,"elapsed":1894,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"35879452-03b2-43d7-a5ed-1721eff62171"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 67.9914\n"]},{"output_type":"execute_result","data":{"text/plain":["67.99136352539062"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## Prune backwards"],"metadata":{"id":"e6N5MU1wRZog"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bfiwe5d3SgVP","executionInfo":{"status":"ok","timestamp":1698621773894,"user_tz":240,"elapsed":286220,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"249e2ecc-85c3-48fe-a0ce-8ca3d6791c7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","100.10379028320312\n","\n","\n","Removed: (11, 1)\n","98.97869873046875\n","\n","\n","Removed: (11, 2)\n","99.02860260009766\n","\n","\n","Removed: (11, 3)\n","98.74519348144531\n","\n","\n","Removed: (11, 4)\n","99.08023834228516\n","\n","\n","Removed: (11, 5)\n","99.12744903564453\n","\n","\n","Removed: (11, 6)\n","99.15473937988281\n","\n","\n","Removed: (11, 7)\n","99.03898620605469\n","\n","\n","Removed: (11, 8)\n","97.15733337402344\n","\n","\n","Removed: (11, 9)\n","97.16557312011719\n","\n","\n","Removed: (11, 11)\n","97.33262634277344\n","\n","\n","Removed: (10, 0)\n","97.36923217773438\n","\n","\n","Removed: (10, 1)\n","97.38016510009766\n","\n","\n","Removed: (10, 3)\n","97.48831176757812\n","\n","\n","Removed: (10, 4)\n","97.46089172363281\n","\n","\n","Removed: (10, 6)\n","97.41268157958984\n","\n","\n","Removed: (10, 7)\n","98.00159454345703\n","\n","\n","Removed: (10, 8)\n","98.22784423828125\n","\n","\n","Removed: (10, 9)\n","98.02510833740234\n","\n","\n","Removed: (10, 10)\n","98.12550354003906\n","\n","\n","Removed: (10, 11)\n","98.09323120117188\n","\n","\n","Removed: (9, 0)\n","98.04710388183594\n","\n","\n","Removed: (9, 2)\n","97.6371841430664\n","\n","\n","Removed: (9, 3)\n","97.615234375\n","\n","\n","Removed: (9, 4)\n","97.75285339355469\n","\n","\n","Removed: (9, 6)\n","98.1245346069336\n","\n","\n","Removed: (9, 7)\n","98.0626449584961\n","\n","\n","Removed: (9, 8)\n","97.92743682861328\n","\n","\n","Removed: (9, 9)\n","97.75663757324219\n","\n","\n","Removed: (9, 10)\n","97.59021759033203\n","\n","\n","Removed: (9, 11)\n","97.45729064941406\n","\n","\n","Removed: (8, 2)\n","97.288330078125\n","\n","\n","Removed: (8, 3)\n","97.66059875488281\n","\n","\n","Removed: (8, 4)\n","97.63050842285156\n","\n","\n","Removed: (8, 7)\n","97.37126159667969\n","\n","\n","Removed: (8, 10)\n","98.52196502685547\n","\n","\n","Removed: (7, 0)\n","98.83324432373047\n","\n","\n","Removed: (7, 1)\n","98.78370666503906\n","\n","\n","Removed: (7, 2)\n","98.702392578125\n","\n","\n","Removed: (7, 3)\n","99.18235778808594\n","\n","\n","Removed: (7, 4)\n","98.49181365966797\n","\n","\n","Removed: (7, 5)\n","97.87548828125\n","\n","\n","Removed: (7, 8)\n","97.36460876464844\n","\n","\n","Removed: (7, 9)\n","97.28739166259766\n","\n","\n","Removed: (6, 0)\n","97.21785736083984\n","\n","\n","Removed: (6, 2)\n","97.25526428222656\n","\n","\n","Removed: (6, 5)\n","98.02972412109375\n","\n","\n","Removed: (6, 6)\n","98.09652709960938\n","\n","\n","Removed: (6, 8)\n","97.14927673339844\n","\n","\n","Removed: (6, 11)\n","97.22547149658203\n","\n","\n","Removed: (5, 9)\n","97.32170867919922\n","\n","\n","Removed: (5, 10)\n","97.4669418334961\n","\n","\n","Removed: (5, 11)\n","97.91899871826172\n","\n","\n","Removed: (4, 0)\n","97.78150939941406\n","\n","\n","Removed: (4, 1)\n","97.16500854492188\n","\n","\n","Removed: (4, 2)\n","97.30622863769531\n","\n","\n","Removed: (4, 3)\n","97.34151458740234\n","\n","\n","Removed: (4, 5)\n","97.2225341796875\n","\n","\n","Removed: (4, 6)\n","97.56124114990234\n","\n","\n","Removed: (4, 7)\n","97.70213317871094\n","\n","\n","Removed: (4, 9)\n","97.3612289428711\n","\n","\n","Removed: (4, 11)\n","97.34341430664062\n","\n","\n","Removed: (3, 0)\n","97.30535888671875\n","\n","\n","Removed: (3, 1)\n","97.17943572998047\n","\n","\n","Removed: (3, 3)\n","98.07479095458984\n","\n","\n","Removed: (3, 4)\n","98.04698944091797\n","\n","\n","Removed: (3, 5)\n","98.05595397949219\n","\n","\n","Removed: (3, 6)\n","97.91146850585938\n","\n","\n","Removed: (3, 7)\n","99.39958953857422\n","\n","\n","Removed: (3, 8)\n","99.1251220703125\n","\n","\n","Removed: (3, 9)\n","99.27898406982422\n","\n","\n","Removed: (3, 10)\n","99.66507720947266\n","\n","\n","Removed: (3, 11)\n","99.4759521484375\n","\n","\n","Removed: (2, 0)\n","99.54483032226562\n","\n","\n","Removed: (2, 1)\n","100.8971939086914\n","\n","\n","Removed: (2, 2)\n","100.59800720214844\n","\n","\n","Removed: (2, 3)\n","98.80732727050781\n","\n","\n","Removed: (2, 5)\n","99.6344223022461\n","\n","\n","Removed: (2, 6)\n","99.41691589355469\n","\n","\n","Removed: (2, 7)\n","99.87725067138672\n","\n","\n","Removed: (2, 8)\n","99.23440551757812\n","\n","\n","Removed: (2, 9)\n","98.6897201538086\n","\n","\n","Removed: (2, 10)\n","100.31320190429688\n","\n","\n","Removed: (2, 11)\n","100.4837875366211\n","\n","\n","Removed: (1, 0)\n","100.44381713867188\n","\n","\n","Removed: (1, 1)\n","99.12571716308594\n","\n","\n","Removed: (1, 2)\n","98.96029663085938\n","\n","\n","Removed: (1, 3)\n","99.01238250732422\n","\n","\n","Removed: (1, 4)\n","98.95176696777344\n","\n","\n","Removed: (1, 6)\n","99.45449829101562\n","\n","\n","Removed: (1, 7)\n","101.10612487792969\n","\n","\n","Removed: (1, 8)\n","101.2740249633789\n","\n","\n","Removed: (1, 9)\n","101.03429412841797\n","\n","\n","Removed: (1, 10)\n","101.12084197998047\n","\n","\n","Removed: (1, 11)\n","99.45032501220703\n","\n","\n","Removed: (0, 0)\n","99.73235321044922\n","\n","\n","Removed: (0, 2)\n","101.15692901611328\n","\n","\n","Removed: (0, 3)\n","99.12918853759766\n","\n","\n","Removed: (0, 4)\n","100.13936614990234\n","\n","\n","Removed: (0, 5)\n","97.82133483886719\n","\n","\n","Removed: (0, 6)\n","98.77555847167969\n","\n","\n","Removed: (0, 7)\n","98.95433044433594\n","\n","\n","Removed: (0, 8)\n","97.93353271484375\n","\n","\n","Removed: (0, 9)\n","97.51397705078125\n","\n","\n","Removed: (0, 10)\n","101.35298156738281\n","\n","\n","Removed: (0, 11)\n","100.47502899169922\n","\n","\n"]}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True)"],"metadata":{"id":"qgpGMTWLbibq","executionInfo":{"status":"ok","timestamp":1698621775904,"user_tz":240,"elapsed":2038,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"664835ee-ed25-4133-fabe-878bea2efd85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 100.4750\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(100.4750, device='cuda:0')"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["backw_3 = curr_circuit.copy()\n","backw_3"],"metadata":{"id":"7_ZC4-k2blg2","executionInfo":{"status":"ok","timestamp":1698621775904,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e7a1ab0-61bf-4504-8492-14918ece8ed3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (1, 5),\n"," (2, 4),\n"," (3, 2),\n"," (4, 4),\n"," (4, 8),\n"," (4, 10),\n"," (5, 0),\n"," (5, 1),\n"," (5, 2),\n"," (5, 3),\n"," (5, 4),\n"," (5, 5),\n"," (5, 6),\n"," (5, 7),\n"," (5, 8),\n"," (6, 1),\n"," (6, 3),\n"," (6, 4),\n"," (6, 7),\n"," (6, 9),\n"," (6, 10),\n"," (7, 6),\n"," (7, 7),\n"," (7, 10),\n"," (7, 11),\n"," (8, 0),\n"," (8, 1),\n"," (8, 5),\n"," (8, 6),\n"," (8, 8),\n"," (8, 9),\n"," (8, 11),\n"," (9, 1),\n"," (9, 5),\n"," (10, 2),\n"," (10, 5),\n"," (11, 10)]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["len(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dry8ANsOMgvg","executionInfo":{"status":"ok","timestamp":1698621775904,"user_tz":240,"elapsed":26,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3cab20fc-e573-4913-ca9a-15579f53b9d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["38"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["Now try 10% threshold:"],"metadata":{"id":"7vMvM9iRiPyo"}},{"cell_type":"code","source":["def find_circuit_backw(threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    # Start with full circuit\n","    curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"Removed:\", (layer, head))\n","                print(new_score)\n","                print(\"\\n\")\n","\n","    return curr_circuit"],"metadata":{"id":"JL6UvAikiQFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circuit = find_circuit_backw(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1IIpte21ipBz","executionInfo":{"status":"ok","timestamp":1698622060194,"user_tz":240,"elapsed":284311,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"03b34377-1387-46e9-e412-73237ffa5ff8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","100.10379028320312\n","\n","\n","Removed: (11, 1)\n","98.97869873046875\n","\n","\n","Removed: (11, 2)\n","99.02860260009766\n","\n","\n","Removed: (11, 3)\n","98.74519348144531\n","\n","\n","Removed: (11, 4)\n","99.08023834228516\n","\n","\n","Removed: (11, 5)\n","99.12744903564453\n","\n","\n","Removed: (11, 6)\n","99.15473937988281\n","\n","\n","Removed: (11, 7)\n","99.03898620605469\n","\n","\n","Removed: (11, 8)\n","97.15733337402344\n","\n","\n","Removed: (11, 9)\n","97.16557312011719\n","\n","\n","Removed: (11, 10)\n","95.91690063476562\n","\n","\n","Removed: (11, 11)\n","96.08448791503906\n","\n","\n","Removed: (10, 0)\n","96.11646270751953\n","\n","\n","Removed: (10, 1)\n","96.08088684082031\n","\n","\n","Removed: (10, 3)\n","96.18419647216797\n","\n","\n","Removed: (10, 4)\n","96.1608657836914\n","\n","\n","Removed: (10, 5)\n","95.62007904052734\n","\n","\n","Removed: (10, 6)\n","95.57417297363281\n","\n","\n","Removed: (10, 7)\n","95.9581069946289\n","\n","\n","Removed: (10, 8)\n","96.15215301513672\n","\n","\n","Removed: (10, 9)\n","95.95096588134766\n","\n","\n","Removed: (10, 10)\n","96.05656433105469\n","\n","\n","Removed: (10, 11)\n","96.03401947021484\n","\n","\n","Removed: (9, 0)\n","96.00611114501953\n","\n","\n","Removed: (9, 2)\n","95.5905532836914\n","\n","\n","Removed: (9, 3)\n","95.58920288085938\n","\n","\n","Removed: (9, 4)\n","95.7115707397461\n","\n","\n","Removed: (9, 5)\n","93.57052612304688\n","\n","\n","Removed: (9, 6)\n","93.87053680419922\n","\n","\n","Removed: (9, 7)\n","93.794677734375\n","\n","\n","Removed: (9, 8)\n","93.67707061767578\n","\n","\n","Removed: (9, 9)\n","93.56371307373047\n","\n","\n","Removed: (9, 10)\n","93.40347290039062\n","\n","\n","Removed: (9, 11)\n","93.252685546875\n","\n","\n","Removed: (8, 0)\n","92.84113311767578\n","\n","\n","Removed: (8, 1)\n","92.20447540283203\n","\n","\n","Removed: (8, 2)\n","92.03264617919922\n","\n","\n","Removed: (8, 3)\n","92.53999328613281\n","\n","\n","Removed: (8, 4)\n","92.50989532470703\n","\n","\n","Removed: (8, 5)\n","91.81832122802734\n","\n","\n","Removed: (8, 7)\n","91.55585479736328\n","\n","\n","Removed: (8, 10)\n","92.86294555664062\n","\n","\n","Removed: (7, 0)\n","93.0345230102539\n","\n","\n","Removed: (7, 1)\n","92.93959045410156\n","\n","\n","Removed: (7, 2)\n","92.82039642333984\n","\n","\n","Removed: (7, 3)\n","93.27853393554688\n","\n","\n","Removed: (7, 4)\n","92.56825256347656\n","\n","\n","Removed: (7, 5)\n","91.95051574707031\n","\n","\n","Removed: (7, 7)\n","90.26195526123047\n","\n","\n","Removed: (7, 9)\n","90.18125915527344\n","\n","\n","Removed: (6, 0)\n","90.00218963623047\n","\n","\n","Removed: (6, 5)\n","90.87544250488281\n","\n","\n","Removed: (6, 6)\n","90.82441711425781\n","\n","\n","Removed: (6, 9)\n","90.53209686279297\n","\n","\n","Removed: (6, 11)\n","90.55366516113281\n","\n","\n","Removed: (5, 1)\n","90.0283432006836\n","\n","\n","Removed: (5, 9)\n","90.18031311035156\n","\n","\n","Removed: (5, 10)\n","90.2971420288086\n","\n","\n","Removed: (5, 11)\n","90.74011993408203\n","\n","\n","Removed: (4, 0)\n","90.59595489501953\n","\n","\n","Removed: (4, 1)\n","90.00525665283203\n","\n","\n","Removed: (4, 2)\n","90.1490249633789\n","\n","\n","Removed: (4, 3)\n","90.14949798583984\n","\n","\n","Removed: (4, 5)\n","90.07490539550781\n","\n","\n","Removed: (4, 6)\n","90.25843048095703\n","\n","\n","Removed: (4, 7)\n","90.80847930908203\n","\n","\n","Removed: (4, 9)\n","90.56050872802734\n","\n","\n","Removed: (3, 0)\n","90.45683288574219\n","\n","\n","Removed: (3, 1)\n","90.32786560058594\n","\n","\n","Removed: (3, 3)\n","90.7720718383789\n","\n","\n","Removed: (3, 4)\n","90.81366729736328\n","\n","\n","Removed: (3, 5)\n","90.76283264160156\n","\n","\n","Removed: (3, 6)\n","90.68366241455078\n","\n","\n","Removed: (3, 7)\n","91.71385192871094\n","\n","\n","Removed: (3, 8)\n","91.53706359863281\n","\n","\n","Removed: (3, 9)\n","91.67466735839844\n","\n","\n","Removed: (3, 10)\n","92.15401458740234\n","\n","\n","Removed: (3, 11)\n","91.96746063232422\n","\n","\n","Removed: (2, 0)\n","92.0322494506836\n","\n","\n","Removed: (2, 1)\n","93.09852600097656\n","\n","\n","Removed: (2, 2)\n","92.76019287109375\n","\n","\n","Removed: (2, 3)\n","91.29632568359375\n","\n","\n","Removed: (2, 5)\n","91.9990005493164\n","\n","\n","Removed: (2, 6)\n","91.8057632446289\n","\n","\n","Removed: (2, 7)\n","92.14385986328125\n","\n","\n","Removed: (2, 8)\n","91.59858703613281\n","\n","\n","Removed: (2, 9)\n","91.20634460449219\n","\n","\n","Removed: (2, 10)\n","92.54611206054688\n","\n","\n","Removed: (2, 11)\n","92.61155700683594\n","\n","\n","Removed: (1, 0)\n","92.28020477294922\n","\n","\n","Removed: (1, 1)\n","91.03311920166016\n","\n","\n","Removed: (1, 2)\n","90.88339233398438\n","\n","\n","Removed: (1, 3)\n","91.0152816772461\n","\n","\n","Removed: (1, 4)\n","90.75822448730469\n","\n","\n","Removed: (1, 6)\n","91.21788787841797\n","\n","\n","Removed: (1, 7)\n","92.57339477539062\n","\n","\n","Removed: (1, 8)\n","92.6741943359375\n","\n","\n","Removed: (1, 9)\n","92.45870971679688\n","\n","\n","Removed: (1, 10)\n","92.44476318359375\n","\n","\n","Removed: (1, 11)\n","91.186767578125\n","\n","\n","Removed: (0, 0)\n","91.41419982910156\n","\n","\n","Removed: (0, 2)\n","92.60443115234375\n","\n","\n","Removed: (0, 3)\n","90.88568115234375\n","\n","\n","Removed: (0, 4)\n","91.53610229492188\n","\n","\n","Removed: (0, 6)\n","92.28630828857422\n","\n","\n","Removed: (0, 7)\n","91.98399353027344\n","\n","\n","Removed: (0, 8)\n","91.45659637451172\n","\n","\n","Removed: (0, 9)\n","91.17745208740234\n","\n","\n","Removed: (0, 10)\n","94.3501205444336\n","\n","\n","Removed: (0, 11)\n","93.57098388671875\n","\n","\n"]}]},{"cell_type":"code","source":["backw_10 = curr_circuit.copy()\n","backw_10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-mSQqFhksjs","executionInfo":{"status":"ok","timestamp":1698622060195,"user_tz":240,"elapsed":34,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4bed65ae-28d5-44b2-ff4f-ccbb70c7e0da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 5),\n"," (1, 5),\n"," (2, 4),\n"," (3, 2),\n"," (4, 4),\n"," (4, 8),\n"," (4, 10),\n"," (4, 11),\n"," (5, 0),\n"," (5, 2),\n"," (5, 3),\n"," (5, 4),\n"," (5, 5),\n"," (5, 6),\n"," (5, 7),\n"," (5, 8),\n"," (6, 1),\n"," (6, 2),\n"," (6, 3),\n"," (6, 4),\n"," (6, 7),\n"," (6, 8),\n"," (6, 10),\n"," (7, 6),\n"," (7, 8),\n"," (7, 10),\n"," (7, 11),\n"," (8, 6),\n"," (8, 8),\n"," (8, 9),\n"," (8, 11),\n"," (9, 1),\n"," (10, 2)]"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdW57VjOKmQO","executionInfo":{"status":"ok","timestamp":1698622062358,"user_tz":240,"elapsed":2175,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fe526cfe-6005-4a91-f3fa-2dedfc0133cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 93.5710\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(93.5710, device='cuda:0')"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["len(backw_10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoaCgwKgKtOX","executionInfo":{"status":"ok","timestamp":1698622062359,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"25c3806c-bcf3-4932-e227-4c5574f721ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["20%:"],"metadata":{"id":"wzmTkj-AKrXG"}},{"cell_type":"code","source":["%%capture\n","curr_circuit = find_circuit_backw(20)"],"metadata":{"id":"vp7F1qFGlv-s","executionInfo":{"status":"ok","timestamp":1698622186278,"user_tz":240,"elapsed":123927,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","height":322},"outputId":"c4de817d-02d3-466a-af33-d9eaa7a4ddd2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-e61ce79fa6b5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurr_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_circuit_backw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-b0631b856dc9>\u001b[0m in \u001b[0;36mfind_circuit_backw\u001b[0;34m(threshold)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mcopy_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_ablate_by_lst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# If the result is less than the threshold, remove the tuple from the original list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-f1c54969a037>\u001b[0m in \u001b[0;36mmean_ablate_by_lst\u001b[0;34m(lst, model, print_output)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mioi_logits_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioi_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_with_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_circuit_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mean_ablation_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mioi_logits_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36madd_mean_ablation_hook\u001b[0;34m(model, means_dataset, circuit, seq_pos_to_keep, is_permanent)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Apply hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_permanent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_permanent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36madd_hook\u001b[0;34m(self, name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook_point_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_point_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     self.check_and_add_hook(\n\u001b[0m\u001b[1;32m    259\u001b[0m                         \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                         \u001b[0mhook_point_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mcheck_and_add_hook\u001b[0;34m(self, hook_point, hook_point_name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         )\n\u001b[0;32m--> 231\u001b[0;31m         hook_point.add_hook(\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_permanent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_permanent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36madd_hook\u001b[0;34m(self, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             full_hook.__name__ = (\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             )  # annotate the `full_hook` with the string representation of the `hook` function\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    429\u001b[0m             )\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     def backward(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mguard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableFuncTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{{:.{PRINT_OPTS.precision}e}}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["backw_20 = curr_circuit.copy()\n","backw_20"],"metadata":{"id":"Liy24wbtnGF3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698622188410,"user_tz":240,"elapsed":2145,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"037ed11f-73d6-4326-83da-e5f5607e15f4","id":"cdL7_maZKyt7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 93.5710\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(93.5710, device='cuda:0')"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["len(backw_20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698622188411,"user_tz":240,"elapsed":81,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ad551950-2e82-428f-92a6-4ac7822ae55b","id":"aLYJuXyCKyuE"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["### set diffs of the three perf lvls"],"metadata":{"id":"M26o5W55NCOd"}},{"cell_type":"code","source":["set(backw_3) - set(backw_10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArPAmmaBNFmP","executionInfo":{"status":"ok","timestamp":1698622188412,"user_tz":240,"elapsed":75,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"91dd4ff1-87f2-44a9-c0c7-2eaacb0b697a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(5, 1), (6, 9), (7, 7), (8, 0), (8, 1), (8, 5), (9, 5), (10, 5), (11, 10)}"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["set(backw_10) - set(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zRGlGdhENSHR","executionInfo":{"status":"ok","timestamp":1698622188413,"user_tz":240,"elapsed":69,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1c7b3e01-6f9d-4023-b2b9-4380a551536e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 5), (4, 11), (6, 2), (6, 8), (7, 8)}"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["set(backw_3) - set(backw_20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE70QPLZNWTf","executionInfo":{"status":"ok","timestamp":1698622188415,"user_tz":240,"elapsed":65,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"dcb26ff7-565c-43a2-d7f5-a4abf8bdb39e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(5, 1), (6, 9), (7, 7), (8, 0), (8, 1), (8, 5), (9, 5), (10, 5), (11, 10)}"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["set(backw_10) - set(backw_20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQ4qRwQHNZvw","executionInfo":{"status":"ok","timestamp":1698622188416,"user_tz":240,"elapsed":56,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"246d7ccf-8f83-47f0-b8a3-0ccfe5835f75"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["set()"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["mean_ablate_by_lst(backw_20, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maGEsWBjNpQH","executionInfo":{"status":"ok","timestamp":1698622190342,"user_tz":240,"elapsed":1974,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c1e81b2a-e346-4f7d-b4d7-f5d2aa0a8e47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 93.5710\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(93.5710, device='cuda:0')"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["mean_ablate_by_lst(backw_20 + [(10, 2)], model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7iaPF6jNjKh","executionInfo":{"status":"ok","timestamp":1698622192410,"user_tz":240,"elapsed":2092,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0bbf6ddd-b0e7-4827-c415-39362110ada4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 93.5710\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(93.5710, device='cuda:0')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["mean_ablate_by_lst([x for x in backw_20 if x != (9, 1)], model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQvoLqd0NuCH","executionInfo":{"status":"ok","timestamp":1698622194415,"user_tz":240,"elapsed":2010,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"372ce106-560c-4ba8-f30a-1a2e8341bca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 71.2875\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(71.2875, device='cuda:0')"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["mean_ablate_by_lst([x for x in backw_20 if x != (9, 1)] + [(10, 2)], model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANOID0JZOFoO","executionInfo":{"status":"ok","timestamp":1698622196449,"user_tz":240,"elapsed":2040,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d9cf6fd4-3e50-4e68-d3cf-d598edba14cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 71.2875\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(71.2875, device='cuda:0')"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["### set diff w repeatLast and repeatFirstAll circs"],"metadata":{"id":"eU4JCw_OQHU7"}},{"cell_type":"code","source":["repeatFirstAll_backw_3 = [(0, 1), (0, 9), (1, 0), (1, 5), (2, 2), (2, 9), (2, 10), (3, 0), (3, 3), (3, 6), (3, 7), (4, 4), (4, 8), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 8), (6, 1), (6, 3), (6, 4), (6, 6), (6, 9), (6, 10), (7, 1), (7, 2), (7, 6), (7, 7), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 11), (9, 1), (9, 9), (10, 1), (10, 2), (11, 8), (11, 9), (11, 10)]\n","repeatFirstAll_backw_10 = [(0, 1), (0, 9), (1, 0), (1, 5), (1, 6), (2, 2), (2, 8), (2, 9), (3, 0), (3, 2), (3, 3), (3, 7), (3, 8), (3, 10), (4, 4), (5, 1), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 10), (6, 0), (6, 1), (6, 3), (6, 4), (6, 6), (6, 9), (6, 10), (6, 11), (7, 0), (7, 6), (7, 8), (7, 10), (7, 11), (8, 0), (8, 1), (8, 6), (8, 8), (8, 11), (9, 1), (10, 2)]\n","repeatFirstAll_backw_20 = [(0, 1), (0, 9), (1, 0), (1, 5), (1, 6), (2, 2), (2, 8), (2, 9), (2, 10), (3, 0), (3, 2), (3, 3), (3, 7), (3, 10), (4, 4), (4, 10), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 8), (5, 10), (6, 1), (6, 3), (6, 4), (6, 6), (6, 9), (6, 10), (7, 2), (7, 6), (7, 7), (7, 10), (7, 11), (8, 0), (8, 6), (8, 8), (8, 11), (9, 1)]"],"metadata":{"id":"FDbiC6osZh3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_ablate_by_lst(repeatFirstAll_backw_3, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFv3kw2tf6cB","executionInfo":{"status":"ok","timestamp":1698622198649,"user_tz":240,"elapsed":2208,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"46f44476-1556-48b1-ea29-d7ae42158709"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 78.6232\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(78.6232, device='cuda:0')"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["mean_ablate_by_lst(repeatFirstAll_backw_10, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXHPL3V3galp","executionInfo":{"status":"ok","timestamp":1698622200443,"user_tz":240,"elapsed":1803,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"af0c1c2c-d187-4d4d-da4b-285dbcdc1dd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 78.4179\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(78.4179, device='cuda:0')"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["mean_ablate_by_lst(repeatFirstAll_backw_20, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kyIEVl2gKNC","executionInfo":{"status":"ok","timestamp":1698622202461,"user_tz":240,"elapsed":2027,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ee43fc29-763a-43f6-b4e0-ae4211f26fd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 74.1122\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(74.1122, device='cuda:0')"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["repLast_backw_3 = [(0, 1), (0, 3), (0, 5), (0, 7), (0, 9), (0, 10), (1, 0), (1, 4), (1, 5), (2, 2), (2, 8), (2, 9), (3, 0), (3, 2), (3, 3), (3, 7), (4, 4), (4, 7), (4, 10), (5, 1), (5, 3), (5, 4), (5, 5), (5, 6), (5, 8), (5, 9), (6, 1), (6, 4), (6, 6), (6, 10), (6, 11), (7, 6), (7, 10), (7, 11), (8, 0), (8, 5), (8, 6), (8, 8), (9, 1), (10, 7)]\n","set(backw_3) - set(repLast_backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjml8aCgQKDS","executionInfo":{"status":"ok","timestamp":1698622202462,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8aa07b37-63a7-4ed8-d7a9-9afa622f7c04"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(2, 4),\n"," (4, 8),\n"," (5, 0),\n"," (5, 2),\n"," (5, 7),\n"," (6, 3),\n"," (6, 7),\n"," (6, 9),\n"," (7, 7),\n"," (8, 1),\n"," (8, 9),\n"," (8, 11),\n"," (9, 5),\n"," (10, 2),\n"," (10, 5),\n"," (11, 10)}"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["mean_ablate_by_lst(repLast_backw_3, model, print_output=True)"],"metadata":{"id":"GYN4hko_hDfu","executionInfo":{"status":"ok","timestamp":1698622204442,"user_tz":240,"elapsed":1989,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cfec061b-610a-46e8-f107-aa8eef6c0548","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 65.7443\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(65.7443, device='cuda:0')"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["set(repLast_backw_3) - set(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9LE3zBUQaG_","executionInfo":{"status":"ok","timestamp":1698622204442,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"68779a6d-770e-43ed-c6cc-dc7e012661ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 3),\n"," (0, 5),\n"," (0, 7),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 4),\n"," (2, 2),\n"," (2, 8),\n"," (2, 9),\n"," (3, 0),\n"," (3, 3),\n"," (3, 7),\n"," (4, 7),\n"," (5, 9),\n"," (6, 6),\n"," (6, 11),\n"," (10, 7)}"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["set(backw_3) - set(repeatFirstAll_backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xP2hXth8Zv6n","executionInfo":{"status":"ok","timestamp":1698622204442,"user_tz":240,"elapsed":17,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"9c8989ce-612a-44fa-f12a-8dea467b396d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(2, 4),\n"," (3, 2),\n"," (4, 10),\n"," (5, 0),\n"," (5, 7),\n"," (6, 7),\n"," (8, 5),\n"," (8, 9),\n"," (9, 5),\n"," (10, 5)}"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["set(repeatFirstAll_backw_3) - set(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDDqiAhoZyPT","executionInfo":{"status":"ok","timestamp":1698622204443,"user_tz":240,"elapsed":16,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7f6c5f5c-80cd-488e-bbb3-5c1d32672cba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 9),\n"," (1, 0),\n"," (2, 2),\n"," (2, 9),\n"," (2, 10),\n"," (3, 0),\n"," (3, 3),\n"," (3, 6),\n"," (3, 7),\n"," (6, 6),\n"," (7, 1),\n"," (7, 2),\n"," (9, 9),\n"," (10, 1),\n"," (11, 8),\n"," (11, 9)}"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["## Prune forwards"],"metadata":{"id":"X3Iera3OlvQL"}},{"cell_type":"code","source":["# # Start with full circuit\n","# curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","# threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","# for layer in range(0, 12):\n","#     for head in range(12):\n","#         # Copying the curr_circuit so we can iterate over one and modify the other\n","#         copy_circuit = curr_circuit.copy()\n","\n","#         # Temporarily removing the current tuple from the copied circuit\n","#         copy_circuit.remove((layer, head))\n","\n","#         new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","#         # print((layer,head), new_score)\n","#         # If the result is less than the threshold, remove the tuple from the original list\n","#         if (100 - new_score) < threshold:\n","#             curr_circuit.remove((layer, head))\n","\n","#             print(\"Removed:\", (layer, head))\n","#             print(new_score)\n","#             print(\"\\n\")"],"metadata":{"id":"mipzZtCCl0x5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prune fwds-backwds iteratively"],"metadata":{"id":"w7bys5l5uleW"}},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"GTOk3N3evb3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"flTHN2eQvapG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 3"],"metadata":{"id":"e8OFeKuxzM3R"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKZjydkhBfTD","executionInfo":{"status":"ok","timestamp":1698622631743,"user_tz":240,"elapsed":427312,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8d684021-8aaa-422e-85ed-7dc334568e4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","100.2175064086914\n","\n","Removed: (0, 2)\n","101.17543029785156\n","\n","Removed: (0, 3)\n","99.70558166503906\n","\n","Removed: (0, 4)\n","100.49411010742188\n","\n","Removed: (0, 5)\n","98.54776763916016\n","\n","Removed: (0, 6)\n","97.98517608642578\n","\n","Removed: (0, 7)\n","97.66582489013672\n","\n","Removed: (0, 8)\n","97.72859191894531\n","\n","Removed: (0, 9)\n","98.5828628540039\n","\n","Removed: (0, 10)\n","100.9132080078125\n","\n","Removed: (0, 11)\n","101.22256469726562\n","\n","Removed: (1, 0)\n","102.34335327148438\n","\n","Removed: (1, 1)\n","101.18263244628906\n","\n","Removed: (1, 2)\n","101.21923828125\n","\n","Removed: (1, 3)\n","101.04120635986328\n","\n","Removed: (1, 4)\n","100.89093017578125\n","\n","Removed: (1, 6)\n","101.30673217773438\n","\n","Removed: (1, 7)\n","102.4504165649414\n","\n","Removed: (1, 8)\n","102.81678009033203\n","\n","Removed: (1, 9)\n","102.7670669555664\n","\n","Removed: (1, 10)\n","101.745849609375\n","\n","Removed: (1, 11)\n","101.41844177246094\n","\n","Removed: (2, 0)\n","101.97945404052734\n","\n","Removed: (2, 1)\n","104.06961059570312\n","\n","Removed: (2, 2)\n","103.98907470703125\n","\n","Removed: (2, 3)\n","101.8916244506836\n","\n","Removed: (2, 4)\n","99.25298309326172\n","\n","Removed: (2, 5)\n","100.0575180053711\n","\n","Removed: (2, 6)\n","99.4823989868164\n","\n","Removed: (2, 7)\n","99.98253631591797\n","\n","Removed: (2, 8)\n","99.43573760986328\n","\n","Removed: (2, 9)\n","99.1654281616211\n","\n","Removed: (2, 10)\n","100.87764739990234\n","\n","Removed: (2, 11)\n","101.392333984375\n","\n","Removed: (3, 0)\n","101.19523620605469\n","\n","Removed: (3, 1)\n","101.16535949707031\n","\n","Removed: (3, 2)\n","97.92501068115234\n","\n","Removed: (3, 3)\n","97.30130767822266\n","\n","Removed: (3, 5)\n","97.52045440673828\n","\n","Removed: (3, 6)\n","97.18236541748047\n","\n","Removed: (3, 7)\n","98.42378997802734\n","\n","Removed: (3, 8)\n","98.04412078857422\n","\n","Removed: (3, 9)\n","98.1982192993164\n","\n","Removed: (3, 10)\n","97.80668640136719\n","\n","Removed: (3, 11)\n","97.4478988647461\n","\n","Removed: (4, 0)\n","97.52734375\n","\n","Removed: (4, 1)\n","97.02669525146484\n","\n","Removed: (4, 2)\n","97.02996826171875\n","\n","Removed: (4, 6)\n","97.83111572265625\n","\n","Removed: (4, 9)\n","97.44226837158203\n","\n","Removed: (4, 11)\n","97.24248504638672\n","\n","Removed: (5, 1)\n","97.3897705078125\n","\n","Removed: (5, 3)\n","97.78221130371094\n","\n","Removed: (5, 5)\n","97.1356201171875\n","\n","Removed: (5, 9)\n","97.08881378173828\n","\n","Removed: (5, 10)\n","97.17808532714844\n","\n","Removed: (5, 11)\n","98.54832458496094\n","\n","Removed: (6, 0)\n","98.09013366699219\n","\n","Removed: (6, 1)\n","97.4452133178711\n","\n","Removed: (6, 2)\n","97.77297973632812\n","\n","Removed: (6, 3)\n","97.33130645751953\n","\n","Removed: (6, 5)\n","97.25289916992188\n","\n","Removed: (6, 11)\n","97.52940368652344\n","\n","Removed: (7, 0)\n","97.376953125\n","\n","Removed: (7, 1)\n","97.3440933227539\n","\n","Removed: (7, 3)\n","98.29029846191406\n","\n","Removed: (7, 4)\n","97.56974792480469\n","\n","Removed: (7, 8)\n","97.13963317871094\n","\n","Removed: (7, 9)\n","97.11727142333984\n","\n","Removed: (8, 2)\n","97.39913940429688\n","\n","Removed: (8, 3)\n","98.71418762207031\n","\n","Removed: (8, 4)\n","98.67926788330078\n","\n","Removed: (8, 5)\n","97.90247344970703\n","\n","Removed: (8, 7)\n","97.61869812011719\n","\n","Removed: (8, 10)\n","99.55375671386719\n","\n","Removed: (9, 0)\n","99.5315933227539\n","\n","Removed: (9, 2)\n","99.1026611328125\n","\n","Removed: (9, 3)\n","98.76776885986328\n","\n","Removed: (9, 4)\n","98.66875457763672\n","\n","Removed: (9, 6)\n","98.92508697509766\n","\n","Removed: (9, 7)\n","98.95206451416016\n","\n","Removed: (9, 8)\n","98.82638549804688\n","\n","Removed: (9, 9)\n","99.20732116699219\n","\n","Removed: (9, 10)\n","99.03112030029297\n","\n","Removed: (9, 11)\n","98.93888092041016\n","\n","Removed: (10, 0)\n","98.96958923339844\n","\n","Removed: (10, 1)\n","98.83573150634766\n","\n","Removed: (10, 3)\n","98.86067962646484\n","\n","Removed: (10, 4)\n","98.73738098144531\n","\n","Removed: (10, 5)\n","98.13134002685547\n","\n","Removed: (10, 6)\n","98.073974609375\n","\n","Removed: (10, 7)\n","99.72003936767578\n","\n","Removed: (10, 8)\n","99.96206665039062\n","\n","Removed: (10, 9)\n","99.75780487060547\n","\n","Removed: (10, 10)\n","99.88154602050781\n","\n","Removed: (10, 11)\n","99.79550170898438\n","\n","Removed: (11, 0)\n","99.181884765625\n","\n","Removed: (11, 1)\n","98.16866302490234\n","\n","Removed: (11, 2)\n","98.24412536621094\n","\n","Removed: (11, 3)\n","97.74618530273438\n","\n","Removed: (11, 4)\n","97.8154296875\n","\n","Removed: (11, 5)\n","97.85801696777344\n","\n","Removed: (11, 6)\n","97.89049530029297\n","\n","Removed: (11, 7)\n","97.86032104492188\n","\n","Removed: (11, 9)\n","97.89908599853516\n","\n","Removed: (11, 11)\n","97.9737319946289\n","\n","backw prune, iter  1\n","\n","Removed: (8, 0)\n","97.22578430175781\n","\n","Removed: (5, 7)\n","97.00944519042969\n","\n","Removed: (4, 3)\n","97.03435516357422\n","\n","fwd prune, iter  2\n"]}]},{"cell_type":"code","source":["fb_3 = curr_circuit.copy()\n","fb_3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET--8aulD8pE","executionInfo":{"status":"ok","timestamp":1698622631747,"user_tz":240,"elapsed":37,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d99def38-8f31-4f30-a847-2029a0451bba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (1, 5),\n"," (3, 4),\n"," (4, 4),\n"," (4, 5),\n"," (4, 7),\n"," (4, 8),\n"," (4, 10),\n"," (5, 0),\n"," (5, 2),\n"," (5, 4),\n"," (5, 6),\n"," (5, 8),\n"," (6, 4),\n"," (6, 6),\n"," (6, 7),\n"," (6, 8),\n"," (6, 9),\n"," (6, 10),\n"," (7, 2),\n"," (7, 5),\n"," (7, 6),\n"," (7, 7),\n"," (7, 10),\n"," (7, 11),\n"," (8, 1),\n"," (8, 6),\n"," (8, 8),\n"," (8, 9),\n"," (8, 11),\n"," (9, 1),\n"," (9, 5),\n"," (10, 2),\n"," (11, 8),\n"," (11, 10)]"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["mean_ablate_by_lst(fb_3, model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLOevwFnbAEK","executionInfo":{"status":"ok","timestamp":1698622633639,"user_tz":240,"elapsed":1910,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"70db1b89-8fed-4343-a37b-328ee7d78789"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0344\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(97.0344, device='cuda:0')"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["mean_ablate_by_lst(fb_3 + [(6, 9)], model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FhfmPCOybE-x","executionInfo":{"status":"ok","timestamp":1698622635611,"user_tz":240,"elapsed":2031,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a11ac514-3c88-4853-d3b0-b34e6be5d3ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 97.0344\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(97.0344, device='cuda:0')"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","source":["#### compare"],"metadata":{"id":"KvRRtGHxScYH"}},{"cell_type":"code","source":["set(backw_3) - set(fb_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLDzDrR9Sa-O","executionInfo":{"status":"ok","timestamp":1698622635612,"user_tz":240,"elapsed":40,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a20c1b81-5de8-44f4-b918-31698467338b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(2, 4),\n"," (3, 2),\n"," (5, 1),\n"," (5, 3),\n"," (5, 5),\n"," (5, 7),\n"," (6, 1),\n"," (6, 3),\n"," (8, 0),\n"," (8, 5),\n"," (10, 5)}"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["set(fb_3) - set(backw_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGKbGobdSiPG","executionInfo":{"status":"ok","timestamp":1698622635612,"user_tz":240,"elapsed":37,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ce4490cc-2ff4-432f-c6fb-6539dce62356"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(3, 4), (4, 5), (4, 7), (6, 6), (6, 8), (7, 2), (7, 5), (11, 8)}"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 20"],"metadata":{"id":"C2fvsn5SFnrO"}},{"cell_type":"code","source":["# threshold = 20\n","# curr_circuit = []\n","# prev_score = 100\n","# new_score = 0\n","# iter = 1\n","# while prev_score != new_score:\n","#     print('\\nfwd prune, iter ', str(iter))\n","#     # track changes in circuit as for some reason it doesn't work with scores\n","#     old_circuit = curr_circuit.copy() # save old before finding new one\n","#     curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","#     if curr_circuit == old_circuit:\n","#         break\n","#     print('\\nbackw prune, iter ', str(iter))\n","#     # prev_score = new_score # save old score before finding new one\n","#     old_circuit = curr_circuit.copy() # save old before finding new one\n","#     curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","#     if curr_circuit == old_circuit:\n","#         break\n","#     iter += 1"],"metadata":{"id":"smR_M0B7FnrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# curr_circuit"],"metadata":{"id":"78x6pmqkFnrP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prune backwds-fwds iteratively"],"metadata":{"id":"1putaGukK8at"}},{"cell_type":"markdown","source":["### iter fwd backw, threshold 3"],"metadata":{"id":"E69b948rS4qQ"}},{"cell_type":"code","source":["threshold = 3\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698623057989,"user_tz":240,"elapsed":422402,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"2EJaexibS4qb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f585ca34-3637-47e1-a7cb-2026902e68db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","backw prune, iter  1\n","\n","Removed: (11, 0)\n","100.10379028320312\n","\n","Removed: (11, 1)\n","98.97869873046875\n","\n","Removed: (11, 2)\n","99.02860260009766\n","\n","Removed: (11, 3)\n","98.74519348144531\n","\n","Removed: (11, 4)\n","99.08023834228516\n","\n","Removed: (11, 5)\n","99.12744903564453\n","\n","Removed: (11, 6)\n","99.15473937988281\n","\n","Removed: (11, 7)\n","99.03898620605469\n","\n","Removed: (11, 8)\n","97.15733337402344\n","\n","Removed: (11, 9)\n","97.16557312011719\n","\n","Removed: (11, 11)\n","97.33262634277344\n","\n","Removed: (10, 0)\n","97.36923217773438\n","\n","Removed: (10, 1)\n","97.38016510009766\n","\n","Removed: (10, 3)\n","97.48831176757812\n","\n","Removed: (10, 4)\n","97.46089172363281\n","\n","Removed: (10, 6)\n","97.41268157958984\n","\n","Removed: (10, 7)\n","98.00159454345703\n","\n","Removed: (10, 8)\n","98.22784423828125\n","\n","Removed: (10, 9)\n","98.02510833740234\n","\n","Removed: (10, 10)\n","98.12550354003906\n","\n","Removed: (10, 11)\n","98.09323120117188\n","\n","Removed: (9, 0)\n","98.04710388183594\n","\n","Removed: (9, 2)\n","97.6371841430664\n","\n","Removed: (9, 3)\n","97.615234375\n","\n","Removed: (9, 4)\n","97.75285339355469\n","\n","Removed: (9, 6)\n","98.1245346069336\n","\n","Removed: (9, 7)\n","98.0626449584961\n","\n","Removed: (9, 8)\n","97.92743682861328\n","\n","Removed: (9, 9)\n","97.75663757324219\n","\n","Removed: (9, 10)\n","97.59021759033203\n","\n","Removed: (9, 11)\n","97.45729064941406\n","\n","Removed: (8, 2)\n","97.288330078125\n","\n","Removed: (8, 3)\n","97.66059875488281\n","\n","Removed: (8, 4)\n","97.63050842285156\n","\n","Removed: (8, 7)\n","97.37126159667969\n","\n","Removed: (8, 10)\n","98.52196502685547\n","\n","Removed: (7, 0)\n","98.83324432373047\n","\n","Removed: (7, 1)\n","98.78370666503906\n","\n","Removed: (7, 2)\n","98.702392578125\n","\n","Removed: (7, 3)\n","99.18235778808594\n","\n","Removed: (7, 4)\n","98.49181365966797\n","\n","Removed: (7, 5)\n","97.87548828125\n","\n","Removed: (7, 8)\n","97.36460876464844\n","\n","Removed: (7, 9)\n","97.28739166259766\n","\n","Removed: (6, 0)\n","97.21785736083984\n","\n","Removed: (6, 2)\n","97.25526428222656\n","\n","Removed: (6, 5)\n","98.02972412109375\n","\n","Removed: (6, 6)\n","98.09652709960938\n","\n","Removed: (6, 8)\n","97.14927673339844\n","\n","Removed: (6, 11)\n","97.22547149658203\n","\n","Removed: (5, 9)\n","97.32170867919922\n","\n","Removed: (5, 10)\n","97.4669418334961\n","\n","Removed: (5, 11)\n","97.91899871826172\n","\n","Removed: (4, 0)\n","97.78150939941406\n","\n","Removed: (4, 1)\n","97.16500854492188\n","\n","Removed: (4, 2)\n","97.30622863769531\n","\n","Removed: (4, 3)\n","97.34151458740234\n","\n","Removed: (4, 5)\n","97.2225341796875\n","\n","Removed: (4, 6)\n","97.56124114990234\n","\n","Removed: (4, 7)\n","97.70213317871094\n","\n","Removed: (4, 9)\n","97.3612289428711\n","\n","Removed: (4, 11)\n","97.34341430664062\n","\n","Removed: (3, 0)\n","97.30535888671875\n","\n","Removed: (3, 1)\n","97.17943572998047\n","\n","Removed: (3, 3)\n","98.07479095458984\n","\n","Removed: (3, 4)\n","98.04698944091797\n","\n","Removed: (3, 5)\n","98.05595397949219\n","\n","Removed: (3, 6)\n","97.91146850585938\n","\n","Removed: (3, 7)\n","99.39958953857422\n","\n","Removed: (3, 8)\n","99.1251220703125\n","\n","Removed: (3, 9)\n","99.27898406982422\n","\n","Removed: (3, 10)\n","99.66507720947266\n","\n","Removed: (3, 11)\n","99.4759521484375\n","\n","Removed: (2, 0)\n","99.54483032226562\n","\n","Removed: (2, 1)\n","100.8971939086914\n","\n","Removed: (2, 2)\n","100.59800720214844\n","\n","Removed: (2, 3)\n","98.80732727050781\n","\n","Removed: (2, 5)\n","99.6344223022461\n","\n","Removed: (2, 6)\n","99.41691589355469\n","\n","Removed: (2, 7)\n","99.87725067138672\n","\n","Removed: (2, 8)\n","99.23440551757812\n","\n","Removed: (2, 9)\n","98.6897201538086\n","\n","Removed: (2, 10)\n","100.31320190429688\n","\n","Removed: (2, 11)\n","100.4837875366211\n","\n","Removed: (1, 0)\n","100.44381713867188\n","\n","Removed: (1, 1)\n","99.12571716308594\n","\n","Removed: (1, 2)\n","98.96029663085938\n","\n","Removed: (1, 3)\n","99.01238250732422\n","\n","Removed: (1, 4)\n","98.95176696777344\n","\n","Removed: (1, 6)\n","99.45449829101562\n","\n","Removed: (1, 7)\n","101.10612487792969\n","\n","Removed: (1, 8)\n","101.2740249633789\n","\n","Removed: (1, 9)\n","101.03429412841797\n","\n","Removed: (1, 10)\n","101.12084197998047\n","\n","Removed: (1, 11)\n","99.45032501220703\n","\n","Removed: (0, 0)\n","99.73235321044922\n","\n","Removed: (0, 2)\n","101.15692901611328\n","\n","Removed: (0, 3)\n","99.12918853759766\n","\n","Removed: (0, 4)\n","100.13936614990234\n","\n","Removed: (0, 5)\n","97.82133483886719\n","\n","Removed: (0, 6)\n","98.77555847167969\n","\n","Removed: (0, 7)\n","98.95433044433594\n","\n","Removed: (0, 8)\n","97.93353271484375\n","\n","Removed: (0, 9)\n","97.51397705078125\n","\n","Removed: (0, 10)\n","101.35298156738281\n","\n","Removed: (0, 11)\n","100.47502899169922\n","\n","fwd prune, iter  1\n","\n","Removed: (2, 4)\n","98.00341033935547\n","\n","Removed: (5, 0)\n","97.83192443847656\n","\n","Removed: (5, 1)\n","97.8128662109375\n","\n","Removed: (5, 2)\n","97.23381042480469\n","\n","Removed: (5, 3)\n","97.52021789550781\n","\n","Removed: (5, 7)\n","97.33483123779297\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["bf_3 = curr_circuit.copy()\n","bf_3"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698623057989,"user_tz":240,"elapsed":27,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"C2EgKgmJS4qb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"502b3741-3dca-4591-bafd-5cba8b9cb0b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (1, 5),\n"," (3, 2),\n"," (4, 4),\n"," (4, 8),\n"," (4, 10),\n"," (5, 4),\n"," (5, 5),\n"," (5, 6),\n"," (5, 8),\n"," (6, 1),\n"," (6, 3),\n"," (6, 4),\n"," (6, 7),\n"," (6, 9),\n"," (6, 10),\n"," (7, 6),\n"," (7, 7),\n"," (7, 10),\n"," (7, 11),\n"," (8, 0),\n"," (8, 1),\n"," (8, 5),\n"," (8, 6),\n"," (8, 8),\n"," (8, 9),\n"," (8, 11),\n"," (9, 1),\n"," (9, 5),\n"," (10, 2),\n"," (10, 5),\n"," (11, 10)]"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["#### compare"],"metadata":{"id":"ZXouisDpS4qb"}},{"cell_type":"code","source":["len(bf_3)"],"metadata":{"id":"kPspQ2ZCVeID","executionInfo":{"status":"ok","timestamp":1698623057989,"user_tz":240,"elapsed":24,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ac6d50f-f2ea-4bf5-fe4b-4441ed0b3ed9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["len(fb_3)"],"metadata":{"id":"4b2csbQpVg5H","executionInfo":{"status":"ok","timestamp":1698623057990,"user_tz":240,"elapsed":24,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"984d6f62-7f46-4978-836f-cdbefeab821c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["35"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["set(backw_3) - set(bf_3)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698623057990,"user_tz":240,"elapsed":23,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"TthWjv5IS4qc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8fb93118-23b9-4d5b-ffe7-356208353402"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(2, 4), (5, 0), (5, 1), (5, 2), (5, 3), (5, 7)}"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["set(bf_3) - set(backw_3)"],"metadata":{"id":"yMADPA_oTFb8","executionInfo":{"status":"ok","timestamp":1698623057990,"user_tz":240,"elapsed":22,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"63782b20-dce1-400f-c292-86b4e00957d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["set()"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["set(fb_3) - (set(fb_3) - set(bf_3))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1698623057990,"user_tz":240,"elapsed":21,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"epw2Vlh2S4qc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b0bbf01-8e24-4928-9be0-d732865bfd07"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(0, 1),\n"," (1, 5),\n"," (4, 4),\n"," (4, 8),\n"," (4, 10),\n"," (5, 4),\n"," (5, 6),\n"," (5, 8),\n"," (6, 4),\n"," (6, 7),\n"," (6, 9),\n"," (6, 10),\n"," (7, 6),\n"," (7, 7),\n"," (7, 10),\n"," (7, 11),\n"," (8, 1),\n"," (8, 6),\n"," (8, 8),\n"," (8, 9),\n"," (8, 11),\n"," (9, 1),\n"," (9, 5),\n"," (10, 2),\n"," (11, 10)}"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["set(bf_3) - set(fb_3)"],"metadata":{"id":"1KXH3MTsTHm9","executionInfo":{"status":"ok","timestamp":1698623057990,"user_tz":240,"elapsed":20,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a932d7c-5065-42d3-b22b-ffc75c3526da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{(3, 2), (5, 5), (6, 1), (6, 3), (8, 0), (8, 5), (10, 5)}"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["Get score of fb_3 without nodes it has that bf_3 doesn't have\n","\n","this is set intersection: https://chat.openai.com/c/c15f48a7-226b-4c89-8ad9-a39a471867f5"],"metadata":{"id":"lfdQ7oy4ttdb"}},{"cell_type":"code","source":["mean_ablate_by_lst(list(set(fb_3) - (set(fb_3) - set(bf_3))), model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_YvvGGutjg3","executionInfo":{"status":"ok","timestamp":1698623059979,"user_tz":240,"elapsed":2009,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"128697ad-757c-4d53-9dd0-6838afd83c73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 89.4520\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(89.4520, device='cuda:0')"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["mean_ablate_by_lst(list(set(bf_3) - (set(bf_3) - set(fb_3))), model, print_output=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbM0-Ml1tmzl","executionInfo":{"status":"ok","timestamp":1698623061890,"user_tz":240,"elapsed":1915,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fca19064-df60-4240-d9d6-d5e1630a03d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 89.4520\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(89.4520, device='cuda:0')"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["(set(fb_3) - (set(fb_3) - set(bf_3))) == (set(bf_3) - (set(bf_3) - set(fb_3)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVT9R1xTt9qC","executionInfo":{"status":"ok","timestamp":1698623061890,"user_tz":240,"elapsed":12,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"45bae0bc-ab7a-4c84-e281-4c3fa2697e07"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":73}]}]}