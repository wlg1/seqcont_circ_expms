{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["DcZG9rm2IAiA","OLkInsdjyHMx","L_00P1qAqS3e"],"authorship_tag":"ABX9TyN4fo1X2GvFn7XDI1U9oD56"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"b13177b7"},"source":["<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","source":["!pip install typing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WThGyJ_SlfWO","executionInfo":{"status":"ok","timestamp":1695313983369,"user_tz":240,"elapsed":6585,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"33cdd3b4-462d-46fe-fcc2-f7c3f0a2b7ea"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: typing in /usr/local/lib/python3.10/dist-packages (3.7.4.3)\n"]},{"output_type":"stream","name":"stderr","text":["Exception in thread Thread-5 (attachment_entry):\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 237, in listen\n","    sock, _ = endpoints_listener.accept()\n","  File \"/usr/lib/python3.10/socket.py\", line 293, in accept\n","    fd, addr = self._accept()\n","TimeoutError: timed out\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy.py\", line 52, in attachment_entry\n","    debugpy.listen(_dap_port)\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/public_api.py\", line 31, in wrapper\n","    return wrapped(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 143, in debug\n","    log.reraise_exception(\"{0}() failed:\", func.__name__, level=\"info\")\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 141, in debug\n","    return func(address, settrace_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 251, in listen\n","    raise RuntimeError(\"timed out waiting for adapter to connect\")\n","RuntimeError: timed out waiting for adapter to connect\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695314078763,"user_tz":240,"elapsed":95445,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f70a772e-ab21-4654-a62c-184e597a7aac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-q1gg317n\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-q1gg317n\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 20a44fe3a8022d353c9cc7c984a8fcab14552d1c\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.14.1)\n","Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.14.5)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.6.1)\n","Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.0.3)\n","Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.2.22)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.23.5)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.5.2)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.33.2)\n","Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.15.10)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.7)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.17.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0.1)\n","Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (2.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.8.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.3.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.36)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.31.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.10)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.1)\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n","\n","  \n","  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n","  install Node.js is deprecated now and will eventually be made inactive.\n","\n","  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n","  instructions to migrate your repo.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n","  information about which versions of Node.js and which Linux distributions\n","  are supported and how to install it.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","\n","                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n","Continuing in 60 seconds (press Ctrl-C to abort) ...\n","\n","\n","## Installing the NodeSource Node.js 16.x repo...\n","\n","\n","## Populating apt-get cache...\n","\n","+ apt-get update\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 https://deb.nodesource.com/node_16.x jammy InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","\n","## Confirming \"jammy\" is supported...\n","\n","+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n","\n","## Adding the NodeSource signing key to your keyring...\n","\n","+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n","\n","## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n","\n","+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n","+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n","\n","## Running `apt-get update` for you...\n","\n","+ apt-get update\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 https://deb.nodesource.com/node_16.x jammy InRelease\n","Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","\n","## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n","## You may also need development tools to build native addons:\n","     sudo apt-get install gcc g++ make\n","## To install the Yarn package manager, run:\n","     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n","     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n","     sudo apt-get update && sudo apt-get install yarn\n","\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","nodejs is already the newest version (16.20.2-deb-1nodesource1).\n","0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n","Collecting git+https://github.com/neelnanda-io/PySvelte.git\n","  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-50r3ufs1\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-50r3ufs1\n","  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (0.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.23.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.0.1+cu118)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.14.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.33.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.66.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.5.3)\n","Requirement already satisfied: typeguard~=2.0 in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.13.3)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.3.7)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.17.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (6.0.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2023.3.post1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (4.8.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.16.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1695314078764,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","import plotly.io as pio\n","\n","if IN_COLAB or not DEBUG_MODE:\n","    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","    pio.renderers.default = \"colab\"\n","else:\n","    pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1695314082092,"user_tz":240,"elapsed":3334,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1695314084928,"user_tz":240,"elapsed":2840,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"cFMTUcQiIAiF","outputId":"ba93d7b1-fa50-4b49-9ce8-1d90a2ca211e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695314084928,"user_tz":240,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x799b6a0a8ac0>"]},"metadata":{},"execution_count":7}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"KFs9BrbzIAiH","executionInfo":{"status":"ok","timestamp":1695314084928,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def imshow(tensor, renderer=None, **kwargs):\n","    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","def line(tensor, renderer=None, **kwargs):\n","    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","    x = utils.to_numpy(x)\n","    y = utils.to_numpy(y)\n","    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["# Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"markdown","source":["Decide which model to use (eg. gpt2-small vs -medium)"],"metadata":{"id":"ssJgoKr2yI8O"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"xLwDyosvIAiJ","executionInfo":{"status":"ok","timestamp":1695314094684,"user_tz":240,"elapsed":9760,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c4ad2f6-6df7-482b-adb4-1fbb85237826"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using pad_token, but it is not set yet.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["# Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fdh5--MfYw7-","executionInfo":{"status":"ok","timestamp":1695314094685,"user_tz":240,"elapsed":34,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5e1c82db-48dc-4ff7-c1ff-3f4ecd9ee6c3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'ARENA_2.0' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ4C_bsXZFfj","executionInfo":{"status":"ok","timestamp":1695314094685,"user_tz":240,"elapsed":32,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"24fdb308-3372-4cfd-df12-7f2c67a302cb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV","executionInfo":{"status":"ok","timestamp":1695314094686,"user_tz":240,"elapsed":32,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["#@title Names list\n","names = [\n","    \"Michael\",\n","    \"Christopher\",\n","    \"Jessica\",\n","    \"Matthew\",\n","    \"Ashley\",\n","    \"Jennifer\",\n","    \"Joshua\",\n","    \"Amanda\",\n","    \"Daniel\",\n","    \"David\",\n","    \"James\",\n","    \"Robert\",\n","    \"John\",\n","    \"Joseph\",\n","    \"Andrew\",\n","    \"Ryan\",\n","    \"Brandon\",\n","    \"Jason\",\n","    \"Justin\",\n","    \"Sarah\",\n","    \"William\",\n","    \"Jonathan\",\n","    \"Stephanie\",\n","    \"Brian\",\n","    \"Nicole\",\n","    \"Nicholas\",\n","    \"Anthony\",\n","    \"Heather\",\n","    \"Eric\",\n","    \"Elizabeth\",\n","    \"Adam\",\n","    \"Megan\",\n","    \"Melissa\",\n","    \"Kevin\",\n","    \"Steven\",\n","    \"Thomas\",\n","    \"Timothy\",\n","    \"Christina\",\n","    \"Kyle\",\n","    \"Rachel\",\n","    \"Laura\",\n","    \"Lauren\",\n","    \"Amber\",\n","    \"Brittany\",\n","    \"Danielle\",\n","    \"Richard\",\n","    \"Kimberly\",\n","    \"Jeffrey\",\n","    \"Amy\",\n","    \"Crystal\",\n","    \"Michelle\",\n","    \"Tiffany\",\n","    \"Jeremy\",\n","    \"Benjamin\",\n","    \"Mark\",\n","    \"Emily\",\n","    \"Aaron\",\n","    \"Charles\",\n","    \"Rebecca\",\n","    \"Jacob\",\n","    \"Stephen\",\n","    \"Patrick\",\n","    \"Sean\",\n","    \"Erin\",\n","    \"Jamie\",\n","    \"Kelly\",\n","    \"Samantha\",\n","    \"Nathan\",\n","    \"Sara\",\n","    \"Dustin\",\n","    \"Paul\",\n","    \"Angela\",\n","    \"Tyler\",\n","    \"Scott\",\n","    \"Katherine\",\n","    \"Andrea\",\n","    \"Gregory\",\n","    \"Erica\",\n","    \"Mary\",\n","    \"Travis\",\n","    \"Lisa\",\n","    \"Kenneth\",\n","    \"Bryan\",\n","    \"Lindsey\",\n","    \"Kristen\",\n","    \"Jose\",\n","    \"Alexander\",\n","    \"Jesse\",\n","    \"Katie\",\n","    \"Lindsay\",\n","    \"Shannon\",\n","    \"Vanessa\",\n","    \"Courtney\",\n","    \"Christine\",\n","    \"Alicia\",\n","    \"Cody\",\n","    \"Allison\",\n","    \"Bradley\",\n","    \"Samuel\",\n","]"],"metadata":{"id":"bLQMPm0kKIRS","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_names(names):\n","    return [name for name in names if len(model.tokenizer.tokenize(name)) == 1]\n","names = filter_names(names)"],"metadata":{"id":"_6aymEHkPUn4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def make_prompts_list(names, template, num_sentences, num_targ_tokens):\n","    sentences = []\n","    generated_set = set() # Ensure none of the generated sentences are the same\n","    while len(sentences) < num_sentences:\n","        unique_names = random.sample(names, k=num_targ_tokens)\n","        temp_template = template\n","        sentence_dict = {}\n","        for i, name in enumerate(unique_names, start=1):\n","            temp_template = temp_template.replace(f\"[S{i}]\", name)\n","            sentence_dict[f'S{i}'] = name\n","        sentence_dict['text'] = temp_template\n","        if sentence_dict['text'] not in generated_set:\n","            generated_set.add(sentence_dict['text'])\n","            sentences.append(sentence_dict)\n","    return sentences"],"metadata":{"id":"tub8nC_9Mp6a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, tokenizer, N, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = N\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"S1\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"S2\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if key != 'text']:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                    target_token = prompt[targ]\n","                else:\n","                    target_token = \"Ġ\" + prompt[targ]\n","                target_index = tokens.index(target_token)\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Repalce io_tokens with correct answer (next, which is '5') and s_tokens with incorrect (current, which repeats)"],"metadata":{"id":"exuTCQ_XmmFP"}},{"cell_type":"code","source":["# template = \"[S1] and [S2] went to the store. [S2] gave a drink to\"\n","template = \"Then, [S1] and [S2] went to the store, [S2] gave a drink to\"\n","num_inputs = 30\n","num_targ_tokens = 2\n","prompts_list = make_prompts_list(names, template, num_inputs, num_targ_tokens)\n","dataset = Dataset(prompts_list, model.tokenizer, num_inputs, S1_is_first=False)"],"metadata":{"id":"b8HJww_CPuzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_2 = Dataset(prompts_list, model.tokenizer, num_inputs, S1_is_first=False)"],"metadata":{"id":"qkUJQaxhktgk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Early heads validation"],"metadata":{"id":"MAqIF4TPiIPO"}},{"cell_type":"code","source":["from torch import Tensor\n","import torch as t\n","device = torch.device(\"cuda:0\")"],"metadata":{"id":"Wn-J48k9k7pI","executionInfo":{"status":"ok","timestamp":1695314094688,"user_tz":240,"elapsed":33,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def generate_repeated_tokens(\n","\tmodel: HookedTransformer,\n","\tseq_len: int,\n","\tbatch: int = 1\n",") -> Float[Tensor, \"batch 2*seq_len\"]:\n","\t'''\n","\tGenerates a sequence of repeated random tokens (no start token).\n","\t'''\n","\trep_tokens_half = t.randint(0, model.cfg.d_vocab, (batch, seq_len), dtype=t.int64)\n","\trep_tokens = t.cat([rep_tokens_half, rep_tokens_half], dim=-1).to(device)\n","\treturn rep_tokens\n","\n","\n","def get_attn_scores(\n","\tmodel: HookedTransformer,\n","\tseq_len: int,\n","\tbatch: int,\n","\t# head_type: Literal[\"duplicate\", \"prev\", \"induction\"]\n","    head_type\n","):\n","\t'''\n","\tReturns attention scores for sequence of duplicated tokens, for every head.\n","\t'''\n","\trep_tokens = generate_repeated_tokens(model, seq_len, batch)\n","\n","\t_, cache = model.run_with_cache(\n","\t\trep_tokens,\n","\t\treturn_type=None,\n","\t\tnames_filter=lambda name: name.endswith(\"pattern\")\n","\t)\n","\n","\t# Get the right indices for the attention scores\n","\n","\tif head_type == \"duplicate\":\n","\t\tsrc_indices = range(seq_len)\n","\t\tdest_indices = range(seq_len, 2 * seq_len)\n","\telif head_type == \"prev\":\n","\t\tsrc_indices = range(seq_len)\n","\t\tdest_indices = range(1, seq_len + 1)\n","\telif head_type == \"induction\":\n","\t\tdest_indices = range(seq_len, 2 * seq_len)\n","\t\tsrc_indices = range(1, seq_len + 1)\n","\telse:\n","\t\traise ValueError(f\"Unknown head type {head_type}\")\n","\n","\tresults = t.zeros(model.cfg.n_layers, model.cfg.n_heads, device=\"cuda\", dtype=t.float32)\n","\tfor layer in range(model.cfg.n_layers):\n","\t\tfor head in range(model.cfg.n_heads):\n","\t\t\tattn_scores: Float[Tensor, \"batch head dest src\"] = cache[\"pattern\", layer]\n","\t\t\tavg_attn_on_duplicates = attn_scores[:, head, dest_indices, src_indices].mean().item()\n","\t\t\tresults[layer, head] = avg_attn_on_duplicates\n","\n","\treturn results\n","\n","\n","def plot_early_head_validation_results(seq_len: int = 50, batch: int = 50):\n","\t'''\n","\tProduces a plot that looks like Figure 18 in the paper.\n","\t'''\n","\thead_types = [\"duplicate\", \"prev\", \"induction\"]\n","\n","\tresults = t.stack([\n","\t\tget_attn_scores(model, seq_len, batch, head_type=head_type)\n","\t\tfor head_type in head_types\n","\t])\n","\n","\timshow(\n","\t\tresults,\n","\t\tfacet_col=0,\n","\t\tfacet_labels=[\n","\t\t\tf\"{head_type.capitalize()} token attention prob.<br>on sequences of random tokens\"\n","\t\t\tfor head_type in head_types\n","\t\t],\n","\t\tlabels={\"x\": \"Head\", \"y\": \"Layer\"},\n","\t\twidth=1300,\n","\t)\n","\n","\n","model.reset_hooks()\n","plot_early_head_validation_results()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"HQFnDG5oiJhO","executionInfo":{"status":"error","timestamp":1695314762858,"user_tz":240,"elapsed":2037,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"de2587bc-c225-4ca3-fd15-70835891d8fa"},"execution_count":22,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-896502ad92dd>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mplot_early_head_validation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-896502ad92dd>\u001b[0m in \u001b[0;36mplot_early_head_validation_results\u001b[0;34m(seq_len, batch)\u001b[0m\n\u001b[1;32m     65\u001b[0m \t])\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \timshow(\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mfacet_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-589803f4b10f>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(tensor, renderer, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_continuous_midpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_continuous_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RdBu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: imshow() got an unexpected keyword argument 'facet_labels'"]}]},{"cell_type":"markdown","source":["# Ablate the model and compare with original"],"metadata":{"id":"Lk3bffnCYq-p"}},{"cell_type":"code","source":["# from ioi_dataset import NAMES, IOIDataset\n","\n","# N = 25\n","# ioi_dataset = IOIDataset(\n","#     prompt_type=\"mixed\",\n","#     N=N,\n","#     tokenizer=model.tokenizer,\n","#     prepend_bos=False,\n","#     seed=1,\n","#     # device=str(device)\n","# )\n","# abc_dataset = ioi_dataset.gen_flipped_prompts(\"ABB->XYZ, BAB->XYZ\")"],"metadata":{"id":"ZtraLbzkaxeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"CgD41x5nbKKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CIRCUIT = {\n","    \"name mover\": [(9, 9), (10, 0), (9, 6)],\n","    \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n","    \"negative name mover\": [(10, 7), (11, 10)],\n","    \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n","    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n","    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n","    # \"previous token\": [(2, 2), (4, 11)],\n","}\n","\n","SEQ_POS_TO_KEEP = {\n","    \"name mover\": \"end\",\n","    \"backup name mover\": \"end\",\n","    \"negative name mover\": \"end\",\n","    \"s2 inhibition\": \"end\",\n","    # \"induction\": \"S2\",\n","    # \"duplicate token\": \"S2\",\n","    # \"previous token\": \"S1+1\",\n","}"],"metadata":{"id":"xEeHN5WHGVad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can set the mean ablation to be over the same dataset, though with some issues"],"metadata":{"id":"rM8DR1CtnYu8"}},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)\n","\n","print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n","print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ayKv53kYsMS","executionInfo":{"status":"ok","timestamp":1689459117270,"user_tz":240,"elapsed":3470,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2dc8e1c0-078c-435c-ce62-f412913906ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (IOI dataset, using entire model): 2.5075\n","Average logit difference (IOI dataset, only using circuit): 2.2445\n"]}]},{"cell_type":"markdown","source":["## Test circuit without main name movers"],"metadata":{"id":"L_00P1qAqS3e"}},{"cell_type":"code","source":["CIRCUIT = {\n","    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n","    \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n","    \"negative name mover\": [(10, 7), (11, 10)],\n","    \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n","    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n","    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n","    # \"previous token\": [(2, 2), (4, 11)],\n","}\n","\n","SEQ_POS_TO_KEEP = {\n","    # \"name mover\": \"end\",\n","    \"backup name mover\": \"end\",\n","    \"negative name mover\": \"end\",\n","    \"s2 inhibition\": \"end\",\n","    # \"induction\": \"S2\",\n","    # \"duplicate token\": \"S2\",\n","    # \"previous token\": \"S1+1\",\n","}"],"metadata":{"id":"YXjIB5_UsQCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)\n","\n","print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n","print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689460494589,"user_tz":240,"elapsed":3776,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3e4a28b8-7464-485d-d88f-7b179349aa9d","id":"B4msk2ajsQCo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (IOI dataset, using entire model): 2.5075\n","Average logit difference (IOI dataset, only using circuit): 1.9428\n"]}]},{"cell_type":"markdown","source":["## Test circuit without backup name movers"],"metadata":{"id":"InHte-EssYme"}},{"cell_type":"code","source":["CIRCUIT = {\n","    \"name mover\": [(9, 9), (10, 0), (9, 6)],\n","    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n","    \"negative name mover\": [(10, 7), (11, 10)],\n","    \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n","    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n","    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n","    # \"previous token\": [(2, 2), (4, 11)],\n","}\n","\n","SEQ_POS_TO_KEEP = {\n","    \"name mover\": \"end\",\n","    # \"backup name mover\": \"end\",\n","    \"negative name mover\": \"end\",\n","    \"s2 inhibition\": \"end\",\n","    # \"induction\": \"S2\",\n","    # \"duplicate token\": \"S2\",\n","    # \"previous token\": \"S1+1\",\n","}"],"metadata":{"id":"j1Nq1n0FsYmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)\n","\n","print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n","print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689460530544,"user_tz":240,"elapsed":2345,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c9600d0f-758c-4174-c3df-275d72ad50a1","id":"FahEXKdZsYmn"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (IOI dataset, using entire model): 2.5075\n","Average logit difference (IOI dataset, only using circuit): 2.0672\n"]}]},{"cell_type":"markdown","source":["## Test circuit without all name movers"],"metadata":{"id":"GyYzaSynnJMU"}},{"cell_type":"code","source":["CIRCUIT = {\n","    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n","    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n","    # \"negative name mover\": [(10, 7), (11, 10)],\n","    \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n","    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n","    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n","    # \"previous token\": [(2, 2), (4, 11)],\n","}\n","\n","SEQ_POS_TO_KEEP = {\n","    # \"name mover\": \"end\",\n","    # \"backup name mover\": \"end\",\n","    # \"negative name mover\": \"end\",\n","    \"s2 inhibition\": \"end\",\n","    # \"induction\": \"S2\",\n","    # \"duplicate token\": \"S2\",\n","    # \"previous token\": \"S1+1\",\n","}"],"metadata":{"id":"qjRrtxjAnN8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(dataset.toks)\n","\n","print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n","print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmEtoBBVnSFO","executionInfo":{"status":"ok","timestamp":1689459181400,"user_tz":240,"elapsed":3040,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c59ed801-185e-450b-b917-017e55785d5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (IOI dataset, using entire model): 2.5075\n","Average logit difference (IOI dataset, only using circuit): 0.4925\n"]}]},{"cell_type":"markdown","source":["This shows name movers are very important."],"metadata":{"id":"uT5eR2IGnhFi"}},{"cell_type":"markdown","source":["## Test a wrong circuit to see that the logit diff doesn't match original"],"metadata":{"id":"nuP3MU-Lc3UF"}},{"cell_type":"markdown","source":["We keep only 4 heads, so that means we knock out most of the circuit"],"metadata":{"id":"we2F85KVnkWK"}},{"cell_type":"code","source":["WRONG_CIRCUIT = {\n","    \"name mover\": [(2,2)],\n","    \"backup name mover\": [(1, 1)],\n","    \"negative name mover\": [],\n","    \"s2 inhibition\": [],\n","    \"induction\": [(4,4)],\n","    \"duplicate token\": [],\n","    \"previous token\": [(8,3)],\n","}"],"metadata":{"id":"8WFaqx18c-kb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","ioi_logits_original, ioi_cache = model.run_with_cache(ioi_dataset.toks)\n","\n","model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=abc_dataset, circuit=WRONG_CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","ioi_logits_minimal = model(ioi_dataset.toks)\n","\n","print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original):.4f}\")\n","print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOsqCpggc8Jm","executionInfo":{"status":"ok","timestamp":1689458223727,"user_tz":240,"elapsed":3630,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"726fbc28-377e-43cd-9f8c-578c447640d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (IOI dataset, using entire model): 2.8052\n","Average logit difference (IOI dataset, only using circuit): -0.7422\n"]}]},{"cell_type":"markdown","source":["# Plot minimality scores"],"metadata":{"id":"drSwyz5ees6u"}},{"cell_type":"code","source":["%%capture\n","!pip install circuitsvis"],"metadata":{"id":"Cmkr5IZ_gG5E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Write a function that converts into this:"],"metadata":{"id":"nVOdpmlKnrH1"}},{"cell_type":"code","source":["K_FOR_EACH_COMPONENT = {\n","    (9, 9): set(),\n","    (10, 0): {(9, 9)},\n","    (9, 6): {(9, 9), (10, 0)},\n","    (10, 7): {(11, 10)},\n","    (11, 10): {(10, 7)},\n","    (8, 10): {(7, 9), (8, 6), (7, 3)},\n","    (7, 9): {(8, 10), (8, 6), (7, 3)},\n","    (8, 6): {(7, 9), (8, 10), (7, 3)},\n","    (7, 3): {(7, 9), (8, 10), (8, 6)},\n","    (5, 5): {(5, 9), (6, 9), (5, 8)},\n","    (5, 9): {(11, 10), (10, 7)},\n","    (6, 9): {(5, 9), (5, 5), (5, 8)},\n","    (5, 8): {(11, 10), (10, 7)},\n","    (0, 1): {(0, 10), (3, 0)},\n","    (0, 10): {(0, 1), (3, 0)},\n","    (3, 0): {(0, 1), (0, 10)},\n","    (4, 11): {(2, 2)},\n","    (2, 2): {(4, 11)},\n","    (11, 2): {(9, 9), (10, 0), (9, 6)},\n","    (10, 6): {(9, 9), (10, 0), (9, 6), (11, 2)},\n","    (10, 10): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6)},\n","    (10, 2): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6), (10, 10)},\n","    (9, 7): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6), (10, 10), (10, 2)},\n","    (10, 1): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6), (10, 10), (10, 2), (9, 7)},\n","    (11, 9): {(9, 9), (10, 0), (9, 6), (9, 0)},\n","    (9, 0): {(9, 9), (10, 0), (9, 6), (11, 9)},\n","}"],"metadata":{"id":"hMYxQOmHfws4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from solutions import *\n","\n","def get_score(\n","\tmodel: HookedTransformer,\n","\tioi_dataset: IOIDataset,\n","\tabc_dataset: IOIDataset,\n","\tK: Set[Tuple[int, int]],\n","\tC: Dict[str, List[Tuple[int, int]]],\n",") -> float:\n","\t'''\n","\tReturns the value F(C \\ K), where F is the logit diff, C is the\n","\tcore circuit, and K is the set of circuit components to remove.\n","\t'''\n","\tC_excl_K = {k: [head for head in v if head not in K] for k, v in C.items()}\n","\tmodel = ioi_circuit_extraction.add_mean_ablation_hook(model, abc_dataset, C_excl_K, SEQ_POS_TO_KEEP)\n","\tlogits = model(ioi_dataset.toks)\n","\tscore = logits_to_ave_logit_diff_2(logits, ioi_dataset).item()\n","\n","\treturn score\n","\n","def get_minimality_score(\n","\t\tmodel: HookedTransformer,\n","\t\tioi_dataset: IOIDataset,\n","\t\tabc_dataset: IOIDataset,\n","\t\tv: Tuple[int, int],\n","\t\tK: Set[Tuple[int, int]],\n","\t\tC: Dict[str, List[Tuple[int, int]]] = CIRCUIT,\n","\t) -> float:\n","\t\t'''\n","\t\tReturns the value | F(C \\ K_union_v) - F(C | K) |, where F is\n","\t\tthe logit diff, C is the core circuit, K is the set of circuit\n","\t\tcomponents to remove, and v is a head (not in K).\n","\t\t'''\n","\t\tassert v not in K\n","\t\tK_union_v = K | {v}\n","\t\tC_excl_K_score = get_score(model, ioi_dataset, abc_dataset, K, C)\n","\t\tC_excl_Kv_score = get_score(model, ioi_dataset, abc_dataset, K_union_v, C)\n","\n","\t\treturn abs(C_excl_K_score - C_excl_Kv_score)\n","\n","def get_all_minimality_scores(\n","\t\tmodel: HookedTransformer,\n","\t\tioi_dataset: IOIDataset = ioi_dataset,\n","\t\tabc_dataset: IOIDataset = abc_dataset,\n","\t\tk_for_each_component: Dict = K_FOR_EACH_COMPONENT\n","\t) -> Dict[Tuple[int, int], float]:\n","\t\t'''\n","\t\tReturns dict of minimality scores for every head in the model (as\n","\t\ta fraction of F(M), the logit diff of the full model).\n","\n","\t\tWarning - this resets all hooks at the end (including permanent).\n","\t\t'''\n","\t\t# Get full circuit score F(M), to divide minimality scores by\n","\t\tmodel.reset_hooks(including_permanent=True)\n","\t\tlogits = model(ioi_dataset.toks)\n","\t\tfull_circuit_score = logits_to_ave_logit_diff_2(logits, ioi_dataset).item()\n","\n","\t\t# Get all minimality scores, using the `get_minimality_score` function\n","\t\tminimality_scores = {}\n","\t\tfor v, K in tqdm(k_for_each_component.items()):\n","\t\t\tscore = get_minimality_score(model, ioi_dataset, abc_dataset, v, K)\n","\t\t\tminimality_scores[v] = score / full_circuit_score\n","\n","\t\tmodel.reset_hooks(including_permanent=True)\n","\n","\t\treturn minimality_scores"],"metadata":{"id":"xa6ecFe2f69c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["minimality_scores = get_all_minimality_scores(model)"],"metadata":{"id":"ma193-c7fGLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_minimal_set_results(minimality_scores: Dict[Tuple[int, int], float]):\n","    '''\n","    Plots the minimality results, in a way resembling figure 7 in the paper.\n","\n","    minimality_scores:\n","        Dict with elements like (9, 9): minimality score for head 9.9 (as described\n","        in section 4.2 of the paper)\n","    '''\n","\n","    CIRCUIT_reversed = {head: k for k, v in CIRCUIT.items() for head in v}\n","    colors = [CIRCUIT_reversed[head].capitalize() + \" head\" for head in minimality_scores.keys()]\n","    color_sequence = [px.colors.qualitative.Dark2[i] for i in [0, 1, 2, 5, 3, 6]] + [\"#BAEA84\"]\n","\n","    bar(\n","        list(minimality_scores.values()),\n","        x=list(map(str, minimality_scores.keys())),\n","        labels={\"x\": \"Attention head\", \"y\": \"Change in logit diff\", \"color\": \"Head type\"},\n","        color=colors,\n","        template=\"ggplot2\",\n","        color_discrete_sequence=color_sequence,\n","        bargap=0.02,\n","        yaxis_tickformat=\".0%\",\n","        legend_title_text=\"\",\n","        title=\"Plot of minimality scores (as percentages of full model logit diff)\",\n","        width=800,\n","        hovermode=\"x unified\"\n","    )\n","\n","plot_minimal_set_results(minimality_scores)"],"metadata":{"id":"uYaFGosUeitY"},"execution_count":null,"outputs":[]}]}