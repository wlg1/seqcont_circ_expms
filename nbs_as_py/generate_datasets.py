# -*- coding: utf-8 -*-
"""generate_datasets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p-i1nwVGk1SyTkR7P87fGoWiC7F-Onoo

The generated datasets should all use the same template for all tasks. Eg) "Table is 1. Chair is 2" should also be represented as "Table is one. Chair is two".

# Setup
(No need to change anything)
"""

# Commented out IPython magic to ensure Python compatibility.
DEBUG_MODE = False
try:
    import google.colab
    IN_COLAB = True
    print("Running as a Colab notebook")
#     %pip install git+https://github.com/neelnanda-io/TransformerLens.git
    # Install another version of node that makes PySvelte work way faster
    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs
    # %pip install git+https://github.com/neelnanda-io/PySvelte.git
except:
    IN_COLAB = False
    print("Running as a Jupyter notebook - intended for development only!")
    from IPython import get_ipython

    ipython = get_ipython()
    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel
    ipython.magic("load_ext autoreload")
    ipython.magic("autoreload 2")

# Import stuff
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import einops
from fancy_einsum import einsum
import tqdm.notebook as tqdm
import random
from pathlib import Path
import plotly.express as px
from torch.utils.data import DataLoader

from jaxtyping import Float, Int
from typing import List, Union, Optional
from functools import partial
import copy

import itertools
from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer
import dataclasses
import datasets
from IPython.display import HTML

import transformer_lens
import transformer_lens.utils as utils
from transformer_lens.hook_points import (
    HookedRootModule,
    HookPoint,
)  # Hooking utilities
from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache

"""We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."""

torch.set_grad_enabled(False)

"""## Load Model"""

model = HookedTransformer.from_pretrained(
    "gpt2-small",
    center_unembed=True,
    center_writing_weights=True,
    fold_ln=True,
    refactor_factored_attn_matrices=True,
)

"""# Get preds fn"""

def remove_batch_dim(
    tensor: Float[torch.Tensor, "1 ..."]
) -> Float[torch.Tensor, "..."]:
    """
    Removes the first dimension of a tensor if it is size 1, otherwise returns the tensor unchanged
    """
    if tensor.shape[0] == 1:
        return tensor.squeeze(0)
    else:
        return tensor

def get_top_preds_moredata(
    prompt: str,
    answer: str,
    model,  # Can't give type hint due to circular imports
    incor: str,
    prepend_space_to_answer: Optional[bool] = True,
    print_details: Optional[bool] = True,
    prepend_bos: Optional[bool] = True, # key change
    top_k: Optional[int] = 10,
):
    """
    Args:
        prompt:
            The prompt string, e.g. "Why did the elephant cross the".
        answer:
            The answer, e.g. "road". Note that if you set prepend_space_to_answer to False, you need
            to think about if you have a space before the answer here (as e.g. in this example the
            answer may really be " road" if the prompt ends without a trailing space).
        model:
            The model.
        prepend_space_to_answer:
            Whether or not to prepend a space to the answer. Note this will only ever prepend a
            space if the answer doesn't already start with one.
        print_details:
            Print the prompt (as a string but broken up by token), answer and top k tokens (all
            with logit, rank and probability).
        prepend_bos:
            Overrides self.cfg.default_prepend_bos if set. Whether to prepend
            the BOS token to the input (applicable when input is a string). Models generally learn
            to use the BOS token as a resting place for attention heads (i.e. a way for them to be
            "turned off"). This therefore often improves performance slightly.
        top_k:
            Top k tokens to print details of (when print_details is set to True).

    Returns:
        None (just prints the results directly).
    """
    if prepend_space_to_answer and not answer.startswith(" "):
        answer = " " + answer
    # GPT-2 often treats the first token weirdly, so lets give it a resting position
    prompt_tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)
    answer_tokens = model.to_tokens(answer, prepend_bos=False)
    tokens = torch.cat((prompt_tokens, answer_tokens), dim=1)
    prompt_str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)
    answer_str_tokens = model.to_str_tokens(answer, prepend_bos=False)
    prompt_length = len(prompt_str_tokens)
    answer_length = len(answer_str_tokens)
    logits = remove_batch_dim(model(tokens))
    probs = logits.softmax(dim=-1)
    answer_ranks = []

    # from end of input to how long answer is (if answer is 1 token, this is just 1)
    for index in range(prompt_length, prompt_length + answer_length):
        answer_token = tokens[0, index]
        answer_str_token = answer_str_tokens[index - prompt_length]
        # Offset by 1 because models predict the NEXT token
        token_probs = probs[index - 1]
        sorted_token_probs, sorted_token_values = token_probs.sort(descending=True)
        correct_rank = torch.arange(len(sorted_token_values))[
            (sorted_token_values == answer_token).cpu()
        ].item()
        answer_ranks.append((answer_str_token, correct_rank))

    k = top_k
    while k < 500:
        toks = [model.to_string(tok) for tok in sorted_token_values[:k]]
        if incor in toks:
            incor_ind = toks.index(incor)
            break
        else:
            k += 50

    if k < 500:
        return logits[index-1, sorted_token_values[:k]], sorted_token_probs[:k], toks, incor_ind
    else:
        return [], [], [], 'cont'

"""# nw template dataset names from scratch

The reason we also evaluate months here is that we don't want to generate numwords templates which don't also work for months.
"""

!pip install faker

from faker import Faker
import random

fake = Faker()

# Generate 100 unique first names
first_names = set()
while len(first_names) < 500:
    first_name = fake.first_name()
    first_names.add(first_name)

first_names = list(first_names)
# first_names[:10]  # Display the first 10 names as an example

def filter_to_single_token(words):
    return [w for w in words if len(model.tokenizer.tokenize(w)) == 1]
names = filter_to_single_token(first_names)
len(names)

def generate_prompts_list(x, y, words, verb):
    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
    month_to_num = {
    'January': 'one', 'February': 'two', 'March': 'three', 'April': 'four', 'May': 'five', 'June': 'six',
    'July': 'seven', 'August': 'eight', 'September': 'nine', 'October': 'ten', 'November': 'eleven', 'December': 'twelve'
    }
    months = [month_to_num[i] for i in months]
    prompts_list = []
    for j in range(1024): # this must come first else 1 2 3 overrepresented!
        for i in range(x, y):
            rand_words = random.sample(words, k=5)
            prompt_dict = {
                'S1': months[i],
                'S2': months[i+1],
                'S3': months[i+2],
                'S4': months[i+3],
                'corr': f" {months[i+4]}",
                'incorr': f" {months[i+3]}",
                'text': f"{rand_words[0]} was {verb} in {months[i]}. {rand_words[1]} was {verb} in {months[i+1]}. {rand_words[2]} was {verb} in {months[i+2]}. {rand_words[3]} was {verb} in {months[i+3]}. {rand_words[4]} was {verb} in",
            }
            prompts_list.append(prompt_dict)
    return prompts_list

# "Claire was born in February. John was born in March. Eve was born in April. Bob was born in”
prompts_list = generate_prompts_list(0, 8, names[:100], 'born')

import copy
month_to_num = {'one': 'January', 'two': 'February', 'three': 'March', 'four': 'April', 'five': 'May', 'six': 'June', 'seven': 'July', 'eight': 'August', 'nine': 'September', 'ten': 'October', 'eleven': 'November', 'twelve': 'December'}

# Revised function to handle the AttributeError
def replace_month_names(data_list):
    out = copy.deepcopy(data_list)
    for item in out:
        # Replace month names in key-value pairs
        for key in list(item.keys()):  # list() to avoid 'RuntimeError: dictionary changed size during iteration'
            value = item[key]
            if value in month_to_num:
                item[key] = month_to_num[value]
            elif key == 'corr' or key == 'incorr':
                item[key] = " " + month_to_num[value.replace(" ", '')]

        # Replace month names in text fields
        if 'text' in item:
            text = item['text']
            for month_name, month_num in month_to_num.items():
                text = text.replace(month_name, str(month_num))
            item['text'] = text

    return out

# Replace the month names in the data
prompts_list_months = replace_month_names(prompts_list)

example_prompt = prompts_list_months[5000]['text']
example_answer = prompts_list_months[5000]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

logit_diffs = []
all_probs = []
good_prompts = []
good_prompts_months = []

for prompt_dict, prompt_dict_months in zip(prompts_list, prompts_list_months):
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']
    prompt_months = prompt_dict_months['text']
    answer_months = prompt_dict_months['corr']
    incor_months = prompt_dict_months['incorr']

    # incor_ind: token id to compare answer to
    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )

    logs_months, probs_months, tok_months, incor_ind_months = get_top_preds_moredata(
        prompt = prompt_months,
        answer = answer_months,
        model = model,
        incor = incor_months
    )

    # only use the prompt if the top choice is the answer, and
    # logit diff between first and second ranked tokens is big enough
    # make sure both
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
        if tok_months[0] == answer_months and probs_months[0] > 0.6 and probs_months[1] < 0.2:
            all_probs.append(probs)
            print(len(good_prompts))
            # incor_ind = toks.index(incor)
            l_diff = logs[0] - logs[incor_ind]
            logit_diffs.append(l_diff.item())
            # print(l_diff.item())
            good_prompts.append(prompt_dict)
            good_prompts_months.append(prompt_dict_months)
            if len(good_prompts) == 1024:
                break

print(len(good_prompts))
print(len(good_prompts_months))

example_prompt = good_prompts[500]['text']
example_answer = good_prompts[500]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

example_prompt = good_prompts_months[500]['text']
example_answer = good_prompts_months[500]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

import pickle

# Saving the dictionary to a file using pickle
with open('nw_prompts_names.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

from google.colab import files

# Download the file to your local machine
files.download('nw_prompts_names.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_names.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import pickle
from google.colab import files

# def save_files(filename):
with open('months_prompts_names.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

files.download('months_prompts_names.pkl')

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# nw template dataset, sold"""

import random

# List of common, short words which are likely to be single tokens in GPT-2
common_words = [
    "Apple", "Ball", "Car", "Dog", "Egg", "Fish", "Gold", "Hat", "Ink", "Jar",
    "Kite", "Lamp", "Moon", "Nest", "Owl", "Pig", "Quilt", "Rat", "Sun", "Tree",
    "Umbrella", "Vase", "Wolf", "Yarn", "Zip", "Bird", "Cat", "Drum", "Frog",
    "Grape", "House", "Ice", "Juice", "Key", "Leaf", "Map", "Nut", "Orange",
    "Piano", "Queen", "Ring", "Star", "Train", "Van", "Whale", "Xylophone",
    "Yacht", "Zebra", "Ax", "Box", "Cow", "Desk", "Ear", "Fan", "Gate", "Hill",
    "Iron", "Joke", "King", "Lion", "Milk", "Nose", "Oil", "Pen", "Quiz", "Rose",
    "Shoe", "Tail", "Vine", "Wall", "Year", "Ant", "Bug", "Corn", "Duck", "Fire",
    "Grass", "Hand", "Island", "Jam", "Knee", "Lake", "Mouse", "Nail", "Pear",
    "Quack", "Road", "Sand", "Tent", "Valley", "Wind", "Yard", "Arm", "Boat",
    "Cake", "Door", "Eye", "Flag", "Horse", "Jeep", "Knife", "Light", "Mountain",
    "Night", "Ocean", "Plate", "Queen", "Rain", "Snow", "Tree", "Umbrella",
    "Valley", "Window", "Yogurt", "Zoo"
]
random_single_word_objects = [obj.capitalize() for obj in common_words]

random_single_word_objects = filter_to_single_token(random_single_word_objects)
len(random_single_word_objects)

prompts_list = generate_prompts_list(0, 8, random_single_word_objects, 'sold')

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

with open('nw_prompts_sold.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)
files.download('nw_prompts_sold.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_sold.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# nw template dataset, made"""

random_single_word_objects = [obj.capitalize() for obj in common_words]

random_single_word_objects = filter_to_single_token(random_single_word_objects)
len(random_single_word_objects)

prompts_list = generate_prompts_list(0, 8, random_single_word_objects, 'made')

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

with open('nw_prompts_made.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)
files.download('nw_prompts_made.pkl')

file_name = 'nw_prompts_made.pkl'
with open(file_name, 'rb') as file:
    data = pickle.load(file)

plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# digits template dataset, sold"""

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_sold.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    prompts_list = pickle.load(file)

# data now contains the contents of your pickle file
print(prompts_list)

month_to_num = {'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'ten': '10', 'eleven': '11', 'twelve': '12'}

# Revised function to handle the AttributeError
def replace_month_names(data_list):
    for item in data_list:
        # Replace month names in key-value pairs
        for key in list(item.keys()):  # list() to avoid 'RuntimeError: dictionary changed size during iteration'
            value = item[key]
            if value in month_to_num:
                item[key] = month_to_num[value]
            elif key == 'corr' or key == 'incorr':
                item[key] = " " + month_to_num[value.replace(" ", '')]

        # Replace month names in text fields
        if 'text' in item:
            text = item['text']
            for month_name, month_num in month_to_num.items():
                text = text.replace(month_name, str(month_num))
            item['text'] = text

    return data_list

# Replace the month names in the data
prompts_list = replace_month_names(prompts_list)
prompts_list

example_prompt = prompts_list[510]['text']
example_answer = prompts_list[510]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

import pickle

# Saving the dictionary to a file using pickle
with open('digits_prompts_sold.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

from google.colab import files

# Download the file to your local machine
files.download('digits_prompts_sold.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'digits_prompts_sold.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# digits template dataset, names"""

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_names.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    prompts_list = pickle.load(file)

# data now contains the contents of your pickle file
print(prompts_list)

month_to_num = {'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'ten': '10', 'eleven': '11', 'twelve': '12'}

# Revised function to handle the AttributeError
def replace_month_names(data_list):
    for item in data_list:
        # Replace month names in key-value pairs
        for key in list(item.keys()):  # list() to avoid 'RuntimeError: dictionary changed size during iteration'
            value = item[key]
            if value in month_to_num:
                item[key] = month_to_num[value]
            elif key == 'corr' or key == 'incorr':
                item[key] = " " + month_to_num[value.replace(" ", '')]

        # Replace month names in text fields
        if 'text' in item:
            text = item['text']
            for month_name, month_num in month_to_num.items():
                text = text.replace(month_name, str(month_num))
            item['text'] = text

    return data_list

# Replace the month names in the data
prompts_list = replace_month_names(prompts_list)
prompts_list

example_prompt = prompts_list[510]['text']
example_answer = prompts_list[510]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

import pickle

# Saving the dictionary to a file using pickle
with open('digits_prompts_names.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

from google.colab import files

# Download the file to your local machine
files.download('digits_prompts_names.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'digits_prompts_names.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# digits template dataset, made"""

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_made.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    prompts_list = pickle.load(file)

# data now contains the contents of your pickle file
print(prompts_list)

month_to_num = {'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'ten': '10', 'eleven': '11', 'twelve': '12'}

# Revised function to handle the AttributeError
def replace_month_names(data_list):
    for item in data_list:
        # Replace month names in key-value pairs
        for key in list(item.keys()):  # list() to avoid 'RuntimeError: dictionary changed size during iteration'
            value = item[key]
            if value in month_to_num:
                item[key] = month_to_num[value]
            elif key == 'corr' or key == 'incorr':
                item[key] = " " + month_to_num[value.replace(" ", '')]

        # Replace month names in text fields
        if 'text' in item:
            text = item['text']
            for month_name, month_num in month_to_num.items():
                text = text.replace(month_name, str(month_num))
            item['text'] = text

    return data_list

# Replace the month names in the data
prompts_list = replace_month_names(prompts_list)
prompts_list

example_prompt = prompts_list[510]['text']
example_answer = prompts_list[510]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

import pickle

# Saving the dictionary to a file using pickle
with open('digits_prompts_made.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

from google.colab import files

# Download the file to your local machine
files.download('digits_prompts_made.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'digits_prompts_made.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# months template dataset, sold"""

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_sold.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    prompts_list = pickle.load(file)

# data now contains the contents of your pickle file
print(prompts_list)

month_to_num = {'one': 'January', 'two': 'February', 'three': 'March', 'four': 'April', 'five': 'May', 'six': 'June', 'seven': 'July', 'eight': 'August', 'nine': 'September', 'ten': 'October', 'eleven': 'November', 'twelve': 'December'}

# Revised function to handle the AttributeError
def replace_month_names(data_list):
    for item in data_list:
        # Replace month names in key-value pairs
        for key in list(item.keys()):  # list() to avoid 'RuntimeError: dictionary changed size during iteration'
            value = item[key]
            if value in month_to_num:
                item[key] = month_to_num[value]
            elif key == 'corr' or key == 'incorr':
                item[key] = " " + month_to_num[value.replace(" ", '')]

        # Replace month names in text fields
        if 'text' in item:
            text = item['text']
            for month_name, month_num in month_to_num.items():
                text = text.replace(month_name, str(month_num))
            item['text'] = text

    return data_list

# Replace the month names in the data
prompts_list = replace_month_names(prompts_list)
prompts_list

example_prompt = prompts_list[510]['text']
example_answer = prompts_list[510]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

import pickle

# Saving the dictionary to a file using pickle
with open('months_prompts_sold.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

from google.colab import files

# Download the file to your local machine
files.download('months_prompts_sold.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'months_prompts_sold.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# m template dataset, names"""

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_names.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    prompts_list = pickle.load(file)

# data now contains the contents of your pickle file
print(prompts_list)

month_to_num = {'one': 'January', 'two': 'February', 'three': 'March', 'four': 'April', 'five': 'May', 'six': 'June', 'seven': 'July', 'eight': 'August', 'nine': 'September', 'ten': 'October', 'eleven': 'November', 'twelve': 'December'}

# Revised function to handle the AttributeError
def replace_month_names(data_list):
    for item in data_list:
        # Replace month names in key-value pairs
        for key in list(item.keys()):  # list() to avoid 'RuntimeError: dictionary changed size during iteration'
            value = item[key]
            if value in month_to_num:
                item[key] = month_to_num[value]
            elif key == 'corr' or key == 'incorr':
                item[key] = " " + month_to_num[value.replace(" ", '')]

        # Replace month names in text fields
        if 'text' in item:
            text = item['text']
            for month_name, month_num in month_to_num.items():
                text = text.replace(month_name, str(month_num))
            item['text'] = text

    return data_list

# Replace the month names in the data
prompts_list = replace_month_names(prompts_list)
prompts_list

example_prompt = prompts_list[510]['text']
example_answer = prompts_list[510]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.4 and probs[1] < 0.3:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

print(len(good_prompts))

import pickle

# Saving the dictionary to a file using pickle
with open('months_prompts_names.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

from google.colab import files

# Download the file to your local machine
files.download('months_prompts_names.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'months_prompts_names.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')

"""# m template dataset, made"""

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'nw_prompts_made.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    prompts_list = pickle.load(file)

# data now contains the contents of your pickle file
print(prompts_list)

month_to_num = {'one': 'January', 'two': 'February', 'three': 'March', 'four': 'April', 'five': 'May', 'six': 'June', 'seven': 'July', 'eight': 'August', 'nine': 'September', 'ten': 'October', 'eleven': 'November', 'twelve': 'December'}

# Revised function to handle the AttributeError
def replace_month_names(data_list):
    for item in data_list:
        # Replace month names in key-value pairs
        for key in list(item.keys()):  # list() to avoid 'RuntimeError: dictionary changed size during iteration'
            value = item[key]
            if value in month_to_num:
                item[key] = month_to_num[value]
            elif key == 'corr' or key == 'incorr':
                item[key] = " " + month_to_num[value.replace(" ", '')]

        # Replace month names in text fields
        if 'text' in item:
            text = item['text']
            for month_name, month_num in month_to_num.items():
                text = text.replace(month_name, str(month_num))
            item['text'] = text

    return data_list

# Replace the month names in the data
prompts_list = replace_month_names(prompts_list)
prompts_list

example_prompt = prompts_list[510]['text']
example_answer = prompts_list[510]['corr']
utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)

logit_diffs = []
all_probs = []
good_prompts = []

for prompt_dict in prompts_list:
    prompt = prompt_dict['text']
    answer = prompt_dict['corr']
    incor = prompt_dict['incorr']

    logs, probs, toks, incor_ind = get_top_preds_moredata(
        prompt = prompt,
        answer = answer,
        model = model,
        incor = incor
    )
    if incor_ind == 'cont':
        continue

    # print(f"{prompt} -> {answer}")
    # print(probs[0].item(), probs[1].item())
    if toks[0] == answer and probs[0] > 0.6 and probs[1] < 0.2:
    # if toks[0] == answer:
        # print('good')
        all_probs.append(probs)
        print(len(good_prompts))
        # incor_ind = toks.index(incor)
        l_diff = logs[0] - logs[incor_ind]
        logit_diffs.append(l_diff.item())
        # print(l_diff.item())
        good_prompts.append(prompt_dict)
        if len(good_prompts) == 1024:
            break

import pickle

# Saving the dictionary to a file using pickle
with open('months_prompts_made.pkl', 'wb') as file:
    pickle.dump(good_prompts, file)

from google.colab import files

# Download the file to your local machine
files.download('months_prompts_made.pkl')

import pickle

# Replace 'your_file_name.pkl' with the name of your uploaded pickle file
file_name = 'months_prompts_made.pkl'

# Load the pickle file
with open(file_name, 'rb') as file:
    data = pickle.load(file)

# data now contains the contents of your pickle file
print(data)

import matplotlib.pyplot as plt

# Creating a histogram for the scores
# plt.hist(logit_diffs, bins = 20, edgecolor='black')  # Adjust the number of bins as needed
plt.hist([probs[0].item() for probs in all_probs], bins = 20, edgecolor='black')  # Adjust the number of bins as needed

# Adding labels and title for clarity
plt.xlabel('probs')
plt.ylabel('Frequency')
plt.title('Distribution')